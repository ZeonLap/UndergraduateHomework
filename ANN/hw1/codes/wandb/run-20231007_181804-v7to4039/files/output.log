18:18:08.796 Training @ 0 epoch...
18:18:08.953   Training iter 50, batch loss 17.3523, batch acc 0.6110
18:18:09.094   Training iter 100, batch loss 3.5277, batch acc 0.8468
18:18:09.215   Training iter 150, batch loss 2.9595, batch acc 0.8804
18:18:09.325   Training iter 200, batch loss 2.8330, batch acc 0.8792
18:18:09.434   Training iter 250, batch loss 2.6204, batch acc 0.8920
18:18:09.527   Training iter 300, batch loss 2.3040, batch acc 0.8978
18:18:09.620   Training iter 350, batch loss 2.2641, batch acc 0.8956
18:18:09.814   Training iter 400, batch loss 2.4184, batch acc 0.8962
18:18:09.964   Training iter 450, batch loss 1.9600, batch acc 0.9124
18:18:10.080   Training iter 500, batch loss 1.8432, batch acc 0.9202
18:18:10.230   Training iter 550, batch loss 1.7540, batch acc 0.9278
18:18:10.353   Training iter 600, batch loss 1.7268, batch acc 0.9232
18:18:10.354 Testing @ 0 epoch...
18:18:10.453     Testing, total mean loss 1.66297, total acc 0.92540
18:18:10.453 Training @ 1 epoch...
18:18:10.571   Training iter 50, batch loss 1.7984, batch acc 0.9218
18:18:10.696   Training iter 100, batch loss 1.5369, batch acc 0.9278
18:18:10.833   Training iter 150, batch loss 1.4316, batch acc 0.9304
18:18:10.927   Training iter 200, batch loss 1.3697, batch acc 0.9362
18:18:11.028   Training iter 250, batch loss 1.3380, batch acc 0.9376
18:18:11.117   Training iter 300, batch loss 1.2863, batch acc 0.9390
18:18:11.213   Training iter 350, batch loss 1.3707, batch acc 0.9388
18:18:11.321   Training iter 400, batch loss 1.2964, batch acc 0.9388
18:18:11.433   Training iter 450, batch loss 1.1992, batch acc 0.9428
18:18:11.528   Training iter 500, batch loss 1.2797, batch acc 0.9396
18:18:11.628   Training iter 550, batch loss 1.2051, batch acc 0.9434
18:18:11.714   Training iter 600, batch loss 1.1799, batch acc 0.9450
18:18:11.715 Training @ 2 epoch...
18:18:12.019   Training iter 50, batch loss 1.0191, batch acc 0.9476
18:18:12.112   Training iter 100, batch loss 0.9685, batch acc 0.9554
18:18:12.210   Training iter 150, batch loss 1.0625, batch acc 0.9486
18:18:12.302   Training iter 200, batch loss 1.1158, batch acc 0.9470
18:18:12.390   Training iter 250, batch loss 0.9682, batch acc 0.9522
18:18:12.489   Training iter 300, batch loss 0.9300, batch acc 0.9504
18:18:12.580   Training iter 350, batch loss 0.9291, batch acc 0.9550
18:18:12.672   Training iter 400, batch loss 0.9666, batch acc 0.9550
18:18:12.765   Training iter 450, batch loss 0.9438, batch acc 0.9494
18:18:12.887   Training iter 500, batch loss 1.1265, batch acc 0.9498
18:18:13.042   Training iter 550, batch loss 0.7671, batch acc 0.9590
18:18:13.190   Training iter 600, batch loss 0.8037, batch acc 0.9600
18:18:13.192 Training @ 3 epoch...
18:18:13.296   Training iter 50, batch loss 0.7234, batch acc 0.9646
18:18:13.410   Training iter 100, batch loss 0.6996, batch acc 0.9638
18:18:13.587   Training iter 150, batch loss 0.8024, batch acc 0.9616
18:18:13.739   Training iter 200, batch loss 0.7025, batch acc 0.9652
18:18:13.845   Training iter 250, batch loss 0.7353, batch acc 0.9626
18:18:14.030   Training iter 300, batch loss 0.7464, batch acc 0.9630
18:18:14.140   Training iter 350, batch loss 0.8027, batch acc 0.9572
18:18:14.251   Training iter 400, batch loss 0.8025, batch acc 0.9580
18:18:14.380   Training iter 450, batch loss 0.8113, batch acc 0.9596
18:18:14.521   Training iter 500, batch loss 0.8529, batch acc 0.9570
18:18:14.740   Training iter 550, batch loss 0.7308, batch acc 0.9640
18:18:14.913   Training iter 600, batch loss 0.5388, batch acc 0.9692
18:18:14.914 Training @ 4 epoch...
18:18:15.023   Training iter 50, batch loss 0.5333, batch acc 0.9714
18:18:15.142   Training iter 100, batch loss 0.6115, batch acc 0.9672
18:18:15.335   Training iter 150, batch loss 0.6231, batch acc 0.9686
18:18:15.477   Training iter 200, batch loss 0.6170, batch acc 0.9672
18:18:15.586   Training iter 250, batch loss 0.6353, batch acc 0.9670
18:18:15.703   Training iter 300, batch loss 0.7358, batch acc 0.9610
18:18:15.870   Training iter 350, batch loss 0.6518, batch acc 0.9640
18:18:15.984   Training iter 400, batch loss 0.7382, batch acc 0.9612
18:18:16.080   Training iter 450, batch loss 0.6588, batch acc 0.9670
18:18:16.230   Training iter 500, batch loss 0.6185, batch acc 0.9692
18:18:16.362   Training iter 550, batch loss 0.6271, batch acc 0.9692
18:18:16.474   Training iter 600, batch loss 0.5985, batch acc 0.9692
18:18:16.475 Training @ 5 epoch...
18:18:16.588   Training iter 50, batch loss 0.5333, batch acc 0.9692
18:18:16.706   Training iter 100, batch loss 0.5585, batch acc 0.9686
18:18:16.797   Training iter 150, batch loss 0.5529, batch acc 0.9686
18:18:16.900   Training iter 200, batch loss 0.5615, batch acc 0.9720
18:18:17.002   Training iter 250, batch loss 0.5634, batch acc 0.9678
18:18:17.091   Training iter 300, batch loss 0.5255, batch acc 0.9742
18:18:17.172   Training iter 350, batch loss 0.4891, batch acc 0.9726
18:18:17.268   Training iter 400, batch loss 0.5259, batch acc 0.9722
18:18:17.406   Training iter 450, batch loss 0.5804, batch acc 0.9664
18:18:17.540   Training iter 500, batch loss 0.5409, batch acc 0.9724
18:18:17.648   Training iter 550, batch loss 0.6353, batch acc 0.9658
18:18:17.762   Training iter 600, batch loss 0.4899, batch acc 0.9724
18:18:17.762 Testing @ 5 epoch...
18:18:17.837     Testing, total mean loss 0.66222, total acc 0.96610
18:18:17.837 Training @ 6 epoch...
18:18:17.941   Training iter 50, batch loss 0.5327, batch acc 0.9730
18:18:18.032   Training iter 100, batch loss 0.5982, batch acc 0.9682
18:18:18.117   Training iter 150, batch loss 0.4461, batch acc 0.9750
18:18:18.200   Training iter 200, batch loss 0.4142, batch acc 0.9772
18:18:18.278   Training iter 250, batch loss 0.4383, batch acc 0.9762
18:18:18.360   Training iter 300, batch loss 0.4506, batch acc 0.9750
18:18:18.465   Training iter 350, batch loss 0.5055, batch acc 0.9720
18:18:18.574   Training iter 400, batch loss 0.4211, batch acc 0.9770
18:18:18.721   Training iter 450, batch loss 0.4595, batch acc 0.9744
18:18:18.843   Training iter 500, batch loss 0.5215, batch acc 0.9750
18:18:18.994   Training iter 550, batch loss 0.4903, batch acc 0.9724
18:18:19.086   Training iter 600, batch loss 0.5296, batch acc 0.9712
18:18:19.087 Training @ 7 epoch...
18:18:19.203   Training iter 50, batch loss 0.3710, batch acc 0.9764
18:18:19.343   Training iter 100, batch loss 0.3939, batch acc 0.9776
18:18:19.436   Training iter 150, batch loss 0.4787, batch acc 0.9718
18:18:19.523   Training iter 200, batch loss 0.4544, batch acc 0.9758
18:18:19.625   Training iter 250, batch loss 0.5280, batch acc 0.9734
18:18:19.712   Training iter 300, batch loss 0.4284, batch acc 0.9770
18:18:19.802   Training iter 350, batch loss 0.4538, batch acc 0.9750
18:18:19.911   Training iter 400, batch loss 0.4374, batch acc 0.9762
18:18:20.008   Training iter 450, batch loss 0.4360, batch acc 0.9730
18:18:20.098   Training iter 500, batch loss 0.4553, batch acc 0.9756
18:18:20.202   Training iter 550, batch loss 0.4076, batch acc 0.9766
18:18:20.289   Training iter 600, batch loss 0.5074, batch acc 0.9712
18:18:20.291 Training @ 8 epoch...
18:18:20.381   Training iter 50, batch loss 0.4298, batch acc 0.9760
18:18:20.470   Training iter 100, batch loss 0.3523, batch acc 0.9800
18:18:20.564   Training iter 150, batch loss 0.4056, batch acc 0.9748
18:18:20.652   Training iter 200, batch loss 0.4726, batch acc 0.9744
18:18:20.741   Training iter 250, batch loss 0.4083, batch acc 0.9760
18:18:20.820   Training iter 300, batch loss 0.3357, batch acc 0.9812
18:18:20.910   Training iter 350, batch loss 0.4715, batch acc 0.9738
18:18:21.009   Training iter 400, batch loss 0.4118, batch acc 0.9758
18:18:21.104   Training iter 450, batch loss 0.3719, batch acc 0.9788
18:18:21.189   Training iter 500, batch loss 0.3795, batch acc 0.9796
18:18:21.281   Training iter 550, batch loss 0.4105, batch acc 0.9760
18:18:21.369   Training iter 600, batch loss 0.4321, batch acc 0.9754
18:18:21.370 Training @ 9 epoch...
18:18:21.471   Training iter 50, batch loss 0.3286, batch acc 0.9810
18:18:21.582   Training iter 100, batch loss 0.4015, batch acc 0.9776
18:18:21.687   Training iter 150, batch loss 0.3488, batch acc 0.9800
18:18:21.786   Training iter 200, batch loss 0.4571, batch acc 0.9756
18:18:21.904   Training iter 250, batch loss 0.3233, batch acc 0.9824
18:18:22.019   Training iter 300, batch loss 0.3757, batch acc 0.9790
18:18:22.144   Training iter 350, batch loss 0.3353, batch acc 0.9840
18:18:22.292   Training iter 400, batch loss 0.3287, batch acc 0.9800
18:18:22.407   Training iter 450, batch loss 0.2988, batch acc 0.9830
18:18:22.501   Training iter 500, batch loss 0.4093, batch acc 0.9726
18:18:22.595   Training iter 550, batch loss 0.3975, batch acc 0.9762
18:18:22.689   Training iter 600, batch loss 0.4842, batch acc 0.9732
18:18:22.691 Training @ 10 epoch...
18:18:22.786   Training iter 50, batch loss 0.3158, batch acc 0.9836
18:18:22.880   Training iter 100, batch loss 0.2965, batch acc 0.9826
18:18:22.996   Training iter 150, batch loss 0.2600, batch acc 0.9842
18:18:23.097   Training iter 200, batch loss 0.3922, batch acc 0.9784
18:18:23.193   Training iter 250, batch loss 0.3775, batch acc 0.9766
18:18:23.277   Training iter 300, batch loss 0.3245, batch acc 0.9816
18:18:23.371   Training iter 350, batch loss 0.3317, batch acc 0.9814
18:18:23.467   Training iter 400, batch loss 0.3642, batch acc 0.9788
18:18:23.567   Training iter 450, batch loss 0.3865, batch acc 0.9806
18:18:23.657   Training iter 500, batch loss 0.4300, batch acc 0.9768
18:18:23.738   Training iter 550, batch loss 0.3423, batch acc 0.9818
18:18:23.859   Training iter 600, batch loss 0.3182, batch acc 0.9838
18:18:23.860 Testing @ 10 epoch...
18:18:23.923     Testing, total mean loss 0.51575, total acc 0.97380
18:18:23.923 Training @ 11 epoch...
18:18:24.021   Training iter 50, batch loss 0.2282, batch acc 0.9878
18:18:24.109   Training iter 100, batch loss 0.3263, batch acc 0.9820
18:18:24.217   Training iter 150, batch loss 0.3877, batch acc 0.9796
18:18:24.318   Training iter 200, batch loss 0.3104, batch acc 0.9804
18:18:24.435   Training iter 250, batch loss 0.3160, batch acc 0.9802
18:18:24.550   Training iter 300, batch loss 0.3050, batch acc 0.9824
18:18:24.673   Training iter 350, batch loss 0.3671, batch acc 0.9798
18:18:24.770   Training iter 400, batch loss 0.2996, batch acc 0.9834
18:18:24.875   Training iter 450, batch loss 0.3813, batch acc 0.9796
18:18:25.004   Training iter 500, batch loss 0.3335, batch acc 0.9828
18:18:25.093   Training iter 550, batch loss 0.3909, batch acc 0.9770
18:18:25.186   Training iter 600, batch loss 0.3179, batch acc 0.9832
18:18:25.188 Training @ 12 epoch...
18:18:25.286   Training iter 50, batch loss 0.2707, batch acc 0.9840
18:18:25.391   Training iter 100, batch loss 0.3398, batch acc 0.9810
18:18:25.519   Training iter 150, batch loss 0.3337, batch acc 0.9806
18:18:25.624   Training iter 200, batch loss 0.3530, batch acc 0.9806
18:18:25.726   Training iter 250, batch loss 0.3430, batch acc 0.9792
18:18:25.829   Training iter 300, batch loss 0.2548, batch acc 0.9858
18:18:25.941   Training iter 350, batch loss 0.3227, batch acc 0.9828
18:18:26.054   Training iter 400, batch loss 0.3235, batch acc 0.9812
18:18:26.145   Training iter 450, batch loss 0.2636, batch acc 0.9854
18:18:26.255   Training iter 500, batch loss 0.2649, batch acc 0.9852
18:18:26.352   Training iter 550, batch loss 0.2792, batch acc 0.9842
18:18:26.464   Training iter 600, batch loss 0.2924, batch acc 0.9844
18:18:26.464 Training @ 13 epoch...
18:18:26.576   Training iter 50, batch loss 0.2781, batch acc 0.9832
18:18:26.694   Training iter 100, batch loss 0.2541, batch acc 0.9836
18:18:26.805   Training iter 150, batch loss 0.2411, batch acc 0.9858
18:18:26.897   Training iter 200, batch loss 0.2676, batch acc 0.9846
18:18:27.021   Training iter 250, batch loss 0.3174, batch acc 0.9836
18:18:27.130   Training iter 300, batch loss 0.3101, batch acc 0.9838
18:18:27.257   Training iter 350, batch loss 0.2757, batch acc 0.9820
18:18:27.374   Training iter 400, batch loss 0.3406, batch acc 0.9784
18:18:27.490   Training iter 450, batch loss 0.2934, batch acc 0.9822
18:18:27.614   Training iter 500, batch loss 0.2760, batch acc 0.9838
18:18:27.727   Training iter 550, batch loss 0.2981, batch acc 0.9836
18:18:27.861   Training iter 600, batch loss 0.2749, batch acc 0.9840
18:18:27.864 Training @ 14 epoch...
18:18:27.998   Training iter 50, batch loss 0.3068, batch acc 0.9832
18:18:28.105   Training iter 100, batch loss 0.2810, batch acc 0.9836
18:18:28.195   Training iter 150, batch loss 0.2323, batch acc 0.9882
18:18:28.290   Training iter 200, batch loss 0.2216, batch acc 0.9860
18:18:28.390   Training iter 250, batch loss 0.2459, batch acc 0.9858
18:18:28.494   Training iter 300, batch loss 0.2598, batch acc 0.9858
18:18:28.580   Training iter 350, batch loss 0.2650, batch acc 0.9842
18:18:28.672   Training iter 400, batch loss 0.2540, batch acc 0.9846
18:18:28.759   Training iter 450, batch loss 0.2758, batch acc 0.9826
18:18:28.857   Training iter 500, batch loss 0.2510, batch acc 0.9864
18:18:28.946   Training iter 550, batch loss 0.3127, batch acc 0.9830
18:18:29.039   Training iter 600, batch loss 0.3013, batch acc 0.9840
18:18:29.040 Training @ 15 epoch...
18:18:29.125   Training iter 50, batch loss 0.2284, batch acc 0.9874
18:18:29.213   Training iter 100, batch loss 0.2494, batch acc 0.9880
18:18:29.307   Training iter 150, batch loss 0.2227, batch acc 0.9886
18:18:29.400   Training iter 200, batch loss 0.2983, batch acc 0.9810
18:18:29.492   Training iter 250, batch loss 0.2532, batch acc 0.9866
18:18:29.588   Training iter 300, batch loss 0.3403, batch acc 0.9816
18:18:29.678   Training iter 350, batch loss 0.2448, batch acc 0.9866
18:18:29.857   Training iter 400, batch loss 0.2702, batch acc 0.9852
18:18:29.988   Training iter 450, batch loss 0.3025, batch acc 0.9822
18:18:30.108   Training iter 500, batch loss 0.3032, batch acc 0.9828
18:18:30.224   Training iter 550, batch loss 0.2358, batch acc 0.9854
18:18:30.336   Training iter 600, batch loss 0.2694, batch acc 0.9852
18:18:30.337 Testing @ 15 epoch...
18:18:30.411     Testing, total mean loss 0.51300, total acc 0.97440
18:18:30.411 Training @ 16 epoch...
18:18:30.515   Training iter 50, batch loss 0.2810, batch acc 0.9846
18:18:30.659   Training iter 100, batch loss 0.2194, batch acc 0.9862
18:18:30.748   Training iter 150, batch loss 0.2346, batch acc 0.9856
18:18:30.836   Training iter 200, batch loss 0.2410, batch acc 0.9858
18:18:30.930   Training iter 250, batch loss 0.2792, batch acc 0.9840
18:18:31.024   Training iter 300, batch loss 0.2327, batch acc 0.9874
18:18:31.110   Training iter 350, batch loss 0.2476, batch acc 0.9858
18:18:31.198   Training iter 400, batch loss 0.2574, batch acc 0.9852
18:18:31.284   Training iter 450, batch loss 0.2325, batch acc 0.9866
18:18:31.373   Training iter 500, batch loss 0.2355, batch acc 0.9846
18:18:31.515   Training iter 550, batch loss 0.2843, batch acc 0.9836
18:18:31.626   Training iter 600, batch loss 0.2352, batch acc 0.9854
18:18:31.628 Training @ 17 epoch...
18:18:31.719   Training iter 50, batch loss 0.2044, batch acc 0.9878
18:18:31.813   Training iter 100, batch loss 0.2098, batch acc 0.9902
18:18:31.918   Training iter 150, batch loss 0.2273, batch acc 0.9886
18:18:32.017   Training iter 200, batch loss 0.2517, batch acc 0.9862
18:18:32.105   Training iter 250, batch loss 0.2418, batch acc 0.9870
18:18:32.194   Training iter 300, batch loss 0.2411, batch acc 0.9842
18:18:32.293   Training iter 350, batch loss 0.2165, batch acc 0.9876
18:18:32.385   Training iter 400, batch loss 0.2521, batch acc 0.9846
18:18:32.489   Training iter 450, batch loss 0.2191, batch acc 0.9874
18:18:32.586   Training iter 500, batch loss 0.2279, batch acc 0.9872
18:18:32.679   Training iter 550, batch loss 0.2966, batch acc 0.9830
18:18:32.902   Training iter 600, batch loss 0.2210, batch acc 0.9854
18:18:32.903 Training @ 18 epoch...
18:18:33.018   Training iter 50, batch loss 0.2278, batch acc 0.9866
18:18:33.129   Training iter 100, batch loss 0.2292, batch acc 0.9872
18:18:33.229   Training iter 150, batch loss 0.2330, batch acc 0.9870
18:18:33.349   Training iter 200, batch loss 0.2163, batch acc 0.9870
18:18:33.506   Training iter 250, batch loss 0.2221, batch acc 0.9880
18:18:33.663   Training iter 300, batch loss 0.2119, batch acc 0.9876
18:18:33.748   Training iter 350, batch loss 0.2374, batch acc 0.9858
18:18:33.858   Training iter 400, batch loss 0.1914, batch acc 0.9898
18:18:34.024   Training iter 450, batch loss 0.2476, batch acc 0.9852
18:18:34.118   Training iter 500, batch loss 0.2279, batch acc 0.9884
18:18:34.220   Training iter 550, batch loss 0.2114, batch acc 0.9870
18:18:34.333   Training iter 600, batch loss 0.2488, batch acc 0.9860
18:18:34.335 Training @ 19 epoch...
18:18:34.428   Training iter 50, batch loss 0.1991, batch acc 0.9872
18:18:34.579   Training iter 100, batch loss 0.2124, batch acc 0.9864
18:18:34.685   Training iter 150, batch loss 0.2226, batch acc 0.9882
18:18:34.774   Training iter 200, batch loss 0.1920, batch acc 0.9882
18:18:34.882   Training iter 250, batch loss 0.2259, batch acc 0.9866
18:18:34.971   Training iter 300, batch loss 0.2513, batch acc 0.9862
18:18:35.071   Training iter 350, batch loss 0.2608, batch acc 0.9860
18:18:35.167   Training iter 400, batch loss 0.2436, batch acc 0.9858
18:18:35.325   Training iter 450, batch loss 0.2319, batch acc 0.9856
18:18:35.431   Training iter 500, batch loss 0.2700, batch acc 0.9840
18:18:35.527   Training iter 550, batch loss 0.2327, batch acc 0.9876
18:18:35.623   Training iter 600, batch loss 0.2754, batch acc 0.9842
18:18:35.625 Training @ 20 epoch...
18:18:35.740   Training iter 50, batch loss 0.1923, batch acc 0.9888
18:18:35.849   Training iter 100, batch loss 0.2113, batch acc 0.9880
18:18:36.002   Training iter 150, batch loss 0.1759, batch acc 0.9900
18:18:36.104   Training iter 200, batch loss 0.2066, batch acc 0.9890
18:18:36.211   Training iter 250, batch loss 0.1828, batch acc 0.9900
18:18:36.337   Training iter 300, batch loss 0.1955, batch acc 0.9892
18:18:36.548   Training iter 350, batch loss 0.2530, batch acc 0.9856
18:18:36.645   Training iter 400, batch loss 0.2149, batch acc 0.9872
18:18:36.737   Training iter 450, batch loss 0.2021, batch acc 0.9896
18:18:36.833   Training iter 500, batch loss 0.2080, batch acc 0.9894
18:18:36.923   Training iter 550, batch loss 0.2306, batch acc 0.9854
18:18:37.070   Training iter 600, batch loss 0.1941, batch acc 0.9900
18:18:37.072 Testing @ 20 epoch...
18:18:37.258     Testing, total mean loss 0.43384, total acc 0.97780
18:18:37.258 Training @ 21 epoch...
18:18:37.351   Training iter 50, batch loss 0.2026, batch acc 0.9884
18:18:37.462   Training iter 100, batch loss 0.1869, batch acc 0.9900
18:18:37.581   Training iter 150, batch loss 0.1783, batch acc 0.9896
18:18:37.688   Training iter 200, batch loss 0.1860, batch acc 0.9898
18:18:37.848   Training iter 250, batch loss 0.2055, batch acc 0.9886
18:18:37.974   Training iter 300, batch loss 0.2284, batch acc 0.9870
18:18:38.081   Training iter 350, batch loss 0.1900, batch acc 0.9894
18:18:38.194   Training iter 400, batch loss 0.2121, batch acc 0.9876
18:18:38.298   Training iter 450, batch loss 0.2292, batch acc 0.9848
18:18:38.406   Training iter 500, batch loss 0.2354, batch acc 0.9856
18:18:38.522   Training iter 550, batch loss 0.2015, batch acc 0.9902
18:18:38.656   Training iter 600, batch loss 0.2595, batch acc 0.9842
18:18:38.658 Training @ 22 epoch...
18:18:38.772   Training iter 50, batch loss 0.1927, batch acc 0.9894
18:18:38.905   Training iter 100, batch loss 0.1952, batch acc 0.9884
18:18:39.038   Training iter 150, batch loss 0.2215, batch acc 0.9856
18:18:39.157   Training iter 200, batch loss 0.2276, batch acc 0.9872
18:18:39.289   Training iter 250, batch loss 0.1759, batch acc 0.9912
18:18:39.377   Training iter 300, batch loss 0.1846, batch acc 0.9900
18:18:39.473   Training iter 350, batch loss 0.2425, batch acc 0.9876
18:18:39.565   Training iter 400, batch loss 0.1900, batch acc 0.9896
18:18:39.675   Training iter 450, batch loss 0.1989, batch acc 0.9890
18:18:39.770   Training iter 500, batch loss 0.2271, batch acc 0.9862
18:18:39.875   Training iter 550, batch loss 0.1709, batch acc 0.9894
18:18:39.971   Training iter 600, batch loss 0.2270, batch acc 0.9882
18:18:39.971 Training @ 23 epoch...
18:18:40.091   Training iter 50, batch loss 0.1880, batch acc 0.9898
18:18:40.194   Training iter 100, batch loss 0.1500, batch acc 0.9918
18:18:40.295   Training iter 150, batch loss 0.1598, batch acc 0.9908
18:18:40.387   Training iter 200, batch loss 0.2032, batch acc 0.9884
18:18:40.485   Training iter 250, batch loss 0.1913, batch acc 0.9894
18:18:40.584   Training iter 300, batch loss 0.2284, batch acc 0.9852
18:18:40.672   Training iter 350, batch loss 0.1977, batch acc 0.9890
18:18:40.774   Training iter 400, batch loss 0.2166, batch acc 0.9884
18:18:40.889   Training iter 450, batch loss 0.2358, batch acc 0.9874
18:18:40.988   Training iter 500, batch loss 0.2534, batch acc 0.9858
18:18:41.083   Training iter 550, batch loss 0.2152, batch acc 0.9876
18:18:41.179   Training iter 600, batch loss 0.1856, batch acc 0.9908
18:18:41.180 Training @ 24 epoch...
18:18:41.275   Training iter 50, batch loss 0.1820, batch acc 0.9900
18:18:41.390   Training iter 100, batch loss 0.1523, batch acc 0.9918
18:18:41.504   Training iter 150, batch loss 0.1916, batch acc 0.9880
18:18:41.613   Training iter 200, batch loss 0.1565, batch acc 0.9908
18:18:41.718   Training iter 250, batch loss 0.1864, batch acc 0.9896
18:18:41.843   Training iter 300, batch loss 0.1920, batch acc 0.9902
18:18:42.005   Training iter 350, batch loss 0.1796, batch acc 0.9884
18:18:42.129   Training iter 400, batch loss 0.1888, batch acc 0.9894
18:18:42.230   Training iter 450, batch loss 0.1807, batch acc 0.9896
18:18:42.318   Training iter 500, batch loss 0.2236, batch acc 0.9870
18:18:42.442   Training iter 550, batch loss 0.2208, batch acc 0.9868
18:18:42.543   Training iter 600, batch loss 0.1981, batch acc 0.9892
18:18:42.544 Training @ 25 epoch...
18:18:42.635   Training iter 50, batch loss 0.1850, batch acc 0.9908
18:18:42.731   Training iter 100, batch loss 0.1723, batch acc 0.9910
18:18:42.824   Training iter 150, batch loss 0.1434, batch acc 0.9922
18:18:42.921   Training iter 200, batch loss 0.1623, batch acc 0.9912
18:18:43.024   Training iter 250, batch loss 0.1994, batch acc 0.9884
18:18:43.124   Training iter 300, batch loss 0.2093, batch acc 0.9896
18:18:43.285   Training iter 350, batch loss 0.2521, batch acc 0.9840
18:18:43.387   Training iter 400, batch loss 0.2867, batch acc 0.9846
18:18:43.485   Training iter 450, batch loss 0.1741, batch acc 0.9894
18:18:43.581   Training iter 500, batch loss 0.1902, batch acc 0.9896
18:18:43.666   Training iter 550, batch loss 0.1787, batch acc 0.9896
18:18:43.754   Training iter 600, batch loss 0.2002, batch acc 0.9894
18:18:43.755 Testing @ 25 epoch...
18:18:43.823     Testing, total mean loss 0.41686, total acc 0.97790
18:18:43.823 Training @ 26 epoch...
18:18:43.924   Training iter 50, batch loss 0.1467, batch acc 0.9930
18:18:44.057   Training iter 100, batch loss 0.1793, batch acc 0.9900
18:18:44.163   Training iter 150, batch loss 0.1681, batch acc 0.9908
18:18:44.270   Training iter 200, batch loss 0.2150, batch acc 0.9880
18:18:44.400   Training iter 250, batch loss 0.1780, batch acc 0.9904
18:18:44.504   Training iter 300, batch loss 0.1796, batch acc 0.9902
18:18:44.615   Training iter 350, batch loss 0.1946, batch acc 0.9888
18:18:44.722   Training iter 400, batch loss 0.1779, batch acc 0.9890
18:18:44.842   Training iter 450, batch loss 0.1590, batch acc 0.9928
18:18:44.974   Training iter 500, batch loss 0.1471, batch acc 0.9906
18:18:45.116   Training iter 550, batch loss 0.2021, batch acc 0.9896
18:18:45.208   Training iter 600, batch loss 0.2171, batch acc 0.9870
18:18:45.208 Training @ 27 epoch...
18:18:45.301   Training iter 50, batch loss 0.1409, batch acc 0.9920
18:18:45.401   Training iter 100, batch loss 0.1599, batch acc 0.9920
18:18:45.497   Training iter 150, batch loss 0.1795, batch acc 0.9902
18:18:45.580   Training iter 200, batch loss 0.1892, batch acc 0.9906
18:18:45.667   Training iter 250, batch loss 0.2002, batch acc 0.9884
18:18:45.751   Training iter 300, batch loss 0.1868, batch acc 0.9900
18:18:45.845   Training iter 350, batch loss 0.1623, batch acc 0.9912
18:18:45.945   Training iter 400, batch loss 0.2085, batch acc 0.9884
18:18:46.048   Training iter 450, batch loss 0.2135, batch acc 0.9860
18:18:46.138   Training iter 500, batch loss 0.1843, batch acc 0.9914
18:18:46.231   Training iter 550, batch loss 0.1716, batch acc 0.9910
18:18:46.326   Training iter 600, batch loss 0.2333, batch acc 0.9858
18:18:46.328 Training @ 28 epoch...
18:18:46.420   Training iter 50, batch loss 0.1296, batch acc 0.9932
18:18:46.516   Training iter 100, batch loss 0.1667, batch acc 0.9906
18:18:46.615   Training iter 150, batch loss 0.1776, batch acc 0.9894
18:18:46.706   Training iter 200, batch loss 0.1567, batch acc 0.9928
18:18:46.805   Training iter 250, batch loss 0.1841, batch acc 0.9898
18:18:46.894   Training iter 300, batch loss 0.1539, batch acc 0.9906
18:18:47.085   Training iter 350, batch loss 0.1686, batch acc 0.9902
18:18:47.204   Training iter 400, batch loss 0.1884, batch acc 0.9882
18:18:47.309   Training iter 450, batch loss 0.2313, batch acc 0.9862
18:18:47.423   Training iter 500, batch loss 0.1648, batch acc 0.9926
18:18:47.543   Training iter 550, batch loss 0.2301, batch acc 0.9866
18:18:47.663   Training iter 600, batch loss 0.2181, batch acc 0.9886
18:18:47.665 Training @ 29 epoch...
18:18:47.792   Training iter 50, batch loss 0.1631, batch acc 0.9906
18:18:47.902   Training iter 100, batch loss 0.1412, batch acc 0.9924
18:18:48.006   Training iter 150, batch loss 0.1811, batch acc 0.9894
18:18:48.117   Training iter 200, batch loss 0.1576, batch acc 0.9918
18:18:48.211   Training iter 250, batch loss 0.1522, batch acc 0.9916
18:18:48.300   Training iter 300, batch loss 0.1604, batch acc 0.9918
18:18:48.395   Training iter 350, batch loss 0.1830, batch acc 0.9884
18:18:48.489   Training iter 400, batch loss 0.2094, batch acc 0.9876
18:18:48.577   Training iter 450, batch loss 0.1786, batch acc 0.9904
18:18:48.673   Training iter 500, batch loss 0.1453, batch acc 0.9932
18:18:48.822   Training iter 550, batch loss 0.2043, batch acc 0.9892
18:18:48.936   Training iter 600, batch loss 0.1607, batch acc 0.9912
18:18:48.937 Training @ 30 epoch...
18:18:49.044   Training iter 50, batch loss 0.1396, batch acc 0.9924
18:18:49.165   Training iter 100, batch loss 0.1498, batch acc 0.9924
18:18:49.277   Training iter 150, batch loss 0.1654, batch acc 0.9914
18:18:49.379   Training iter 200, batch loss 0.1641, batch acc 0.9920
18:18:49.491   Training iter 250, batch loss 0.1290, batch acc 0.9928
18:18:49.613   Training iter 300, batch loss 0.2065, batch acc 0.9894
18:18:49.723   Training iter 350, batch loss 0.2479, batch acc 0.9850
18:18:49.880   Training iter 400, batch loss 0.2106, batch acc 0.9880
18:18:50.011   Training iter 450, batch loss 0.2122, batch acc 0.9892
18:18:50.147   Training iter 500, batch loss 0.1827, batch acc 0.9906
18:18:50.278   Training iter 550, batch loss 0.1653, batch acc 0.9906
18:18:50.405   Training iter 600, batch loss 0.1796, batch acc 0.9892
18:18:50.406 Testing @ 30 epoch...
18:18:50.497     Testing, total mean loss 0.43783, total acc 0.97670
18:18:50.497 Training @ 31 epoch...
18:18:50.628   Training iter 50, batch loss 0.1649, batch acc 0.9902
18:18:50.738   Training iter 100, batch loss 0.1562, batch acc 0.9920
18:18:50.856   Training iter 150, batch loss 0.1708, batch acc 0.9908
18:18:50.959   Training iter 200, batch loss 0.1345, batch acc 0.9928
18:18:51.060   Training iter 250, batch loss 0.1728, batch acc 0.9908
18:18:51.156   Training iter 300, batch loss 0.2043, batch acc 0.9894
18:18:51.257   Training iter 350, batch loss 0.1738, batch acc 0.9894
18:18:51.362   Training iter 400, batch loss 0.1272, batch acc 0.9926
18:18:51.461   Training iter 450, batch loss 0.1384, batch acc 0.9924
18:18:51.563   Training iter 500, batch loss 0.1500, batch acc 0.9926
18:18:51.659   Training iter 550, batch loss 0.1677, batch acc 0.9914
18:18:51.767   Training iter 600, batch loss 0.1655, batch acc 0.9918
18:18:51.768 Training @ 32 epoch...
18:18:51.877   Training iter 50, batch loss 0.1895, batch acc 0.9886
18:18:51.988   Training iter 100, batch loss 0.1282, batch acc 0.9934
18:18:52.077   Training iter 150, batch loss 0.1460, batch acc 0.9926
18:18:52.175   Training iter 200, batch loss 0.1694, batch acc 0.9894
18:18:52.271   Training iter 250, batch loss 0.1480, batch acc 0.9922
18:18:52.355   Training iter 300, batch loss 0.1195, batch acc 0.9944
18:18:52.452   Training iter 350, batch loss 0.1544, batch acc 0.9924
18:18:52.595   Training iter 400, batch loss 0.1908, batch acc 0.9892
18:18:52.712   Training iter 450, batch loss 0.1795, batch acc 0.9908
18:18:52.852   Training iter 500, batch loss 0.1858, batch acc 0.9900
18:18:52.959   Training iter 550, batch loss 0.1516, batch acc 0.9916
18:18:53.071   Training iter 600, batch loss 0.1595, batch acc 0.9902
18:18:53.072 Training @ 33 epoch...
18:18:53.187   Training iter 50, batch loss 0.1378, batch acc 0.9926
18:18:53.313   Training iter 100, batch loss 0.1468, batch acc 0.9914
18:18:53.432   Training iter 150, batch loss 0.1907, batch acc 0.9878
18:18:53.525   Training iter 200, batch loss 0.1588, batch acc 0.9922
18:18:53.624   Training iter 250, batch loss 0.1848, batch acc 0.9900
18:18:53.773   Training iter 300, batch loss 0.1224, batch acc 0.9938
18:18:53.899   Training iter 350, batch loss 0.1597, batch acc 0.9912
18:18:54.017   Training iter 400, batch loss 0.2046, batch acc 0.9884
18:18:54.108   Training iter 450, batch loss 0.1761, batch acc 0.9902
18:18:54.204   Training iter 500, batch loss 0.1461, batch acc 0.9910
18:18:54.298   Training iter 550, batch loss 0.1278, batch acc 0.9944
18:18:54.391   Training iter 600, batch loss 0.2051, batch acc 0.9882
18:18:54.393 Training @ 34 epoch...
18:18:54.492   Training iter 50, batch loss 0.1272, batch acc 0.9926
18:18:54.587   Training iter 100, batch loss 0.1571, batch acc 0.9922
18:18:54.677   Training iter 150, batch loss 0.1132, batch acc 0.9952
18:18:54.774   Training iter 200, batch loss 0.1585, batch acc 0.9918
18:18:54.877   Training iter 250, batch loss 0.1619, batch acc 0.9922
18:18:54.976   Training iter 300, batch loss 0.1467, batch acc 0.9928
18:18:55.071   Training iter 350, batch loss 0.1651, batch acc 0.9908
18:18:55.173   Training iter 400, batch loss 0.1857, batch acc 0.9904
18:18:55.264   Training iter 450, batch loss 0.2015, batch acc 0.9878
18:18:55.360   Training iter 500, batch loss 0.1970, batch acc 0.9878
18:18:55.471   Training iter 550, batch loss 0.1447, batch acc 0.9920
18:18:55.581   Training iter 600, batch loss 0.2116, batch acc 0.9882
18:18:55.583 Training @ 35 epoch...
18:18:55.704   Training iter 50, batch loss 0.1231, batch acc 0.9940
18:18:55.815   Training iter 100, batch loss 0.1808, batch acc 0.9900
18:18:55.932   Training iter 150, batch loss 0.1533, batch acc 0.9922
18:18:56.062   Training iter 200, batch loss 0.1653, batch acc 0.9898
18:18:56.174   Training iter 250, batch loss 0.1307, batch acc 0.9938
18:18:56.303   Training iter 300, batch loss 0.1456, batch acc 0.9934
18:18:56.398   Training iter 350, batch loss 0.1517, batch acc 0.9924
18:18:56.494   Training iter 400, batch loss 0.1806, batch acc 0.9892
18:18:56.587   Training iter 450, batch loss 0.1462, batch acc 0.9938
18:18:56.677   Training iter 500, batch loss 0.1648, batch acc 0.9906
18:18:56.781   Training iter 550, batch loss 0.1697, batch acc 0.9910
18:18:56.890   Training iter 600, batch loss 0.1572, batch acc 0.9928
18:18:56.892 Testing @ 35 epoch...
18:18:56.959     Testing, total mean loss 0.42099, total acc 0.97720
18:18:56.959 Training @ 36 epoch...
18:18:57.060   Training iter 50, batch loss 0.1572, batch acc 0.9920
18:18:57.145   Training iter 100, batch loss 0.1321, batch acc 0.9942
18:18:57.242   Training iter 150, batch loss 0.1494, batch acc 0.9918
18:18:57.357   Training iter 200, batch loss 0.1388, batch acc 0.9922
18:18:57.461   Training iter 250, batch loss 0.1469, batch acc 0.9922
18:18:57.570   Training iter 300, batch loss 0.1444, batch acc 0.9924
18:18:57.666   Training iter 350, batch loss 0.1706, batch acc 0.9898
18:18:57.764   Training iter 400, batch loss 0.1470, batch acc 0.9938
18:18:57.872   Training iter 450, batch loss 0.1362, batch acc 0.9922
18:18:57.995   Training iter 500, batch loss 0.1443, batch acc 0.9924
18:18:58.100   Training iter 550, batch loss 0.1991, batch acc 0.9898
18:18:58.191   Training iter 600, batch loss 0.1827, batch acc 0.9896
18:18:58.191 Training @ 37 epoch...
18:18:58.286   Training iter 50, batch loss 0.1296, batch acc 0.9938
18:18:58.439   Training iter 100, batch loss 0.1524, batch acc 0.9918
18:18:58.558   Training iter 150, batch loss 0.1498, batch acc 0.9922
18:18:58.685   Training iter 200, batch loss 0.1645, batch acc 0.9910
18:18:58.812   Training iter 250, batch loss 0.2033, batch acc 0.9902
18:18:58.939   Training iter 300, batch loss 0.1451, batch acc 0.9938
18:18:59.068   Training iter 350, batch loss 0.1478, batch acc 0.9924
18:18:59.223   Training iter 400, batch loss 0.1481, batch acc 0.9928
18:18:59.339   Training iter 450, batch loss 0.1660, batch acc 0.9910
18:18:59.445   Training iter 500, batch loss 0.1868, batch acc 0.9900
18:18:59.583   Training iter 550, batch loss 0.1522, batch acc 0.9916
18:18:59.692   Training iter 600, batch loss 0.1579, batch acc 0.9916
18:18:59.694 Training @ 38 epoch...
18:18:59.807   Training iter 50, batch loss 0.1345, batch acc 0.9938
18:18:59.925   Training iter 100, batch loss 0.1325, batch acc 0.9920
18:19:00.061   Training iter 150, batch loss 0.1237, batch acc 0.9938
18:19:00.165   Training iter 200, batch loss 0.1561, batch acc 0.9908
18:19:00.271   Training iter 250, batch loss 0.1345, batch acc 0.9940
18:19:00.380   Training iter 300, batch loss 0.1667, batch acc 0.9906
18:19:00.497   Training iter 350, batch loss 0.1488, batch acc 0.9934
18:19:00.611   Training iter 400, batch loss 0.1549, batch acc 0.9926
18:19:00.716   Training iter 450, batch loss 0.1362, batch acc 0.9920
18:19:00.821   Training iter 500, batch loss 0.1390, batch acc 0.9926
18:19:00.930   Training iter 550, batch loss 0.1795, batch acc 0.9898
18:19:01.040   Training iter 600, batch loss 0.1724, batch acc 0.9902
18:19:01.041 Training @ 39 epoch...
18:19:01.141   Training iter 50, batch loss 0.1445, batch acc 0.9914
18:19:01.269   Training iter 100, batch loss 0.1441, batch acc 0.9926
18:19:01.384   Training iter 150, batch loss 0.1280, batch acc 0.9932
18:19:01.513   Training iter 200, batch loss 0.1376, batch acc 0.9940
18:19:01.647   Training iter 250, batch loss 0.1663, batch acc 0.9916
18:19:01.767   Training iter 300, batch loss 0.1329, batch acc 0.9946
18:19:01.896   Training iter 350, batch loss 0.1308, batch acc 0.9928
18:19:02.021   Training iter 400, batch loss 0.1549, batch acc 0.9932
18:19:02.128   Training iter 450, batch loss 0.2054, batch acc 0.9890
18:19:02.224   Training iter 500, batch loss 0.1625, batch acc 0.9912
18:19:02.325   Training iter 550, batch loss 0.1405, batch acc 0.9918
18:19:02.428   Training iter 600, batch loss 0.1649, batch acc 0.9908
18:19:02.429 Training @ 40 epoch...
18:19:02.526   Training iter 50, batch loss 0.1344, batch acc 0.9936
18:19:02.627   Training iter 100, batch loss 0.1520, batch acc 0.9932
18:19:02.724   Training iter 150, batch loss 0.1234, batch acc 0.9940
18:19:02.819   Training iter 200, batch loss 0.1237, batch acc 0.9942
18:19:02.925   Training iter 250, batch loss 0.1279, batch acc 0.9938
18:19:03.032   Training iter 300, batch loss 0.1401, batch acc 0.9946
18:19:03.121   Training iter 350, batch loss 0.1492, batch acc 0.9938
18:19:03.228   Training iter 400, batch loss 0.1625, batch acc 0.9916
18:19:03.328   Training iter 450, batch loss 0.1491, batch acc 0.9928
18:19:03.454   Training iter 500, batch loss 0.1374, batch acc 0.9936
18:19:03.547   Training iter 550, batch loss 0.1639, batch acc 0.9924
18:19:03.644   Training iter 600, batch loss 0.1549, batch acc 0.9920
18:19:03.646 Testing @ 40 epoch...
18:19:03.713     Testing, total mean loss 0.44750, total acc 0.97620
18:19:03.713 Training @ 41 epoch...
18:19:03.825   Training iter 50, batch loss 0.1546, batch acc 0.9922
18:19:03.931   Training iter 100, batch loss 0.1194, batch acc 0.9934
18:19:04.070   Training iter 150, batch loss 0.1430, batch acc 0.9924
18:19:04.249   Training iter 200, batch loss 0.1403, batch acc 0.9930
18:19:04.352   Training iter 250, batch loss 0.1146, batch acc 0.9946
18:19:04.479   Training iter 300, batch loss 0.1508, batch acc 0.9924
18:19:04.603   Training iter 350, batch loss 0.1564, batch acc 0.9920
18:19:04.735   Training iter 400, batch loss 0.1464, batch acc 0.9928
18:19:04.830   Training iter 450, batch loss 0.1501, batch acc 0.9930
18:19:04.945   Training iter 500, batch loss 0.1651, batch acc 0.9910
18:19:05.047   Training iter 550, batch loss 0.1404, batch acc 0.9936
18:19:05.138   Training iter 600, batch loss 0.1461, batch acc 0.9924
18:19:05.138 Training @ 42 epoch...
18:19:05.241   Training iter 50, batch loss 0.1353, batch acc 0.9924
18:19:05.340   Training iter 100, batch loss 0.1238, batch acc 0.9936
18:19:05.435   Training iter 150, batch loss 0.1306, batch acc 0.9924
18:19:05.536   Training iter 200, batch loss 0.1731, batch acc 0.9912
18:19:05.651   Training iter 250, batch loss 0.1432, batch acc 0.9926
18:19:05.783   Training iter 300, batch loss 0.1544, batch acc 0.9918
18:19:05.903   Training iter 350, batch loss 0.1124, batch acc 0.9952
18:19:05.995   Training iter 400, batch loss 0.1525, batch acc 0.9914
18:19:06.106   Training iter 450, batch loss 0.1516, batch acc 0.9930
18:19:06.191   Training iter 500, batch loss 0.1382, batch acc 0.9928
18:19:06.295   Training iter 550, batch loss 0.1415, batch acc 0.9938
18:19:06.385   Training iter 600, batch loss 0.1760, batch acc 0.9914
18:19:06.388 Training @ 43 epoch...
18:19:06.503   Training iter 50, batch loss 0.1434, batch acc 0.9924
18:19:06.601   Training iter 100, batch loss 0.1254, batch acc 0.9950
18:19:06.709   Training iter 150, batch loss 0.1346, batch acc 0.9928
18:19:06.820   Training iter 200, batch loss 0.1588, batch acc 0.9920
18:19:06.955   Training iter 250, batch loss 0.1346, batch acc 0.9926
18:19:07.075   Training iter 300, batch loss 0.1356, batch acc 0.9922
18:19:07.286   Training iter 350, batch loss 0.1349, batch acc 0.9928
18:19:07.390   Training iter 400, batch loss 0.1317, batch acc 0.9934
18:19:07.514   Training iter 450, batch loss 0.1234, batch acc 0.9942
18:19:07.613   Training iter 500, batch loss 0.1252, batch acc 0.9932
18:19:07.756   Training iter 550, batch loss 0.1729, batch acc 0.9910
18:19:07.849   Training iter 600, batch loss 0.1551, batch acc 0.9916
18:19:07.851 Training @ 44 epoch...
18:19:07.966   Training iter 50, batch loss 0.1326, batch acc 0.9924
18:19:08.107   Training iter 100, batch loss 0.1392, batch acc 0.9922
18:19:08.215   Training iter 150, batch loss 0.1591, batch acc 0.9904
18:19:08.326   Training iter 200, batch loss 0.1288, batch acc 0.9930
18:19:08.430   Training iter 250, batch loss 0.1360, batch acc 0.9942
18:19:08.534   Training iter 300, batch loss 0.1460, batch acc 0.9920
18:19:08.630   Training iter 350, batch loss 0.1467, batch acc 0.9928
18:19:08.729   Training iter 400, batch loss 0.1180, batch acc 0.9950
18:19:08.821   Training iter 450, batch loss 0.0973, batch acc 0.9962
18:19:08.936   Training iter 500, batch loss 0.1242, batch acc 0.9940
18:19:09.023   Training iter 550, batch loss 0.1765, batch acc 0.9920
18:19:09.110   Training iter 600, batch loss 0.1416, batch acc 0.9924
18:19:09.112 Training @ 45 epoch...
18:19:09.221   Training iter 50, batch loss 0.1059, batch acc 0.9948
18:19:09.317   Training iter 100, batch loss 0.1102, batch acc 0.9954
18:19:09.409   Training iter 150, batch loss 0.1195, batch acc 0.9940
18:19:09.523   Training iter 200, batch loss 0.1033, batch acc 0.9954
18:19:09.690   Training iter 250, batch loss 0.1325, batch acc 0.9938
18:19:09.822   Training iter 300, batch loss 0.1139, batch acc 0.9942
18:19:09.953   Training iter 350, batch loss 0.1453, batch acc 0.9930
18:19:10.093   Training iter 400, batch loss 0.1420, batch acc 0.9924
18:19:10.227   Training iter 450, batch loss 0.1646, batch acc 0.9920
18:19:10.384   Training iter 500, batch loss 0.2146, batch acc 0.9884
18:19:10.501   Training iter 550, batch loss 0.1672, batch acc 0.9910
18:19:10.614   Training iter 600, batch loss 0.1400, batch acc 0.9926
18:19:10.614 Testing @ 45 epoch...
18:19:10.695     Testing, total mean loss 0.40934, total acc 0.97880
18:19:10.695 Training @ 46 epoch...
18:19:10.806   Training iter 50, batch loss 0.1081, batch acc 0.9950
18:19:10.930   Training iter 100, batch loss 0.1253, batch acc 0.9946
18:19:11.044   Training iter 150, batch loss 0.1118, batch acc 0.9952
18:19:11.151   Training iter 200, batch loss 0.1372, batch acc 0.9942
18:19:11.261   Training iter 250, batch loss 0.1421, batch acc 0.9926
18:19:11.459   Training iter 300, batch loss 0.1269, batch acc 0.9942
18:19:11.576   Training iter 350, batch loss 0.1383, batch acc 0.9928
18:19:11.704   Training iter 400, batch loss 0.1479, batch acc 0.9916
18:19:11.825   Training iter 450, batch loss 0.1303, batch acc 0.9938
18:19:11.948   Training iter 500, batch loss 0.1283, batch acc 0.9942
18:19:12.070   Training iter 550, batch loss 0.1204, batch acc 0.9940
18:19:12.188   Training iter 600, batch loss 0.1542, batch acc 0.9918
18:19:12.189 Training @ 47 epoch...
18:19:12.308   Training iter 50, batch loss 0.1068, batch acc 0.9952
18:19:12.435   Training iter 100, batch loss 0.1231, batch acc 0.9944
18:19:12.568   Training iter 150, batch loss 0.1078, batch acc 0.9956
18:19:12.698   Training iter 200, batch loss 0.0943, batch acc 0.9962
18:19:12.815   Training iter 250, batch loss 0.1327, batch acc 0.9942
18:19:12.952   Training iter 300, batch loss 0.1385, batch acc 0.9928
18:19:13.087   Training iter 350, batch loss 0.1532, batch acc 0.9932
18:19:13.180   Training iter 400, batch loss 0.1375, batch acc 0.9930
18:19:13.276   Training iter 450, batch loss 0.1278, batch acc 0.9936
18:19:13.365   Training iter 500, batch loss 0.1220, batch acc 0.9940
18:19:13.460   Training iter 550, batch loss 0.1603, batch acc 0.9904
18:19:13.557   Training iter 600, batch loss 0.1662, batch acc 0.9898
18:19:13.559 Training @ 48 epoch...
18:19:13.666   Training iter 50, batch loss 0.1298, batch acc 0.9944
18:19:13.766   Training iter 100, batch loss 0.1080, batch acc 0.9936
18:19:13.860   Training iter 150, batch loss 0.1578, batch acc 0.9916
18:19:13.964   Training iter 200, batch loss 0.1544, batch acc 0.9930
18:19:14.063   Training iter 250, batch loss 0.1328, batch acc 0.9930
18:19:14.162   Training iter 300, batch loss 0.1728, batch acc 0.9922
18:19:14.261   Training iter 350, batch loss 0.1613, batch acc 0.9918
18:19:14.355   Training iter 400, batch loss 0.1162, batch acc 0.9942
18:19:14.448   Training iter 450, batch loss 0.1223, batch acc 0.9934
18:19:14.554   Training iter 500, batch loss 0.1314, batch acc 0.9924
18:19:14.666   Training iter 550, batch loss 0.1216, batch acc 0.9942
18:19:14.820   Training iter 600, batch loss 0.1326, batch acc 0.9938
18:19:14.823 Training @ 49 epoch...
18:19:14.933   Training iter 50, batch loss 0.1293, batch acc 0.9936
18:19:15.031   Training iter 100, batch loss 0.1228, batch acc 0.9948
18:19:15.153   Training iter 150, batch loss 0.1404, batch acc 0.9920
18:19:15.270   Training iter 200, batch loss 0.1290, batch acc 0.9944
18:19:15.365   Training iter 250, batch loss 0.1375, batch acc 0.9926
18:19:15.546   Training iter 300, batch loss 0.1219, batch acc 0.9946
18:19:15.673   Training iter 350, batch loss 0.1289, batch acc 0.9952
18:19:15.790   Training iter 400, batch loss 0.1446, batch acc 0.9938
18:19:15.930   Training iter 450, batch loss 0.1203, batch acc 0.9936
18:19:16.054   Training iter 500, batch loss 0.1384, batch acc 0.9934
18:19:16.176   Training iter 550, batch loss 0.1327, batch acc 0.9936
18:19:16.273   Training iter 600, batch loss 0.1373, batch acc 0.9938
18:19:16.273 Training @ 50 epoch...
18:19:16.371   Training iter 50, batch loss 0.1216, batch acc 0.9944
18:19:16.474   Training iter 100, batch loss 0.1171, batch acc 0.9946
18:19:16.592   Training iter 150, batch loss 0.0915, batch acc 0.9964
18:19:16.689   Training iter 200, batch loss 0.1369, batch acc 0.9934
18:19:16.789   Training iter 250, batch loss 0.0935, batch acc 0.9958
18:19:16.887   Training iter 300, batch loss 0.1334, batch acc 0.9926
18:19:16.991   Training iter 350, batch loss 0.1252, batch acc 0.9942
18:19:17.099   Training iter 400, batch loss 0.1222, batch acc 0.9936
18:19:17.195   Training iter 450, batch loss 0.1481, batch acc 0.9920
18:19:17.301   Training iter 500, batch loss 0.1669, batch acc 0.9902
18:19:17.394   Training iter 550, batch loss 0.1268, batch acc 0.9944
18:19:17.493   Training iter 600, batch loss 0.1523, batch acc 0.9926
18:19:17.493 Testing @ 50 epoch...
18:19:17.559     Testing, total mean loss 0.41192, total acc 0.97770
18:19:17.559 Training @ 51 epoch...
18:19:17.727   Training iter 50, batch loss 0.1123, batch acc 0.9958
18:19:17.857   Training iter 100, batch loss 0.1124, batch acc 0.9946
18:19:17.964   Training iter 150, batch loss 0.1128, batch acc 0.9948
18:19:18.090   Training iter 200, batch loss 0.0999, batch acc 0.9944
18:19:18.248   Training iter 250, batch loss 0.1564, batch acc 0.9932
18:19:18.371   Training iter 300, batch loss 0.1172, batch acc 0.9942
18:19:18.492   Training iter 350, batch loss 0.1661, batch acc 0.9924
18:19:18.611   Training iter 400, batch loss 0.1163, batch acc 0.9952
18:19:18.746   Training iter 450, batch loss 0.1455, batch acc 0.9916
18:19:18.860   Training iter 500, batch loss 0.1512, batch acc 0.9926
18:19:18.956   Training iter 550, batch loss 0.1532, batch acc 0.9926
18:19:19.052   Training iter 600, batch loss 0.1299, batch acc 0.9932
18:19:19.053 Training @ 52 epoch...
18:19:19.149   Training iter 50, batch loss 0.1158, batch acc 0.9940
18:19:19.254   Training iter 100, batch loss 0.1498, batch acc 0.9910
18:19:19.339   Training iter 150, batch loss 0.1047, batch acc 0.9948
18:19:19.436   Training iter 200, batch loss 0.1243, batch acc 0.9946
18:19:19.531   Training iter 250, batch loss 0.1040, batch acc 0.9956
18:19:19.628   Training iter 300, batch loss 0.1213, batch acc 0.9948
18:19:19.722   Training iter 350, batch loss 0.1287, batch acc 0.9932
18:19:19.824   Training iter 400, batch loss 0.1654, batch acc 0.9922
18:19:19.921   Training iter 450, batch loss 0.1383, batch acc 0.9928
18:19:20.015   Training iter 500, batch loss 0.1337, batch acc 0.9946
18:19:20.115   Training iter 550, batch loss 0.1199, batch acc 0.9948
18:19:20.211   Training iter 600, batch loss 0.1593, batch acc 0.9930
18:19:20.211 Training @ 53 epoch...
18:19:20.316   Training iter 50, batch loss 0.1037, batch acc 0.9948
18:19:20.426   Training iter 100, batch loss 0.1056, batch acc 0.9952
18:19:20.519   Training iter 150, batch loss 0.1012, batch acc 0.9944
18:19:20.631   Training iter 200, batch loss 0.1145, batch acc 0.9950
18:19:20.729   Training iter 250, batch loss 0.1379, batch acc 0.9928
18:19:20.849   Training iter 300, batch loss 0.1272, batch acc 0.9944
18:19:20.967   Training iter 350, batch loss 0.1648, batch acc 0.9914
18:19:21.131   Training iter 400, batch loss 0.1905, batch acc 0.9900
18:19:21.262   Training iter 450, batch loss 0.1327, batch acc 0.9926
18:19:21.402   Training iter 500, batch loss 0.1139, batch acc 0.9950
18:19:21.538   Training iter 550, batch loss 0.1828, batch acc 0.9914
18:19:21.678   Training iter 600, batch loss 0.1630, batch acc 0.9930
18:19:21.678 Training @ 54 epoch...
18:19:21.807   Training iter 50, batch loss 0.1426, batch acc 0.9922
18:19:21.937   Training iter 100, batch loss 0.1009, batch acc 0.9970
18:19:22.058   Training iter 150, batch loss 0.1094, batch acc 0.9954
18:19:22.164   Training iter 200, batch loss 0.1363, batch acc 0.9930
18:19:22.279   Training iter 250, batch loss 0.1369, batch acc 0.9928
18:19:22.378   Training iter 300, batch loss 0.1043, batch acc 0.9964
18:19:22.492   Training iter 350, batch loss 0.1490, batch acc 0.9932
18:19:22.602   Training iter 400, batch loss 0.1587, batch acc 0.9922
18:19:22.708   Training iter 450, batch loss 0.1357, batch acc 0.9930
18:19:22.812   Training iter 500, batch loss 0.1528, batch acc 0.9904
18:19:22.923   Training iter 550, batch loss 0.1519, batch acc 0.9920
18:19:23.039   Training iter 600, batch loss 0.1241, batch acc 0.9938
18:19:23.040 Training @ 55 epoch...
18:19:23.146   Training iter 50, batch loss 0.1073, batch acc 0.9942
18:19:23.258   Training iter 100, batch loss 0.1023, batch acc 0.9944
18:19:23.356   Training iter 150, batch loss 0.1206, batch acc 0.9944
18:19:23.464   Training iter 200, batch loss 0.1288, batch acc 0.9934
18:19:23.575   Training iter 250, batch loss 0.1344, batch acc 0.9934
18:19:23.708   Training iter 300, batch loss 0.1257, batch acc 0.9954
18:19:23.839   Training iter 350, batch loss 0.1098, batch acc 0.9952
18:19:23.978   Training iter 400, batch loss 0.1369, batch acc 0.9954
18:19:24.117   Training iter 450, batch loss 0.1809, batch acc 0.9904
18:19:24.259   Training iter 500, batch loss 0.1435, batch acc 0.9930
18:19:24.346   Training iter 550, batch loss 0.1211, batch acc 0.9942
18:19:24.436   Training iter 600, batch loss 0.1613, batch acc 0.9928
18:19:24.438 Testing @ 55 epoch...
18:19:24.512     Testing, total mean loss 0.42280, total acc 0.97840
18:19:24.512 Training @ 56 epoch...
18:19:24.620   Training iter 50, batch loss 0.1092, batch acc 0.9938
18:19:24.715   Training iter 100, batch loss 0.0970, batch acc 0.9964
18:19:24.825   Training iter 150, batch loss 0.1384, batch acc 0.9926
18:19:24.929   Training iter 200, batch loss 0.1294, batch acc 0.9940
18:19:25.028   Training iter 250, batch loss 0.1274, batch acc 0.9934
18:19:25.135   Training iter 300, batch loss 0.1253, batch acc 0.9940
18:19:25.286   Training iter 350, batch loss 0.1197, batch acc 0.9940
18:19:25.378   Training iter 400, batch loss 0.1220, batch acc 0.9942
18:19:25.471   Training iter 450, batch loss 0.1046, batch acc 0.9942
18:19:25.575   Training iter 500, batch loss 0.1324, batch acc 0.9940
18:19:25.672   Training iter 550, batch loss 0.1314, batch acc 0.9940
18:19:25.771   Training iter 600, batch loss 0.1310, batch acc 0.9928
18:19:25.772 Training @ 57 epoch...
18:19:25.892   Training iter 50, batch loss 0.0978, batch acc 0.9962
18:19:25.993   Training iter 100, batch loss 0.1232, batch acc 0.9942
18:19:26.086   Training iter 150, batch loss 0.1109, batch acc 0.9956
18:19:26.193   Training iter 200, batch loss 0.1090, batch acc 0.9944
18:19:26.300   Training iter 250, batch loss 0.1291, batch acc 0.9940
18:19:26.409   Training iter 300, batch loss 0.1449, batch acc 0.9928
18:19:26.533   Training iter 350, batch loss 0.1066, batch acc 0.9956
18:19:26.639   Training iter 400, batch loss 0.1115, batch acc 0.9950
18:19:26.763   Training iter 450, batch loss 0.1329, batch acc 0.9932
18:19:26.890   Training iter 500, batch loss 0.1408, batch acc 0.9928
18:19:27.007   Training iter 550, batch loss 0.1299, batch acc 0.9940
18:19:27.139   Training iter 600, batch loss 0.1302, batch acc 0.9934
18:19:27.139 Training @ 58 epoch...
18:19:27.238   Training iter 50, batch loss 0.1366, batch acc 0.9944
18:19:27.335   Training iter 100, batch loss 0.1013, batch acc 0.9964
18:19:27.429   Training iter 150, batch loss 0.1183, batch acc 0.9950
18:19:27.547   Training iter 200, batch loss 0.1234, batch acc 0.9938
18:19:27.641   Training iter 250, batch loss 0.1098, batch acc 0.9956
18:19:27.736   Training iter 300, batch loss 0.1162, batch acc 0.9952
18:19:27.897   Training iter 350, batch loss 0.1013, batch acc 0.9954
18:19:27.996   Training iter 400, batch loss 0.1471, batch acc 0.9926
18:19:28.096   Training iter 450, batch loss 0.1298, batch acc 0.9932
18:19:28.196   Training iter 500, batch loss 0.1500, batch acc 0.9920
18:19:28.292   Training iter 550, batch loss 0.1181, batch acc 0.9950
18:19:28.393   Training iter 600, batch loss 0.1710, batch acc 0.9902
18:19:28.393 Training @ 59 epoch...
18:19:28.506   Training iter 50, batch loss 0.1068, batch acc 0.9958
18:19:28.650   Training iter 100, batch loss 0.1080, batch acc 0.9950
18:19:28.747   Training iter 150, batch loss 0.1144, batch acc 0.9944
18:19:28.847   Training iter 200, batch loss 0.1241, batch acc 0.9938
18:19:28.944   Training iter 250, batch loss 0.1366, batch acc 0.9924
18:19:29.053   Training iter 300, batch loss 0.1541, batch acc 0.9916
18:19:29.156   Training iter 350, batch loss 0.1047, batch acc 0.9952
18:19:29.274   Training iter 400, batch loss 0.1573, batch acc 0.9930
18:19:29.386   Training iter 450, batch loss 0.1577, batch acc 0.9918
18:19:29.498   Training iter 500, batch loss 0.1241, batch acc 0.9944
18:19:29.605   Training iter 550, batch loss 0.1327, batch acc 0.9934
18:19:29.734   Training iter 600, batch loss 0.1377, batch acc 0.9940
18:19:29.734 Training @ 60 epoch...
18:19:29.871   Training iter 50, batch loss 0.1063, batch acc 0.9942
18:19:30.026   Training iter 100, batch loss 0.1126, batch acc 0.9936
18:19:30.128   Training iter 150, batch loss 0.1156, batch acc 0.9952
18:19:30.217   Training iter 200, batch loss 0.1244, batch acc 0.9958
18:19:30.307   Training iter 250, batch loss 0.1177, batch acc 0.9934
18:19:30.403   Training iter 300, batch loss 0.1228, batch acc 0.9942
18:19:30.502   Training iter 350, batch loss 0.1254, batch acc 0.9950
18:19:30.602   Training iter 400, batch loss 0.1009, batch acc 0.9958
18:19:30.695   Training iter 450, batch loss 0.1285, batch acc 0.9948
18:19:30.787   Training iter 500, batch loss 0.1468, batch acc 0.9942
18:19:30.882   Training iter 550, batch loss 0.1203, batch acc 0.9938
18:19:30.981   Training iter 600, batch loss 0.1300, batch acc 0.9934
18:19:30.988 Testing @ 60 epoch...
18:19:31.056     Testing, total mean loss 0.44229, total acc 0.97830
18:19:31.057 Training @ 61 epoch...
18:19:31.147   Training iter 50, batch loss 0.1027, batch acc 0.9944
18:19:31.245   Training iter 100, batch loss 0.1142, batch acc 0.9950
18:19:31.361   Training iter 150, batch loss 0.1053, batch acc 0.9944
18:19:31.472   Training iter 200, batch loss 0.1006, batch acc 0.9960
18:19:31.584   Training iter 250, batch loss 0.1335, batch acc 0.9938
18:19:31.686   Training iter 300, batch loss 0.0975, batch acc 0.9960
18:19:31.789   Training iter 350, batch loss 0.1322, batch acc 0.9932
18:19:31.910   Training iter 400, batch loss 0.1736, batch acc 0.9910
18:19:32.067   Training iter 450, batch loss 0.1245, batch acc 0.9940
18:19:32.205   Training iter 500, batch loss 0.1221, batch acc 0.9940
18:19:32.388   Training iter 550, batch loss 0.1578, batch acc 0.9914
18:19:32.552   Training iter 600, batch loss 0.1316, batch acc 0.9940
18:19:32.553 Training @ 62 epoch...
18:19:32.679   Training iter 50, batch loss 0.1128, batch acc 0.9944
18:19:32.809   Training iter 100, batch loss 0.1057, batch acc 0.9944
18:19:32.971   Training iter 150, batch loss 0.1245, batch acc 0.9932
18:19:33.231   Training iter 200, batch loss 0.1517, batch acc 0.9932
18:19:33.380   Training iter 250, batch loss 0.1267, batch acc 0.9944
18:19:33.497   Training iter 300, batch loss 0.1224, batch acc 0.9942
18:19:33.671   Training iter 350, batch loss 0.1236, batch acc 0.9954
18:19:33.840   Training iter 400, batch loss 0.1326, batch acc 0.9938
18:19:33.965   Training iter 450, batch loss 0.1311, batch acc 0.9946
18:19:34.167   Training iter 500, batch loss 0.1216, batch acc 0.9940
18:19:34.292   Training iter 550, batch loss 0.1047, batch acc 0.9948
18:19:34.428   Training iter 600, batch loss 0.1296, batch acc 0.9942
18:19:34.430 Training @ 63 epoch...
18:19:34.594   Training iter 50, batch loss 0.0921, batch acc 0.9948
18:19:34.713   Training iter 100, batch loss 0.0851, batch acc 0.9970
18:19:34.815   Training iter 150, batch loss 0.1059, batch acc 0.9960
18:19:34.952   Training iter 200, batch loss 0.1147, batch acc 0.9942
18:19:35.107   Training iter 250, batch loss 0.1080, batch acc 0.9964
18:19:35.279   Training iter 300, batch loss 0.1390, batch acc 0.9930
18:19:35.450   Training iter 350, batch loss 0.1510, batch acc 0.9930
18:19:35.785   Training iter 400, batch loss 0.1257, batch acc 0.9934
18:19:35.911   Training iter 450, batch loss 0.1116, batch acc 0.9940
18:19:36.027   Training iter 500, batch loss 0.1842, batch acc 0.9906
18:19:36.127   Training iter 550, batch loss 0.1411, batch acc 0.9944
18:19:36.276   Training iter 600, batch loss 0.1519, batch acc 0.9928
18:19:36.277 Training @ 64 epoch...
18:19:36.490   Training iter 50, batch loss 0.1514, batch acc 0.9926
18:19:36.614   Training iter 100, batch loss 0.1161, batch acc 0.9946
18:19:36.798   Training iter 150, batch loss 0.1350, batch acc 0.9944
18:19:36.959   Training iter 200, batch loss 0.1006, batch acc 0.9956
18:19:37.212   Training iter 250, batch loss 0.1138, batch acc 0.9950
18:19:37.366   Training iter 300, batch loss 0.0989, batch acc 0.9950
18:19:37.560   Training iter 350, batch loss 0.1194, batch acc 0.9924
18:19:37.711   Training iter 400, batch loss 0.1212, batch acc 0.9938
18:19:37.913   Training iter 450, batch loss 0.1488, batch acc 0.9938
18:19:38.065   Training iter 500, batch loss 0.1454, batch acc 0.9926
18:19:38.245   Training iter 550, batch loss 0.0904, batch acc 0.9966
18:19:38.374   Training iter 600, batch loss 0.1289, batch acc 0.9932
18:19:38.374 Training @ 65 epoch...
18:19:38.491   Training iter 50, batch loss 0.1033, batch acc 0.9952
18:19:38.617   Training iter 100, batch loss 0.1029, batch acc 0.9958
18:19:38.740   Training iter 150, batch loss 0.1095, batch acc 0.9942
18:19:38.934   Training iter 200, batch loss 0.1070, batch acc 0.9942
18:19:39.061   Training iter 250, batch loss 0.1200, batch acc 0.9942
18:19:39.178   Training iter 300, batch loss 0.1282, batch acc 0.9934
18:19:39.282   Training iter 350, batch loss 0.0987, batch acc 0.9962
18:19:39.410   Training iter 400, batch loss 0.1687, batch acc 0.9916
18:19:39.509   Training iter 450, batch loss 0.1363, batch acc 0.9932
18:19:39.628   Training iter 500, batch loss 0.1219, batch acc 0.9938
18:19:39.715   Training iter 550, batch loss 0.1175, batch acc 0.9954
18:19:39.814   Training iter 600, batch loss 0.1218, batch acc 0.9934
18:19:39.814 Testing @ 65 epoch...
18:19:39.898     Testing, total mean loss 0.40667, total acc 0.97870
18:19:39.899 Training @ 66 epoch...
18:19:40.005   Training iter 50, batch loss 0.0996, batch acc 0.9952
18:19:40.110   Training iter 100, batch loss 0.1027, batch acc 0.9942
18:19:40.215   Training iter 150, batch loss 0.1227, batch acc 0.9930
18:19:40.378   Training iter 200, batch loss 0.1140, batch acc 0.9942
18:19:40.478   Training iter 250, batch loss 0.0861, batch acc 0.9960
18:19:40.591   Training iter 300, batch loss 0.1203, batch acc 0.9942
18:19:40.703   Training iter 350, batch loss 0.1231, batch acc 0.9948
18:19:40.884   Training iter 400, batch loss 0.1466, batch acc 0.9930
18:19:41.021   Training iter 450, batch loss 0.1024, batch acc 0.9952
18:19:41.213   Training iter 500, batch loss 0.1314, batch acc 0.9928
18:19:41.336   Training iter 550, batch loss 0.1330, batch acc 0.9938
18:19:41.503   Training iter 600, batch loss 0.1260, batch acc 0.9942
18:19:41.504 Training @ 67 epoch...
18:19:41.642   Training iter 50, batch loss 0.0917, batch acc 0.9956
18:19:41.789   Training iter 100, batch loss 0.1056, batch acc 0.9954
18:19:41.881   Training iter 150, batch loss 0.1169, batch acc 0.9948
18:19:41.973   Training iter 200, batch loss 0.1408, batch acc 0.9938
18:19:42.070   Training iter 250, batch loss 0.1493, batch acc 0.9924
18:19:42.228   Training iter 300, batch loss 0.1177, batch acc 0.9942
18:19:42.323   Training iter 350, batch loss 0.1131, batch acc 0.9942
18:19:42.461   Training iter 400, batch loss 0.1030, batch acc 0.9942
18:19:42.562   Training iter 450, batch loss 0.1028, batch acc 0.9954
18:19:42.653   Training iter 500, batch loss 0.1072, batch acc 0.9946
18:19:42.752   Training iter 550, batch loss 0.1279, batch acc 0.9944
18:19:42.843   Training iter 600, batch loss 0.1498, batch acc 0.9932
18:19:42.843 Training @ 68 epoch...
18:19:42.948   Training iter 50, batch loss 0.1159, batch acc 0.9940
18:19:43.047   Training iter 100, batch loss 0.1008, batch acc 0.9958
18:19:43.163   Training iter 150, batch loss 0.0955, batch acc 0.9970
18:19:43.280   Training iter 200, batch loss 0.1074, batch acc 0.9952
18:19:43.374   Training iter 250, batch loss 0.1363, batch acc 0.9932
18:19:43.473   Training iter 300, batch loss 0.1205, batch acc 0.9952
18:19:43.575   Training iter 350, batch loss 0.1485, batch acc 0.9924
18:19:43.684   Training iter 400, batch loss 0.1240, batch acc 0.9946
18:19:43.832   Training iter 450, batch loss 0.0953, batch acc 0.9954
18:19:43.971   Training iter 500, batch loss 0.0992, batch acc 0.9962
18:19:44.157   Training iter 550, batch loss 0.1220, batch acc 0.9924
18:19:44.311   Training iter 600, batch loss 0.1316, batch acc 0.9930
18:19:44.311 Training @ 69 epoch...
18:19:44.458   Training iter 50, batch loss 0.1248, batch acc 0.9940
18:19:44.596   Training iter 100, batch loss 0.1083, batch acc 0.9952
18:19:44.708   Training iter 150, batch loss 0.1296, batch acc 0.9934
18:19:44.829   Training iter 200, batch loss 0.1194, batch acc 0.9948
18:19:45.002   Training iter 250, batch loss 0.1287, batch acc 0.9940
18:19:45.132   Training iter 300, batch loss 0.1284, batch acc 0.9944
18:19:45.253   Training iter 350, batch loss 0.0996, batch acc 0.9960
18:19:45.425   Training iter 400, batch loss 0.1046, batch acc 0.9958
18:19:45.572   Training iter 450, batch loss 0.1173, batch acc 0.9940
18:19:45.690   Training iter 500, batch loss 0.1279, batch acc 0.9944
18:19:45.785   Training iter 550, batch loss 0.1371, batch acc 0.9940
18:19:45.922   Training iter 600, batch loss 0.1426, batch acc 0.9938
18:19:45.922 Training @ 70 epoch...
18:19:46.096   Training iter 50, batch loss 0.1291, batch acc 0.9942
18:19:46.324   Training iter 100, batch loss 0.1156, batch acc 0.9936
18:19:46.498   Training iter 150, batch loss 0.1078, batch acc 0.9948
18:19:46.687   Training iter 200, batch loss 0.0937, batch acc 0.9966
18:19:46.866   Training iter 250, batch loss 0.1085, batch acc 0.9944
18:19:47.059   Training iter 300, batch loss 0.0976, batch acc 0.9962
18:19:47.262   Training iter 350, batch loss 0.1247, batch acc 0.9936
18:19:47.359   Training iter 400, batch loss 0.1146, batch acc 0.9944
18:19:47.473   Training iter 450, batch loss 0.1312, batch acc 0.9936
18:19:47.585   Training iter 500, batch loss 0.1208, batch acc 0.9940
18:19:47.714   Training iter 550, batch loss 0.1183, batch acc 0.9942
18:19:47.855   Training iter 600, batch loss 0.1502, batch acc 0.9942
18:19:47.856 Testing @ 70 epoch...
18:19:47.948     Testing, total mean loss 0.40483, total acc 0.97950
18:19:47.948 Training @ 71 epoch...
18:19:48.107   Training iter 50, batch loss 0.1124, batch acc 0.9952
18:19:48.212   Training iter 100, batch loss 0.1006, batch acc 0.9958
18:19:48.317   Training iter 150, batch loss 0.1093, batch acc 0.9956
18:19:48.416   Training iter 200, batch loss 0.1173, batch acc 0.9940
18:19:48.512   Training iter 250, batch loss 0.1030, batch acc 0.9948
18:19:48.690   Training iter 300, batch loss 0.1263, batch acc 0.9944
18:19:48.838   Training iter 350, batch loss 0.1465, batch acc 0.9928
18:19:48.990   Training iter 400, batch loss 0.1128, batch acc 0.9944
18:19:49.140   Training iter 450, batch loss 0.1068, batch acc 0.9952
18:19:49.316   Training iter 500, batch loss 0.1018, batch acc 0.9958
18:19:49.438   Training iter 550, batch loss 0.1226, batch acc 0.9940
18:19:49.589   Training iter 600, batch loss 0.1245, batch acc 0.9944
18:19:49.590 Training @ 72 epoch...
18:19:49.719   Training iter 50, batch loss 0.1165, batch acc 0.9954
18:19:49.855   Training iter 100, batch loss 0.0826, batch acc 0.9964
18:19:49.982   Training iter 150, batch loss 0.1404, batch acc 0.9930
18:19:50.115   Training iter 200, batch loss 0.1085, batch acc 0.9942
18:19:50.253   Training iter 250, batch loss 0.0956, batch acc 0.9972
18:19:50.357   Training iter 300, batch loss 0.1123, batch acc 0.9956
18:19:50.460   Training iter 350, batch loss 0.1048, batch acc 0.9960
18:19:50.561   Training iter 400, batch loss 0.1390, batch acc 0.9936
18:19:50.665   Training iter 450, batch loss 0.1376, batch acc 0.9928
18:19:50.759   Training iter 500, batch loss 0.0864, batch acc 0.9972
18:19:50.853   Training iter 550, batch loss 0.1097, batch acc 0.9952
18:19:50.952   Training iter 600, batch loss 0.1128, batch acc 0.9950
18:19:50.954 Training @ 73 epoch...
18:19:51.046   Training iter 50, batch loss 0.0815, batch acc 0.9960
18:19:51.161   Training iter 100, batch loss 0.0888, batch acc 0.9952
18:19:51.263   Training iter 150, batch loss 0.1110, batch acc 0.9956
18:19:51.375   Training iter 200, batch loss 0.1199, batch acc 0.9944
18:19:51.469   Training iter 250, batch loss 0.1098, batch acc 0.9956
18:19:51.566   Training iter 300, batch loss 0.1124, batch acc 0.9956
18:19:51.661   Training iter 350, batch loss 0.1112, batch acc 0.9944
18:19:51.770   Training iter 400, batch loss 0.1128, batch acc 0.9948
18:19:51.873   Training iter 450, batch loss 0.1529, batch acc 0.9914
18:19:51.970   Training iter 500, batch loss 0.1438, batch acc 0.9936
18:19:52.062   Training iter 550, batch loss 0.1671, batch acc 0.9916
18:19:52.152   Training iter 600, batch loss 0.1244, batch acc 0.9956
18:19:52.154 Training @ 74 epoch...
18:19:52.288   Training iter 50, batch loss 0.1049, batch acc 0.9968
18:19:52.397   Training iter 100, batch loss 0.1140, batch acc 0.9938
18:19:52.511   Training iter 150, batch loss 0.1170, batch acc 0.9948
18:19:52.640   Training iter 200, batch loss 0.1116, batch acc 0.9944
18:19:52.759   Training iter 250, batch loss 0.1110, batch acc 0.9950
18:19:52.881   Training iter 300, batch loss 0.1049, batch acc 0.9954
18:19:53.007   Training iter 350, batch loss 0.1044, batch acc 0.9954
18:19:53.108   Training iter 400, batch loss 0.1218, batch acc 0.9944
18:19:53.207   Training iter 450, batch loss 0.0968, batch acc 0.9960
18:19:53.315   Training iter 500, batch loss 0.0976, batch acc 0.9956
18:19:53.426   Training iter 550, batch loss 0.1584, batch acc 0.9924
18:19:53.534   Training iter 600, batch loss 0.1320, batch acc 0.9954
18:19:53.534 Training @ 75 epoch...
18:19:53.653   Training iter 50, batch loss 0.1036, batch acc 0.9956
18:19:53.761   Training iter 100, batch loss 0.1303, batch acc 0.9938
18:19:53.871   Training iter 150, batch loss 0.0978, batch acc 0.9968
18:19:53.978   Training iter 200, batch loss 0.1082, batch acc 0.9944
18:19:54.080   Training iter 250, batch loss 0.1216, batch acc 0.9940
18:19:54.177   Training iter 300, batch loss 0.1283, batch acc 0.9938
18:19:54.285   Training iter 350, batch loss 0.1295, batch acc 0.9940
18:19:54.398   Training iter 400, batch loss 0.1090, batch acc 0.9940
18:19:54.492   Training iter 450, batch loss 0.0990, batch acc 0.9952
18:19:54.593   Training iter 500, batch loss 0.1226, batch acc 0.9938
18:19:54.693   Training iter 550, batch loss 0.1058, batch acc 0.9950
18:19:54.794   Training iter 600, batch loss 0.1202, batch acc 0.9942
18:19:54.796 Testing @ 75 epoch...
18:19:54.877     Testing, total mean loss 0.41134, total acc 0.97860
18:19:54.877 Training @ 76 epoch...
18:19:54.991   Training iter 50, batch loss 0.1125, batch acc 0.9940
18:19:55.124   Training iter 100, batch loss 0.1065, batch acc 0.9946
18:19:55.270   Training iter 150, batch loss 0.1049, batch acc 0.9950
18:19:55.489   Training iter 200, batch loss 0.0994, batch acc 0.9962
18:19:55.648   Training iter 250, batch loss 0.1232, batch acc 0.9944
18:19:55.832   Training iter 300, batch loss 0.1370, batch acc 0.9930
18:19:55.972   Training iter 350, batch loss 0.1036, batch acc 0.9960
18:19:56.099   Training iter 400, batch loss 0.0901, batch acc 0.9968
18:19:56.227   Training iter 450, batch loss 0.1463, batch acc 0.9922
18:19:56.358   Training iter 500, batch loss 0.1123, batch acc 0.9956
18:19:56.590   Training iter 550, batch loss 0.1564, batch acc 0.9912
18:19:56.710   Training iter 600, batch loss 0.1423, batch acc 0.9922
18:19:56.710 Training @ 77 epoch...
18:19:56.844   Training iter 50, batch loss 0.1013, batch acc 0.9960
18:19:56.976   Training iter 100, batch loss 0.1051, batch acc 0.9950
18:19:57.099   Training iter 150, batch loss 0.1255, batch acc 0.9948
18:19:57.248   Training iter 200, batch loss 0.1016, batch acc 0.9952
18:19:57.371   Training iter 250, batch loss 0.0902, batch acc 0.9972
18:19:57.488   Training iter 300, batch loss 0.1540, batch acc 0.9922
18:19:57.605   Training iter 350, batch loss 0.1207, batch acc 0.9934
18:19:57.723   Training iter 400, batch loss 0.1290, batch acc 0.9930
18:19:57.862   Training iter 450, batch loss 0.1404, batch acc 0.9942
18:19:57.987   Training iter 500, batch loss 0.1041, batch acc 0.9950
18:19:58.161   Training iter 550, batch loss 0.1160, batch acc 0.9950
18:19:58.306   Training iter 600, batch loss 0.1228, batch acc 0.9948
18:19:58.308 Training @ 78 epoch...
18:19:58.463   Training iter 50, batch loss 0.1189, batch acc 0.9956
18:19:58.612   Training iter 100, batch loss 0.1043, batch acc 0.9958
18:19:58.753   Training iter 150, batch loss 0.0683, batch acc 0.9974
18:19:58.890   Training iter 200, batch loss 0.1321, batch acc 0.9940
18:19:59.027   Training iter 250, batch loss 0.0810, batch acc 0.9956
18:19:59.158   Training iter 300, batch loss 0.1316, batch acc 0.9952
18:19:59.308   Training iter 350, batch loss 0.1298, batch acc 0.9932
18:19:59.438   Training iter 400, batch loss 0.0715, batch acc 0.9982
18:19:59.570   Training iter 450, batch loss 0.1323, batch acc 0.9934
18:19:59.693   Training iter 500, batch loss 0.1308, batch acc 0.9930
18:19:59.802   Training iter 550, batch loss 0.1477, batch acc 0.9928
18:19:59.904   Training iter 600, batch loss 0.1369, batch acc 0.9938
18:19:59.904 Training @ 79 epoch...
18:20:00.048   Training iter 50, batch loss 0.1103, batch acc 0.9968
18:20:00.324   Training iter 100, batch loss 0.1092, batch acc 0.9952
18:20:00.467   Training iter 150, batch loss 0.1458, batch acc 0.9926
18:20:00.608   Training iter 200, batch loss 0.1137, batch acc 0.9952
18:20:00.739   Training iter 250, batch loss 0.1080, batch acc 0.9944
18:20:00.982   Training iter 300, batch loss 0.1179, batch acc 0.9948
18:20:01.124   Training iter 350, batch loss 0.1550, batch acc 0.9934
18:20:01.261   Training iter 400, batch loss 0.1327, batch acc 0.9952
18:20:01.371   Training iter 450, batch loss 0.1118, batch acc 0.9946
18:20:01.517   Training iter 500, batch loss 0.0988, batch acc 0.9950
18:20:01.643   Training iter 550, batch loss 0.1130, batch acc 0.9962
18:20:01.746   Training iter 600, batch loss 0.0996, batch acc 0.9948
18:20:01.747 Training @ 80 epoch...
18:20:01.883   Training iter 50, batch loss 0.0902, batch acc 0.9962
18:20:02.000   Training iter 100, batch loss 0.0794, batch acc 0.9968
18:20:02.100   Training iter 150, batch loss 0.0912, batch acc 0.9976
18:20:02.229   Training iter 200, batch loss 0.1040, batch acc 0.9956
18:20:02.350   Training iter 250, batch loss 0.1403, batch acc 0.9938
18:20:02.438   Training iter 300, batch loss 0.1287, batch acc 0.9938
18:20:02.541   Training iter 350, batch loss 0.1264, batch acc 0.9944
18:20:02.632   Training iter 400, batch loss 0.1656, batch acc 0.9914
18:20:02.736   Training iter 450, batch loss 0.1799, batch acc 0.9906
18:20:02.826   Training iter 500, batch loss 0.1257, batch acc 0.9936
18:20:02.927   Training iter 550, batch loss 0.1376, batch acc 0.9930
18:20:03.032   Training iter 600, batch loss 0.1047, batch acc 0.9960
18:20:03.033 Testing @ 80 epoch...
18:20:03.097     Testing, total mean loss 0.40530, total acc 0.97930
18:20:03.097 Training @ 81 epoch...
18:20:03.201   Training iter 50, batch loss 0.1220, batch acc 0.9940
18:20:03.293   Training iter 100, batch loss 0.1111, batch acc 0.9954
18:20:03.407   Training iter 150, batch loss 0.1095, batch acc 0.9954
18:20:03.495   Training iter 200, batch loss 0.0955, batch acc 0.9966
18:20:03.587   Training iter 250, batch loss 0.0982, batch acc 0.9962
18:20:03.700   Training iter 300, batch loss 0.0985, batch acc 0.9952
18:20:03.803   Training iter 350, batch loss 0.1087, batch acc 0.9952
18:20:03.912   Training iter 400, batch loss 0.1080, batch acc 0.9944
18:20:04.038   Training iter 450, batch loss 0.1082, batch acc 0.9948
18:20:04.152   Training iter 500, batch loss 0.1301, batch acc 0.9934
18:20:04.274   Training iter 550, batch loss 0.1025, batch acc 0.9958
18:20:04.392   Training iter 600, batch loss 0.1190, batch acc 0.9938
18:20:04.393 Training @ 82 epoch...
18:20:04.529   Training iter 50, batch loss 0.0846, batch acc 0.9962
18:20:04.626   Training iter 100, batch loss 0.1077, batch acc 0.9958
18:20:04.723   Training iter 150, batch loss 0.1195, batch acc 0.9944
18:20:04.808   Training iter 200, batch loss 0.1137, batch acc 0.9956
18:20:04.909   Training iter 250, batch loss 0.1441, batch acc 0.9928
18:20:05.012   Training iter 300, batch loss 0.1125, batch acc 0.9948
18:20:05.096   Training iter 350, batch loss 0.1157, batch acc 0.9950
18:20:05.199   Training iter 400, batch loss 0.1302, batch acc 0.9948
18:20:05.296   Training iter 450, batch loss 0.1197, batch acc 0.9944
18:20:05.389   Training iter 500, batch loss 0.1373, batch acc 0.9938
18:20:05.484   Training iter 550, batch loss 0.0890, batch acc 0.9958
18:20:05.579   Training iter 600, batch loss 0.1215, batch acc 0.9954
18:20:05.580 Training @ 83 epoch...
18:20:05.678   Training iter 50, batch loss 0.1121, batch acc 0.9954
18:20:05.778   Training iter 100, batch loss 0.1311, batch acc 0.9946
18:20:05.890   Training iter 150, batch loss 0.1063, batch acc 0.9956
18:20:05.991   Training iter 200, batch loss 0.1209, batch acc 0.9950
18:20:06.083   Training iter 250, batch loss 0.0810, batch acc 0.9958
18:20:06.181   Training iter 300, batch loss 0.1120, batch acc 0.9954
18:20:06.275   Training iter 350, batch loss 0.0850, batch acc 0.9968
18:20:06.373   Training iter 400, batch loss 0.1231, batch acc 0.9944
18:20:06.470   Training iter 450, batch loss 0.1231, batch acc 0.9936
18:20:06.601   Training iter 500, batch loss 0.0884, batch acc 0.9946
18:20:06.716   Training iter 550, batch loss 0.1373, batch acc 0.9942
18:20:06.829   Training iter 600, batch loss 0.1464, batch acc 0.9930
18:20:06.831 Training @ 84 epoch...
18:20:07.276   Training iter 50, batch loss 0.1160, batch acc 0.9940
18:20:07.416   Training iter 100, batch loss 0.1212, batch acc 0.9946
18:20:07.565   Training iter 150, batch loss 0.1280, batch acc 0.9936
18:20:07.744   Training iter 200, batch loss 0.0997, batch acc 0.9958
18:20:07.865   Training iter 250, batch loss 0.1054, batch acc 0.9948
18:20:07.990   Training iter 300, batch loss 0.1519, batch acc 0.9924
18:20:08.103   Training iter 350, batch loss 0.1201, batch acc 0.9944
18:20:08.268   Training iter 400, batch loss 0.1240, batch acc 0.9934
18:20:08.445   Training iter 450, batch loss 0.1095, batch acc 0.9952
18:20:08.612   Training iter 500, batch loss 0.1676, batch acc 0.9908
18:20:08.726   Training iter 550, batch loss 0.0999, batch acc 0.9958
18:20:08.830   Training iter 600, batch loss 0.1035, batch acc 0.9960
18:20:08.832 Training @ 85 epoch...
18:20:08.961   Training iter 50, batch loss 0.1019, batch acc 0.9950
18:20:09.064   Training iter 100, batch loss 0.1073, batch acc 0.9958
18:20:09.164   Training iter 150, batch loss 0.1063, batch acc 0.9952
18:20:09.268   Training iter 200, batch loss 0.1193, batch acc 0.9944
18:20:09.377   Training iter 250, batch loss 0.0870, batch acc 0.9958
18:20:09.476   Training iter 300, batch loss 0.1189, batch acc 0.9946
18:20:09.611   Training iter 350, batch loss 0.1280, batch acc 0.9936
18:20:09.744   Training iter 400, batch loss 0.0981, batch acc 0.9962
18:20:09.873   Training iter 450, batch loss 0.1278, batch acc 0.9940
18:20:10.024   Training iter 500, batch loss 0.1052, batch acc 0.9958
18:20:10.182   Training iter 550, batch loss 0.1194, batch acc 0.9950
18:20:10.319   Training iter 600, batch loss 0.1331, batch acc 0.9934
18:20:10.320 Testing @ 85 epoch...
18:20:10.488     Testing, total mean loss 0.44890, total acc 0.97620
18:20:10.488 Training @ 86 epoch...
18:20:10.581   Training iter 50, batch loss 0.1167, batch acc 0.9954
18:20:10.687   Training iter 100, batch loss 0.0824, batch acc 0.9970
18:20:10.790   Training iter 150, batch loss 0.0899, batch acc 0.9946
18:20:10.877   Training iter 200, batch loss 0.1012, batch acc 0.9956
18:20:10.990   Training iter 250, batch loss 0.1046, batch acc 0.9946
18:20:11.216   Training iter 300, batch loss 0.0939, batch acc 0.9960
18:20:11.320   Training iter 350, batch loss 0.0913, batch acc 0.9966
18:20:11.420   Training iter 400, batch loss 0.1268, batch acc 0.9932
18:20:11.503   Training iter 450, batch loss 0.1522, batch acc 0.9930
18:20:11.604   Training iter 500, batch loss 0.1019, batch acc 0.9958
18:20:11.703   Training iter 550, batch loss 0.1278, batch acc 0.9944
18:20:11.802   Training iter 600, batch loss 0.1119, batch acc 0.9952
18:20:11.804 Training @ 87 epoch...
18:20:11.909   Training iter 50, batch loss 0.0987, batch acc 0.9958
18:20:12.109   Training iter 100, batch loss 0.1037, batch acc 0.9958
18:20:12.213   Training iter 150, batch loss 0.1273, batch acc 0.9926
18:20:12.327   Training iter 200, batch loss 0.0919, batch acc 0.9974
18:20:12.448   Training iter 250, batch loss 0.0946, batch acc 0.9950
18:20:12.559   Training iter 300, batch loss 0.1065, batch acc 0.9956
18:20:12.668   Training iter 350, batch loss 0.1024, batch acc 0.9954
18:20:12.785   Training iter 400, batch loss 0.1021, batch acc 0.9962
18:20:12.897   Training iter 450, batch loss 0.1069, batch acc 0.9956
18:20:13.032   Training iter 500, batch loss 0.1437, batch acc 0.9916
18:20:13.213   Training iter 550, batch loss 0.1396, batch acc 0.9938
18:20:13.628   Training iter 600, batch loss 0.1357, batch acc 0.9930
18:20:13.629 Training @ 88 epoch...
18:20:13.805   Training iter 50, batch loss 0.1073, batch acc 0.9956
18:20:13.989   Training iter 100, batch loss 0.0857, batch acc 0.9952
18:20:14.123   Training iter 150, batch loss 0.1162, batch acc 0.9946
18:20:14.234   Training iter 200, batch loss 0.0957, batch acc 0.9960
18:20:14.368   Training iter 250, batch loss 0.1163, batch acc 0.9952
18:20:14.564   Training iter 300, batch loss 0.1127, batch acc 0.9942
18:20:14.665   Training iter 350, batch loss 0.1107, batch acc 0.9960
18:20:14.759   Training iter 400, batch loss 0.1254, batch acc 0.9952
18:20:14.857   Training iter 450, batch loss 0.1357, batch acc 0.9952
18:20:15.079   Training iter 500, batch loss 0.1327, batch acc 0.9936
18:20:15.315   Training iter 550, batch loss 0.1186, batch acc 0.9948
18:20:15.531   Training iter 600, batch loss 0.1145, batch acc 0.9956
18:20:15.532 Training @ 89 epoch...
18:20:15.748   Training iter 50, batch loss 0.0877, batch acc 0.9972
18:20:15.937   Training iter 100, batch loss 0.1282, batch acc 0.9938
18:20:16.142   Training iter 150, batch loss 0.0857, batch acc 0.9964
18:20:16.295   Training iter 200, batch loss 0.0877, batch acc 0.9978
18:20:16.622   Training iter 250, batch loss 0.1275, batch acc 0.9922
18:20:16.765   Training iter 300, batch loss 0.0989, batch acc 0.9962
18:20:16.926   Training iter 350, batch loss 0.1098, batch acc 0.9954
18:20:17.117   Training iter 400, batch loss 0.0845, batch acc 0.9968
18:20:17.247   Training iter 450, batch loss 0.1138, batch acc 0.9950
18:20:17.546   Training iter 500, batch loss 0.1276, batch acc 0.9936
18:20:17.646   Training iter 550, batch loss 0.1510, batch acc 0.9916
18:20:17.942   Training iter 600, batch loss 0.1202, batch acc 0.9946
18:20:17.944 Training @ 90 epoch...
18:20:18.254   Training iter 50, batch loss 0.0902, batch acc 0.9960
18:20:18.389   Training iter 100, batch loss 0.0878, batch acc 0.9960
18:20:18.521   Training iter 150, batch loss 0.0987, batch acc 0.9956
18:20:18.657   Training iter 200, batch loss 0.1127, batch acc 0.9940
18:20:18.795   Training iter 250, batch loss 0.1382, batch acc 0.9948
18:20:18.930   Training iter 300, batch loss 0.1578, batch acc 0.9918
18:20:19.073   Training iter 350, batch loss 0.1016, batch acc 0.9946
18:20:19.179   Training iter 400, batch loss 0.1173, batch acc 0.9938
18:20:19.285   Training iter 450, batch loss 0.0994, batch acc 0.9954
18:20:19.392   Training iter 500, batch loss 0.1358, batch acc 0.9946
18:20:19.493   Training iter 550, batch loss 0.1041, batch acc 0.9962
18:20:19.601   Training iter 600, batch loss 0.1428, batch acc 0.9932
18:20:19.603 Testing @ 90 epoch...
18:20:19.697     Testing, total mean loss 0.43386, total acc 0.97740
18:20:19.698 Training @ 91 epoch...
18:20:19.823   Training iter 50, batch loss 0.0962, batch acc 0.9962
18:20:19.935   Training iter 100, batch loss 0.1082, batch acc 0.9952
18:20:20.048   Training iter 150, batch loss 0.1353, batch acc 0.9932
18:20:20.157   Training iter 200, batch loss 0.1064, batch acc 0.9954
18:20:20.250   Training iter 250, batch loss 0.1067, batch acc 0.9944
18:20:20.347   Training iter 300, batch loss 0.0980, batch acc 0.9964
18:20:20.446   Training iter 350, batch loss 0.0979, batch acc 0.9966
18:20:20.558   Training iter 400, batch loss 0.0963, batch acc 0.9954
18:20:20.665   Training iter 450, batch loss 0.1169, batch acc 0.9946
18:20:20.779   Training iter 500, batch loss 0.0934, batch acc 0.9958
18:20:20.877   Training iter 550, batch loss 0.1240, batch acc 0.9940
18:20:20.968   Training iter 600, batch loss 0.1138, batch acc 0.9952
18:20:20.968 Training @ 92 epoch...
18:20:21.202   Training iter 50, batch loss 0.1183, batch acc 0.9958
18:20:21.330   Training iter 100, batch loss 0.1268, batch acc 0.9946
18:20:21.456   Training iter 150, batch loss 0.1175, batch acc 0.9956
18:20:21.582   Training iter 200, batch loss 0.1014, batch acc 0.9968
18:20:21.720   Training iter 250, batch loss 0.1319, batch acc 0.9942
18:20:21.882   Training iter 300, batch loss 0.1154, batch acc 0.9944
18:20:22.001   Training iter 350, batch loss 0.1003, batch acc 0.9946
18:20:22.103   Training iter 400, batch loss 0.1163, batch acc 0.9944
18:20:22.201   Training iter 450, batch loss 0.1245, batch acc 0.9944
18:20:22.304   Training iter 500, batch loss 0.1009, batch acc 0.9962
18:20:22.419   Training iter 550, batch loss 0.1247, batch acc 0.9946
18:20:22.529   Training iter 600, batch loss 0.1275, batch acc 0.9950
18:20:22.530 Training @ 93 epoch...
18:20:22.621   Training iter 50, batch loss 0.1441, batch acc 0.9946
18:20:22.712   Training iter 100, batch loss 0.0981, batch acc 0.9964
18:20:22.814   Training iter 150, batch loss 0.0631, batch acc 0.9982
18:20:22.910   Training iter 200, batch loss 0.0893, batch acc 0.9960
18:20:23.004   Training iter 250, batch loss 0.0887, batch acc 0.9970
18:20:23.114   Training iter 300, batch loss 0.0921, batch acc 0.9956
18:20:23.208   Training iter 350, batch loss 0.0914, batch acc 0.9966
18:20:23.305   Training iter 400, batch loss 0.1111, batch acc 0.9954
18:20:23.402   Training iter 450, batch loss 0.1189, batch acc 0.9954
18:20:23.489   Training iter 500, batch loss 0.1221, batch acc 0.9960
18:20:23.589   Training iter 550, batch loss 0.1207, batch acc 0.9942
18:20:23.686   Training iter 600, batch loss 0.1435, batch acc 0.9936
18:20:23.687 Training @ 94 epoch...
18:20:23.781   Training iter 50, batch loss 0.1159, batch acc 0.9948
18:20:23.898   Training iter 100, batch loss 0.0828, batch acc 0.9964
18:20:23.993   Training iter 150, batch loss 0.1223, batch acc 0.9946
18:20:24.098   Training iter 200, batch loss 0.0912, batch acc 0.9970
18:20:24.414   Training iter 250, batch loss 0.1010, batch acc 0.9954
18:20:24.584   Training iter 300, batch loss 0.1046, batch acc 0.9964
18:20:24.817   Training iter 350, batch loss 0.1164, batch acc 0.9962
18:20:24.969   Training iter 400, batch loss 0.0903, batch acc 0.9970
18:20:25.176   Training iter 450, batch loss 0.1048, batch acc 0.9958
18:20:25.298   Training iter 500, batch loss 0.1249, batch acc 0.9948
18:20:25.460   Training iter 550, batch loss 0.1095, batch acc 0.9966
18:20:25.582   Training iter 600, batch loss 0.1158, batch acc 0.9940
18:20:25.582 Training @ 95 epoch...
18:20:25.715   Training iter 50, batch loss 0.1192, batch acc 0.9942
18:20:25.874   Training iter 100, batch loss 0.1161, batch acc 0.9948
18:20:25.999   Training iter 150, batch loss 0.1310, batch acc 0.9936
18:20:26.115   Training iter 200, batch loss 0.1123, batch acc 0.9954
18:20:26.215   Training iter 250, batch loss 0.1019, batch acc 0.9964
18:20:26.328   Training iter 300, batch loss 0.1123, batch acc 0.9948
18:20:26.433   Training iter 350, batch loss 0.1124, batch acc 0.9956
18:20:26.525   Training iter 400, batch loss 0.1172, batch acc 0.9954
18:20:26.661   Training iter 450, batch loss 0.1199, batch acc 0.9954
18:20:26.788   Training iter 500, batch loss 0.1343, batch acc 0.9948
18:20:26.918   Training iter 550, batch loss 0.0983, batch acc 0.9964
18:20:27.027   Training iter 600, batch loss 0.1154, batch acc 0.9958
18:20:27.029 Testing @ 95 epoch...
18:20:27.208     Testing, total mean loss 0.43780, total acc 0.97770
18:20:27.208 Training @ 96 epoch...
18:20:27.432   Training iter 50, batch loss 0.1067, batch acc 0.9944
18:20:27.608   Training iter 100, batch loss 0.0893, batch acc 0.9960
18:20:27.778   Training iter 150, batch loss 0.0963, batch acc 0.9950
18:20:27.943   Training iter 200, batch loss 0.0914, batch acc 0.9962
18:20:28.183   Training iter 250, batch loss 0.0928, batch acc 0.9958
18:20:28.345   Training iter 300, batch loss 0.1082, batch acc 0.9958
18:20:28.463   Training iter 350, batch loss 0.0945, batch acc 0.9952
18:20:28.577   Training iter 400, batch loss 0.1022, batch acc 0.9954
18:20:28.694   Training iter 450, batch loss 0.1077, batch acc 0.9952
18:20:28.883   Training iter 500, batch loss 0.1416, batch acc 0.9938
18:20:29.046   Training iter 550, batch loss 0.1104, batch acc 0.9964
18:20:29.195   Training iter 600, batch loss 0.1029, batch acc 0.9950
18:20:29.195 Training @ 97 epoch...
18:20:29.377   Training iter 50, batch loss 0.0996, batch acc 0.9964
18:20:29.497   Training iter 100, batch loss 0.0945, batch acc 0.9966
18:20:29.623   Training iter 150, batch loss 0.0897, batch acc 0.9962
18:20:29.729   Training iter 200, batch loss 0.0787, batch acc 0.9968
18:20:29.884   Training iter 250, batch loss 0.1017, batch acc 0.9958
18:20:30.031   Training iter 300, batch loss 0.1033, batch acc 0.9954
18:20:30.239   Training iter 350, batch loss 0.1019, batch acc 0.9948
18:20:30.406   Training iter 400, batch loss 0.1059, batch acc 0.9952
18:20:30.687   Training iter 450, batch loss 0.1310, batch acc 0.9942
18:20:30.922   Training iter 500, batch loss 0.1087, batch acc 0.9956
18:20:31.090   Training iter 550, batch loss 0.1246, batch acc 0.9944
18:20:31.285   Training iter 600, batch loss 0.0978, batch acc 0.9952
18:20:31.287 Training @ 98 epoch...
18:20:31.520   Training iter 50, batch loss 0.0950, batch acc 0.9964
18:20:31.750   Training iter 100, batch loss 0.0874, batch acc 0.9966
18:20:31.869   Training iter 150, batch loss 0.0943, batch acc 0.9968
18:20:32.006   Training iter 200, batch loss 0.0880, batch acc 0.9962
18:20:32.113   Training iter 250, batch loss 0.0950, batch acc 0.9972
18:20:32.216   Training iter 300, batch loss 0.0960, batch acc 0.9962
18:20:32.340   Training iter 350, batch loss 0.1106, batch acc 0.9942
18:20:32.441   Training iter 400, batch loss 0.1012, batch acc 0.9958
18:20:32.544   Training iter 450, batch loss 0.1164, batch acc 0.9948
18:20:32.655   Training iter 500, batch loss 0.1406, batch acc 0.9928
18:20:32.783   Training iter 550, batch loss 0.1621, batch acc 0.9932
18:20:32.980   Training iter 600, batch loss 0.1152, batch acc 0.9952
18:20:32.983 Training @ 99 epoch...
18:20:33.098   Training iter 50, batch loss 0.0981, batch acc 0.9976
18:20:33.262   Training iter 100, batch loss 0.0874, batch acc 0.9974
18:20:33.386   Training iter 150, batch loss 0.0894, batch acc 0.9958
18:20:33.508   Training iter 200, batch loss 0.0988, batch acc 0.9960
18:20:33.622   Training iter 250, batch loss 0.1142, batch acc 0.9948
18:20:33.758   Training iter 300, batch loss 0.1117, batch acc 0.9958
18:20:33.847   Training iter 350, batch loss 0.0894, batch acc 0.9972
18:20:33.936   Training iter 400, batch loss 0.0983, batch acc 0.9944
18:20:34.029   Training iter 450, batch loss 0.1196, batch acc 0.9952
18:20:34.119   Training iter 500, batch loss 0.1034, batch acc 0.9952
18:20:34.212   Training iter 550, batch loss 0.1256, batch acc 0.9950
18:20:34.308   Training iter 600, batch loss 0.1338, batch acc 0.9938
18:20:34.309 Testing @ 99 epoch...
18:20:34.409     Testing, total mean loss 0.38285, total acc 0.98150