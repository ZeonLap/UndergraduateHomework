20:49:42.553 Training @ 0 epoch...
20:49:42.839   Training iter 50, batch loss 44.1415, batch acc 0.1140
20:49:43.011   Training iter 100, batch loss 16.8289, batch acc 0.4518
20:49:43.220   Training iter 150, batch loss 5.8298, batch acc 0.7476
20:49:43.446   Training iter 200, batch loss 3.8697, batch acc 0.8380
20:49:43.645   Training iter 250, batch loss 2.9025, batch acc 0.8754
20:49:43.866   Training iter 300, batch loss 2.7353, batch acc 0.8818
20:49:44.060   Training iter 350, batch loss 2.5020, batch acc 0.8838
20:49:44.273   Training iter 400, batch loss 2.1200, batch acc 0.8992
20:49:44.482   Training iter 450, batch loss 1.9686, batch acc 0.9112
20:49:44.804   Training iter 500, batch loss 1.9525, batch acc 0.9102
20:49:45.059   Training iter 550, batch loss 1.8607, batch acc 0.9122
20:49:45.314   Training iter 600, batch loss 1.6236, batch acc 0.9250
20:49:45.316 Testing @ 0 epoch...
20:49:45.416     Testing, total mean loss 1.36961, total acc 0.93420
20:49:45.416 Training @ 1 epoch...
20:49:45.801   Training iter 50, batch loss 1.5538, batch acc 0.9274
20:49:46.228   Training iter 100, batch loss 1.2406, batch acc 0.9390
20:49:46.597   Training iter 150, batch loss 1.3339, batch acc 0.9352
20:49:46.855   Training iter 200, batch loss 1.3490, batch acc 0.9364
20:49:47.099   Training iter 250, batch loss 1.5197, batch acc 0.9290
20:49:47.445   Training iter 300, batch loss 1.1827, batch acc 0.9356
20:49:47.670   Training iter 350, batch loss 1.2351, batch acc 0.9384
20:49:47.960   Training iter 400, batch loss 1.2970, batch acc 0.9350
20:49:48.266   Training iter 450, batch loss 1.2934, batch acc 0.9390
20:49:48.646   Training iter 500, batch loss 0.9912, batch acc 0.9506
20:49:49.001   Training iter 550, batch loss 1.1182, batch acc 0.9450
20:49:49.309   Training iter 600, batch loss 1.0209, batch acc 0.9464
20:49:49.310 Training @ 2 epoch...
20:49:49.588   Training iter 50, batch loss 0.9446, batch acc 0.9502
20:49:49.922   Training iter 100, batch loss 0.9166, batch acc 0.9530
20:49:50.209   Training iter 150, batch loss 0.9400, batch acc 0.9538
20:49:50.431   Training iter 200, batch loss 0.9260, batch acc 0.9528
20:49:50.758   Training iter 250, batch loss 0.9702, batch acc 0.9518
20:49:50.935   Training iter 300, batch loss 0.8266, batch acc 0.9566
20:49:51.153   Training iter 350, batch loss 0.7944, batch acc 0.9584
20:49:51.451   Training iter 400, batch loss 0.9474, batch acc 0.9514
20:49:51.603   Training iter 450, batch loss 0.8740, batch acc 0.9506
20:49:51.817   Training iter 500, batch loss 0.8345, batch acc 0.9556
20:49:52.022   Training iter 550, batch loss 0.9379, batch acc 0.9550
20:49:52.274   Training iter 600, batch loss 0.9056, batch acc 0.9516
20:49:52.276 Training @ 3 epoch...
20:49:52.596   Training iter 50, batch loss 0.7033, batch acc 0.9594
20:49:52.939   Training iter 100, batch loss 0.5668, batch acc 0.9662
20:49:53.197   Training iter 150, batch loss 0.8038, batch acc 0.9564
20:49:53.601   Training iter 200, batch loss 0.7308, batch acc 0.9630
20:49:53.875   Training iter 250, batch loss 0.8357, batch acc 0.9582
20:49:54.141   Training iter 300, batch loss 0.7429, batch acc 0.9628
20:49:54.623   Training iter 350, batch loss 0.6335, batch acc 0.9626
20:49:54.909   Training iter 400, batch loss 0.7325, batch acc 0.9642
20:49:55.199   Training iter 450, batch loss 0.7321, batch acc 0.9634
20:49:55.379   Training iter 500, batch loss 0.7245, batch acc 0.9626
20:49:55.594   Training iter 550, batch loss 0.8137, batch acc 0.9562
20:49:55.834   Training iter 600, batch loss 0.7608, batch acc 0.9608
20:49:55.836 Training @ 4 epoch...
20:49:56.053   Training iter 50, batch loss 0.4455, batch acc 0.9730
20:49:56.240   Training iter 100, batch loss 0.5543, batch acc 0.9690
20:49:56.503   Training iter 150, batch loss 0.6143, batch acc 0.9662
20:49:56.769   Training iter 200, batch loss 0.5851, batch acc 0.9672
20:49:57.010   Training iter 250, batch loss 0.5668, batch acc 0.9686
20:49:57.220   Training iter 300, batch loss 0.6493, batch acc 0.9650
20:49:57.607   Training iter 350, batch loss 0.6836, batch acc 0.9640
20:49:57.919   Training iter 400, batch loss 0.6103, batch acc 0.9678
20:49:58.260   Training iter 450, batch loss 0.6610, batch acc 0.9634
20:49:58.527   Training iter 500, batch loss 0.6491, batch acc 0.9660
20:49:58.815   Training iter 550, batch loss 0.5151, batch acc 0.9694
20:49:59.113   Training iter 600, batch loss 0.5188, batch acc 0.9710
20:49:59.114 Training @ 5 epoch...
20:49:59.321   Training iter 50, batch loss 0.5536, batch acc 0.9686
20:49:59.540   Training iter 100, batch loss 0.4245, batch acc 0.9770
20:49:59.774   Training iter 150, batch loss 0.5089, batch acc 0.9704
20:49:59.991   Training iter 200, batch loss 0.5454, batch acc 0.9704
20:50:00.267   Training iter 250, batch loss 0.5264, batch acc 0.9698
20:50:00.566   Training iter 300, batch loss 0.4841, batch acc 0.9702
20:50:00.836   Training iter 350, batch loss 0.4470, batch acc 0.9752
20:50:01.097   Training iter 400, batch loss 0.4817, batch acc 0.9720
20:50:01.394   Training iter 450, batch loss 0.5765, batch acc 0.9692
20:50:01.565   Training iter 500, batch loss 0.4189, batch acc 0.9746
20:50:01.766   Training iter 550, batch loss 0.3841, batch acc 0.9774
20:50:01.969   Training iter 600, batch loss 0.4891, batch acc 0.9732
20:50:01.970 Testing @ 5 epoch...
20:50:02.063     Testing, total mean loss 0.74809, total acc 0.96060
20:50:02.063 Training @ 6 epoch...
20:50:02.292   Training iter 50, batch loss 0.4334, batch acc 0.9742
20:50:02.465   Training iter 100, batch loss 0.3389, batch acc 0.9784
20:50:02.689   Training iter 150, batch loss 0.3986, batch acc 0.9788
20:50:02.965   Training iter 200, batch loss 0.4114, batch acc 0.9744
20:50:03.212   Training iter 250, batch loss 0.3807, batch acc 0.9790
20:50:03.465   Training iter 300, batch loss 0.4638, batch acc 0.9718
20:50:03.677   Training iter 350, batch loss 0.3925, batch acc 0.9756
20:50:03.917   Training iter 400, batch loss 0.4602, batch acc 0.9746
20:50:04.228   Training iter 450, batch loss 0.4410, batch acc 0.9726
20:50:04.503   Training iter 500, batch loss 0.4727, batch acc 0.9742
20:50:04.747   Training iter 550, batch loss 0.4124, batch acc 0.9740
20:50:04.964   Training iter 600, batch loss 0.4852, batch acc 0.9720
20:50:04.964 Training @ 7 epoch...
20:50:05.166   Training iter 50, batch loss 0.3526, batch acc 0.9778
20:50:05.414   Training iter 100, batch loss 0.3885, batch acc 0.9780
20:50:05.661   Training iter 150, batch loss 0.3837, batch acc 0.9758
20:50:05.927   Training iter 200, batch loss 0.3015, batch acc 0.9816
20:50:06.131   Training iter 250, batch loss 0.3659, batch acc 0.9760
20:50:06.360   Training iter 300, batch loss 0.3577, batch acc 0.9768
20:50:06.651   Training iter 350, batch loss 0.3466, batch acc 0.9780
20:50:07.054   Training iter 400, batch loss 0.3786, batch acc 0.9780
20:50:07.281   Training iter 450, batch loss 0.3886, batch acc 0.9784
20:50:07.591   Training iter 500, batch loss 0.3716, batch acc 0.9774
20:50:07.989   Training iter 550, batch loss 0.3618, batch acc 0.9774
20:50:08.480   Training iter 600, batch loss 0.3719, batch acc 0.9802
20:50:08.481 Training @ 8 epoch...
20:50:08.773   Training iter 50, batch loss 0.2793, batch acc 0.9832
20:50:09.172   Training iter 100, batch loss 0.3191, batch acc 0.9814
20:50:09.675   Training iter 150, batch loss 0.3140, batch acc 0.9812
20:50:10.062   Training iter 200, batch loss 0.2907, batch acc 0.9796
20:50:10.539   Training iter 250, batch loss 0.3130, batch acc 0.9800
20:50:10.906   Training iter 300, batch loss 0.4390, batch acc 0.9756
20:50:11.166   Training iter 350, batch loss 0.3573, batch acc 0.9808
20:50:11.399   Training iter 400, batch loss 0.2676, batch acc 0.9836
20:50:11.587   Training iter 450, batch loss 0.3215, batch acc 0.9802
20:50:11.809   Training iter 500, batch loss 0.3039, batch acc 0.9810
20:50:12.035   Training iter 550, batch loss 0.3976, batch acc 0.9760
20:50:12.377   Training iter 600, batch loss 0.3221, batch acc 0.9796
20:50:12.379 Training @ 9 epoch...
20:50:12.623   Training iter 50, batch loss 0.2990, batch acc 0.9816
20:50:12.978   Training iter 100, batch loss 0.2329, batch acc 0.9862
20:50:13.346   Training iter 150, batch loss 0.2475, batch acc 0.9854
20:50:13.570   Training iter 200, batch loss 0.2062, batch acc 0.9882
20:50:13.787   Training iter 250, batch loss 0.3439, batch acc 0.9810
20:50:14.025   Training iter 300, batch loss 0.2704, batch acc 0.9816
20:50:14.317   Training iter 350, batch loss 0.3158, batch acc 0.9804
20:50:14.520   Training iter 400, batch loss 0.3315, batch acc 0.9802
20:50:14.851   Training iter 450, batch loss 0.3160, batch acc 0.9816
20:50:15.100   Training iter 500, batch loss 0.2786, batch acc 0.9826
20:50:15.433   Training iter 550, batch loss 0.4037, batch acc 0.9748
20:50:15.714   Training iter 600, batch loss 0.3623, batch acc 0.9796
20:50:15.715 Training @ 10 epoch...
20:50:16.004   Training iter 50, batch loss 0.2667, batch acc 0.9842
20:50:16.206   Training iter 100, batch loss 0.2175, batch acc 0.9874
20:50:16.413   Training iter 150, batch loss 0.2665, batch acc 0.9828
20:50:16.592   Training iter 200, batch loss 0.3327, batch acc 0.9808
20:50:16.774   Training iter 250, batch loss 0.2263, batch acc 0.9852
20:50:17.101   Training iter 300, batch loss 0.2393, batch acc 0.9854
20:50:17.288   Training iter 350, batch loss 0.2742, batch acc 0.9820
20:50:17.487   Training iter 400, batch loss 0.2677, batch acc 0.9816
20:50:17.694   Training iter 450, batch loss 0.2916, batch acc 0.9824
20:50:17.916   Training iter 500, batch loss 0.2789, batch acc 0.9824
20:50:18.148   Training iter 550, batch loss 0.2881, batch acc 0.9814
20:50:18.417   Training iter 600, batch loss 0.2213, batch acc 0.9852
20:50:18.418 Testing @ 10 epoch...
20:50:18.616     Testing, total mean loss 0.51335, total acc 0.97200
20:50:18.616 Training @ 11 epoch...
20:50:18.840   Training iter 50, batch loss 0.2348, batch acc 0.9842
20:50:19.134   Training iter 100, batch loss 0.2315, batch acc 0.9862
20:50:19.339   Training iter 150, batch loss 0.1982, batch acc 0.9860
20:50:19.624   Training iter 200, batch loss 0.2154, batch acc 0.9862
20:50:19.978   Training iter 250, batch loss 0.2658, batch acc 0.9834
20:50:20.276   Training iter 300, batch loss 0.2477, batch acc 0.9836
20:50:20.532   Training iter 350, batch loss 0.2994, batch acc 0.9808
20:50:20.829   Training iter 400, batch loss 0.2612, batch acc 0.9830
20:50:21.070   Training iter 450, batch loss 0.2224, batch acc 0.9854
20:50:21.331   Training iter 500, batch loss 0.2419, batch acc 0.9840
20:50:21.545   Training iter 550, batch loss 0.3162, batch acc 0.9808
20:50:21.745   Training iter 600, batch loss 0.3030, batch acc 0.9826
20:50:21.745 Training @ 12 epoch...
20:50:21.952   Training iter 50, batch loss 0.2084, batch acc 0.9860
20:50:22.144   Training iter 100, batch loss 0.2085, batch acc 0.9890
20:50:22.338   Training iter 150, batch loss 0.1828, batch acc 0.9886
20:50:22.529   Training iter 200, batch loss 0.1841, batch acc 0.9882
20:50:22.721   Training iter 250, batch loss 0.1935, batch acc 0.9886
20:50:22.952   Training iter 300, batch loss 0.2393, batch acc 0.9858
20:50:23.146   Training iter 350, batch loss 0.2095, batch acc 0.9876
20:50:23.315   Training iter 400, batch loss 0.2220, batch acc 0.9858
20:50:23.521   Training iter 450, batch loss 0.1963, batch acc 0.9872
20:50:23.749   Training iter 500, batch loss 0.2504, batch acc 0.9826
20:50:23.989   Training iter 550, batch loss 0.2436, batch acc 0.9832
20:50:24.224   Training iter 600, batch loss 0.3174, batch acc 0.9814
20:50:24.227 Training @ 13 epoch...
20:50:24.449   Training iter 50, batch loss 0.2315, batch acc 0.9858
20:50:24.661   Training iter 100, batch loss 0.1963, batch acc 0.9868
20:50:24.912   Training iter 150, batch loss 0.1987, batch acc 0.9864
20:50:25.143   Training iter 200, batch loss 0.2205, batch acc 0.9856
20:50:25.415   Training iter 250, batch loss 0.1975, batch acc 0.9870
20:50:25.678   Training iter 300, batch loss 0.2099, batch acc 0.9858
20:50:25.939   Training iter 350, batch loss 0.1860, batch acc 0.9872
20:50:26.215   Training iter 400, batch loss 0.2003, batch acc 0.9860
20:50:26.591   Training iter 450, batch loss 0.2265, batch acc 0.9838
20:50:26.855   Training iter 500, batch loss 0.1566, batch acc 0.9910
20:50:27.169   Training iter 550, batch loss 0.1688, batch acc 0.9880
20:50:27.354   Training iter 600, batch loss 0.2690, batch acc 0.9848
20:50:27.356 Training @ 14 epoch...
20:50:27.541   Training iter 50, batch loss 0.1796, batch acc 0.9868
20:50:27.741   Training iter 100, batch loss 0.1609, batch acc 0.9902
20:50:27.925   Training iter 150, batch loss 0.1572, batch acc 0.9908
20:50:28.153   Training iter 200, batch loss 0.2057, batch acc 0.9856
20:50:28.361   Training iter 250, batch loss 0.1863, batch acc 0.9868
20:50:28.571   Training iter 300, batch loss 0.1707, batch acc 0.9886
20:50:28.823   Training iter 350, batch loss 0.1843, batch acc 0.9890
20:50:29.068   Training iter 400, batch loss 0.2897, batch acc 0.9818
20:50:29.368   Training iter 450, batch loss 0.2371, batch acc 0.9836
20:50:29.672   Training iter 500, batch loss 0.2399, batch acc 0.9840
20:50:30.047   Training iter 550, batch loss 0.2239, batch acc 0.9856
20:50:30.329   Training iter 600, batch loss 0.2740, batch acc 0.9836
20:50:30.329 Training @ 15 epoch...
20:50:30.523   Training iter 50, batch loss 0.1767, batch acc 0.9882
20:50:30.772   Training iter 100, batch loss 0.1829, batch acc 0.9868
20:50:31.001   Training iter 150, batch loss 0.1756, batch acc 0.9896
20:50:31.296   Training iter 200, batch loss 0.2016, batch acc 0.9870
20:50:31.544   Training iter 250, batch loss 0.1829, batch acc 0.9870
20:50:31.741   Training iter 300, batch loss 0.2033, batch acc 0.9878
20:50:31.929   Training iter 350, batch loss 0.2070, batch acc 0.9868
20:50:32.179   Training iter 400, batch loss 0.1780, batch acc 0.9874
20:50:32.424   Training iter 450, batch loss 0.1875, batch acc 0.9866
20:50:32.668   Training iter 500, batch loss 0.2070, batch acc 0.9868
20:50:32.976   Training iter 550, batch loss 0.2182, batch acc 0.9850
20:50:33.174   Training iter 600, batch loss 0.1912, batch acc 0.9874
20:50:33.175 Testing @ 15 epoch...
20:50:33.294     Testing, total mean loss 0.41192, total acc 0.97830
20:50:33.294 Training @ 16 epoch...
20:50:33.501   Training iter 50, batch loss 0.1651, batch acc 0.9892
20:50:33.693   Training iter 100, batch loss 0.1578, batch acc 0.9896
20:50:33.901   Training iter 150, batch loss 0.2185, batch acc 0.9852
20:50:34.167   Training iter 200, batch loss 0.1810, batch acc 0.9884
20:50:34.439   Training iter 250, batch loss 0.1441, batch acc 0.9910
20:50:34.703   Training iter 300, batch loss 0.2825, batch acc 0.9808
20:50:34.894   Training iter 350, batch loss 0.1677, batch acc 0.9888
20:50:35.175   Training iter 400, batch loss 0.2089, batch acc 0.9852
20:50:35.413   Training iter 450, batch loss 0.1934, batch acc 0.9876
20:50:35.763   Training iter 500, batch loss 0.1574, batch acc 0.9902
20:50:36.025   Training iter 550, batch loss 0.1567, batch acc 0.9896
20:50:36.275   Training iter 600, batch loss 0.2088, batch acc 0.9872
20:50:36.276 Training @ 17 epoch...
20:50:36.499   Training iter 50, batch loss 0.1530, batch acc 0.9902
20:50:36.712   Training iter 100, batch loss 0.1226, batch acc 0.9934
20:50:36.933   Training iter 150, batch loss 0.0979, batch acc 0.9942
20:50:37.182   Training iter 200, batch loss 0.1572, batch acc 0.9900
20:50:37.371   Training iter 250, batch loss 0.2416, batch acc 0.9844
20:50:37.809   Training iter 300, batch loss 0.1934, batch acc 0.9864
20:50:38.088   Training iter 350, batch loss 0.1525, batch acc 0.9904
20:50:38.416   Training iter 400, batch loss 0.1430, batch acc 0.9908
20:50:38.734   Training iter 450, batch loss 0.1761, batch acc 0.9888
20:50:38.996   Training iter 500, batch loss 0.1778, batch acc 0.9888
20:50:39.366   Training iter 550, batch loss 0.1487, batch acc 0.9898
20:50:39.655   Training iter 600, batch loss 0.1468, batch acc 0.9900
20:50:39.657 Training @ 18 epoch...
20:50:40.000   Training iter 50, batch loss 0.1332, batch acc 0.9912
20:50:40.205   Training iter 100, batch loss 0.1462, batch acc 0.9914
20:50:40.395   Training iter 150, batch loss 0.2142, batch acc 0.9864
20:50:40.627   Training iter 200, batch loss 0.1863, batch acc 0.9880
20:50:40.882   Training iter 250, batch loss 0.1452, batch acc 0.9900
20:50:41.286   Training iter 300, batch loss 0.1485, batch acc 0.9908
20:50:41.633   Training iter 350, batch loss 0.1453, batch acc 0.9910
20:50:41.960   Training iter 400, batch loss 0.1990, batch acc 0.9870
20:50:42.183   Training iter 450, batch loss 0.2235, batch acc 0.9852
20:50:42.393   Training iter 500, batch loss 0.1412, batch acc 0.9912
20:50:42.628   Training iter 550, batch loss 0.1690, batch acc 0.9890
20:50:42.908   Training iter 600, batch loss 0.1614, batch acc 0.9888
20:50:42.908 Training @ 19 epoch...
20:50:43.157   Training iter 50, batch loss 0.1468, batch acc 0.9904
20:50:43.414   Training iter 100, batch loss 0.0935, batch acc 0.9942
20:50:43.646   Training iter 150, batch loss 0.1433, batch acc 0.9906
20:50:43.933   Training iter 200, batch loss 0.1369, batch acc 0.9930
20:50:44.171   Training iter 250, batch loss 0.1671, batch acc 0.9886
20:50:44.429   Training iter 300, batch loss 0.0948, batch acc 0.9944
20:50:44.641   Training iter 350, batch loss 0.1554, batch acc 0.9898
20:50:44.923   Training iter 400, batch loss 0.1410, batch acc 0.9916
20:50:45.185   Training iter 450, batch loss 0.1638, batch acc 0.9910
20:50:45.502   Training iter 500, batch loss 0.1624, batch acc 0.9892
20:50:45.712   Training iter 550, batch loss 0.1200, batch acc 0.9918
20:50:45.923   Training iter 600, batch loss 0.1359, batch acc 0.9898
20:50:45.924 Training @ 20 epoch...
20:50:46.138   Training iter 50, batch loss 0.1626, batch acc 0.9884
20:50:46.363   Training iter 100, batch loss 0.1837, batch acc 0.9874
20:50:46.655   Training iter 150, batch loss 0.1521, batch acc 0.9874
20:50:46.912   Training iter 200, batch loss 0.1101, batch acc 0.9922
20:50:47.161   Training iter 250, batch loss 0.1450, batch acc 0.9912
20:50:47.404   Training iter 300, batch loss 0.1147, batch acc 0.9928
20:50:47.611   Training iter 350, batch loss 0.1685, batch acc 0.9882
20:50:47.854   Training iter 400, batch loss 0.1253, batch acc 0.9914
20:50:48.046   Training iter 450, batch loss 0.1843, batch acc 0.9886
20:50:48.274   Training iter 500, batch loss 0.1536, batch acc 0.9914
20:50:48.517   Training iter 550, batch loss 0.1311, batch acc 0.9908
20:50:48.729   Training iter 600, batch loss 0.1426, batch acc 0.9900
20:50:48.730 Testing @ 20 epoch...
20:50:48.816     Testing, total mean loss 0.45345, total acc 0.97680
20:50:48.816 Training @ 21 epoch...
20:50:49.021   Training iter 50, batch loss 0.0934, batch acc 0.9942
20:50:49.218   Training iter 100, batch loss 0.1182, batch acc 0.9928
20:50:49.451   Training iter 150, batch loss 0.1168, batch acc 0.9920
20:50:49.707   Training iter 200, batch loss 0.1276, batch acc 0.9914
20:50:49.966   Training iter 250, batch loss 0.1228, batch acc 0.9938
20:50:50.201   Training iter 300, batch loss 0.1424, batch acc 0.9918
20:50:50.384   Training iter 350, batch loss 0.1506, batch acc 0.9906
20:50:50.583   Training iter 400, batch loss 0.1360, batch acc 0.9912
20:50:50.773   Training iter 450, batch loss 0.1475, batch acc 0.9906
20:50:50.970   Training iter 500, batch loss 0.1665, batch acc 0.9896
20:50:51.177   Training iter 550, batch loss 0.1588, batch acc 0.9904
20:50:51.375   Training iter 600, batch loss 0.1286, batch acc 0.9922
20:50:51.376 Training @ 22 epoch...
20:50:51.570   Training iter 50, batch loss 0.1416, batch acc 0.9916
20:50:51.795   Training iter 100, batch loss 0.0953, batch acc 0.9940
20:50:52.017   Training iter 150, batch loss 0.1039, batch acc 0.9938
20:50:52.242   Training iter 200, batch loss 0.1023, batch acc 0.9934
20:50:52.479   Training iter 250, batch loss 0.1824, batch acc 0.9882
20:50:52.721   Training iter 300, batch loss 0.1367, batch acc 0.9912
20:50:53.032   Training iter 350, batch loss 0.1060, batch acc 0.9938
20:50:53.237   Training iter 400, batch loss 0.1413, batch acc 0.9896
20:50:53.565   Training iter 450, batch loss 0.1247, batch acc 0.9922
20:50:53.817   Training iter 500, batch loss 0.1254, batch acc 0.9918
20:50:54.049   Training iter 550, batch loss 0.1460, batch acc 0.9910
20:50:54.285   Training iter 600, batch loss 0.1426, batch acc 0.9904
20:50:54.286 Training @ 23 epoch...
20:50:54.501   Training iter 50, batch loss 0.1245, batch acc 0.9924
20:50:54.736   Training iter 100, batch loss 0.1065, batch acc 0.9924
20:50:55.053   Training iter 150, batch loss 0.1464, batch acc 0.9912
20:50:55.290   Training iter 200, batch loss 0.1410, batch acc 0.9922
20:50:55.548   Training iter 250, batch loss 0.1239, batch acc 0.9918
20:50:55.850   Training iter 300, batch loss 0.1040, batch acc 0.9934
20:50:56.107   Training iter 350, batch loss 0.1383, batch acc 0.9906
20:50:56.323   Training iter 400, batch loss 0.1208, batch acc 0.9930
20:50:56.536   Training iter 450, batch loss 0.1505, batch acc 0.9908
20:50:56.750   Training iter 500, batch loss 0.1018, batch acc 0.9926
20:50:57.064   Training iter 550, batch loss 0.1283, batch acc 0.9932
20:50:57.287   Training iter 600, batch loss 0.1023, batch acc 0.9934
20:50:57.288 Training @ 24 epoch...
20:50:57.611   Training iter 50, batch loss 0.1115, batch acc 0.9938
20:50:57.814   Training iter 100, batch loss 0.1244, batch acc 0.9928
20:50:58.180   Training iter 150, batch loss 0.1192, batch acc 0.9928
20:50:58.434   Training iter 200, batch loss 0.1074, batch acc 0.9926
20:50:58.735   Training iter 250, batch loss 0.1419, batch acc 0.9912
20:50:59.083   Training iter 300, batch loss 0.1581, batch acc 0.9898
20:50:59.286   Training iter 350, batch loss 0.1373, batch acc 0.9912
20:50:59.517   Training iter 400, batch loss 0.1516, batch acc 0.9902
20:50:59.831   Training iter 450, batch loss 0.1117, batch acc 0.9936
20:51:00.108   Training iter 500, batch loss 0.1410, batch acc 0.9900
20:51:00.326   Training iter 550, batch loss 0.1287, batch acc 0.9920
20:51:00.575   Training iter 600, batch loss 0.1285, batch acc 0.9924
20:51:00.576 Training @ 25 epoch...
20:51:00.831   Training iter 50, batch loss 0.1228, batch acc 0.9924
20:51:01.133   Training iter 100, batch loss 0.1044, batch acc 0.9934
20:51:01.388   Training iter 150, batch loss 0.1520, batch acc 0.9898
20:51:01.633   Training iter 200, batch loss 0.1826, batch acc 0.9886
20:51:01.879   Training iter 250, batch loss 0.1286, batch acc 0.9918
20:51:02.090   Training iter 300, batch loss 0.1243, batch acc 0.9922
20:51:02.320   Training iter 350, batch loss 0.1399, batch acc 0.9904
20:51:02.552   Training iter 400, batch loss 0.1397, batch acc 0.9908
20:51:02.752   Training iter 450, batch loss 0.1045, batch acc 0.9942
20:51:03.360   Training iter 500, batch loss 0.0938, batch acc 0.9934
20:51:03.570   Training iter 550, batch loss 0.1122, batch acc 0.9928
20:51:03.860   Training iter 600, batch loss 0.1449, batch acc 0.9908
20:51:03.860 Testing @ 25 epoch...
20:51:03.990     Testing, total mean loss 0.54050, total acc 0.97390
20:51:03.991 Training @ 26 epoch...
20:51:04.237   Training iter 50, batch loss 0.1330, batch acc 0.9922
20:51:04.570   Training iter 100, batch loss 0.1084, batch acc 0.9922
20:51:04.826   Training iter 150, batch loss 0.1113, batch acc 0.9930
20:51:05.185   Training iter 200, batch loss 0.1369, batch acc 0.9920
20:51:05.530   Training iter 250, batch loss 0.1273, batch acc 0.9908
20:51:05.839   Training iter 300, batch loss 0.1550, batch acc 0.9892
20:51:06.164   Training iter 350, batch loss 0.0985, batch acc 0.9942
20:51:06.578   Training iter 400, batch loss 0.1327, batch acc 0.9910
20:51:06.879   Training iter 450, batch loss 0.1315, batch acc 0.9918
20:51:07.171   Training iter 500, batch loss 0.1288, batch acc 0.9924
20:51:07.517   Training iter 550, batch loss 0.1024, batch acc 0.9950
20:51:07.832   Training iter 600, batch loss 0.0896, batch acc 0.9942
20:51:07.834 Training @ 27 epoch...
20:51:08.083   Training iter 50, batch loss 0.0813, batch acc 0.9950
20:51:08.429   Training iter 100, batch loss 0.0900, batch acc 0.9950
20:51:08.801   Training iter 150, batch loss 0.1032, batch acc 0.9932
20:51:09.089   Training iter 200, batch loss 0.1056, batch acc 0.9916
20:51:09.335   Training iter 250, batch loss 0.1089, batch acc 0.9928
20:51:09.592   Training iter 300, batch loss 0.0913, batch acc 0.9938
20:51:09.803   Training iter 350, batch loss 0.1099, batch acc 0.9922
20:51:10.108   Training iter 400, batch loss 0.1258, batch acc 0.9918
20:51:10.577   Training iter 450, batch loss 0.1037, batch acc 0.9934
20:51:10.957   Training iter 500, batch loss 0.1179, batch acc 0.9924
20:51:11.249   Training iter 550, batch loss 0.1206, batch acc 0.9932
20:51:11.670   Training iter 600, batch loss 0.1373, batch acc 0.9912
20:51:11.672 Training @ 28 epoch...
20:51:11.973   Training iter 50, batch loss 0.1092, batch acc 0.9928
20:51:12.284   Training iter 100, batch loss 0.0983, batch acc 0.9936
20:51:12.615   Training iter 150, batch loss 0.0692, batch acc 0.9956
20:51:12.880   Training iter 200, batch loss 0.0960, batch acc 0.9932
20:51:13.296   Training iter 250, batch loss 0.1132, batch acc 0.9940
20:51:14.190   Training iter 300, batch loss 0.0904, batch acc 0.9958
20:51:14.429   Training iter 350, batch loss 0.0955, batch acc 0.9942
20:51:14.967   Training iter 400, batch loss 0.0902, batch acc 0.9942
20:51:15.340   Training iter 450, batch loss 0.0960, batch acc 0.9938
20:51:15.612   Training iter 500, batch loss 0.1754, batch acc 0.9876
20:51:15.924   Training iter 550, batch loss 0.1278, batch acc 0.9922
20:51:16.265   Training iter 600, batch loss 0.1513, batch acc 0.9910
20:51:16.267 Training @ 29 epoch...
20:51:16.566   Training iter 50, batch loss 0.1207, batch acc 0.9924
20:51:16.786   Training iter 100, batch loss 0.0875, batch acc 0.9950
20:51:17.071   Training iter 150, batch loss 0.1283, batch acc 0.9916
20:51:17.329   Training iter 200, batch loss 0.1005, batch acc 0.9940
20:51:17.572   Training iter 250, batch loss 0.1183, batch acc 0.9930
20:51:17.807   Training iter 300, batch loss 0.0741, batch acc 0.9958
20:51:18.026   Training iter 350, batch loss 0.0836, batch acc 0.9946
20:51:18.278   Training iter 400, batch loss 0.0788, batch acc 0.9942
20:51:18.524   Training iter 450, batch loss 0.1173, batch acc 0.9940
20:51:18.768   Training iter 500, batch loss 0.1274, batch acc 0.9924
20:51:19.002   Training iter 550, batch loss 0.0902, batch acc 0.9954
20:51:19.198   Training iter 600, batch loss 0.1400, batch acc 0.9908
20:51:19.198 Training @ 30 epoch...
20:51:19.397   Training iter 50, batch loss 0.0959, batch acc 0.9930
20:51:19.586   Training iter 100, batch loss 0.0752, batch acc 0.9960
20:51:19.829   Training iter 150, batch loss 0.0688, batch acc 0.9950
20:51:20.044   Training iter 200, batch loss 0.0777, batch acc 0.9942
20:51:20.302   Training iter 250, batch loss 0.0943, batch acc 0.9942
20:51:20.506   Training iter 300, batch loss 0.1015, batch acc 0.9936
20:51:20.740   Training iter 350, batch loss 0.1037, batch acc 0.9922
20:51:20.966   Training iter 400, batch loss 0.1162, batch acc 0.9938
20:51:21.248   Training iter 450, batch loss 0.0970, batch acc 0.9950
20:51:21.497   Training iter 500, batch loss 0.0905, batch acc 0.9948
20:51:21.753   Training iter 550, batch loss 0.1012, batch acc 0.9954
20:51:21.954   Training iter 600, batch loss 0.1255, batch acc 0.9912
20:51:21.956 Testing @ 30 epoch...
20:51:22.063     Testing, total mean loss 0.39794, total acc 0.97860
20:51:22.063 Training @ 31 epoch...
20:51:22.250   Training iter 50, batch loss 0.0916, batch acc 0.9948
20:51:22.435   Training iter 100, batch loss 0.0660, batch acc 0.9966
20:51:22.623   Training iter 150, batch loss 0.0584, batch acc 0.9962
20:51:22.804   Training iter 200, batch loss 0.1053, batch acc 0.9944
20:51:23.010   Training iter 250, batch loss 0.0848, batch acc 0.9956
20:51:23.202   Training iter 300, batch loss 0.0746, batch acc 0.9950
20:51:23.391   Training iter 350, batch loss 0.0878, batch acc 0.9950
20:51:23.579   Training iter 400, batch loss 0.1071, batch acc 0.9940
20:51:23.777   Training iter 450, batch loss 0.1049, batch acc 0.9926
20:51:24.020   Training iter 500, batch loss 0.0778, batch acc 0.9960
20:51:24.242   Training iter 550, batch loss 0.1720, batch acc 0.9898
20:51:24.463   Training iter 600, batch loss 0.1437, batch acc 0.9914
20:51:24.465 Training @ 32 epoch...
20:51:24.705   Training iter 50, batch loss 0.1211, batch acc 0.9916
20:51:24.919   Training iter 100, batch loss 0.0970, batch acc 0.9936
20:51:25.115   Training iter 150, batch loss 0.0823, batch acc 0.9956
20:51:25.313   Training iter 200, batch loss 0.0855, batch acc 0.9940
20:51:25.515   Training iter 250, batch loss 0.0733, batch acc 0.9968
20:51:25.701   Training iter 300, batch loss 0.0759, batch acc 0.9962
20:51:25.899   Training iter 350, batch loss 0.1403, batch acc 0.9910
20:51:26.103   Training iter 400, batch loss 0.1166, batch acc 0.9932
20:51:26.298   Training iter 450, batch loss 0.1223, batch acc 0.9918
20:51:26.478   Training iter 500, batch loss 0.1445, batch acc 0.9914
20:51:26.666   Training iter 550, batch loss 0.0982, batch acc 0.9940
20:51:26.893   Training iter 600, batch loss 0.1351, batch acc 0.9928
20:51:26.895 Training @ 33 epoch...
20:51:27.131   Training iter 50, batch loss 0.1244, batch acc 0.9914
20:51:27.364   Training iter 100, batch loss 0.1187, batch acc 0.9912
20:51:27.612   Training iter 150, batch loss 0.0864, batch acc 0.9954
20:51:27.797   Training iter 200, batch loss 0.0869, batch acc 0.9936
20:51:27.995   Training iter 250, batch loss 0.0930, batch acc 0.9946
20:51:28.185   Training iter 300, batch loss 0.0962, batch acc 0.9942
20:51:28.369   Training iter 350, batch loss 0.0808, batch acc 0.9952
20:51:28.553   Training iter 400, batch loss 0.0856, batch acc 0.9944
20:51:28.749   Training iter 450, batch loss 0.1157, batch acc 0.9924
20:51:28.924   Training iter 500, batch loss 0.0900, batch acc 0.9950
20:51:29.132   Training iter 550, batch loss 0.1270, batch acc 0.9910
20:51:29.310   Training iter 600, batch loss 0.1162, batch acc 0.9942
20:51:29.310 Training @ 34 epoch...
20:51:29.491   Training iter 50, batch loss 0.1084, batch acc 0.9934
20:51:29.702   Training iter 100, batch loss 0.0955, batch acc 0.9942
20:51:29.924   Training iter 150, batch loss 0.0757, batch acc 0.9954
20:51:30.177   Training iter 200, batch loss 0.0981, batch acc 0.9944
20:51:30.399   Training iter 250, batch loss 0.0819, batch acc 0.9950
20:51:30.584   Training iter 300, batch loss 0.1244, batch acc 0.9926
20:51:30.779   Training iter 350, batch loss 0.0998, batch acc 0.9938
20:51:30.969   Training iter 400, batch loss 0.0926, batch acc 0.9944
20:51:31.158   Training iter 450, batch loss 0.0920, batch acc 0.9942
20:51:31.341   Training iter 500, batch loss 0.1107, batch acc 0.9938
20:51:31.525   Training iter 550, batch loss 0.0941, batch acc 0.9944
20:51:31.710   Training iter 600, batch loss 0.1118, batch acc 0.9936
20:51:31.712 Training @ 35 epoch...
20:51:31.897   Training iter 50, batch loss 0.1019, batch acc 0.9946
20:51:32.098   Training iter 100, batch loss 0.0933, batch acc 0.9948
20:51:32.287   Training iter 150, batch loss 0.0668, batch acc 0.9956
20:51:32.515   Training iter 200, batch loss 0.0848, batch acc 0.9946
20:51:32.743   Training iter 250, batch loss 0.0875, batch acc 0.9942
20:51:32.989   Training iter 300, batch loss 0.0793, batch acc 0.9948
20:51:33.235   Training iter 350, batch loss 0.0941, batch acc 0.9930
20:51:33.420   Training iter 400, batch loss 0.0901, batch acc 0.9952
20:51:33.605   Training iter 450, batch loss 0.0943, batch acc 0.9936
20:51:33.821   Training iter 500, batch loss 0.0905, batch acc 0.9952
20:51:34.014   Training iter 550, batch loss 0.1146, batch acc 0.9932
20:51:34.202   Training iter 600, batch loss 0.1088, batch acc 0.9930
20:51:34.204 Testing @ 35 epoch...
20:51:34.289     Testing, total mean loss 0.46413, total acc 0.97610
20:51:34.289 Training @ 36 epoch...
20:51:34.477   Training iter 50, batch loss 0.1111, batch acc 0.9928
20:51:34.670   Training iter 100, batch loss 0.1003, batch acc 0.9932
20:51:34.850   Training iter 150, batch loss 0.1234, batch acc 0.9918
20:51:35.045   Training iter 200, batch loss 0.0824, batch acc 0.9946
20:51:35.260   Training iter 250, batch loss 0.0756, batch acc 0.9966
20:51:35.486   Training iter 300, batch loss 0.0655, batch acc 0.9968
20:51:35.710   Training iter 350, batch loss 0.1081, batch acc 0.9936
20:51:35.936   Training iter 400, batch loss 0.1524, batch acc 0.9888
20:51:36.198   Training iter 450, batch loss 0.1066, batch acc 0.9934
20:51:36.452   Training iter 500, batch loss 0.0980, batch acc 0.9942
20:51:36.861   Training iter 550, batch loss 0.1026, batch acc 0.9920
20:51:37.175   Training iter 600, batch loss 0.0972, batch acc 0.9938
20:51:37.175 Training @ 37 epoch...
20:51:37.550   Training iter 50, batch loss 0.0837, batch acc 0.9956
20:51:37.893   Training iter 100, batch loss 0.0824, batch acc 0.9948
20:51:38.189   Training iter 150, batch loss 0.1028, batch acc 0.9938
20:51:38.436   Training iter 200, batch loss 0.1143, batch acc 0.9936
20:51:38.705   Training iter 250, batch loss 0.0641, batch acc 0.9968
20:51:38.979   Training iter 300, batch loss 0.1517, batch acc 0.9900
20:51:39.257   Training iter 350, batch loss 0.0909, batch acc 0.9946
20:51:39.484   Training iter 400, batch loss 0.0786, batch acc 0.9954
20:51:39.691   Training iter 450, batch loss 0.1013, batch acc 0.9940
20:51:39.923   Training iter 500, batch loss 0.0707, batch acc 0.9958
20:51:40.129   Training iter 550, batch loss 0.1001, batch acc 0.9926
20:51:40.357   Training iter 600, batch loss 0.1161, batch acc 0.9942
20:51:40.358 Training @ 38 epoch...
20:51:40.569   Training iter 50, batch loss 0.0881, batch acc 0.9950
20:51:40.770   Training iter 100, batch loss 0.0797, batch acc 0.9952
20:51:41.022   Training iter 150, batch loss 0.0825, batch acc 0.9958
20:51:41.260   Training iter 200, batch loss 0.0862, batch acc 0.9956
20:51:41.512   Training iter 250, batch loss 0.1296, batch acc 0.9916
20:51:41.752   Training iter 300, batch loss 0.0812, batch acc 0.9954
20:51:42.099   Training iter 350, batch loss 0.0968, batch acc 0.9940
20:51:42.329   Training iter 400, batch loss 0.1045, batch acc 0.9944
20:51:42.526   Training iter 450, batch loss 0.0842, batch acc 0.9950
20:51:42.783   Training iter 500, batch loss 0.1060, batch acc 0.9936
20:51:43.026   Training iter 550, batch loss 0.1225, batch acc 0.9938
20:51:43.249   Training iter 600, batch loss 0.1613, batch acc 0.9896
20:51:43.251 Training @ 39 epoch...
20:51:43.521   Training iter 50, batch loss 0.0806, batch acc 0.9958
20:51:43.733   Training iter 100, batch loss 0.0912, batch acc 0.9950
20:51:43.942   Training iter 150, batch loss 0.1423, batch acc 0.9912
20:51:44.227   Training iter 200, batch loss 0.0930, batch acc 0.9942
20:51:44.480   Training iter 250, batch loss 0.1253, batch acc 0.9914
20:51:44.719   Training iter 300, batch loss 0.0699, batch acc 0.9962
20:51:44.995   Training iter 350, batch loss 0.0779, batch acc 0.9956
20:51:45.275   Training iter 400, batch loss 0.0766, batch acc 0.9948
20:51:45.508   Training iter 450, batch loss 0.0765, batch acc 0.9950
20:51:45.755   Training iter 500, batch loss 0.1025, batch acc 0.9936
20:51:46.023   Training iter 550, batch loss 0.0949, batch acc 0.9944
20:51:46.325   Training iter 600, batch loss 0.0895, batch acc 0.9956
20:51:46.326 Training @ 40 epoch...
20:51:46.541   Training iter 50, batch loss 0.0835, batch acc 0.9950
20:51:46.769   Training iter 100, batch loss 0.1029, batch acc 0.9934
20:51:47.002   Training iter 150, batch loss 0.0712, batch acc 0.9954
20:51:47.471   Training iter 200, batch loss 0.0725, batch acc 0.9960
20:51:47.808   Training iter 250, batch loss 0.0790, batch acc 0.9950
20:51:48.195   Training iter 300, batch loss 0.1118, batch acc 0.9932
20:51:48.480   Training iter 350, batch loss 0.0936, batch acc 0.9936
20:51:48.764   Training iter 400, batch loss 0.0529, batch acc 0.9976
20:51:49.048   Training iter 450, batch loss 0.0667, batch acc 0.9958
20:51:49.256   Training iter 500, batch loss 0.0875, batch acc 0.9938
20:51:49.449   Training iter 550, batch loss 0.1062, batch acc 0.9948
20:51:49.657   Training iter 600, batch loss 0.0844, batch acc 0.9952
20:51:49.658 Testing @ 40 epoch...
20:51:49.756     Testing, total mean loss 0.33701, total acc 0.98240
20:51:49.756 Training @ 41 epoch...
20:51:49.945   Training iter 50, batch loss 0.0624, batch acc 0.9958
20:51:50.202   Training iter 100, batch loss 0.0745, batch acc 0.9954
20:51:50.437   Training iter 150, batch loss 0.0776, batch acc 0.9948
20:51:50.827   Training iter 200, batch loss 0.0814, batch acc 0.9954
20:51:51.105   Training iter 250, batch loss 0.0850, batch acc 0.9952
20:51:51.357   Training iter 300, batch loss 0.0646, batch acc 0.9964
20:51:51.635   Training iter 350, batch loss 0.0532, batch acc 0.9976
20:51:51.822   Training iter 400, batch loss 0.0584, batch acc 0.9960
20:51:52.083   Training iter 450, batch loss 0.0963, batch acc 0.9938
20:51:52.335   Training iter 500, batch loss 0.0849, batch acc 0.9946
20:51:52.590   Training iter 550, batch loss 0.0698, batch acc 0.9958
20:51:52.926   Training iter 600, batch loss 0.0968, batch acc 0.9934
20:51:52.928 Training @ 42 epoch...
20:51:53.426   Training iter 50, batch loss 0.0504, batch acc 0.9972
20:51:53.826   Training iter 100, batch loss 0.0627, batch acc 0.9958
20:51:54.078   Training iter 150, batch loss 0.0661, batch acc 0.9954
20:51:54.338   Training iter 200, batch loss 0.0857, batch acc 0.9940
20:51:54.715   Training iter 250, batch loss 0.0588, batch acc 0.9964
20:51:54.969   Training iter 300, batch loss 0.0546, batch acc 0.9964
20:51:55.257   Training iter 350, batch loss 0.0744, batch acc 0.9942
20:51:55.541   Training iter 400, batch loss 0.0578, batch acc 0.9974
20:51:55.807   Training iter 450, batch loss 0.0895, batch acc 0.9956
20:51:56.118   Training iter 500, batch loss 0.0722, batch acc 0.9954
20:51:56.384   Training iter 550, batch loss 0.0859, batch acc 0.9940
20:51:56.661   Training iter 600, batch loss 0.1242, batch acc 0.9930
20:51:56.662 Training @ 43 epoch...
20:51:56.872   Training iter 50, batch loss 0.0652, batch acc 0.9958
20:51:57.080   Training iter 100, batch loss 0.0599, batch acc 0.9966
20:51:57.354   Training iter 150, batch loss 0.0909, batch acc 0.9932
20:51:57.600   Training iter 200, batch loss 0.0754, batch acc 0.9956
20:51:57.795   Training iter 250, batch loss 0.0939, batch acc 0.9942
20:51:58.034   Training iter 300, batch loss 0.0758, batch acc 0.9958
20:51:58.295   Training iter 350, batch loss 0.0916, batch acc 0.9950
20:51:58.576   Training iter 400, batch loss 0.0698, batch acc 0.9960
20:51:58.799   Training iter 450, batch loss 0.0862, batch acc 0.9950
20:51:59.042   Training iter 500, batch loss 0.0832, batch acc 0.9952
20:51:59.287   Training iter 550, batch loss 0.0908, batch acc 0.9936
20:51:59.545   Training iter 600, batch loss 0.1199, batch acc 0.9922
20:51:59.547 Training @ 44 epoch...
20:51:59.799   Training iter 50, batch loss 0.0823, batch acc 0.9950
20:52:00.131   Training iter 100, batch loss 0.0692, batch acc 0.9966
20:52:00.434   Training iter 150, batch loss 0.0990, batch acc 0.9938
20:52:00.683   Training iter 200, batch loss 0.0621, batch acc 0.9972
20:52:00.984   Training iter 250, batch loss 0.0716, batch acc 0.9964
20:52:01.351   Training iter 300, batch loss 0.0898, batch acc 0.9960
20:52:01.664   Training iter 350, batch loss 0.0722, batch acc 0.9948
20:52:01.952   Training iter 400, batch loss 0.0807, batch acc 0.9956
20:52:02.318   Training iter 450, batch loss 0.0753, batch acc 0.9966
20:52:02.583   Training iter 500, batch loss 0.0839, batch acc 0.9950
20:52:02.841   Training iter 550, batch loss 0.0819, batch acc 0.9958
20:52:03.039   Training iter 600, batch loss 0.1169, batch acc 0.9922
20:52:03.041 Training @ 45 epoch...
20:52:03.368   Training iter 50, batch loss 0.0729, batch acc 0.9954
20:52:03.681   Training iter 100, batch loss 0.0692, batch acc 0.9956
20:52:03.995   Training iter 150, batch loss 0.0757, batch acc 0.9950
20:52:04.251   Training iter 200, batch loss 0.0609, batch acc 0.9978
20:52:04.544   Training iter 250, batch loss 0.0675, batch acc 0.9962
20:52:04.926   Training iter 300, batch loss 0.0966, batch acc 0.9940
20:52:05.366   Training iter 350, batch loss 0.0780, batch acc 0.9962
20:52:05.712   Training iter 400, batch loss 0.0819, batch acc 0.9958
20:52:06.101   Training iter 450, batch loss 0.0763, batch acc 0.9958
20:52:06.393   Training iter 500, batch loss 0.0754, batch acc 0.9952
20:52:06.686   Training iter 550, batch loss 0.1121, batch acc 0.9938
20:52:06.884   Training iter 600, batch loss 0.0861, batch acc 0.9944
20:52:06.886 Testing @ 45 epoch...
20:52:07.052     Testing, total mean loss 0.32155, total acc 0.98210
20:52:07.052 Training @ 46 epoch...
20:52:07.280   Training iter 50, batch loss 0.0678, batch acc 0.9966
20:52:07.599   Training iter 100, batch loss 0.0630, batch acc 0.9958
20:52:07.903   Training iter 150, batch loss 0.0524, batch acc 0.9966
20:52:08.362   Training iter 200, batch loss 0.0854, batch acc 0.9940
20:52:08.765   Training iter 250, batch loss 0.0589, batch acc 0.9978
20:52:09.238   Training iter 300, batch loss 0.0822, batch acc 0.9960
20:52:09.486   Training iter 350, batch loss 0.1006, batch acc 0.9936
20:52:09.825   Training iter 400, batch loss 0.1464, batch acc 0.9912
20:52:10.208   Training iter 450, batch loss 0.0998, batch acc 0.9938
20:52:10.500   Training iter 500, batch loss 0.0696, batch acc 0.9962
20:52:10.843   Training iter 550, batch loss 0.0886, batch acc 0.9940
20:52:11.128   Training iter 600, batch loss 0.0954, batch acc 0.9942
20:52:11.129 Training @ 47 epoch...
20:52:11.335   Training iter 50, batch loss 0.0652, batch acc 0.9976
20:52:11.676   Training iter 100, batch loss 0.0629, batch acc 0.9960
20:52:11.907   Training iter 150, batch loss 0.0864, batch acc 0.9946
20:52:12.212   Training iter 200, batch loss 0.0927, batch acc 0.9958
20:52:12.425   Training iter 250, batch loss 0.1523, batch acc 0.9902
20:52:12.676   Training iter 300, batch loss 0.0969, batch acc 0.9948
20:52:12.973   Training iter 350, batch loss 0.0857, batch acc 0.9940
20:52:13.266   Training iter 400, batch loss 0.0920, batch acc 0.9940
20:52:13.955   Training iter 450, batch loss 0.1047, batch acc 0.9946
20:52:14.189   Training iter 500, batch loss 0.0955, batch acc 0.9940
20:52:14.392   Training iter 550, batch loss 0.0711, batch acc 0.9956
20:52:14.606   Training iter 600, batch loss 0.0903, batch acc 0.9948
20:52:14.606 Training @ 48 epoch...
20:52:14.801   Training iter 50, batch loss 0.0646, batch acc 0.9956
20:52:15.058   Training iter 100, batch loss 0.0767, batch acc 0.9952
20:52:15.260   Training iter 150, batch loss 0.0748, batch acc 0.9964
20:52:15.493   Training iter 200, batch loss 0.0857, batch acc 0.9944
20:52:15.718   Training iter 250, batch loss 0.0503, batch acc 0.9980
20:52:15.962   Training iter 300, batch loss 0.0690, batch acc 0.9962
20:52:16.202   Training iter 350, batch loss 0.0870, batch acc 0.9958
20:52:16.415   Training iter 400, batch loss 0.1016, batch acc 0.9932
20:52:16.697   Training iter 450, batch loss 0.1141, batch acc 0.9928
20:52:16.885   Training iter 500, batch loss 0.0889, batch acc 0.9958
20:52:17.095   Training iter 550, batch loss 0.1088, batch acc 0.9934
20:52:17.290   Training iter 600, batch loss 0.0985, batch acc 0.9938
20:52:17.291 Training @ 49 epoch...
20:52:17.502   Training iter 50, batch loss 0.0809, batch acc 0.9950
20:52:17.712   Training iter 100, batch loss 0.0713, batch acc 0.9958
20:52:17.940   Training iter 150, batch loss 0.0823, batch acc 0.9954
20:52:18.159   Training iter 200, batch loss 0.0721, batch acc 0.9960
20:52:18.397   Training iter 250, batch loss 0.0993, batch acc 0.9940
20:52:18.599   Training iter 300, batch loss 0.0852, batch acc 0.9966
20:52:18.834   Training iter 350, batch loss 0.0762, batch acc 0.9954
20:52:19.081   Training iter 400, batch loss 0.0924, batch acc 0.9944
20:52:19.308   Training iter 450, batch loss 0.0606, batch acc 0.9962
20:52:19.555   Training iter 500, batch loss 0.0776, batch acc 0.9946
20:52:19.757   Training iter 550, batch loss 0.0657, batch acc 0.9954
20:52:19.940   Training iter 600, batch loss 0.0746, batch acc 0.9958
20:52:19.942 Training @ 50 epoch...
20:52:20.182   Training iter 50, batch loss 0.0699, batch acc 0.9960
20:52:20.444   Training iter 100, batch loss 0.0877, batch acc 0.9938
20:52:20.638   Training iter 150, batch loss 0.0876, batch acc 0.9952
20:52:20.850   Training iter 200, batch loss 0.0699, batch acc 0.9966
20:52:21.064   Training iter 250, batch loss 0.1127, batch acc 0.9932
20:52:21.262   Training iter 300, batch loss 0.0869, batch acc 0.9948
20:52:21.455   Training iter 350, batch loss 0.0565, batch acc 0.9968
20:52:21.686   Training iter 400, batch loss 0.0955, batch acc 0.9942
20:52:21.920   Training iter 450, batch loss 0.0561, batch acc 0.9974
20:52:22.173   Training iter 500, batch loss 0.0762, batch acc 0.9950
20:52:22.400   Training iter 550, batch loss 0.0749, batch acc 0.9942
20:52:22.617   Training iter 600, batch loss 0.1160, batch acc 0.9916
20:52:22.619 Testing @ 50 epoch...
20:52:22.715     Testing, total mean loss 0.37733, total acc 0.97990
20:52:22.715 Training @ 51 epoch...
20:52:22.904   Training iter 50, batch loss 0.0690, batch acc 0.9952
20:52:23.119   Training iter 100, batch loss 0.0827, batch acc 0.9956
20:52:23.307   Training iter 150, batch loss 0.0610, batch acc 0.9964
20:52:23.504   Training iter 200, batch loss 0.0457, batch acc 0.9976
20:52:23.692   Training iter 250, batch loss 0.0671, batch acc 0.9956
20:52:23.881   Training iter 300, batch loss 0.0862, batch acc 0.9940
20:52:24.084   Training iter 350, batch loss 0.0683, batch acc 0.9970
20:52:24.286   Training iter 400, batch loss 0.0886, batch acc 0.9954
20:52:24.474   Training iter 450, batch loss 0.0973, batch acc 0.9952
20:52:24.713   Training iter 500, batch loss 0.0984, batch acc 0.9946
20:52:24.960   Training iter 550, batch loss 0.0791, batch acc 0.9954
20:52:25.281   Training iter 600, batch loss 0.0812, batch acc 0.9960
20:52:25.283 Training @ 52 epoch...
20:52:25.482   Training iter 50, batch loss 0.0694, batch acc 0.9960
20:52:25.689   Training iter 100, batch loss 0.0590, batch acc 0.9970
20:52:25.966   Training iter 150, batch loss 0.0799, batch acc 0.9954
20:52:26.174   Training iter 200, batch loss 0.0876, batch acc 0.9944
20:52:26.372   Training iter 250, batch loss 0.0775, batch acc 0.9956
20:52:26.581   Training iter 300, batch loss 0.0979, batch acc 0.9940
20:52:26.786   Training iter 350, batch loss 0.1037, batch acc 0.9946
20:52:26.974   Training iter 400, batch loss 0.1214, batch acc 0.9924
20:52:27.175   Training iter 450, batch loss 0.0920, batch acc 0.9952
20:52:27.400   Training iter 500, batch loss 0.1015, batch acc 0.9942
20:52:27.699   Training iter 550, batch loss 0.1097, batch acc 0.9932
20:52:27.925   Training iter 600, batch loss 0.0958, batch acc 0.9946
20:52:27.926 Training @ 53 epoch...
20:52:28.192   Training iter 50, batch loss 0.0884, batch acc 0.9944
20:52:28.387   Training iter 100, batch loss 0.0765, batch acc 0.9954
20:52:28.574   Training iter 150, batch loss 0.0629, batch acc 0.9966
20:52:28.758   Training iter 200, batch loss 0.0588, batch acc 0.9966
20:52:28.958   Training iter 250, batch loss 0.0575, batch acc 0.9972
20:52:29.154   Training iter 300, batch loss 0.1052, batch acc 0.9940
20:52:29.371   Training iter 350, batch loss 0.0962, batch acc 0.9944
20:52:29.558   Training iter 400, batch loss 0.1145, batch acc 0.9936
20:52:29.780   Training iter 450, batch loss 0.1344, batch acc 0.9930
20:52:29.978   Training iter 500, batch loss 0.1023, batch acc 0.9938
20:52:30.170   Training iter 550, batch loss 0.0989, batch acc 0.9934
20:52:30.395   Training iter 600, batch loss 0.1262, batch acc 0.9928
20:52:30.396 Training @ 54 epoch...
20:52:30.625   Training iter 50, batch loss 0.0998, batch acc 0.9950
20:52:30.903   Training iter 100, batch loss 0.0830, batch acc 0.9954
20:52:31.177   Training iter 150, batch loss 0.0692, batch acc 0.9960
20:52:31.375   Training iter 200, batch loss 0.0784, batch acc 0.9934
20:52:31.600   Training iter 250, batch loss 0.0705, batch acc 0.9966
20:52:31.780   Training iter 300, batch loss 0.1484, batch acc 0.9904
20:52:31.981   Training iter 350, batch loss 0.1256, batch acc 0.9924
20:52:32.180   Training iter 400, batch loss 0.0801, batch acc 0.9956
20:52:32.369   Training iter 450, batch loss 0.0847, batch acc 0.9956
20:52:32.595   Training iter 500, batch loss 0.0837, batch acc 0.9950
20:52:32.799   Training iter 550, batch loss 0.0971, batch acc 0.9962
20:52:32.987   Training iter 600, batch loss 0.0860, batch acc 0.9940
20:52:32.987 Training @ 55 epoch...
20:52:33.212   Training iter 50, batch loss 0.0555, batch acc 0.9970
20:52:33.450   Training iter 100, batch loss 0.0817, batch acc 0.9960
20:52:33.693   Training iter 150, batch loss 0.0842, batch acc 0.9956
20:52:33.968   Training iter 200, batch loss 0.0747, batch acc 0.9954
20:52:34.202   Training iter 250, batch loss 0.0667, batch acc 0.9958
20:52:34.450   Training iter 300, batch loss 0.0795, batch acc 0.9956
20:52:34.657   Training iter 350, batch loss 0.1062, batch acc 0.9938
20:52:34.853   Training iter 400, batch loss 0.0666, batch acc 0.9964
20:52:35.064   Training iter 450, batch loss 0.0759, batch acc 0.9954
20:52:35.258   Training iter 500, batch loss 0.0708, batch acc 0.9958
20:52:35.463   Training iter 550, batch loss 0.0795, batch acc 0.9962
20:52:35.721   Training iter 600, batch loss 0.1233, batch acc 0.9914
20:52:35.722 Testing @ 55 epoch...
20:52:35.854     Testing, total mean loss 0.36488, total acc 0.98020
20:52:35.854 Training @ 56 epoch...
20:52:36.112   Training iter 50, batch loss 0.0641, batch acc 0.9962
20:52:36.515   Training iter 100, batch loss 0.0814, batch acc 0.9954
20:52:36.803   Training iter 150, batch loss 0.1001, batch acc 0.9940
20:52:37.127   Training iter 200, batch loss 0.0578, batch acc 0.9960
20:52:37.387   Training iter 250, batch loss 0.0627, batch acc 0.9962
20:52:37.681   Training iter 300, batch loss 0.0724, batch acc 0.9960
20:52:38.006   Training iter 350, batch loss 0.0966, batch acc 0.9952
20:52:38.275   Training iter 400, batch loss 0.1098, batch acc 0.9928
20:52:38.594   Training iter 450, batch loss 0.0856, batch acc 0.9944
20:52:38.842   Training iter 500, batch loss 0.0999, batch acc 0.9944
20:52:39.117   Training iter 550, batch loss 0.1118, batch acc 0.9938
20:52:39.430   Training iter 600, batch loss 0.1509, batch acc 0.9892
20:52:39.430 Training @ 57 epoch...
20:52:39.715   Training iter 50, batch loss 0.1050, batch acc 0.9932
20:52:40.037   Training iter 100, batch loss 0.1002, batch acc 0.9934
20:52:40.244   Training iter 150, batch loss 0.0568, batch acc 0.9970
20:52:40.444   Training iter 200, batch loss 0.0836, batch acc 0.9948
20:52:40.639   Training iter 250, batch loss 0.0658, batch acc 0.9956
20:52:40.826   Training iter 300, batch loss 0.0957, batch acc 0.9950
20:52:41.021   Training iter 350, batch loss 0.0981, batch acc 0.9932
20:52:41.207   Training iter 400, batch loss 0.0475, batch acc 0.9970
20:52:41.394   Training iter 450, batch loss 0.0762, batch acc 0.9960
20:52:41.588   Training iter 500, batch loss 0.0635, batch acc 0.9968
20:52:41.775   Training iter 550, batch loss 0.0899, batch acc 0.9950
20:52:42.135   Training iter 600, batch loss 0.0966, batch acc 0.9934
20:52:42.136 Training @ 58 epoch...
20:52:42.450   Training iter 50, batch loss 0.0851, batch acc 0.9954
20:52:42.766   Training iter 100, batch loss 0.0926, batch acc 0.9946
20:52:42.973   Training iter 150, batch loss 0.0597, batch acc 0.9972
20:52:43.168   Training iter 200, batch loss 0.0727, batch acc 0.9954
20:52:43.380   Training iter 250, batch loss 0.1023, batch acc 0.9934
20:52:43.602   Training iter 300, batch loss 0.0718, batch acc 0.9962
20:52:43.801   Training iter 350, batch loss 0.0760, batch acc 0.9962
20:52:44.006   Training iter 400, batch loss 0.0899, batch acc 0.9948
20:52:44.200   Training iter 450, batch loss 0.0614, batch acc 0.9972
20:52:44.405   Training iter 500, batch loss 0.1094, batch acc 0.9936
20:52:44.612   Training iter 550, batch loss 0.0754, batch acc 0.9954
20:52:44.832   Training iter 600, batch loss 0.0772, batch acc 0.9958
20:52:44.834 Training @ 59 epoch...
20:52:45.082   Training iter 50, batch loss 0.0477, batch acc 0.9976
20:52:45.323   Training iter 100, batch loss 0.0716, batch acc 0.9954
20:52:45.563   Training iter 150, batch loss 0.0861, batch acc 0.9938
20:52:45.773   Training iter 200, batch loss 0.0709, batch acc 0.9954
20:52:45.969   Training iter 250, batch loss 0.0703, batch acc 0.9952
20:52:46.161   Training iter 300, batch loss 0.0982, batch acc 0.9950
20:52:46.467   Training iter 350, batch loss 0.1219, batch acc 0.9920
20:52:46.718   Training iter 400, batch loss 0.1039, batch acc 0.9950
20:52:46.963   Training iter 450, batch loss 0.0709, batch acc 0.9964
20:52:47.176   Training iter 500, batch loss 0.0623, batch acc 0.9956
20:52:47.415   Training iter 550, batch loss 0.0940, batch acc 0.9944
20:52:47.652   Training iter 600, batch loss 0.0831, batch acc 0.9960
20:52:47.654 Training @ 60 epoch...
20:52:47.887   Training iter 50, batch loss 0.0884, batch acc 0.9958
20:52:48.158   Training iter 100, batch loss 0.0867, batch acc 0.9942
20:52:48.430   Training iter 150, batch loss 0.0655, batch acc 0.9968
20:52:48.667   Training iter 200, batch loss 0.0545, batch acc 0.9966
20:52:48.899   Training iter 250, batch loss 0.0489, batch acc 0.9978
20:52:49.188   Training iter 300, batch loss 0.0736, batch acc 0.9960
20:52:49.414   Training iter 350, batch loss 0.0594, batch acc 0.9962
20:52:49.661   Training iter 400, batch loss 0.0435, batch acc 0.9980
20:52:49.867   Training iter 450, batch loss 0.0656, batch acc 0.9964
20:52:50.277   Training iter 500, batch loss 0.0567, batch acc 0.9968
20:52:50.579   Training iter 550, batch loss 0.0687, batch acc 0.9960
20:52:50.833   Training iter 600, batch loss 0.0734, batch acc 0.9958
20:52:50.834 Testing @ 60 epoch...
20:52:51.018     Testing, total mean loss 0.37459, total acc 0.98010
20:52:51.019 Training @ 61 epoch...
20:52:51.346   Training iter 50, batch loss 0.0878, batch acc 0.9960
20:52:51.645   Training iter 100, batch loss 0.1072, batch acc 0.9932
20:52:52.061   Training iter 150, batch loss 0.0501, batch acc 0.9978
20:52:52.347   Training iter 200, batch loss 0.0553, batch acc 0.9972
20:52:52.619   Training iter 250, batch loss 0.0742, batch acc 0.9952
20:52:52.873   Training iter 300, batch loss 0.0875, batch acc 0.9948
20:52:53.150   Training iter 350, batch loss 0.0747, batch acc 0.9954
20:52:53.440   Training iter 400, batch loss 0.0795, batch acc 0.9954
20:52:53.755   Training iter 450, batch loss 0.0812, batch acc 0.9948
20:52:54.009   Training iter 500, batch loss 0.0934, batch acc 0.9938
20:52:54.254   Training iter 550, batch loss 0.1024, batch acc 0.9938
20:52:54.437   Training iter 600, batch loss 0.0801, batch acc 0.9956
20:52:54.438 Training @ 62 epoch...
20:52:54.629   Training iter 50, batch loss 0.0718, batch acc 0.9960
20:52:54.828   Training iter 100, batch loss 0.0632, batch acc 0.9968
20:52:55.118   Training iter 150, batch loss 0.0643, batch acc 0.9958
20:52:55.348   Training iter 200, batch loss 0.0777, batch acc 0.9946
20:52:55.606   Training iter 250, batch loss 0.0526, batch acc 0.9976
20:52:55.871   Training iter 300, batch loss 0.0697, batch acc 0.9958
20:52:56.139   Training iter 350, batch loss 0.0534, batch acc 0.9972
20:52:56.402   Training iter 400, batch loss 0.0684, batch acc 0.9960
20:52:56.617   Training iter 450, batch loss 0.0942, batch acc 0.9932
20:52:56.868   Training iter 500, batch loss 0.0559, batch acc 0.9968
20:52:57.126   Training iter 550, batch loss 0.1088, batch acc 0.9924
20:52:57.316   Training iter 600, batch loss 0.1051, batch acc 0.9934
20:52:57.316 Training @ 63 epoch...
20:52:57.523   Training iter 50, batch loss 0.0838, batch acc 0.9938
20:52:57.739   Training iter 100, batch loss 0.0684, batch acc 0.9958
20:52:57.969   Training iter 150, batch loss 0.0660, batch acc 0.9964
20:52:58.280   Training iter 200, batch loss 0.0584, batch acc 0.9968
20:52:58.540   Training iter 250, batch loss 0.0493, batch acc 0.9974
20:52:58.743   Training iter 300, batch loss 0.1408, batch acc 0.9918
20:52:59.051   Training iter 350, batch loss 0.1059, batch acc 0.9944
20:52:59.492   Training iter 400, batch loss 0.1194, batch acc 0.9922
20:52:59.831   Training iter 450, batch loss 0.0531, batch acc 0.9980
20:53:00.153   Training iter 500, batch loss 0.0854, batch acc 0.9940
20:53:00.442   Training iter 550, batch loss 0.0590, batch acc 0.9964
20:53:00.759   Training iter 600, batch loss 0.0732, batch acc 0.9960
20:53:00.759 Training @ 64 epoch...
20:53:00.994   Training iter 50, batch loss 0.0873, batch acc 0.9950
20:53:01.296   Training iter 100, batch loss 0.0831, batch acc 0.9950
20:53:01.501   Training iter 150, batch loss 0.1261, batch acc 0.9920
20:53:01.707   Training iter 200, batch loss 0.0927, batch acc 0.9946
20:53:01.914   Training iter 250, batch loss 0.0653, batch acc 0.9956
20:53:02.154   Training iter 300, batch loss 0.0504, batch acc 0.9976
20:53:02.399   Training iter 350, batch loss 0.0385, batch acc 0.9978
20:53:02.629   Training iter 400, batch loss 0.0452, batch acc 0.9980
20:53:02.883   Training iter 450, batch loss 0.0617, batch acc 0.9970
20:53:03.136   Training iter 500, batch loss 0.0688, batch acc 0.9966
20:53:03.479   Training iter 550, batch loss 0.0753, batch acc 0.9960
20:53:03.659   Training iter 600, batch loss 0.0951, batch acc 0.9938
20:53:03.660 Training @ 65 epoch...
20:53:03.852   Training iter 50, batch loss 0.0563, batch acc 0.9972
20:53:04.132   Training iter 100, batch loss 0.0606, batch acc 0.9972
20:53:04.428   Training iter 150, batch loss 0.0620, batch acc 0.9974
20:53:04.713   Training iter 200, batch loss 0.0796, batch acc 0.9950
20:53:04.937   Training iter 250, batch loss 0.0588, batch acc 0.9964
20:53:05.190   Training iter 300, batch loss 0.0580, batch acc 0.9970
20:53:05.428   Training iter 350, batch loss 0.0853, batch acc 0.9944
20:53:05.668   Training iter 400, batch loss 0.0873, batch acc 0.9948
20:53:05.861   Training iter 450, batch loss 0.0813, batch acc 0.9954
20:53:06.085   Training iter 500, batch loss 0.0652, batch acc 0.9962
20:53:06.344   Training iter 550, batch loss 0.0631, batch acc 0.9970
20:53:06.700   Training iter 600, batch loss 0.0601, batch acc 0.9968
20:53:06.702 Testing @ 65 epoch...
20:53:06.826     Testing, total mean loss 0.38707, total acc 0.97900
20:53:06.826 Training @ 66 epoch...
20:53:07.069   Training iter 50, batch loss 0.0664, batch acc 0.9968
20:53:07.270   Training iter 100, batch loss 0.0535, batch acc 0.9970
20:53:07.503   Training iter 150, batch loss 0.0715, batch acc 0.9964
20:53:07.736   Training iter 200, batch loss 0.0619, batch acc 0.9970
20:53:08.032   Training iter 250, batch loss 0.0574, batch acc 0.9964
20:53:08.292   Training iter 300, batch loss 0.0746, batch acc 0.9964
20:53:08.645   Training iter 350, batch loss 0.0887, batch acc 0.9932
20:53:09.006   Training iter 400, batch loss 0.0801, batch acc 0.9956
20:53:09.205   Training iter 450, batch loss 0.0734, batch acc 0.9960
20:53:09.433   Training iter 500, batch loss 0.0610, batch acc 0.9964
20:53:09.681   Training iter 550, batch loss 0.0796, batch acc 0.9946
20:53:09.986   Training iter 600, batch loss 0.0641, batch acc 0.9966
20:53:09.987 Training @ 67 epoch...
20:53:10.242   Training iter 50, batch loss 0.0645, batch acc 0.9960
20:53:10.455   Training iter 100, batch loss 0.0699, batch acc 0.9960
20:53:10.766   Training iter 150, batch loss 0.0661, batch acc 0.9964
20:53:10.990   Training iter 200, batch loss 0.0687, batch acc 0.9958
20:53:11.409   Training iter 250, batch loss 0.0762, batch acc 0.9954
20:53:11.692   Training iter 300, batch loss 0.0593, batch acc 0.9978
20:53:11.907   Training iter 350, batch loss 0.0491, batch acc 0.9974
20:53:12.167   Training iter 400, batch loss 0.0654, batch acc 0.9960
20:53:12.431   Training iter 450, batch loss 0.0822, batch acc 0.9956
20:53:12.622   Training iter 500, batch loss 0.0747, batch acc 0.9952
20:53:12.841   Training iter 550, batch loss 0.0992, batch acc 0.9948
20:53:13.084   Training iter 600, batch loss 0.0990, batch acc 0.9930
20:53:13.085 Training @ 68 epoch...
20:53:13.275   Training iter 50, batch loss 0.0626, batch acc 0.9968
20:53:13.507   Training iter 100, batch loss 0.0657, batch acc 0.9968
20:53:13.744   Training iter 150, batch loss 0.0656, batch acc 0.9952
20:53:13.975   Training iter 200, batch loss 0.0747, batch acc 0.9954
20:53:14.262   Training iter 250, batch loss 0.0446, batch acc 0.9982
20:53:14.477   Training iter 300, batch loss 0.0562, batch acc 0.9970
20:53:14.682   Training iter 350, batch loss 0.0765, batch acc 0.9958
20:53:14.872   Training iter 400, batch loss 0.1020, batch acc 0.9950
20:53:15.079   Training iter 450, batch loss 0.1191, batch acc 0.9926
20:53:15.315   Training iter 500, batch loss 0.1287, batch acc 0.9908
20:53:15.554   Training iter 550, batch loss 0.1181, batch acc 0.9924
20:53:15.747   Training iter 600, batch loss 0.0701, batch acc 0.9958
20:53:15.748 Training @ 69 epoch...
20:53:15.961   Training iter 50, batch loss 0.0577, batch acc 0.9976
20:53:16.173   Training iter 100, batch loss 0.0445, batch acc 0.9974
20:53:16.407   Training iter 150, batch loss 0.0631, batch acc 0.9960
20:53:16.656   Training iter 200, batch loss 0.0615, batch acc 0.9958
20:53:16.900   Training iter 250, batch loss 0.0577, batch acc 0.9974
20:53:17.161   Training iter 300, batch loss 0.0544, batch acc 0.9978
20:53:17.368   Training iter 350, batch loss 0.0741, batch acc 0.9956
20:53:17.551   Training iter 400, batch loss 0.0594, batch acc 0.9970
20:53:17.747   Training iter 450, batch loss 0.1026, batch acc 0.9940
20:53:17.976   Training iter 500, batch loss 0.0730, batch acc 0.9958
20:53:18.222   Training iter 550, batch loss 0.0579, batch acc 0.9966
20:53:18.467   Training iter 600, batch loss 0.0922, batch acc 0.9948
20:53:18.468 Training @ 70 epoch...
20:53:18.727   Training iter 50, batch loss 0.0701, batch acc 0.9960
20:53:19.031   Training iter 100, batch loss 0.0476, batch acc 0.9972
20:53:19.309   Training iter 150, batch loss 0.0531, batch acc 0.9964
20:53:19.612   Training iter 200, batch loss 0.0356, batch acc 0.9980
20:53:20.020   Training iter 250, batch loss 0.0527, batch acc 0.9970
20:53:20.216   Training iter 300, batch loss 0.0869, batch acc 0.9950
20:53:20.412   Training iter 350, batch loss 0.0734, batch acc 0.9954
20:53:20.673   Training iter 400, batch loss 0.0533, batch acc 0.9980
20:53:20.905   Training iter 450, batch loss 0.0753, batch acc 0.9946
20:53:21.150   Training iter 500, batch loss 0.0444, batch acc 0.9970
20:53:21.350   Training iter 550, batch loss 0.0654, batch acc 0.9956
20:53:21.674   Training iter 600, batch loss 0.0776, batch acc 0.9970
20:53:21.675 Testing @ 70 epoch...
20:53:21.853     Testing, total mean loss 0.34504, total acc 0.98060
20:53:21.853 Training @ 71 epoch...
20:53:22.190   Training iter 50, batch loss 0.0574, batch acc 0.9958
20:53:22.403   Training iter 100, batch loss 0.0302, batch acc 0.9990
20:53:22.635   Training iter 150, batch loss 0.0624, batch acc 0.9966
20:53:22.879   Training iter 200, batch loss 0.0607, batch acc 0.9968
20:53:23.080   Training iter 250, batch loss 0.0503, batch acc 0.9976
20:53:23.299   Training iter 300, batch loss 0.0548, batch acc 0.9964
20:53:23.503   Training iter 350, batch loss 0.0869, batch acc 0.9938
20:53:23.706   Training iter 400, batch loss 0.0865, batch acc 0.9936
20:53:23.922   Training iter 450, batch loss 0.0654, batch acc 0.9962
20:53:24.125   Training iter 500, batch loss 0.0537, batch acc 0.9976
20:53:24.319   Training iter 550, batch loss 0.0809, batch acc 0.9952
20:53:24.507   Training iter 600, batch loss 0.0646, batch acc 0.9968
20:53:24.509 Training @ 72 epoch...
20:53:24.723   Training iter 50, batch loss 0.0540, batch acc 0.9964
20:53:24.936   Training iter 100, batch loss 0.0812, batch acc 0.9958
20:53:25.146   Training iter 150, batch loss 0.0629, batch acc 0.9968
20:53:25.383   Training iter 200, batch loss 0.0856, batch acc 0.9956
20:53:25.611   Training iter 250, batch loss 0.0521, batch acc 0.9978
20:53:25.848   Training iter 300, batch loss 0.0681, batch acc 0.9956
20:53:26.058   Training iter 350, batch loss 0.0639, batch acc 0.9966
20:53:26.255   Training iter 400, batch loss 0.0699, batch acc 0.9964
20:53:26.445   Training iter 450, batch loss 0.0962, batch acc 0.9952
20:53:26.630   Training iter 500, batch loss 0.0638, batch acc 0.9968
20:53:26.833   Training iter 550, batch loss 0.0568, batch acc 0.9964
20:53:27.026   Training iter 600, batch loss 0.0713, batch acc 0.9946
20:53:27.028 Training @ 73 epoch...
20:53:27.237   Training iter 50, batch loss 0.0550, batch acc 0.9964
20:53:27.422   Training iter 100, batch loss 0.0481, batch acc 0.9972
20:53:27.612   Training iter 150, batch loss 0.0555, batch acc 0.9966
20:53:27.844   Training iter 200, batch loss 0.0777, batch acc 0.9946
20:53:28.087   Training iter 250, batch loss 0.0678, batch acc 0.9964
20:53:28.320   Training iter 300, batch loss 0.0483, batch acc 0.9972
20:53:28.553   Training iter 350, batch loss 0.0539, batch acc 0.9978
20:53:28.748   Training iter 400, batch loss 0.0616, batch acc 0.9974
20:53:28.923   Training iter 450, batch loss 0.0686, batch acc 0.9960
20:53:29.128   Training iter 500, batch loss 0.0918, batch acc 0.9956
20:53:29.327   Training iter 550, batch loss 0.0958, batch acc 0.9944
20:53:29.509   Training iter 600, batch loss 0.0646, batch acc 0.9962
20:53:29.510 Training @ 74 epoch...
20:53:29.702   Training iter 50, batch loss 0.0412, batch acc 0.9976
20:53:29.886   Training iter 100, batch loss 0.0500, batch acc 0.9970
20:53:30.067   Training iter 150, batch loss 0.0776, batch acc 0.9956
20:53:30.274   Training iter 200, batch loss 0.0597, batch acc 0.9978
20:53:30.464   Training iter 250, batch loss 0.0661, batch acc 0.9966
20:53:30.670   Training iter 300, batch loss 0.0604, batch acc 0.9972
20:53:30.898   Training iter 350, batch loss 0.0868, batch acc 0.9942
20:53:31.135   Training iter 400, batch loss 0.0715, batch acc 0.9962
20:53:31.365   Training iter 450, batch loss 0.0739, batch acc 0.9972
20:53:31.603   Training iter 500, batch loss 0.0605, batch acc 0.9960
20:53:31.822   Training iter 550, batch loss 0.0980, batch acc 0.9942
20:53:32.020   Training iter 600, batch loss 0.0705, batch acc 0.9954
20:53:32.021 Training @ 75 epoch...
20:53:32.211   Training iter 50, batch loss 0.0759, batch acc 0.9958
20:53:32.419   Training iter 100, batch loss 0.0463, batch acc 0.9976
20:53:32.621   Training iter 150, batch loss 0.0749, batch acc 0.9954
20:53:32.804   Training iter 200, batch loss 0.0801, batch acc 0.9956
20:53:33.000   Training iter 250, batch loss 0.0647, batch acc 0.9966
20:53:33.184   Training iter 300, batch loss 0.0496, batch acc 0.9976
20:53:33.365   Training iter 350, batch loss 0.0703, batch acc 0.9960
20:53:33.667   Training iter 400, batch loss 0.0742, batch acc 0.9966
20:53:33.910   Training iter 450, batch loss 0.0754, batch acc 0.9966
20:53:34.143   Training iter 500, batch loss 0.0503, batch acc 0.9982
20:53:34.425   Training iter 550, batch loss 0.0681, batch acc 0.9962
20:53:34.604   Training iter 600, batch loss 0.1225, batch acc 0.9932
20:53:34.605 Testing @ 75 epoch...
20:53:34.701     Testing, total mean loss 0.42402, total acc 0.97740
20:53:34.701 Training @ 76 epoch...
20:53:34.935   Training iter 50, batch loss 0.0736, batch acc 0.9968
20:53:35.159   Training iter 100, batch loss 0.0755, batch acc 0.9954
20:53:35.484   Training iter 150, batch loss 0.0934, batch acc 0.9948
20:53:35.764   Training iter 200, batch loss 0.0525, batch acc 0.9968
20:53:36.043   Training iter 250, batch loss 0.0512, batch acc 0.9980
20:53:36.324   Training iter 300, batch loss 0.0861, batch acc 0.9950
20:53:36.562   Training iter 350, batch loss 0.0942, batch acc 0.9956
20:53:36.822   Training iter 400, batch loss 0.0782, batch acc 0.9962
20:53:37.101   Training iter 450, batch loss 0.0729, batch acc 0.9952
20:53:37.403   Training iter 500, batch loss 0.0678, batch acc 0.9970
20:53:37.620   Training iter 550, batch loss 0.0650, batch acc 0.9966
20:53:38.034   Training iter 600, batch loss 0.0824, batch acc 0.9952
20:53:38.035 Training @ 77 epoch...
20:53:38.334   Training iter 50, batch loss 0.0730, batch acc 0.9956
20:53:38.607   Training iter 100, batch loss 0.0511, batch acc 0.9976
20:53:38.875   Training iter 150, batch loss 0.0504, batch acc 0.9972
20:53:39.132   Training iter 200, batch loss 0.0663, batch acc 0.9966
20:53:39.452   Training iter 250, batch loss 0.0522, batch acc 0.9966
20:53:39.692   Training iter 300, batch loss 0.0651, batch acc 0.9960
20:53:40.044   Training iter 350, batch loss 0.1307, batch acc 0.9918
20:53:40.403   Training iter 400, batch loss 0.0958, batch acc 0.9940
20:53:40.634   Training iter 450, batch loss 0.0993, batch acc 0.9932
20:53:40.881   Training iter 500, batch loss 0.1076, batch acc 0.9938
20:53:41.107   Training iter 550, batch loss 0.0910, batch acc 0.9944
20:53:41.402   Training iter 600, batch loss 0.0592, batch acc 0.9966
20:53:41.402 Training @ 78 epoch...
20:53:41.655   Training iter 50, batch loss 0.0487, batch acc 0.9974
20:53:41.990   Training iter 100, batch loss 0.0547, batch acc 0.9972
20:53:42.208   Training iter 150, batch loss 0.0498, batch acc 0.9970
20:53:42.456   Training iter 200, batch loss 0.0474, batch acc 0.9974
20:53:42.719   Training iter 250, batch loss 0.0484, batch acc 0.9976
20:53:43.043   Training iter 300, batch loss 0.0588, batch acc 0.9970
20:53:43.305   Training iter 350, batch loss 0.0576, batch acc 0.9964
20:53:43.531   Training iter 400, batch loss 0.0508, batch acc 0.9974
20:53:43.784   Training iter 450, batch loss 0.0506, batch acc 0.9974
20:53:44.048   Training iter 500, batch loss 0.0736, batch acc 0.9958
20:53:44.254   Training iter 550, batch loss 0.0688, batch acc 0.9960
20:53:44.493   Training iter 600, batch loss 0.0848, batch acc 0.9960
20:53:44.494 Training @ 79 epoch...
20:53:44.696   Training iter 50, batch loss 0.0327, batch acc 0.9988
20:53:44.936   Training iter 100, batch loss 0.0574, batch acc 0.9966
20:53:45.202   Training iter 150, batch loss 0.0658, batch acc 0.9954
20:53:45.459   Training iter 200, batch loss 0.0718, batch acc 0.9966
20:53:45.728   Training iter 250, batch loss 0.0668, batch acc 0.9968
20:53:46.019   Training iter 300, batch loss 0.0888, batch acc 0.9940
20:53:46.245   Training iter 350, batch loss 0.0830, batch acc 0.9956
20:53:46.528   Training iter 400, batch loss 0.0847, batch acc 0.9954
20:53:46.809   Training iter 450, batch loss 0.0948, batch acc 0.9934
20:53:47.088   Training iter 500, batch loss 0.0723, batch acc 0.9958
20:53:47.300   Training iter 550, batch loss 0.0692, batch acc 0.9964
20:53:47.590   Training iter 600, batch loss 0.0886, batch acc 0.9946
20:53:47.592 Training @ 80 epoch...
20:53:47.814   Training iter 50, batch loss 0.0911, batch acc 0.9950
20:53:48.164   Training iter 100, batch loss 0.0776, batch acc 0.9952
20:53:48.412   Training iter 150, batch loss 0.0716, batch acc 0.9960
20:53:48.768   Training iter 200, batch loss 0.0652, batch acc 0.9974
20:53:49.065   Training iter 250, batch loss 0.0602, batch acc 0.9968
20:53:49.548   Training iter 300, batch loss 0.0556, batch acc 0.9974
20:53:49.837   Training iter 350, batch loss 0.0439, batch acc 0.9978
20:53:50.116   Training iter 400, batch loss 0.0769, batch acc 0.9950
20:53:50.467   Training iter 450, batch loss 0.0620, batch acc 0.9972
20:53:50.831   Training iter 500, batch loss 0.0608, batch acc 0.9958
20:53:51.176   Training iter 550, batch loss 0.0730, batch acc 0.9954
20:53:51.438   Training iter 600, batch loss 0.0785, batch acc 0.9960
20:53:51.440 Testing @ 80 epoch...
20:53:51.557     Testing, total mean loss 0.36474, total acc 0.98030
20:53:51.557 Training @ 81 epoch...
20:53:51.944   Training iter 50, batch loss 0.0611, batch acc 0.9976
20:53:52.224   Training iter 100, batch loss 0.0987, batch acc 0.9944
20:53:52.480   Training iter 150, batch loss 0.1179, batch acc 0.9936
20:53:52.724   Training iter 200, batch loss 0.0756, batch acc 0.9956
20:53:52.912   Training iter 250, batch loss 0.0824, batch acc 0.9948
20:53:53.242   Training iter 300, batch loss 0.0717, batch acc 0.9956
20:53:53.593   Training iter 350, batch loss 0.0868, batch acc 0.9952
20:53:53.990   Training iter 400, batch loss 0.0695, batch acc 0.9964
20:53:54.263   Training iter 450, batch loss 0.0871, batch acc 0.9950
20:53:54.584   Training iter 500, batch loss 0.0576, batch acc 0.9972
20:53:54.903   Training iter 550, batch loss 0.1526, batch acc 0.9916
20:53:55.225   Training iter 600, batch loss 0.1439, batch acc 0.9918
20:53:55.228 Training @ 82 epoch...
20:53:55.474   Training iter 50, batch loss 0.0711, batch acc 0.9964
20:53:55.727   Training iter 100, batch loss 0.0950, batch acc 0.9942
20:53:55.985   Training iter 150, batch loss 0.0715, batch acc 0.9958
20:53:56.381   Training iter 200, batch loss 0.0653, batch acc 0.9968
20:53:56.650   Training iter 250, batch loss 0.0789, batch acc 0.9950
20:53:56.916   Training iter 300, batch loss 0.0993, batch acc 0.9942
20:53:57.300   Training iter 350, batch loss 0.0834, batch acc 0.9958
20:53:57.616   Training iter 400, batch loss 0.0741, batch acc 0.9952
20:53:57.915   Training iter 450, batch loss 0.0552, batch acc 0.9968
20:53:58.291   Training iter 500, batch loss 0.0582, batch acc 0.9970
20:53:58.532   Training iter 550, batch loss 0.0770, batch acc 0.9962
20:53:58.814   Training iter 600, batch loss 0.0522, batch acc 0.9974
20:53:58.814 Training @ 83 epoch...
20:53:59.063   Training iter 50, batch loss 0.0550, batch acc 0.9962
20:53:59.349   Training iter 100, batch loss 0.0597, batch acc 0.9966
20:53:59.572   Training iter 150, batch loss 0.0445, batch acc 0.9980
20:53:59.882   Training iter 200, batch loss 0.0581, batch acc 0.9970
20:54:00.233   Training iter 250, batch loss 0.0581, batch acc 0.9970
20:54:00.557   Training iter 300, batch loss 0.0688, batch acc 0.9952
20:54:00.841   Training iter 350, batch loss 0.0674, batch acc 0.9968
20:54:01.080   Training iter 400, batch loss 0.0964, batch acc 0.9940
20:54:01.296   Training iter 450, batch loss 0.0576, batch acc 0.9966
20:54:01.560   Training iter 500, batch loss 0.0606, batch acc 0.9972
20:54:01.790   Training iter 550, batch loss 0.0561, batch acc 0.9982
20:54:02.123   Training iter 600, batch loss 0.0715, batch acc 0.9964
20:54:02.128 Training @ 84 epoch...
20:54:02.337   Training iter 50, batch loss 0.0657, batch acc 0.9964
20:54:02.557   Training iter 100, batch loss 0.0716, batch acc 0.9966
20:54:02.894   Training iter 150, batch loss 0.0638, batch acc 0.9976
20:54:03.137   Training iter 200, batch loss 0.0940, batch acc 0.9942
20:54:03.385   Training iter 250, batch loss 0.0874, batch acc 0.9948
20:54:03.689   Training iter 300, batch loss 0.0983, batch acc 0.9954
20:54:03.921   Training iter 350, batch loss 0.0545, batch acc 0.9972
20:54:04.240   Training iter 400, batch loss 0.0686, batch acc 0.9964
20:54:04.426   Training iter 450, batch loss 0.0536, batch acc 0.9970
20:54:04.616   Training iter 500, batch loss 0.0839, batch acc 0.9954
20:54:04.836   Training iter 550, batch loss 0.0854, batch acc 0.9956
20:54:05.128   Training iter 600, batch loss 0.1111, batch acc 0.9930
20:54:05.130 Training @ 85 epoch...
20:54:05.459   Training iter 50, batch loss 0.1129, batch acc 0.9946
20:54:05.793   Training iter 100, batch loss 0.0985, batch acc 0.9944
20:54:06.110   Training iter 150, batch loss 0.0832, batch acc 0.9952
20:54:06.432   Training iter 200, batch loss 0.0582, batch acc 0.9966
20:54:06.616   Training iter 250, batch loss 0.0480, batch acc 0.9974
20:54:06.892   Training iter 300, batch loss 0.0560, batch acc 0.9968
20:54:07.189   Training iter 350, batch loss 0.0601, batch acc 0.9972
20:54:07.537   Training iter 400, batch loss 0.0808, batch acc 0.9962
20:54:07.766   Training iter 450, batch loss 0.0798, batch acc 0.9950
20:54:08.104   Training iter 500, batch loss 0.0781, batch acc 0.9958
20:54:08.367   Training iter 550, batch loss 0.0677, batch acc 0.9968
20:54:08.656   Training iter 600, batch loss 0.0617, batch acc 0.9972
20:54:08.658 Testing @ 85 epoch...
20:54:08.796     Testing, total mean loss 0.37764, total acc 0.98050
20:54:08.796 Training @ 86 epoch...
20:54:09.075   Training iter 50, batch loss 0.0589, batch acc 0.9964
20:54:09.354   Training iter 100, batch loss 0.0701, batch acc 0.9964
20:54:09.605   Training iter 150, batch loss 0.0549, batch acc 0.9970
20:54:09.847   Training iter 200, batch loss 0.0558, batch acc 0.9966
20:54:10.141   Training iter 250, batch loss 0.0798, batch acc 0.9954
20:54:10.401   Training iter 300, batch loss 0.0625, batch acc 0.9974
20:54:10.579   Training iter 350, batch loss 0.0641, batch acc 0.9962
20:54:10.778   Training iter 400, batch loss 0.0838, batch acc 0.9954
20:54:10.987   Training iter 450, batch loss 0.0658, batch acc 0.9972
20:54:11.209   Training iter 500, batch loss 0.0834, batch acc 0.9948
20:54:11.436   Training iter 550, batch loss 0.0710, batch acc 0.9958
20:54:11.670   Training iter 600, batch loss 0.0833, batch acc 0.9966
20:54:11.671 Training @ 87 epoch...
20:54:11.925   Training iter 50, batch loss 0.0597, batch acc 0.9970
20:54:12.190   Training iter 100, batch loss 0.0720, batch acc 0.9958
20:54:12.390   Training iter 150, batch loss 0.0871, batch acc 0.9948
20:54:12.747   Training iter 200, batch loss 0.0537, batch acc 0.9974
20:54:12.969   Training iter 250, batch loss 0.0500, batch acc 0.9972
20:54:13.225   Training iter 300, batch loss 0.0596, batch acc 0.9974
20:54:13.564   Training iter 350, batch loss 0.0558, batch acc 0.9976
20:54:13.942   Training iter 400, batch loss 0.0866, batch acc 0.9944
20:54:14.395   Training iter 450, batch loss 0.0505, batch acc 0.9978
20:54:14.743   Training iter 500, batch loss 0.0651, batch acc 0.9964
20:54:15.091   Training iter 550, batch loss 0.0561, batch acc 0.9976
20:54:15.454   Training iter 600, batch loss 0.0624, batch acc 0.9964
20:54:15.455 Training @ 88 epoch...
20:54:15.687   Training iter 50, batch loss 0.0502, batch acc 0.9982
20:54:15.927   Training iter 100, batch loss 0.0539, batch acc 0.9978
20:54:16.226   Training iter 150, batch loss 0.0452, batch acc 0.9982
20:54:16.520   Training iter 200, batch loss 0.0563, batch acc 0.9966
20:54:16.818   Training iter 250, batch loss 0.0925, batch acc 0.9940
20:54:17.195   Training iter 300, batch loss 0.0658, batch acc 0.9966
20:54:17.460   Training iter 350, batch loss 0.0452, batch acc 0.9984
20:54:17.722   Training iter 400, batch loss 0.0658, batch acc 0.9956
20:54:17.978   Training iter 450, batch loss 0.0754, batch acc 0.9960
20:54:18.183   Training iter 500, batch loss 0.0692, batch acc 0.9960
20:54:18.469   Training iter 550, batch loss 0.0947, batch acc 0.9940
20:54:18.692   Training iter 600, batch loss 0.0673, batch acc 0.9962
20:54:18.693 Training @ 89 epoch...
20:54:19.020   Training iter 50, batch loss 0.0521, batch acc 0.9974
20:54:19.223   Training iter 100, batch loss 0.0811, batch acc 0.9952
20:54:19.435   Training iter 150, batch loss 0.0521, batch acc 0.9974
20:54:19.654   Training iter 200, batch loss 0.0452, batch acc 0.9978
20:54:19.892   Training iter 250, batch loss 0.0655, batch acc 0.9966
20:54:20.200   Training iter 300, batch loss 0.0650, batch acc 0.9962
20:54:20.587   Training iter 350, batch loss 0.0357, batch acc 0.9984
20:54:20.958   Training iter 400, batch loss 0.0603, batch acc 0.9958
20:54:21.286   Training iter 450, batch loss 0.0707, batch acc 0.9962
20:54:21.478   Training iter 500, batch loss 0.0670, batch acc 0.9960
20:54:21.782   Training iter 550, batch loss 0.0848, batch acc 0.9942
20:54:22.014   Training iter 600, batch loss 0.0753, batch acc 0.9956
20:54:22.016 Training @ 90 epoch...
20:54:22.298   Training iter 50, batch loss 0.0915, batch acc 0.9948
20:54:22.533   Training iter 100, batch loss 0.0996, batch acc 0.9948
20:54:22.742   Training iter 150, batch loss 0.0595, batch acc 0.9970
20:54:22.958   Training iter 200, batch loss 0.0656, batch acc 0.9978
20:54:23.203   Training iter 250, batch loss 0.0721, batch acc 0.9960
20:54:23.450   Training iter 300, batch loss 0.0600, batch acc 0.9970
20:54:23.763   Training iter 350, batch loss 0.0852, batch acc 0.9952
20:54:23.989   Training iter 400, batch loss 0.0970, batch acc 0.9938
20:54:24.214   Training iter 450, batch loss 0.0662, batch acc 0.9970
20:54:24.418   Training iter 500, batch loss 0.1195, batch acc 0.9920
20:54:24.607   Training iter 550, batch loss 0.1382, batch acc 0.9916
20:54:24.816   Training iter 600, batch loss 0.0778, batch acc 0.9966
20:54:24.817 Testing @ 90 epoch...
20:54:25.117     Testing, total mean loss 0.39230, total acc 0.98030
20:54:25.117 Training @ 91 epoch...
20:54:25.316   Training iter 50, batch loss 0.0673, batch acc 0.9966
20:54:25.521   Training iter 100, batch loss 0.0869, batch acc 0.9958
20:54:25.740   Training iter 150, batch loss 0.0610, batch acc 0.9960
20:54:26.000   Training iter 200, batch loss 0.0566, batch acc 0.9968
20:54:26.270   Training iter 250, batch loss 0.0611, batch acc 0.9968
20:54:26.524   Training iter 300, batch loss 0.0514, batch acc 0.9976
20:54:26.788   Training iter 350, batch loss 0.0630, batch acc 0.9964
20:54:27.018   Training iter 400, batch loss 0.0662, batch acc 0.9966
20:54:27.268   Training iter 450, batch loss 0.0639, batch acc 0.9962
20:54:27.497   Training iter 500, batch loss 0.0439, batch acc 0.9974
20:54:27.713   Training iter 550, batch loss 0.0558, batch acc 0.9970
20:54:27.934   Training iter 600, batch loss 0.0726, batch acc 0.9954
20:54:27.935 Training @ 92 epoch...
20:54:28.182   Training iter 50, batch loss 0.0476, batch acc 0.9976
20:54:28.445   Training iter 100, batch loss 0.0714, batch acc 0.9970
20:54:28.686   Training iter 150, batch loss 0.0676, batch acc 0.9978
20:54:28.952   Training iter 200, batch loss 0.0841, batch acc 0.9952
20:54:29.243   Training iter 250, batch loss 0.1030, batch acc 0.9938
20:54:29.539   Training iter 300, batch loss 0.1331, batch acc 0.9924
20:54:29.737   Training iter 350, batch loss 0.1046, batch acc 0.9938
20:54:29.990   Training iter 400, batch loss 0.1109, batch acc 0.9930
20:54:30.216   Training iter 450, batch loss 0.0547, batch acc 0.9974
20:54:30.858   Training iter 500, batch loss 0.0782, batch acc 0.9946
20:54:31.152   Training iter 550, batch loss 0.0565, batch acc 0.9976
20:54:31.419   Training iter 600, batch loss 0.0726, batch acc 0.9960
20:54:31.419 Training @ 93 epoch...
20:54:31.671   Training iter 50, batch loss 0.0497, batch acc 0.9970
20:54:31.942   Training iter 100, batch loss 0.0484, batch acc 0.9968
20:54:32.238   Training iter 150, batch loss 0.0556, batch acc 0.9966
20:54:32.476   Training iter 200, batch loss 0.0530, batch acc 0.9970
20:54:32.691   Training iter 250, batch loss 0.0877, batch acc 0.9952
20:54:32.879   Training iter 300, batch loss 0.1086, batch acc 0.9930
20:54:33.092   Training iter 350, batch loss 0.1006, batch acc 0.9944
20:54:33.307   Training iter 400, batch loss 0.0929, batch acc 0.9954
20:54:33.472   Training iter 450, batch loss 0.0887, batch acc 0.9946
20:54:33.685   Training iter 500, batch loss 0.1190, batch acc 0.9926
20:54:33.875   Training iter 550, batch loss 0.1084, batch acc 0.9934
20:54:34.084   Training iter 600, batch loss 0.0887, batch acc 0.9954
20:54:34.085 Training @ 94 epoch...
20:54:34.317   Training iter 50, batch loss 0.0737, batch acc 0.9960
20:54:34.562   Training iter 100, batch loss 0.0792, batch acc 0.9960
20:54:34.794   Training iter 150, batch loss 0.0363, batch acc 0.9984
20:54:35.082   Training iter 200, batch loss 0.0693, batch acc 0.9966
20:54:35.382   Training iter 250, batch loss 0.1279, batch acc 0.9924
20:54:35.585   Training iter 300, batch loss 0.1037, batch acc 0.9932
20:54:35.927   Training iter 350, batch loss 0.0990, batch acc 0.9938
20:54:36.189   Training iter 400, batch loss 0.0773, batch acc 0.9946
20:54:36.368   Training iter 450, batch loss 0.0635, batch acc 0.9962
20:54:36.595   Training iter 500, batch loss 0.0654, batch acc 0.9962
20:54:36.832   Training iter 550, batch loss 0.0584, batch acc 0.9964
20:54:37.034   Training iter 600, batch loss 0.0514, batch acc 0.9972
20:54:37.035 Training @ 95 epoch...
20:54:37.302   Training iter 50, batch loss 0.0526, batch acc 0.9966
20:54:37.541   Training iter 100, batch loss 0.0430, batch acc 0.9984
20:54:38.033   Training iter 150, batch loss 0.0406, batch acc 0.9984
20:54:38.354   Training iter 200, batch loss 0.0682, batch acc 0.9966
20:54:38.636   Training iter 250, batch loss 0.0538, batch acc 0.9968
20:54:38.838   Training iter 300, batch loss 0.0547, batch acc 0.9972
20:54:39.035   Training iter 350, batch loss 0.0964, batch acc 0.9934
20:54:39.225   Training iter 400, batch loss 0.1068, batch acc 0.9930
20:54:39.409   Training iter 450, batch loss 0.0831, batch acc 0.9950
20:54:39.611   Training iter 500, batch loss 0.0745, batch acc 0.9964
20:54:39.806   Training iter 550, batch loss 0.0642, batch acc 0.9954
20:54:40.013   Training iter 600, batch loss 0.0503, batch acc 0.9980
20:54:40.015 Testing @ 95 epoch...
20:54:40.171     Testing, total mean loss 0.38005, total acc 0.98240
20:54:40.171 Training @ 96 epoch...
20:54:40.391   Training iter 50, batch loss 0.0659, batch acc 0.9962
20:54:40.629   Training iter 100, batch loss 0.0741, batch acc 0.9952
20:54:40.864   Training iter 150, batch loss 0.0641, batch acc 0.9966
20:54:41.135   Training iter 200, batch loss 0.0716, batch acc 0.9954
20:54:41.341   Training iter 250, batch loss 0.0599, batch acc 0.9966
20:54:41.529   Training iter 300, batch loss 0.0529, batch acc 0.9972
20:54:41.734   Training iter 350, batch loss 0.0695, batch acc 0.9950
20:54:41.917   Training iter 400, batch loss 0.0735, batch acc 0.9956
20:54:42.122   Training iter 450, batch loss 0.0712, batch acc 0.9952
20:54:42.325   Training iter 500, batch loss 0.0644, batch acc 0.9964
20:54:42.511   Training iter 550, batch loss 0.0683, batch acc 0.9956
20:54:42.756   Training iter 600, batch loss 0.0577, batch acc 0.9964
20:54:42.756 Training @ 97 epoch...
20:54:43.020   Training iter 50, batch loss 0.0413, batch acc 0.9978
20:54:43.351   Training iter 100, batch loss 0.0596, batch acc 0.9970
20:54:43.612   Training iter 150, batch loss 0.0733, batch acc 0.9960
20:54:43.885   Training iter 200, batch loss 0.0812, batch acc 0.9962
20:54:44.182   Training iter 250, batch loss 0.0684, batch acc 0.9970
20:54:44.371   Training iter 300, batch loss 0.0552, batch acc 0.9970
20:54:44.568   Training iter 350, batch loss 0.0794, batch acc 0.9954
20:54:44.770   Training iter 400, batch loss 0.0690, batch acc 0.9958
20:54:44.969   Training iter 450, batch loss 0.0497, batch acc 0.9974
20:54:45.192   Training iter 500, batch loss 0.0763, batch acc 0.9948
20:54:45.394   Training iter 550, batch loss 0.0646, batch acc 0.9960
20:54:45.668   Training iter 600, batch loss 0.0949, batch acc 0.9944
20:54:45.670 Training @ 98 epoch...
20:54:45.854   Training iter 50, batch loss 0.0737, batch acc 0.9960
20:54:46.059   Training iter 100, batch loss 0.0415, batch acc 0.9984
20:54:46.284   Training iter 150, batch loss 0.0485, batch acc 0.9972
20:54:46.471   Training iter 200, batch loss 0.0615, batch acc 0.9968
20:54:46.683   Training iter 250, batch loss 0.0898, batch acc 0.9960
20:54:46.947   Training iter 300, batch loss 0.0708, batch acc 0.9960
20:54:47.170   Training iter 350, batch loss 0.0619, batch acc 0.9964
20:54:47.397   Training iter 400, batch loss 0.0588, batch acc 0.9974
20:54:47.579   Training iter 450, batch loss 0.0863, batch acc 0.9946
20:54:47.793   Training iter 500, batch loss 0.0590, batch acc 0.9970
20:54:48.016   Training iter 550, batch loss 0.0754, batch acc 0.9952
20:54:48.211   Training iter 600, batch loss 0.1091, batch acc 0.9930
20:54:48.212 Training @ 99 epoch...
20:54:48.399   Training iter 50, batch loss 0.0749, batch acc 0.9958
20:54:48.615   Training iter 100, batch loss 0.1084, batch acc 0.9936
20:54:48.818   Training iter 150, batch loss 0.0742, batch acc 0.9956
20:54:49.066   Training iter 200, batch loss 0.0958, batch acc 0.9952
20:54:49.343   Training iter 250, batch loss 0.0739, batch acc 0.9954
20:54:49.557   Training iter 300, batch loss 0.0772, batch acc 0.9958
20:54:49.818   Training iter 350, batch loss 0.0473, batch acc 0.9968
20:54:50.058   Training iter 400, batch loss 0.0663, batch acc 0.9960
20:54:50.255   Training iter 450, batch loss 0.0565, batch acc 0.9970
20:54:50.455   Training iter 500, batch loss 0.0602, batch acc 0.9972
20:54:50.645   Training iter 550, batch loss 0.1022, batch acc 0.9942
20:54:50.842   Training iter 600, batch loss 0.0851, batch acc 0.9944
20:54:50.846 Testing @ 99 epoch...
20:54:50.946     Testing, total mean loss 0.33166, total acc 0.98230