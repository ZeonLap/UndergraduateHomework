18:55:32.793 Training @ 0 epoch...
18:55:33.051   Training iter 50, batch loss 0.7910, batch acc 0.4456
18:55:33.256   Training iter 100, batch loss 0.4982, batch acc 0.7606
18:55:33.345   Training iter 150, batch loss 0.3901, batch acc 0.8464
18:55:33.488   Training iter 200, batch loss 0.3183, batch acc 0.8658
18:55:33.693   Training iter 250, batch loss 0.2692, batch acc 0.8872
18:55:33.852   Training iter 300, batch loss 0.2440, batch acc 0.8958
18:55:34.083   Training iter 350, batch loss 0.2348, batch acc 0.8978
18:55:34.234   Training iter 400, batch loss 0.2167, batch acc 0.9054
18:55:34.404   Training iter 450, batch loss 0.2065, batch acc 0.9120
18:55:34.578   Training iter 500, batch loss 0.1989, batch acc 0.9130
18:55:34.787   Training iter 550, batch loss 0.1914, batch acc 0.9198
18:55:34.890   Training iter 600, batch loss 0.1882, batch acc 0.9174
18:55:34.899 Testing @ 0 epoch...
18:55:34.999     Testing, total mean loss 0.17143, total acc 0.92890
18:55:34.999 Training @ 1 epoch...
18:55:35.166   Training iter 50, batch loss 0.1819, batch acc 0.9234
18:55:35.265   Training iter 100, batch loss 0.1775, batch acc 0.9278
18:55:35.411   Training iter 150, batch loss 0.1696, batch acc 0.9356
18:55:35.580   Training iter 200, batch loss 0.1725, batch acc 0.9304
18:55:35.783   Training iter 250, batch loss 0.1674, batch acc 0.9326
18:55:35.901   Training iter 300, batch loss 0.1617, batch acc 0.9340
18:55:35.975   Training iter 350, batch loss 0.1589, batch acc 0.9380
18:55:36.059   Training iter 400, batch loss 0.1651, batch acc 0.9318
18:55:36.163   Training iter 450, batch loss 0.1594, batch acc 0.9374
18:55:36.348   Training iter 500, batch loss 0.1552, batch acc 0.9428
18:55:36.457   Training iter 550, batch loss 0.1634, batch acc 0.9344
18:55:36.543   Training iter 600, batch loss 0.1556, batch acc 0.9408
18:55:36.544 Training @ 2 epoch...
18:55:36.665   Training iter 50, batch loss 0.1510, batch acc 0.9414
18:55:36.761   Training iter 100, batch loss 0.1503, batch acc 0.9436
18:55:36.865   Training iter 150, batch loss 0.1461, batch acc 0.9442
18:55:36.989   Training iter 200, batch loss 0.1445, batch acc 0.9466
18:55:37.088   Training iter 250, batch loss 0.1407, batch acc 0.9508
18:55:37.182   Training iter 300, batch loss 0.1381, batch acc 0.9506
18:55:37.306   Training iter 350, batch loss 0.1371, batch acc 0.9520
18:55:37.402   Training iter 400, batch loss 0.1407, batch acc 0.9468
18:55:37.486   Training iter 450, batch loss 0.1350, batch acc 0.9522
18:55:37.633   Training iter 500, batch loss 0.1332, batch acc 0.9552
18:55:37.820   Training iter 550, batch loss 0.1303, batch acc 0.9604
18:55:37.917   Training iter 600, batch loss 0.1323, batch acc 0.9514
18:55:37.918 Training @ 3 epoch...
18:55:38.055   Training iter 50, batch loss 0.1351, batch acc 0.9516
18:55:38.223   Training iter 100, batch loss 0.1246, batch acc 0.9576
18:55:38.345   Training iter 150, batch loss 0.1278, batch acc 0.9540
18:55:38.415   Training iter 200, batch loss 0.1247, batch acc 0.9576
18:55:38.497   Training iter 250, batch loss 0.1297, batch acc 0.9528
18:55:38.599   Training iter 300, batch loss 0.1249, batch acc 0.9604
18:55:38.675   Training iter 350, batch loss 0.1237, batch acc 0.9600
18:55:38.807   Training iter 400, batch loss 0.1301, batch acc 0.9530
18:55:38.904   Training iter 450, batch loss 0.1246, batch acc 0.9580
18:55:39.007   Training iter 500, batch loss 0.1235, batch acc 0.9596
18:55:39.089   Training iter 550, batch loss 0.1270, batch acc 0.9550
18:55:39.167   Training iter 600, batch loss 0.1279, batch acc 0.9546
18:55:39.168 Training @ 4 epoch...
18:55:39.242   Training iter 50, batch loss 0.1210, batch acc 0.9622
18:55:39.401   Training iter 100, batch loss 0.1263, batch acc 0.9578
18:55:39.483   Training iter 150, batch loss 0.1176, batch acc 0.9600
18:55:39.561   Training iter 200, batch loss 0.1179, batch acc 0.9612
18:55:39.653   Training iter 250, batch loss 0.1181, batch acc 0.9588
18:55:39.754   Training iter 300, batch loss 0.1184, batch acc 0.9616
18:55:39.837   Training iter 350, batch loss 0.1155, batch acc 0.9652
18:55:39.916   Training iter 400, batch loss 0.1174, batch acc 0.9634
18:55:40.015   Training iter 450, batch loss 0.1210, batch acc 0.9588
18:55:40.115   Training iter 500, batch loss 0.1187, batch acc 0.9588
18:55:40.239   Training iter 550, batch loss 0.1130, batch acc 0.9668
18:55:40.316   Training iter 600, batch loss 0.1139, batch acc 0.9608
18:55:40.316 Training @ 5 epoch...
18:55:40.400   Training iter 50, batch loss 0.1191, batch acc 0.9618
18:55:40.530   Training iter 100, batch loss 0.1102, batch acc 0.9662
18:55:40.633   Training iter 150, batch loss 0.1114, batch acc 0.9666
18:55:40.722   Training iter 200, batch loss 0.1209, batch acc 0.9600
18:55:40.795   Training iter 250, batch loss 0.1135, batch acc 0.9650
18:55:40.893   Training iter 300, batch loss 0.1093, batch acc 0.9676
18:55:40.984   Training iter 350, batch loss 0.1100, batch acc 0.9680
18:55:41.120   Training iter 400, batch loss 0.1132, batch acc 0.9650
18:55:41.193   Training iter 450, batch loss 0.1120, batch acc 0.9640
18:55:41.282   Training iter 500, batch loss 0.1158, batch acc 0.9590
18:55:41.359   Training iter 550, batch loss 0.1081, batch acc 0.9692
18:55:41.439   Training iter 600, batch loss 0.1076, batch acc 0.9674
18:55:41.439 Testing @ 5 epoch...
18:55:41.482     Testing, total mean loss 0.11091, total acc 0.96410
18:55:41.482 Training @ 6 epoch...
18:55:41.557   Training iter 50, batch loss 0.1032, batch acc 0.9702
18:55:41.677   Training iter 100, batch loss 0.1002, batch acc 0.9730
18:55:41.753   Training iter 150, batch loss 0.1062, batch acc 0.9676
18:55:41.883   Training iter 200, batch loss 0.1019, batch acc 0.9696
18:55:41.997   Training iter 250, batch loss 0.1079, batch acc 0.9666
18:55:42.111   Training iter 300, batch loss 0.1088, batch acc 0.9670
18:55:42.276   Training iter 350, batch loss 0.1113, batch acc 0.9664
18:55:42.429   Training iter 400, batch loss 0.1079, batch acc 0.9642
18:55:42.616   Training iter 450, batch loss 0.1051, batch acc 0.9666
18:55:42.847   Training iter 500, batch loss 0.1073, batch acc 0.9672
18:55:43.013   Training iter 550, batch loss 0.1097, batch acc 0.9666
18:55:43.127   Training iter 600, batch loss 0.1082, batch acc 0.9630
18:55:43.127 Training @ 7 epoch...
18:55:43.267   Training iter 50, batch loss 0.1064, batch acc 0.9652
18:55:43.542   Training iter 100, batch loss 0.1026, batch acc 0.9688
18:55:43.642   Training iter 150, batch loss 0.0982, batch acc 0.9710
18:55:43.911   Training iter 200, batch loss 0.1050, batch acc 0.9648
18:55:44.040   Training iter 250, batch loss 0.1004, batch acc 0.9700
18:55:44.298   Training iter 300, batch loss 0.1079, batch acc 0.9650
18:55:44.399   Training iter 350, batch loss 0.1049, batch acc 0.9672
18:55:44.500   Training iter 400, batch loss 0.0988, batch acc 0.9726
18:55:44.755   Training iter 450, batch loss 0.1003, batch acc 0.9706
18:55:44.839   Training iter 500, batch loss 0.0974, batch acc 0.9712
18:55:44.949   Training iter 550, batch loss 0.1026, batch acc 0.9684
18:55:45.085   Training iter 600, batch loss 0.1047, batch acc 0.9682
18:55:45.086 Training @ 8 epoch...
18:55:45.200   Training iter 50, batch loss 0.0983, batch acc 0.9710
18:55:45.327   Training iter 100, batch loss 0.0971, batch acc 0.9720
18:55:45.568   Training iter 150, batch loss 0.0981, batch acc 0.9728
18:55:45.690   Training iter 200, batch loss 0.0975, batch acc 0.9702
18:55:45.953   Training iter 250, batch loss 0.1019, batch acc 0.9692
18:55:46.089   Training iter 300, batch loss 0.1027, batch acc 0.9714
18:55:46.231   Training iter 350, batch loss 0.0970, batch acc 0.9720
18:55:46.433   Training iter 400, batch loss 0.0976, batch acc 0.9706
18:55:46.519   Training iter 450, batch loss 0.0999, batch acc 0.9696
18:55:46.650   Training iter 500, batch loss 0.1004, batch acc 0.9690
18:55:46.818   Training iter 550, batch loss 0.1023, batch acc 0.9668
18:55:46.921   Training iter 600, batch loss 0.1014, batch acc 0.9680
18:55:46.922 Training @ 9 epoch...
18:55:47.070   Training iter 50, batch loss 0.1011, batch acc 0.9672
18:55:47.278   Training iter 100, batch loss 0.0996, batch acc 0.9708
18:55:47.448   Training iter 150, batch loss 0.1020, batch acc 0.9694
18:55:47.602   Training iter 200, batch loss 0.0959, batch acc 0.9720
18:55:47.709   Training iter 250, batch loss 0.0964, batch acc 0.9730
18:55:47.814   Training iter 300, batch loss 0.1008, batch acc 0.9676
18:55:47.925   Training iter 350, batch loss 0.0955, batch acc 0.9736
18:55:48.032   Training iter 400, batch loss 0.0976, batch acc 0.9708
18:55:48.160   Training iter 450, batch loss 0.0953, batch acc 0.9730
18:55:48.277   Training iter 500, batch loss 0.0934, batch acc 0.9696
18:55:48.417   Training iter 550, batch loss 0.0966, batch acc 0.9742
18:55:48.541   Training iter 600, batch loss 0.0947, batch acc 0.9740
18:55:48.543 Training @ 10 epoch...
18:55:48.664   Training iter 50, batch loss 0.0935, batch acc 0.9754
18:55:48.787   Training iter 100, batch loss 0.0968, batch acc 0.9684
18:55:48.964   Training iter 150, batch loss 0.0977, batch acc 0.9698
18:55:49.080   Training iter 200, batch loss 0.0979, batch acc 0.9714
18:55:49.178   Training iter 250, batch loss 0.0963, batch acc 0.9742
18:55:49.252   Training iter 300, batch loss 0.0935, batch acc 0.9708
18:55:49.357   Training iter 350, batch loss 0.0900, batch acc 0.9748
18:55:49.445   Training iter 400, batch loss 0.0920, batch acc 0.9744
18:55:49.520   Training iter 450, batch loss 0.0959, batch acc 0.9714
18:55:49.601   Training iter 500, batch loss 0.0934, batch acc 0.9732
18:55:49.727   Training iter 550, batch loss 0.0949, batch acc 0.9740
18:55:49.820   Training iter 600, batch loss 0.0894, batch acc 0.9714
18:55:49.821 Testing @ 10 epoch...
18:55:49.875     Testing, total mean loss 0.10258, total acc 0.96780
18:55:49.875 Training @ 11 epoch...
18:55:49.981   Training iter 50, batch loss 0.0923, batch acc 0.9728
18:55:50.080   Training iter 100, batch loss 0.0925, batch acc 0.9738
18:55:50.203   Training iter 150, batch loss 0.0931, batch acc 0.9726
18:55:50.299   Training iter 200, batch loss 0.0940, batch acc 0.9712
18:55:50.389   Training iter 250, batch loss 0.0953, batch acc 0.9702
18:55:50.508   Training iter 300, batch loss 0.0863, batch acc 0.9786
18:55:50.594   Training iter 350, batch loss 0.0898, batch acc 0.9744
18:55:50.686   Training iter 400, batch loss 0.0944, batch acc 0.9696
18:55:50.805   Training iter 450, batch loss 0.0909, batch acc 0.9740
18:55:50.910   Training iter 500, batch loss 0.0911, batch acc 0.9746
18:55:51.021   Training iter 550, batch loss 0.0958, batch acc 0.9692
18:55:51.129   Training iter 600, batch loss 0.0868, batch acc 0.9760
18:55:51.131 Training @ 12 epoch...
18:55:51.247   Training iter 50, batch loss 0.0936, batch acc 0.9712
18:55:51.361   Training iter 100, batch loss 0.0874, batch acc 0.9762
18:55:51.459   Training iter 150, batch loss 0.0927, batch acc 0.9726
18:55:51.558   Training iter 200, batch loss 0.0887, batch acc 0.9754
18:55:51.661   Training iter 250, batch loss 0.0932, batch acc 0.9738
18:55:51.796   Training iter 300, batch loss 0.0842, batch acc 0.9786
18:55:51.902   Training iter 350, batch loss 0.0924, batch acc 0.9738
18:55:51.999   Training iter 400, batch loss 0.0909, batch acc 0.9730
18:55:52.090   Training iter 450, batch loss 0.0971, batch acc 0.9690
18:55:52.190   Training iter 500, batch loss 0.0915, batch acc 0.9718
18:55:52.285   Training iter 550, batch loss 0.0867, batch acc 0.9770
18:55:52.391   Training iter 600, batch loss 0.0873, batch acc 0.9754
18:55:52.394 Training @ 13 epoch...
18:55:52.477   Training iter 50, batch loss 0.0867, batch acc 0.9744
18:55:52.576   Training iter 100, batch loss 0.0847, batch acc 0.9774
18:55:52.680   Training iter 150, batch loss 0.0882, batch acc 0.9750
18:55:52.759   Training iter 200, batch loss 0.0890, batch acc 0.9748
18:55:52.862   Training iter 250, batch loss 0.0871, batch acc 0.9770
18:55:52.964   Training iter 300, batch loss 0.0883, batch acc 0.9740
18:55:53.059   Training iter 350, batch loss 0.0894, batch acc 0.9748
18:55:53.136   Training iter 400, batch loss 0.0900, batch acc 0.9738
18:55:53.229   Training iter 450, batch loss 0.0896, batch acc 0.9728
18:55:53.316   Training iter 500, batch loss 0.0932, batch acc 0.9712
18:55:53.400   Training iter 550, batch loss 0.0863, batch acc 0.9744
18:55:53.500   Training iter 600, batch loss 0.0886, batch acc 0.9748
18:55:53.502 Training @ 14 epoch...
18:55:53.597   Training iter 50, batch loss 0.0860, batch acc 0.9756
18:55:53.692   Training iter 100, batch loss 0.0863, batch acc 0.9764
18:55:53.792   Training iter 150, batch loss 0.0877, batch acc 0.9760
18:55:53.869   Training iter 200, batch loss 0.0849, batch acc 0.9788
18:55:53.984   Training iter 250, batch loss 0.0807, batch acc 0.9774
18:55:54.109   Training iter 300, batch loss 0.0893, batch acc 0.9724
18:55:54.203   Training iter 350, batch loss 0.0860, batch acc 0.9764
18:55:54.316   Training iter 400, batch loss 0.0929, batch acc 0.9696
18:55:54.425   Training iter 450, batch loss 0.0873, batch acc 0.9712
18:55:54.534   Training iter 500, batch loss 0.0862, batch acc 0.9770
18:55:54.663   Training iter 550, batch loss 0.0890, batch acc 0.9736
18:55:54.795   Training iter 600, batch loss 0.0863, batch acc 0.9768
18:55:54.797 Training @ 15 epoch...
18:55:54.926   Training iter 50, batch loss 0.0850, batch acc 0.9778
18:55:55.029   Training iter 100, batch loss 0.0787, batch acc 0.9818
18:55:55.116   Training iter 150, batch loss 0.0846, batch acc 0.9760
18:55:55.265   Training iter 200, batch loss 0.0861, batch acc 0.9742
18:55:55.383   Training iter 250, batch loss 0.0895, batch acc 0.9730
18:55:55.495   Training iter 300, batch loss 0.0909, batch acc 0.9722
18:55:55.644   Training iter 350, batch loss 0.0839, batch acc 0.9782
18:55:55.741   Training iter 400, batch loss 0.0803, batch acc 0.9806
18:55:55.837   Training iter 450, batch loss 0.0899, batch acc 0.9742
18:55:55.998   Training iter 500, batch loss 0.0888, batch acc 0.9740
18:55:56.094   Training iter 550, batch loss 0.0882, batch acc 0.9742
18:55:56.201   Training iter 600, batch loss 0.0841, batch acc 0.9778
18:55:56.201 Testing @ 15 epoch...
18:55:56.298     Testing, total mean loss 0.09400, total acc 0.96990
18:55:56.298 Training @ 16 epoch...
18:55:56.529   Training iter 50, batch loss 0.0856, batch acc 0.9768
18:55:56.765   Training iter 100, batch loss 0.0801, batch acc 0.9784
18:55:56.954   Training iter 150, batch loss 0.0807, batch acc 0.9786
18:55:57.099   Training iter 200, batch loss 0.0831, batch acc 0.9752
18:55:57.271   Training iter 250, batch loss 0.0859, batch acc 0.9768
18:55:57.394   Training iter 300, batch loss 0.0833, batch acc 0.9770
18:55:57.473   Training iter 350, batch loss 0.0806, batch acc 0.9796
18:55:57.607   Training iter 400, batch loss 0.0886, batch acc 0.9732
18:55:57.701   Training iter 450, batch loss 0.0839, batch acc 0.9756
18:55:57.782   Training iter 500, batch loss 0.0901, batch acc 0.9748
18:55:57.882   Training iter 550, batch loss 0.0911, batch acc 0.9716
18:55:57.971   Training iter 600, batch loss 0.0860, batch acc 0.9744
18:55:57.972 Training @ 17 epoch...
18:55:58.093   Training iter 50, batch loss 0.0827, batch acc 0.9774
18:55:58.200   Training iter 100, batch loss 0.0834, batch acc 0.9780
18:55:58.302   Training iter 150, batch loss 0.0830, batch acc 0.9784
18:55:58.403   Training iter 200, batch loss 0.0827, batch acc 0.9782
18:55:58.501   Training iter 250, batch loss 0.0841, batch acc 0.9780
18:55:58.593   Training iter 300, batch loss 0.0836, batch acc 0.9764
18:55:58.678   Training iter 350, batch loss 0.0829, batch acc 0.9766
18:55:58.806   Training iter 400, batch loss 0.0831, batch acc 0.9760
18:55:58.920   Training iter 450, batch loss 0.0858, batch acc 0.9774
18:55:59.012   Training iter 500, batch loss 0.0857, batch acc 0.9750
18:55:59.156   Training iter 550, batch loss 0.0841, batch acc 0.9740
18:55:59.243   Training iter 600, batch loss 0.0880, batch acc 0.9738
18:55:59.244 Training @ 18 epoch...
18:55:59.354   Training iter 50, batch loss 0.0816, batch acc 0.9778
18:55:59.481   Training iter 100, batch loss 0.0800, batch acc 0.9782
18:55:59.626   Training iter 150, batch loss 0.0822, batch acc 0.9772
18:55:59.729   Training iter 200, batch loss 0.0813, batch acc 0.9772
18:55:59.828   Training iter 250, batch loss 0.0838, batch acc 0.9746
18:55:59.942   Training iter 300, batch loss 0.0840, batch acc 0.9760
18:56:00.078   Training iter 350, batch loss 0.0807, batch acc 0.9784
18:56:00.253   Training iter 400, batch loss 0.0800, batch acc 0.9788
18:56:00.418   Training iter 450, batch loss 0.0802, batch acc 0.9760
18:56:00.512   Training iter 500, batch loss 0.0852, batch acc 0.9760
18:56:00.631   Training iter 550, batch loss 0.0865, batch acc 0.9750
18:56:00.832   Training iter 600, batch loss 0.0829, batch acc 0.9740
18:56:00.833 Training @ 19 epoch...
18:56:01.028   Training iter 50, batch loss 0.0803, batch acc 0.9786
18:56:01.168   Training iter 100, batch loss 0.0824, batch acc 0.9782
18:56:01.302   Training iter 150, batch loss 0.0861, batch acc 0.9744
18:56:01.431   Training iter 200, batch loss 0.0814, batch acc 0.9806
18:56:01.648   Training iter 250, batch loss 0.0836, batch acc 0.9758
18:56:01.771   Training iter 300, batch loss 0.0810, batch acc 0.9794
18:56:01.893   Training iter 350, batch loss 0.0787, batch acc 0.9798
18:56:02.030   Training iter 400, batch loss 0.0793, batch acc 0.9774
18:56:02.196   Training iter 450, batch loss 0.0827, batch acc 0.9742
18:56:02.330   Training iter 500, batch loss 0.0806, batch acc 0.9720
18:56:02.541   Training iter 550, batch loss 0.0793, batch acc 0.9786
18:56:02.656   Training iter 600, batch loss 0.0835, batch acc 0.9744
18:56:02.657 Training @ 20 epoch...
18:56:02.759   Training iter 50, batch loss 0.0751, batch acc 0.9810
18:56:02.884   Training iter 100, batch loss 0.0789, batch acc 0.9790
18:56:03.054   Training iter 150, batch loss 0.0788, batch acc 0.9780
18:56:03.196   Training iter 200, batch loss 0.0790, batch acc 0.9790
18:56:03.291   Training iter 250, batch loss 0.0804, batch acc 0.9774
18:56:03.417   Training iter 300, batch loss 0.0794, batch acc 0.9784
18:56:03.536   Training iter 350, batch loss 0.0874, batch acc 0.9740
18:56:03.632   Training iter 400, batch loss 0.0798, batch acc 0.9800
18:56:03.751   Training iter 450, batch loss 0.0805, batch acc 0.9776
18:56:03.863   Training iter 500, batch loss 0.0842, batch acc 0.9734
18:56:03.965   Training iter 550, batch loss 0.0853, batch acc 0.9778
18:56:04.083   Training iter 600, batch loss 0.0821, batch acc 0.9764
18:56:04.083 Testing @ 20 epoch...
18:56:04.171     Testing, total mean loss 0.08767, total acc 0.97180
18:56:04.171 Training @ 21 epoch...
18:56:04.344   Training iter 50, batch loss 0.0760, batch acc 0.9810
18:56:04.437   Training iter 100, batch loss 0.0834, batch acc 0.9748
18:56:04.528   Training iter 150, batch loss 0.0776, batch acc 0.9802
18:56:04.615   Training iter 200, batch loss 0.0811, batch acc 0.9760
18:56:04.705   Training iter 250, batch loss 0.0797, batch acc 0.9796
18:56:04.797   Training iter 300, batch loss 0.0810, batch acc 0.9760
18:56:04.898   Training iter 350, batch loss 0.0832, batch acc 0.9764
18:56:04.993   Training iter 400, batch loss 0.0810, batch acc 0.9800
18:56:05.146   Training iter 450, batch loss 0.0818, batch acc 0.9776
18:56:05.266   Training iter 500, batch loss 0.0790, batch acc 0.9798
18:56:05.378   Training iter 550, batch loss 0.0817, batch acc 0.9742
18:56:05.503   Training iter 600, batch loss 0.0773, batch acc 0.9808
18:56:05.505 Training @ 22 epoch...
18:56:05.630   Training iter 50, batch loss 0.0728, batch acc 0.9810
18:56:05.750   Training iter 100, batch loss 0.0754, batch acc 0.9792
18:56:05.879   Training iter 150, batch loss 0.0759, batch acc 0.9790
18:56:06.037   Training iter 200, batch loss 0.0800, batch acc 0.9782
18:56:06.154   Training iter 250, batch loss 0.0807, batch acc 0.9760
18:56:06.236   Training iter 300, batch loss 0.0853, batch acc 0.9734
18:56:06.346   Training iter 350, batch loss 0.0780, batch acc 0.9792
18:56:06.454   Training iter 400, batch loss 0.0856, batch acc 0.9732
18:56:06.583   Training iter 450, batch loss 0.0819, batch acc 0.9764
18:56:06.725   Training iter 500, batch loss 0.0752, batch acc 0.9814
18:56:06.864   Training iter 550, batch loss 0.0769, batch acc 0.9804
18:56:06.988   Training iter 600, batch loss 0.0787, batch acc 0.9776
18:56:06.989 Training @ 23 epoch...
18:56:07.138   Training iter 50, batch loss 0.0750, batch acc 0.9804
18:56:07.313   Training iter 100, batch loss 0.0807, batch acc 0.9758
18:56:07.437   Training iter 150, batch loss 0.0737, batch acc 0.9814
18:56:07.605   Training iter 200, batch loss 0.0790, batch acc 0.9764
18:56:08.029   Training iter 250, batch loss 0.0772, batch acc 0.9804
18:56:08.175   Training iter 300, batch loss 0.0781, batch acc 0.9778
18:56:08.295   Training iter 350, batch loss 0.0792, batch acc 0.9780
18:56:08.412   Training iter 400, batch loss 0.0803, batch acc 0.9790
18:56:08.530   Training iter 450, batch loss 0.0784, batch acc 0.9784
18:56:08.701   Training iter 500, batch loss 0.0818, batch acc 0.9752
18:56:08.927   Training iter 550, batch loss 0.0800, batch acc 0.9764
18:56:09.128   Training iter 600, batch loss 0.0777, batch acc 0.9748
18:56:09.129 Training @ 24 epoch...
18:56:09.208   Training iter 50, batch loss 0.0770, batch acc 0.9782
18:56:09.304   Training iter 100, batch loss 0.0752, batch acc 0.9812
18:56:09.433   Training iter 150, batch loss 0.0783, batch acc 0.9798
18:56:09.539   Training iter 200, batch loss 0.0805, batch acc 0.9770
18:56:09.622   Training iter 250, batch loss 0.0792, batch acc 0.9772
18:56:09.733   Training iter 300, batch loss 0.0721, batch acc 0.9820
18:56:09.828   Training iter 350, batch loss 0.0789, batch acc 0.9776
18:56:09.917   Training iter 400, batch loss 0.0785, batch acc 0.9812
18:56:10.047   Training iter 450, batch loss 0.0827, batch acc 0.9754
18:56:10.131   Training iter 500, batch loss 0.0787, batch acc 0.9760
18:56:10.215   Training iter 550, batch loss 0.0766, batch acc 0.9796
18:56:10.308   Training iter 600, batch loss 0.0797, batch acc 0.9768
18:56:10.310 Training @ 25 epoch...
18:56:10.404   Training iter 50, batch loss 0.0798, batch acc 0.9774
18:56:10.495   Training iter 100, batch loss 0.0756, batch acc 0.9810
18:56:10.601   Training iter 150, batch loss 0.0797, batch acc 0.9776
18:56:10.736   Training iter 200, batch loss 0.0777, batch acc 0.9782
18:56:10.894   Training iter 250, batch loss 0.0722, batch acc 0.9812
18:56:11.008   Training iter 300, batch loss 0.0812, batch acc 0.9762
18:56:11.129   Training iter 350, batch loss 0.0765, batch acc 0.9796
18:56:11.270   Training iter 400, batch loss 0.0747, batch acc 0.9788
18:56:11.389   Training iter 450, batch loss 0.0776, batch acc 0.9766
18:56:11.498   Training iter 500, batch loss 0.0748, batch acc 0.9782
18:56:11.617   Training iter 550, batch loss 0.0776, batch acc 0.9792
18:56:11.713   Training iter 600, batch loss 0.0803, batch acc 0.9768
18:56:11.715 Testing @ 25 epoch...
18:56:11.761     Testing, total mean loss 0.08745, total acc 0.97400
18:56:11.761 Training @ 26 epoch...
18:56:11.847   Training iter 50, batch loss 0.0780, batch acc 0.9796
18:56:11.964   Training iter 100, batch loss 0.0800, batch acc 0.9794
18:56:12.065   Training iter 150, batch loss 0.0747, batch acc 0.9808
18:56:12.196   Training iter 200, batch loss 0.0800, batch acc 0.9782
18:56:12.294   Training iter 250, batch loss 0.0782, batch acc 0.9758
18:56:12.395   Training iter 300, batch loss 0.0755, batch acc 0.9820
18:56:12.480   Training iter 350, batch loss 0.0741, batch acc 0.9804
18:56:12.586   Training iter 400, batch loss 0.0767, batch acc 0.9798
18:56:12.665   Training iter 450, batch loss 0.0767, batch acc 0.9790
18:56:12.764   Training iter 500, batch loss 0.0782, batch acc 0.9778
18:56:12.851   Training iter 550, batch loss 0.0766, batch acc 0.9778
18:56:12.950   Training iter 600, batch loss 0.0723, batch acc 0.9802
18:56:12.950 Training @ 27 epoch...
18:56:13.186   Training iter 50, batch loss 0.0762, batch acc 0.9792
18:56:13.318   Training iter 100, batch loss 0.0758, batch acc 0.9790
18:56:13.438   Training iter 150, batch loss 0.0713, batch acc 0.9820
18:56:13.537   Training iter 200, batch loss 0.0720, batch acc 0.9810
18:56:13.666   Training iter 250, batch loss 0.0786, batch acc 0.9792
18:56:13.793   Training iter 300, batch loss 0.0780, batch acc 0.9778
18:56:13.933   Training iter 350, batch loss 0.0791, batch acc 0.9788
18:56:14.041   Training iter 400, batch loss 0.0767, batch acc 0.9796
18:56:14.156   Training iter 450, batch loss 0.0764, batch acc 0.9768
18:56:14.274   Training iter 500, batch loss 0.0795, batch acc 0.9754
18:56:14.389   Training iter 550, batch loss 0.0746, batch acc 0.9802
18:56:14.557   Training iter 600, batch loss 0.0737, batch acc 0.9812
18:56:14.558 Training @ 28 epoch...
18:56:14.654   Training iter 50, batch loss 0.0738, batch acc 0.9828
18:56:14.744   Training iter 100, batch loss 0.0711, batch acc 0.9820
18:56:14.833   Training iter 150, batch loss 0.0746, batch acc 0.9784
18:56:14.927   Training iter 200, batch loss 0.0736, batch acc 0.9812
18:56:15.059   Training iter 250, batch loss 0.0738, batch acc 0.9782
18:56:15.221   Training iter 300, batch loss 0.0742, batch acc 0.9820
18:56:15.328   Training iter 350, batch loss 0.0771, batch acc 0.9802
18:56:15.427   Training iter 400, batch loss 0.0752, batch acc 0.9786
18:56:15.520   Training iter 450, batch loss 0.0777, batch acc 0.9780
18:56:15.611   Training iter 500, batch loss 0.0762, batch acc 0.9792
18:56:15.705   Training iter 550, batch loss 0.0798, batch acc 0.9756
18:56:15.800   Training iter 600, batch loss 0.0750, batch acc 0.9776
18:56:15.800 Training @ 29 epoch...
18:56:15.893   Training iter 50, batch loss 0.0716, batch acc 0.9826
18:56:15.990   Training iter 100, batch loss 0.0710, batch acc 0.9818
18:56:16.076   Training iter 150, batch loss 0.0734, batch acc 0.9810
18:56:16.174   Training iter 200, batch loss 0.0762, batch acc 0.9770
18:56:16.258   Training iter 250, batch loss 0.0739, batch acc 0.9816
18:56:16.353   Training iter 300, batch loss 0.0710, batch acc 0.9814
18:56:16.563   Training iter 350, batch loss 0.0736, batch acc 0.9794
18:56:16.732   Training iter 400, batch loss 0.0800, batch acc 0.9760
18:56:16.935   Training iter 450, batch loss 0.0738, batch acc 0.9812
18:56:17.115   Training iter 500, batch loss 0.0768, batch acc 0.9762
18:56:17.330   Training iter 550, batch loss 0.0746, batch acc 0.9802
18:56:17.535   Training iter 600, batch loss 0.0798, batch acc 0.9764
18:56:17.535 Training @ 30 epoch...
18:56:17.689   Training iter 50, batch loss 0.0741, batch acc 0.9808
18:56:17.870   Training iter 100, batch loss 0.0725, batch acc 0.9806
18:56:17.964   Training iter 150, batch loss 0.0750, batch acc 0.9806
18:56:18.146   Training iter 200, batch loss 0.0748, batch acc 0.9772
18:56:18.244   Training iter 250, batch loss 0.0741, batch acc 0.9774
18:56:18.371   Training iter 300, batch loss 0.0735, batch acc 0.9800
18:56:18.455   Training iter 350, batch loss 0.0734, batch acc 0.9846
18:56:18.620   Training iter 400, batch loss 0.0786, batch acc 0.9766
18:56:18.757   Training iter 450, batch loss 0.0740, batch acc 0.9800
18:56:19.093   Training iter 500, batch loss 0.0767, batch acc 0.9780
18:56:19.189   Training iter 550, batch loss 0.0737, batch acc 0.9806
18:56:19.283   Training iter 600, batch loss 0.0703, batch acc 0.9844
18:56:19.284 Testing @ 30 epoch...
18:56:19.359     Testing, total mean loss 0.08284, total acc 0.97320
18:56:19.359 Training @ 31 epoch...
18:56:19.516   Training iter 50, batch loss 0.0716, batch acc 0.9846
18:56:19.672   Training iter 100, batch loss 0.0717, batch acc 0.9800
18:56:19.784   Training iter 150, batch loss 0.0748, batch acc 0.9796
18:56:19.926   Training iter 200, batch loss 0.0650, batch acc 0.9858
18:56:20.096   Training iter 250, batch loss 0.0734, batch acc 0.9822
18:56:20.184   Training iter 300, batch loss 0.0756, batch acc 0.9784
18:56:20.267   Training iter 350, batch loss 0.0750, batch acc 0.9780
18:56:20.346   Training iter 400, batch loss 0.0775, batch acc 0.9786
18:56:20.430   Training iter 450, batch loss 0.0776, batch acc 0.9794
18:56:20.510   Training iter 500, batch loss 0.0786, batch acc 0.9748
18:56:20.613   Training iter 550, batch loss 0.0718, batch acc 0.9808
18:56:20.703   Training iter 600, batch loss 0.0701, batch acc 0.9818
18:56:20.704 Training @ 32 epoch...
18:56:20.823   Training iter 50, batch loss 0.0740, batch acc 0.9790
18:56:20.950   Training iter 100, batch loss 0.0709, batch acc 0.9814
18:56:21.064   Training iter 150, batch loss 0.0721, batch acc 0.9802
18:56:21.204   Training iter 200, batch loss 0.0737, batch acc 0.9788
18:56:21.349   Training iter 250, batch loss 0.0700, batch acc 0.9808
18:56:21.495   Training iter 300, batch loss 0.0790, batch acc 0.9778
18:56:21.595   Training iter 350, batch loss 0.0728, batch acc 0.9822
18:56:21.691   Training iter 400, batch loss 0.0764, batch acc 0.9796
18:56:21.781   Training iter 450, batch loss 0.0781, batch acc 0.9764
18:56:21.868   Training iter 500, batch loss 0.0749, batch acc 0.9800
18:56:21.957   Training iter 550, batch loss 0.0716, batch acc 0.9832
18:56:22.064   Training iter 600, batch loss 0.0724, batch acc 0.9806
18:56:22.065 Training @ 33 epoch...
18:56:22.169   Training iter 50, batch loss 0.0726, batch acc 0.9834
18:56:22.278   Training iter 100, batch loss 0.0715, batch acc 0.9808
18:56:22.429   Training iter 150, batch loss 0.0730, batch acc 0.9804
18:56:22.604   Training iter 200, batch loss 0.0751, batch acc 0.9828
18:56:22.745   Training iter 250, batch loss 0.0703, batch acc 0.9810
18:56:23.074   Training iter 300, batch loss 0.0757, batch acc 0.9772
18:56:23.223   Training iter 350, batch loss 0.0697, batch acc 0.9828
18:56:23.398   Training iter 400, batch loss 0.0751, batch acc 0.9788
18:56:23.591   Training iter 450, batch loss 0.0731, batch acc 0.9786
18:56:23.691   Training iter 500, batch loss 0.0751, batch acc 0.9790
18:56:23.777   Training iter 550, batch loss 0.0766, batch acc 0.9774
18:56:23.878   Training iter 600, batch loss 0.0728, batch acc 0.9808
18:56:23.878 Training @ 34 epoch...
18:56:23.969   Training iter 50, batch loss 0.0719, batch acc 0.9816
18:56:24.075   Training iter 100, batch loss 0.0682, batch acc 0.9816
18:56:24.211   Training iter 150, batch loss 0.0744, batch acc 0.9798
18:56:24.295   Training iter 200, batch loss 0.0689, batch acc 0.9850
18:56:24.391   Training iter 250, batch loss 0.0749, batch acc 0.9808
18:56:24.469   Training iter 300, batch loss 0.0697, batch acc 0.9836
18:56:24.551   Training iter 350, batch loss 0.0737, batch acc 0.9826
18:56:24.632   Training iter 400, batch loss 0.0791, batch acc 0.9740
18:56:24.819   Training iter 450, batch loss 0.0729, batch acc 0.9794
18:56:24.997   Training iter 500, batch loss 0.0722, batch acc 0.9804
18:56:25.162   Training iter 550, batch loss 0.0741, batch acc 0.9788
18:56:25.332   Training iter 600, batch loss 0.0753, batch acc 0.9800
18:56:25.332 Training @ 35 epoch...
18:56:25.666   Training iter 50, batch loss 0.0709, batch acc 0.9814
18:56:25.792   Training iter 100, batch loss 0.0734, batch acc 0.9790
18:56:25.996   Training iter 150, batch loss 0.0762, batch acc 0.9788
18:56:26.182   Training iter 200, batch loss 0.0719, batch acc 0.9808
18:56:26.334   Training iter 250, batch loss 0.0696, batch acc 0.9806
18:56:26.495   Training iter 300, batch loss 0.0751, batch acc 0.9792
18:56:26.620   Training iter 350, batch loss 0.0711, batch acc 0.9796
18:56:26.751   Training iter 400, batch loss 0.0706, batch acc 0.9830
18:56:26.884   Training iter 450, batch loss 0.0753, batch acc 0.9794
18:56:27.036   Training iter 500, batch loss 0.0706, batch acc 0.9826
18:56:27.140   Training iter 550, batch loss 0.0715, batch acc 0.9804
18:56:27.361   Training iter 600, batch loss 0.0700, batch acc 0.9804
18:56:27.363 Testing @ 35 epoch...
18:56:27.469     Testing, total mean loss 0.08526, total acc 0.97340
18:56:27.469 Training @ 36 epoch...
18:56:27.566   Training iter 50, batch loss 0.0712, batch acc 0.9804
18:56:27.698   Training iter 100, batch loss 0.0717, batch acc 0.9810
18:56:27.847   Training iter 150, batch loss 0.0722, batch acc 0.9824
18:56:27.979   Training iter 200, batch loss 0.0748, batch acc 0.9796
18:56:28.130   Training iter 250, batch loss 0.0743, batch acc 0.9786
18:56:28.351   Training iter 300, batch loss 0.0738, batch acc 0.9792
18:56:28.562   Training iter 350, batch loss 0.0720, batch acc 0.9812
18:56:28.715   Training iter 400, batch loss 0.0742, batch acc 0.9804
18:56:28.905   Training iter 450, batch loss 0.0740, batch acc 0.9808
18:56:29.121   Training iter 500, batch loss 0.0775, batch acc 0.9788
18:56:29.251   Training iter 550, batch loss 0.0714, batch acc 0.9812
18:56:29.346   Training iter 600, batch loss 0.0690, batch acc 0.9802
18:56:29.347 Training @ 37 epoch...
18:56:29.449   Training iter 50, batch loss 0.0705, batch acc 0.9792
18:56:29.558   Training iter 100, batch loss 0.0730, batch acc 0.9800
18:56:29.652   Training iter 150, batch loss 0.0692, batch acc 0.9824
18:56:29.748   Training iter 200, batch loss 0.0694, batch acc 0.9810
18:56:29.843   Training iter 250, batch loss 0.0662, batch acc 0.9848
18:56:29.941   Training iter 300, batch loss 0.0775, batch acc 0.9770
18:56:30.041   Training iter 350, batch loss 0.0736, batch acc 0.9792
18:56:30.135   Training iter 400, batch loss 0.0718, batch acc 0.9822
18:56:30.240   Training iter 450, batch loss 0.0723, batch acc 0.9824
18:56:30.349   Training iter 500, batch loss 0.0733, batch acc 0.9814
18:56:30.465   Training iter 550, batch loss 0.0701, batch acc 0.9818
18:56:30.588   Training iter 600, batch loss 0.0723, batch acc 0.9812
18:56:30.589 Training @ 38 epoch...
18:56:30.769   Training iter 50, batch loss 0.0632, batch acc 0.9858
18:56:30.878   Training iter 100, batch loss 0.0700, batch acc 0.9810
18:56:31.014   Training iter 150, batch loss 0.0681, batch acc 0.9838
18:56:31.122   Training iter 200, batch loss 0.0724, batch acc 0.9784
18:56:31.241   Training iter 250, batch loss 0.0719, batch acc 0.9808
18:56:31.360   Training iter 300, batch loss 0.0708, batch acc 0.9812
18:56:31.519   Training iter 350, batch loss 0.0708, batch acc 0.9820
18:56:31.680   Training iter 400, batch loss 0.0686, batch acc 0.9830
18:56:31.836   Training iter 450, batch loss 0.0766, batch acc 0.9796
18:56:31.949   Training iter 500, batch loss 0.0778, batch acc 0.9786
18:56:32.119   Training iter 550, batch loss 0.0735, batch acc 0.9794
18:56:32.283   Training iter 600, batch loss 0.0754, batch acc 0.9774
18:56:32.285 Training @ 39 epoch...
18:56:32.566   Training iter 50, batch loss 0.0694, batch acc 0.9832
18:56:32.793   Training iter 100, batch loss 0.0658, batch acc 0.9842
18:56:32.981   Training iter 150, batch loss 0.0732, batch acc 0.9808
18:56:33.087   Training iter 200, batch loss 0.0763, batch acc 0.9780
18:56:33.262   Training iter 250, batch loss 0.0678, batch acc 0.9824
18:56:33.400   Training iter 300, batch loss 0.0713, batch acc 0.9786
18:56:33.581   Training iter 350, batch loss 0.0701, batch acc 0.9836
18:56:33.809   Training iter 400, batch loss 0.0746, batch acc 0.9794
18:56:33.962   Training iter 450, batch loss 0.0718, batch acc 0.9802
18:56:34.097   Training iter 500, batch loss 0.0694, batch acc 0.9816
18:56:34.222   Training iter 550, batch loss 0.0703, batch acc 0.9828
18:56:34.401   Training iter 600, batch loss 0.0729, batch acc 0.9792
18:56:34.403 Training @ 40 epoch...
18:56:34.540   Training iter 50, batch loss 0.0705, batch acc 0.9826
18:56:34.685   Training iter 100, batch loss 0.0685, batch acc 0.9826
18:56:34.870   Training iter 150, batch loss 0.0697, batch acc 0.9810
18:56:34.983   Training iter 200, batch loss 0.0667, batch acc 0.9850
18:56:35.070   Training iter 250, batch loss 0.0697, batch acc 0.9806
18:56:35.157   Training iter 300, batch loss 0.0726, batch acc 0.9790
18:56:35.245   Training iter 350, batch loss 0.0700, batch acc 0.9814
18:56:35.344   Training iter 400, batch loss 0.0732, batch acc 0.9760
18:56:35.424   Training iter 450, batch loss 0.0758, batch acc 0.9790
18:56:35.545   Training iter 500, batch loss 0.0755, batch acc 0.9786
18:56:35.639   Training iter 550, batch loss 0.0736, batch acc 0.9790
18:56:35.725   Training iter 600, batch loss 0.0698, batch acc 0.9860
18:56:35.726 Testing @ 40 epoch...
18:56:35.784     Testing, total mean loss 0.08472, total acc 0.97200
18:56:35.784 Training @ 41 epoch...
18:56:35.890   Training iter 50, batch loss 0.0702, batch acc 0.9824
18:56:35.989   Training iter 100, batch loss 0.0700, batch acc 0.9820
18:56:36.084   Training iter 150, batch loss 0.0729, batch acc 0.9778
18:56:36.164   Training iter 200, batch loss 0.0775, batch acc 0.9786
18:56:36.252   Training iter 250, batch loss 0.0738, batch acc 0.9814
18:56:36.349   Training iter 300, batch loss 0.0657, batch acc 0.9832
18:56:36.431   Training iter 350, batch loss 0.0705, batch acc 0.9800
18:56:36.542   Training iter 400, batch loss 0.0744, batch acc 0.9788
18:56:36.646   Training iter 450, batch loss 0.0693, batch acc 0.9828
18:56:36.742   Training iter 500, batch loss 0.0684, batch acc 0.9802
18:56:36.851   Training iter 550, batch loss 0.0694, batch acc 0.9834
18:56:36.954   Training iter 600, batch loss 0.0696, batch acc 0.9850
18:56:36.954 Training @ 42 epoch...
18:56:37.068   Training iter 50, batch loss 0.0682, batch acc 0.9806
18:56:37.194   Training iter 100, batch loss 0.0707, batch acc 0.9810
18:56:37.315   Training iter 150, batch loss 0.0733, batch acc 0.9820
18:56:37.452   Training iter 200, batch loss 0.0709, batch acc 0.9822
18:56:37.559   Training iter 250, batch loss 0.0699, batch acc 0.9794
18:56:37.713   Training iter 300, batch loss 0.0662, batch acc 0.9832
18:56:37.883   Training iter 350, batch loss 0.0717, batch acc 0.9824
18:56:37.984   Training iter 400, batch loss 0.0713, batch acc 0.9800
18:56:38.072   Training iter 450, batch loss 0.0701, batch acc 0.9806
18:56:38.163   Training iter 500, batch loss 0.0731, batch acc 0.9798
18:56:38.269   Training iter 550, batch loss 0.0685, batch acc 0.9802
18:56:38.388   Training iter 600, batch loss 0.0753, batch acc 0.9798
18:56:38.388 Training @ 43 epoch...
18:56:38.504   Training iter 50, batch loss 0.0665, batch acc 0.9822
18:56:38.611   Training iter 100, batch loss 0.0703, batch acc 0.9820
18:56:38.699   Training iter 150, batch loss 0.0709, batch acc 0.9792
18:56:38.788   Training iter 200, batch loss 0.0701, batch acc 0.9798
18:56:38.920   Training iter 250, batch loss 0.0760, batch acc 0.9800
18:56:39.010   Training iter 300, batch loss 0.0711, batch acc 0.9798
18:56:39.109   Training iter 350, batch loss 0.0726, batch acc 0.9796
18:56:39.198   Training iter 400, batch loss 0.0661, batch acc 0.9856
18:56:39.312   Training iter 450, batch loss 0.0703, batch acc 0.9792
18:56:39.407   Training iter 500, batch loss 0.0698, batch acc 0.9820
18:56:39.496   Training iter 550, batch loss 0.0722, batch acc 0.9800
18:56:39.628   Training iter 600, batch loss 0.0710, batch acc 0.9780
18:56:39.628 Training @ 44 epoch...
18:56:39.712   Training iter 50, batch loss 0.0730, batch acc 0.9808
18:56:39.870   Training iter 100, batch loss 0.0696, batch acc 0.9814
18:56:40.033   Training iter 150, batch loss 0.0704, batch acc 0.9822
18:56:40.168   Training iter 200, batch loss 0.0668, batch acc 0.9828
18:56:40.317   Training iter 250, batch loss 0.0681, batch acc 0.9820
18:56:40.434   Training iter 300, batch loss 0.0681, batch acc 0.9802
18:56:40.544   Training iter 350, batch loss 0.0718, batch acc 0.9790
18:56:40.686   Training iter 400, batch loss 0.0743, batch acc 0.9796
18:56:40.772   Training iter 450, batch loss 0.0687, batch acc 0.9830
18:56:40.868   Training iter 500, batch loss 0.0705, batch acc 0.9800
18:56:40.965   Training iter 550, batch loss 0.0705, batch acc 0.9812
18:56:41.079   Training iter 600, batch loss 0.0702, batch acc 0.9800
18:56:41.081 Training @ 45 epoch...
18:56:41.179   Training iter 50, batch loss 0.0677, batch acc 0.9818
18:56:41.275   Training iter 100, batch loss 0.0698, batch acc 0.9806
18:56:41.368   Training iter 150, batch loss 0.0660, batch acc 0.9844
18:56:41.454   Training iter 200, batch loss 0.0708, batch acc 0.9822
18:56:41.557   Training iter 250, batch loss 0.0699, batch acc 0.9792
18:56:41.654   Training iter 300, batch loss 0.0717, batch acc 0.9806
18:56:41.739   Training iter 350, batch loss 0.0674, batch acc 0.9816
18:56:41.827   Training iter 400, batch loss 0.0707, batch acc 0.9786
18:56:41.944   Training iter 450, batch loss 0.0664, batch acc 0.9842
18:56:42.027   Training iter 500, batch loss 0.0685, batch acc 0.9806
18:56:42.118   Training iter 550, batch loss 0.0699, batch acc 0.9808
18:56:42.211   Training iter 600, batch loss 0.0726, batch acc 0.9812
18:56:42.212 Testing @ 45 epoch...
18:56:42.259     Testing, total mean loss 0.08153, total acc 0.97500
18:56:42.260 Training @ 46 epoch...
18:56:42.380   Training iter 50, batch loss 0.0679, batch acc 0.9822
18:56:42.471   Training iter 100, batch loss 0.0677, batch acc 0.9818
18:56:42.566   Training iter 150, batch loss 0.0669, batch acc 0.9826
18:56:42.698   Training iter 200, batch loss 0.0670, batch acc 0.9810
18:56:42.818   Training iter 250, batch loss 0.0695, batch acc 0.9808
18:56:42.924   Training iter 300, batch loss 0.0655, batch acc 0.9846
18:56:43.054   Training iter 350, batch loss 0.0691, batch acc 0.9810
18:56:43.193   Training iter 400, batch loss 0.0697, batch acc 0.9820
18:56:43.343   Training iter 450, batch loss 0.0703, batch acc 0.9802
18:56:43.506   Training iter 500, batch loss 0.0742, batch acc 0.9760
18:56:43.606   Training iter 550, batch loss 0.0708, batch acc 0.9794
18:56:43.727   Training iter 600, batch loss 0.0672, batch acc 0.9840
18:56:43.728 Training @ 47 epoch...
18:56:43.837   Training iter 50, batch loss 0.0665, batch acc 0.9818
18:56:43.962   Training iter 100, batch loss 0.0682, batch acc 0.9820
18:56:44.062   Training iter 150, batch loss 0.0687, batch acc 0.9826
18:56:44.217   Training iter 200, batch loss 0.0696, batch acc 0.9818
18:56:44.319   Training iter 250, batch loss 0.0682, batch acc 0.9838
18:56:44.449   Training iter 300, batch loss 0.0718, batch acc 0.9796
18:56:44.579   Training iter 350, batch loss 0.0732, batch acc 0.9780
18:56:44.693   Training iter 400, batch loss 0.0715, batch acc 0.9792
18:56:44.810   Training iter 450, batch loss 0.0660, batch acc 0.9818
18:56:44.912   Training iter 500, batch loss 0.0688, batch acc 0.9824
18:56:44.998   Training iter 550, batch loss 0.0679, batch acc 0.9834
18:56:45.099   Training iter 600, batch loss 0.0723, batch acc 0.9792
18:56:45.099 Training @ 48 epoch...
18:56:45.220   Training iter 50, batch loss 0.0653, batch acc 0.9822
18:56:45.313   Training iter 100, batch loss 0.0744, batch acc 0.9800
18:56:45.425   Training iter 150, batch loss 0.0694, batch acc 0.9812
18:56:45.569   Training iter 200, batch loss 0.0680, batch acc 0.9826
18:56:45.754   Training iter 250, batch loss 0.0703, batch acc 0.9808
18:56:45.896   Training iter 300, batch loss 0.0733, batch acc 0.9792
18:56:46.021   Training iter 350, batch loss 0.0651, batch acc 0.9832
18:56:46.169   Training iter 400, batch loss 0.0663, batch acc 0.9848
18:56:46.319   Training iter 450, batch loss 0.0706, batch acc 0.9784
18:56:46.633   Training iter 500, batch loss 0.0667, batch acc 0.9838
18:56:46.881   Training iter 550, batch loss 0.0688, batch acc 0.9822
18:56:47.069   Training iter 600, batch loss 0.0702, batch acc 0.9814
18:56:47.071 Training @ 49 epoch...
18:56:47.207   Training iter 50, batch loss 0.0680, batch acc 0.9814
18:56:47.330   Training iter 100, batch loss 0.0674, batch acc 0.9806
18:56:47.439   Training iter 150, batch loss 0.0703, batch acc 0.9808
18:56:47.563   Training iter 200, batch loss 0.0668, batch acc 0.9830
18:56:47.686   Training iter 250, batch loss 0.0723, batch acc 0.9810
18:56:47.793   Training iter 300, batch loss 0.0721, batch acc 0.9804
18:56:47.893   Training iter 350, batch loss 0.0687, batch acc 0.9844
18:56:47.993   Training iter 400, batch loss 0.0678, batch acc 0.9832
18:56:48.251   Training iter 450, batch loss 0.0652, batch acc 0.9836
18:56:48.410   Training iter 500, batch loss 0.0722, batch acc 0.9776
18:56:48.527   Training iter 550, batch loss 0.0693, batch acc 0.9812
18:56:48.659   Training iter 600, batch loss 0.0690, batch acc 0.9810
18:56:48.659 Training @ 50 epoch...
18:56:48.786   Training iter 50, batch loss 0.0626, batch acc 0.9870
18:56:48.954   Training iter 100, batch loss 0.0654, batch acc 0.9810
18:56:49.113   Training iter 150, batch loss 0.0684, batch acc 0.9822
18:56:49.267   Training iter 200, batch loss 0.0668, batch acc 0.9828
18:56:49.359   Training iter 250, batch loss 0.0691, batch acc 0.9818
18:56:49.464   Training iter 300, batch loss 0.0697, batch acc 0.9792
18:56:49.622   Training iter 350, batch loss 0.0710, batch acc 0.9826
18:56:49.827   Training iter 400, batch loss 0.0739, batch acc 0.9806
18:56:49.928   Training iter 450, batch loss 0.0692, batch acc 0.9824
18:56:50.121   Training iter 500, batch loss 0.0675, batch acc 0.9818
18:56:50.245   Training iter 550, batch loss 0.0708, batch acc 0.9790
18:56:50.381   Training iter 600, batch loss 0.0714, batch acc 0.9792
18:56:50.381 Testing @ 50 epoch...
18:56:50.464     Testing, total mean loss 0.08275, total acc 0.97290
18:56:50.464 Training @ 51 epoch...
18:56:50.582   Training iter 50, batch loss 0.0643, batch acc 0.9842
18:56:50.721   Training iter 100, batch loss 0.0671, batch acc 0.9826
18:56:50.818   Training iter 150, batch loss 0.0690, batch acc 0.9808
18:56:50.933   Training iter 200, batch loss 0.0627, batch acc 0.9830
18:56:51.118   Training iter 250, batch loss 0.0656, batch acc 0.9818
18:56:51.254   Training iter 300, batch loss 0.0674, batch acc 0.9820
18:56:51.434   Training iter 350, batch loss 0.0670, batch acc 0.9816
18:56:51.550   Training iter 400, batch loss 0.0709, batch acc 0.9782
18:56:51.698   Training iter 450, batch loss 0.0707, batch acc 0.9820
18:56:52.100   Training iter 500, batch loss 0.0713, batch acc 0.9820
18:56:52.231   Training iter 550, batch loss 0.0710, batch acc 0.9792
18:56:52.331   Training iter 600, batch loss 0.0701, batch acc 0.9814
18:56:52.332 Training @ 52 epoch...
18:56:52.421   Training iter 50, batch loss 0.0624, batch acc 0.9852
18:56:52.546   Training iter 100, batch loss 0.0653, batch acc 0.9832
18:56:52.673   Training iter 150, batch loss 0.0703, batch acc 0.9822
18:56:52.785   Training iter 200, batch loss 0.0713, batch acc 0.9790
18:56:52.896   Training iter 250, batch loss 0.0691, batch acc 0.9818
18:56:53.036   Training iter 300, batch loss 0.0704, batch acc 0.9790
18:56:53.140   Training iter 350, batch loss 0.0651, batch acc 0.9840
18:56:53.289   Training iter 400, batch loss 0.0695, batch acc 0.9820
18:56:53.403   Training iter 450, batch loss 0.0698, batch acc 0.9806
18:56:53.531   Training iter 500, batch loss 0.0694, batch acc 0.9818
18:56:53.651   Training iter 550, batch loss 0.0694, batch acc 0.9822
18:56:53.793   Training iter 600, batch loss 0.0657, batch acc 0.9818
18:56:53.794 Training @ 53 epoch...
18:56:53.928   Training iter 50, batch loss 0.0647, batch acc 0.9854
18:56:54.028   Training iter 100, batch loss 0.0662, batch acc 0.9832
18:56:54.162   Training iter 150, batch loss 0.0679, batch acc 0.9828
18:56:54.287   Training iter 200, batch loss 0.0686, batch acc 0.9810
18:56:54.385   Training iter 250, batch loss 0.0669, batch acc 0.9838
18:56:54.498   Training iter 300, batch loss 0.0690, batch acc 0.9814
18:56:54.626   Training iter 350, batch loss 0.0693, batch acc 0.9820
18:56:54.737   Training iter 400, batch loss 0.0706, batch acc 0.9820
18:56:54.842   Training iter 450, batch loss 0.0711, batch acc 0.9820
18:56:55.079   Training iter 500, batch loss 0.0730, batch acc 0.9804
18:56:55.226   Training iter 550, batch loss 0.0678, batch acc 0.9818
18:56:55.345   Training iter 600, batch loss 0.0668, batch acc 0.9828
18:56:55.346 Training @ 54 epoch...
18:56:55.551   Training iter 50, batch loss 0.0662, batch acc 0.9844
18:56:55.688   Training iter 100, batch loss 0.0661, batch acc 0.9832
18:56:55.810   Training iter 150, batch loss 0.0688, batch acc 0.9804
18:56:55.964   Training iter 200, batch loss 0.0716, batch acc 0.9806
18:56:56.084   Training iter 250, batch loss 0.0687, batch acc 0.9830
18:56:56.234   Training iter 300, batch loss 0.0681, batch acc 0.9802
18:56:56.323   Training iter 350, batch loss 0.0691, batch acc 0.9810
18:56:56.435   Training iter 400, batch loss 0.0665, batch acc 0.9850
18:56:56.558   Training iter 450, batch loss 0.0704, batch acc 0.9802
18:56:56.655   Training iter 500, batch loss 0.0641, batch acc 0.9852
18:56:56.784   Training iter 550, batch loss 0.0694, batch acc 0.9800
18:56:56.985   Training iter 600, batch loss 0.0649, batch acc 0.9830
18:56:56.986 Training @ 55 epoch...
18:56:57.132   Training iter 50, batch loss 0.0633, batch acc 0.9830
18:56:57.324   Training iter 100, batch loss 0.0715, batch acc 0.9820
18:56:57.505   Training iter 150, batch loss 0.0673, batch acc 0.9828
18:56:57.730   Training iter 200, batch loss 0.0677, batch acc 0.9834
18:56:58.411   Training iter 250, batch loss 0.0700, batch acc 0.9804
18:56:59.179   Training iter 300, batch loss 0.0655, batch acc 0.9814
18:56:59.725   Training iter 350, batch loss 0.0643, batch acc 0.9838
18:57:01.086   Training iter 400, batch loss 0.0728, batch acc 0.9792
18:57:01.684   Training iter 450, batch loss 0.0688, batch acc 0.9804
18:57:02.269   Training iter 500, batch loss 0.0684, batch acc 0.9820
18:57:03.254   Training iter 550, batch loss 0.0621, batch acc 0.9854
18:57:04.417   Training iter 600, batch loss 0.0684, batch acc 0.9796
18:57:04.417 Testing @ 55 epoch...
18:57:05.029     Testing, total mean loss 0.08039, total acc 0.97370
18:57:05.030 Training @ 56 epoch...
18:57:05.725   Training iter 50, batch loss 0.0670, batch acc 0.9824
18:57:06.306   Training iter 100, batch loss 0.0623, batch acc 0.9864
18:57:06.438   Training iter 150, batch loss 0.0694, batch acc 0.9794
18:57:06.562   Training iter 200, batch loss 0.0708, batch acc 0.9798
18:57:06.685   Training iter 250, batch loss 0.0654, batch acc 0.9836
18:57:06.914   Training iter 300, batch loss 0.0689, batch acc 0.9832
18:57:07.167   Training iter 350, batch loss 0.0661, batch acc 0.9826
18:57:07.298   Training iter 400, batch loss 0.0662, batch acc 0.9816
18:57:07.813   Training iter 450, batch loss 0.0713, batch acc 0.9798
18:57:08.094   Training iter 500, batch loss 0.0705, batch acc 0.9810
18:57:08.234   Training iter 550, batch loss 0.0706, batch acc 0.9786
18:57:08.332   Training iter 600, batch loss 0.0667, batch acc 0.9822
18:57:08.334 Training @ 57 epoch...
18:57:08.438   Training iter 50, batch loss 0.0669, batch acc 0.9826
18:57:08.531   Training iter 100, batch loss 0.0635, batch acc 0.9838
18:57:08.718   Training iter 150, batch loss 0.0679, batch acc 0.9802
18:57:08.880   Training iter 200, batch loss 0.0676, batch acc 0.9844
18:57:09.043   Training iter 250, batch loss 0.0661, batch acc 0.9816
18:57:09.159   Training iter 300, batch loss 0.0657, batch acc 0.9846
18:57:09.266   Training iter 350, batch loss 0.0687, batch acc 0.9808
18:57:09.369   Training iter 400, batch loss 0.0678, batch acc 0.9836
18:57:09.494   Training iter 450, batch loss 0.0670, batch acc 0.9840
18:57:09.646   Training iter 500, batch loss 0.0690, batch acc 0.9806
18:57:09.818   Training iter 550, batch loss 0.0689, batch acc 0.9810
18:57:09.995   Training iter 600, batch loss 0.0703, batch acc 0.9814
18:57:09.997 Training @ 58 epoch...
18:57:10.139   Training iter 50, batch loss 0.0700, batch acc 0.9792
18:57:10.306   Training iter 100, batch loss 0.0683, batch acc 0.9800
18:57:10.418   Training iter 150, batch loss 0.0654, batch acc 0.9838
18:57:10.547   Training iter 200, batch loss 0.0692, batch acc 0.9812
18:57:10.722   Training iter 250, batch loss 0.0664, batch acc 0.9830
18:57:10.817   Training iter 300, batch loss 0.0673, batch acc 0.9842
18:57:10.988   Training iter 350, batch loss 0.0650, batch acc 0.9854
18:57:11.109   Training iter 400, batch loss 0.0718, batch acc 0.9806
18:57:11.197   Training iter 450, batch loss 0.0651, batch acc 0.9842
18:57:11.291   Training iter 500, batch loss 0.0678, batch acc 0.9812
18:57:11.482   Training iter 550, batch loss 0.0691, batch acc 0.9808
18:57:11.612   Training iter 600, batch loss 0.0681, batch acc 0.9832
18:57:11.612 Training @ 59 epoch...
18:57:11.791   Training iter 50, batch loss 0.0638, batch acc 0.9838
18:57:11.923   Training iter 100, batch loss 0.0653, batch acc 0.9818
18:57:12.084   Training iter 150, batch loss 0.0665, batch acc 0.9830
18:57:12.226   Training iter 200, batch loss 0.0649, batch acc 0.9838
18:57:12.345   Training iter 250, batch loss 0.0674, batch acc 0.9814
18:57:12.458   Training iter 300, batch loss 0.0627, batch acc 0.9858
18:57:12.564   Training iter 350, batch loss 0.0661, batch acc 0.9838
18:57:12.683   Training iter 400, batch loss 0.0675, batch acc 0.9812
18:57:12.858   Training iter 450, batch loss 0.0723, batch acc 0.9792
18:57:13.020   Training iter 500, batch loss 0.0721, batch acc 0.9792
18:57:13.126   Training iter 550, batch loss 0.0673, batch acc 0.9858
18:57:13.279   Training iter 600, batch loss 0.0700, batch acc 0.9818
18:57:13.281 Training @ 60 epoch...
18:57:13.408   Training iter 50, batch loss 0.0690, batch acc 0.9802
18:57:13.511   Training iter 100, batch loss 0.0673, batch acc 0.9840
18:57:13.633   Training iter 150, batch loss 0.0613, batch acc 0.9868
18:57:13.744   Training iter 200, batch loss 0.0629, batch acc 0.9840
18:57:13.833   Training iter 250, batch loss 0.0672, batch acc 0.9812
18:57:13.956   Training iter 300, batch loss 0.0688, batch acc 0.9822
18:57:14.070   Training iter 350, batch loss 0.0702, batch acc 0.9810
18:57:14.170   Training iter 400, batch loss 0.0704, batch acc 0.9792
18:57:14.263   Training iter 450, batch loss 0.0719, batch acc 0.9800
18:57:14.356   Training iter 500, batch loss 0.0640, batch acc 0.9812
18:57:14.458   Training iter 550, batch loss 0.0681, batch acc 0.9824
18:57:14.546   Training iter 600, batch loss 0.0671, batch acc 0.9836
18:57:14.546 Testing @ 60 epoch...
18:57:14.591     Testing, total mean loss 0.08153, total acc 0.97400
18:57:14.591 Training @ 61 epoch...
18:57:14.670   Training iter 50, batch loss 0.0626, batch acc 0.9854
18:57:14.748   Training iter 100, batch loss 0.0660, batch acc 0.9834
18:57:14.905   Training iter 150, batch loss 0.0671, batch acc 0.9820
18:57:15.066   Training iter 200, batch loss 0.0669, batch acc 0.9854
18:57:15.230   Training iter 250, batch loss 0.0688, batch acc 0.9814
18:57:15.398   Training iter 300, batch loss 0.0656, batch acc 0.9834
18:57:15.532   Training iter 350, batch loss 0.0666, batch acc 0.9794
18:57:15.702   Training iter 400, batch loss 0.0691, batch acc 0.9810
18:57:15.871   Training iter 450, batch loss 0.0660, batch acc 0.9828
18:57:16.166   Training iter 500, batch loss 0.0701, batch acc 0.9792
18:57:16.363   Training iter 550, batch loss 0.0680, batch acc 0.9812
18:57:16.561   Training iter 600, batch loss 0.0668, batch acc 0.9820
18:57:16.563 Training @ 62 epoch...
18:57:16.734   Training iter 50, batch loss 0.0660, batch acc 0.9834
18:57:16.896   Training iter 100, batch loss 0.0655, batch acc 0.9844
18:57:17.033   Training iter 150, batch loss 0.0658, batch acc 0.9850
18:57:17.203   Training iter 200, batch loss 0.0615, batch acc 0.9862
18:57:17.311   Training iter 250, batch loss 0.0637, batch acc 0.9844
18:57:17.428   Training iter 300, batch loss 0.0691, batch acc 0.9828
18:57:17.547   Training iter 350, batch loss 0.0674, batch acc 0.9792
18:57:17.678   Training iter 400, batch loss 0.0704, batch acc 0.9812
18:57:17.788   Training iter 450, batch loss 0.0653, batch acc 0.9830
18:57:17.971   Training iter 500, batch loss 0.0702, batch acc 0.9812
18:57:18.162   Training iter 550, batch loss 0.0703, batch acc 0.9798
18:57:18.337   Training iter 600, batch loss 0.0700, batch acc 0.9808
18:57:18.338 Training @ 63 epoch...
18:57:18.489   Training iter 50, batch loss 0.0653, batch acc 0.9830
18:57:18.680   Training iter 100, batch loss 0.0652, batch acc 0.9834
18:57:18.931   Training iter 150, batch loss 0.0689, batch acc 0.9804
18:57:19.083   Training iter 200, batch loss 0.0690, batch acc 0.9822
18:57:19.202   Training iter 250, batch loss 0.0657, batch acc 0.9826
18:57:19.324   Training iter 300, batch loss 0.0618, batch acc 0.9850
18:57:19.449   Training iter 350, batch loss 0.0683, batch acc 0.9816
18:57:19.550   Training iter 400, batch loss 0.0668, batch acc 0.9832
18:57:19.722   Training iter 450, batch loss 0.0701, batch acc 0.9804
18:57:19.912   Training iter 500, batch loss 0.0671, batch acc 0.9828
18:57:20.049   Training iter 550, batch loss 0.0694, batch acc 0.9822
18:57:20.191   Training iter 600, batch loss 0.0629, batch acc 0.9852
18:57:20.192 Training @ 64 epoch...
18:57:20.367   Training iter 50, batch loss 0.0627, batch acc 0.9868
18:57:20.670   Training iter 100, batch loss 0.0609, batch acc 0.9864
18:57:20.772   Training iter 150, batch loss 0.0649, batch acc 0.9828
18:57:21.006   Training iter 200, batch loss 0.0653, batch acc 0.9842
18:57:21.185   Training iter 250, batch loss 0.0645, batch acc 0.9846
18:57:21.350   Training iter 300, batch loss 0.0681, batch acc 0.9818
18:57:21.485   Training iter 350, batch loss 0.0684, batch acc 0.9810
18:57:21.623   Training iter 400, batch loss 0.0651, batch acc 0.9838
18:57:21.902   Training iter 450, batch loss 0.0669, batch acc 0.9824
18:57:22.016   Training iter 500, batch loss 0.0731, batch acc 0.9768
18:57:22.153   Training iter 550, batch loss 0.0693, batch acc 0.9816
18:57:22.260   Training iter 600, batch loss 0.0696, batch acc 0.9798
18:57:22.262 Training @ 65 epoch...
18:57:22.362   Training iter 50, batch loss 0.0623, batch acc 0.9850
18:57:22.455   Training iter 100, batch loss 0.0647, batch acc 0.9856
18:57:22.577   Training iter 150, batch loss 0.0679, batch acc 0.9786
18:57:22.668   Training iter 200, batch loss 0.0659, batch acc 0.9824
18:57:22.813   Training iter 250, batch loss 0.0632, batch acc 0.9818
18:57:22.974   Training iter 300, batch loss 0.0656, batch acc 0.9848
18:57:23.091   Training iter 350, batch loss 0.0683, batch acc 0.9820
18:57:23.193   Training iter 400, batch loss 0.0666, batch acc 0.9824
18:57:23.316   Training iter 450, batch loss 0.0672, batch acc 0.9826
18:57:23.453   Training iter 500, batch loss 0.0629, batch acc 0.9842
18:57:23.584   Training iter 550, batch loss 0.0694, batch acc 0.9802
18:57:23.728   Training iter 600, batch loss 0.0702, batch acc 0.9820
18:57:23.730 Testing @ 65 epoch...
18:57:23.809     Testing, total mean loss 0.08571, total acc 0.97220
18:57:23.809 Training @ 66 epoch...
18:57:23.981   Training iter 50, batch loss 0.0685, batch acc 0.9850
18:57:24.110   Training iter 100, batch loss 0.0650, batch acc 0.9834
18:57:24.212   Training iter 150, batch loss 0.0672, batch acc 0.9814
18:57:24.323   Training iter 200, batch loss 0.0659, batch acc 0.9824
18:57:24.483   Training iter 250, batch loss 0.0640, batch acc 0.9846
18:57:24.598   Training iter 300, batch loss 0.0649, batch acc 0.9834
18:57:24.753   Training iter 350, batch loss 0.0639, batch acc 0.9826
18:57:24.882   Training iter 400, batch loss 0.0686, batch acc 0.9810
18:57:25.037   Training iter 450, batch loss 0.0730, batch acc 0.9804
18:57:25.205   Training iter 500, batch loss 0.0657, batch acc 0.9832
18:57:25.306   Training iter 550, batch loss 0.0712, batch acc 0.9798
18:57:25.439   Training iter 600, batch loss 0.0643, batch acc 0.9828
18:57:25.440 Training @ 67 epoch...
18:57:25.546   Training iter 50, batch loss 0.0626, batch acc 0.9854
18:57:25.674   Training iter 100, batch loss 0.0622, batch acc 0.9854
18:57:25.787   Training iter 150, batch loss 0.0623, batch acc 0.9850
18:57:25.910   Training iter 200, batch loss 0.0733, batch acc 0.9766
18:57:26.019   Training iter 250, batch loss 0.0685, batch acc 0.9844
18:57:26.144   Training iter 300, batch loss 0.0653, batch acc 0.9826
18:57:26.234   Training iter 350, batch loss 0.0716, batch acc 0.9774
18:57:26.312   Training iter 400, batch loss 0.0658, batch acc 0.9828
18:57:26.418   Training iter 450, batch loss 0.0682, batch acc 0.9820
18:57:26.567   Training iter 500, batch loss 0.0650, batch acc 0.9854
18:57:26.706   Training iter 550, batch loss 0.0667, batch acc 0.9822
18:57:26.843   Training iter 600, batch loss 0.0659, batch acc 0.9822
18:57:26.845 Training @ 68 epoch...
18:57   Training iter 50, batch loss 0.0647, batch acc 0.9822
18:57:27.212   Training iter 100, batch loss 0.0647, batch acc 0.9848
18:57:27.329   Training iter 150, batch loss 0.0647, batch acc 0.9820
18:57:27.487   Training iter 200, batch loss 0.0657, batch acc 0.9816
18:57:27.630   Training iter 250, batch loss 0.0656, batch acc 0.9824
18:57:27.796   Training iter 300, batch loss 0.0708, batch acc 0.9794
18:57:27.939   Training iter 350, batch loss 0.0644, batch acc 0.9842
18:57:28.069   Training iter 400, batch loss 0.0649, batch acc 0.9824
18:57:28.195   Training iter 450, batch loss 0.0633, batch acc 0.9824
18:57:28.333   Training iter 500, batch loss 0.0667, batch acc 0.9842
18:57:28.461   Training iter 550, batch loss 0.0667, batch acc 0.9824
18:57:28.580   Training iter 600, batch loss 0.0684, batch acc 0.9812
18:57:28.582 Training @ 69 epoch...
18:57:28.852   Training iter 50, batch loss 0.0645, batch acc 0.9852
18:57:29.213   Training iter 100, batch loss 0.0672, batch acc 0.9814
18:57:29.364   Training iter 150, batch loss 0.0701, batch acc 0.9804
18:57:29.571   Training iter 200, batch loss 0.0649, batch acc 0.9838
18:57:29.702   Training iter 250, batch loss 0.0665, batch acc 0.9814
18:57:29.836   Training iter 300, batch loss 0.0628, batch acc 0.9864
18:57:30.118   Training iter 350, batch loss 0.0670, batch acc 0.9834
18:57:30.875   Training iter 400, batch loss 0.0691, batch acc 0.9842
18:57:31.588   Training iter 450, batch loss 0.0663, batch acc 0.9838
18:57:32.461   Training iter 500, batch loss 0.0710, batch acc 0.9794
18:57:33.235   Training iter 550, batch loss 0.0656, batch acc 0.9818
18:57:34.147   Training iter 600, batch loss 0.0621, batch acc 0.9846
18:57:34.148 Training @ 70 epoch...
18:57:34.880   Training iter 50, batch loss 0.0661, batch acc 0.9826
18:57:36.105   Training iter 100, batch loss 0.0641, batch acc 0.9836
18:57:37.610   Training iter 150, batch loss 0.0645, batch acc 0.9824
18:57:38.575   Training iter 200, batch loss 0.0701, batch acc 0.9812
18:57:38.924   Training iter 250, batch loss 0.0672, batch acc 0.9814
18:57:39.071   Training iter 300, batch loss 0.0632, batch acc 0.9824
18:57:39.211   Training iter 350, batch loss 0.0654, batch acc 0.9854
18:57:39.416   Training iter 400, batch loss 0.0629, batch acc 0.9856
18:57:39.584   Training iter 450, batch loss 0.0673, batch acc 0.9824
18:57:39.839   Training iter 500, batch loss 0.0647, batch acc 0.9838
18:57:39.976   Training iter 550, batch loss 0.0663, batch acc 0.9836
18:57:40.087   Training iter 600, batch loss 0.0665, batch acc 0.9826
18:57:40.088 Testing @ 70 epoch...
18:57:40.200     Testing, total mean loss 0.08052, total acc 0.97380
18:57:40.200 Training @ 71 epoch...
18:57:40.330   Training iter 50, batch loss 0.0629, batch acc 0.9826
18:57:40.528   Training iter 100, batch loss 0.0656, batch acc 0.9840
18:57:40.687   Training iter 150, batch loss 0.0655, batch acc 0.9806
18:57:40.820   Training iter 200, batch loss 0.0670, batch acc 0.9824
18:57:40.938   Training iter 250, batch loss 0.0652, batch acc 0.9832
18:57:41.029   Training iter 300, batch loss 0.0672, batch acc 0.9816
18:57:41.234   Training iter 350, batch loss 0.0660, batch acc 0.9824
18:57:41.388   Training iter 400, batch loss 0.0661, batch acc 0.9822
18:57:41.636   Training iter 450, batch loss 0.0659, batch acc 0.9848
18:57:41.782   Training iter 500, batch loss 0.0653, batch acc 0.9804
18:57:41.896   Training iter 550, batch loss 0.0655, batch acc 0.9850
18:57:42.021   Training iter 600, batch loss 0.0662, batch acc 0.9834
18:57:42.025 Training @ 72 epoch...
18:57:42.166   Training iter 50, batch loss 0.0650, batch acc 0.9814
18:57:42.295   Training iter 100, batch loss 0.0621, batch acc 0.9830
18:57:42.405   Training iter 150, batch loss 0.0650, batch acc 0.9830
18:57:42.503   Training iter 200, batch loss 0.0650, batch acc 0.9846
18:57:42.636   Training iter 250, batch loss 0.0667, batch acc 0.9804
18:57:42.800   Training iter 300, batch loss 0.0644, batch acc 0.9844
18:57:42.913   Training iter 350, batch loss 0.0641, batch acc 0.9850
18:57:43.057   Training iter 400, batch loss 0.0678, batch acc 0.9812
18:57:43.247   Training iter 450, batch loss 0.0704, batch acc 0.9812
18:57:43.335   Training iter 500, batch loss 0.0669, batch acc 0.9828
18:57:43.426   Training iter 550, batch loss 0.0612, batch acc 0.9862
18:57:43.506   Training iter 600, batch loss 0.0695, batch acc 0.9798
18:57:43.507 Training @ 73 epoch...
18:57:43.682   Training iter 50, batch loss 0.0617, batch acc 0.9850
18:57:43.781   Training iter 100, batch loss 0.0613, batch acc 0.9844
18:57:43.914   Training iter 150, batch loss 0.0643, batch acc 0.9848
18:57:44.040   Training iter 200, batch loss 0.0650, batch acc 0.9858
18:57:44.162   Training iter 250, batch loss 0.0654, batch acc 0.9830
18:57:44.246   Training iter 300, batch loss 0.0639, batch acc 0.9842
18:57:44.338   Training iter 350, batch loss 0.0643, batch acc 0.9852
18:57:44.422   Training iter 400, batch loss 0.0691, batch acc 0.9810
18:57:44.694   Training iter 450, batch loss 0.0685, batch acc 0.9788
18:57:44.799   Training iter 500, batch loss 0.0667, batch acc 0.9814
18:57:44.925   Training iter 550, batch loss 0.0687, batch acc 0.9782
18:57:45.052   Training iter 600, batch loss 0.0637, batch acc 0.9836
18:57:45.053 Training @ 74 epoch...
18:57:45.164   Training iter 50, batch loss 0.0633, batch acc 0.9832
18:57:45.272   Training iter 100, batch loss 0.0666, batch acc 0.9822
18:57:45.385   Training iter 150, batch loss 0.0631, batch acc 0.9854
18:57:45.568   Training iter 200, batch loss 0.0659, batch acc 0.9814
18:57:45.749   Training iter 250, batch loss 0.0641, batch acc 0.9824
18:57:45.879   Training iter 300, batch loss 0.0612, batch acc 0.9854
18:57:46.037   Training iter 350, batch loss 0.0674, batch acc 0.9816
18:57:46.146   Training iter 400, batch loss 0.0644, batch acc 0.9810
18:57:46.270   Training iter 450, batch loss 0.0715, batch acc 0.9812
18:57:46.417   Training iter 500, batch loss 0.0649, batch acc 0.9840
18:57:46.644   Training iter 550, batch loss 0.0679, batch acc 0.9822
18:57:46.736   Training iter 600, batch loss 0.0686, batch acc 0.9812
18:57:46.737 Training @ 75 epoch...
18:57:46.966   Training iter 50, batch loss 0.0643, batch acc 0.9846
18:57:47.084   Training iter 100, batch loss 0.0655, batch acc 0.9830
18:57:47.379   Training iter 150, batch loss 0.0672, batch acc 0.9822
18:57:47.481   Training iter 200, batch loss 0.0651, batch acc 0.9834
18:57:47.709   Training iter 250, batch loss 0.0677, batch acc 0.9818
18:57:47.826   Training iter 300, batch loss 0.0683, batch acc 0.9818
18:57:48.041   Training iter 350, batch loss 0.0688, batch acc 0.9798
18:57:48.171   Training iter 400, batch loss 0.0677, batch acc 0.9828
18:57:48.313   Training iter 450, batch loss 0.0642, batch acc 0.9824
18:57:48.610   Training iter 500, batch loss 0.0665, batch acc 0.9830
18:57:48.751   Training iter 550, batch loss 0.0666, batch acc 0.9816
18:57:48.911   Training iter 600, batch loss 0.0635, batch acc 0.9864
18:57:48.911 Testing @ 75 epoch...
18:57:49.015     Testing, total mean loss 0.07872, total acc 0.97340
18:57:49.015 Training @ 76 epoch...
18:57:49.129   Training iter 50, batch loss 0.0637, batch acc 0.9836
18:57:49.245   Training iter 100, batch loss 0.0631, batch acc 0.9836
18:57:49.369   Training iter 150, batch loss 0.0668, batch acc 0.9828
18:57:49.466   Training iter 200, batch loss 0.0640, batch acc 0.9856
18:57:49.603   Training iter 250, batch loss 0.0654, batch acc 0.9814
18:57:49.741   Training iter 300, batch loss 0.0634, batch acc 0.9862
18:57:49.841   Training iter 350, batch loss 0.0651, batch acc 0.9848
18:57:49.986   Training iter 400, batch loss 0.0601, batch acc 0.9868
18:57:50.153   Training iter 450, batch loss 0.0664, batch acc 0.9798
18:57:50.244   Training iter 500, batch loss 0.0670, batch acc 0.9806
18:57:50.332   Training iter 550, batch loss 0.0715, batch acc 0.9782
18:57:50.565   Training iter 600, batch loss 0.0658, batch acc 0.9824
18:57:50.566 Training @ 77 epoch...
18:57:50.742   Training iter 50, batch loss 0.0678, batch acc 0.9816
18:57:50.916   Training iter 100, batch loss 0.0633, batch acc 0.9838
18:57:51.075   Training iter 150, batch loss 0.0650, batch acc 0.9854
18:57:51.219   Training iter 200, batch loss 0.0655, batch acc 0.9806
18:57:51.467   Training iter 250, batch loss 0.0622, batch acc 0.9864
18:57:51.650   Training iter 300, batch loss 0.0649, batch acc 0.9830
18:57:51.832   Training iter 350, batch loss 0.0690, batch acc 0.9790
18:57:51.922   Training iter 400, batch loss 0.0669, batch acc 0.9838
18:57:52.145   Training iter 450, batch loss 0.0629, batch acc 0.9850
18:57:52.279   Training iter 500, batch loss 0.0662, batch acc 0.9814
18:57:52.373   Training iter 550, batch loss 0.0675, batch acc 0.9828
18:57:52.452   Training iter 600, batch loss 0.0662, batch acc 0.9846
18:57:52.458 Training @ 78 epoch...
18:57:52.555   Training iter 50, batch loss 0.0673, batch acc 0.9822
18:57:52.703   Training iter 100, batch loss 0.0629, batch acc 0.9844
18:57:52.814   Training iter 150, batch loss 0.0628, batch acc 0.9856
18:57:52.894   Training iter 200, batch loss 0.0679, batch acc 0.9796
18:57:52.975   Training iter 250, batch loss 0.0654, batch acc 0.9852
18:57:53.055   Training iter 300, batch loss 0.0643, batch acc 0.9826
18:57:53.132   Training iter 350, batch loss 0.0665, batch acc 0.9830
18:57:53.237   Training iter 400, batch loss 0.0608, batch acc 0.9850
18:57:53.353   Training iter 450, batch loss 0.0674, batch acc 0.9824
18:57:53.483   Training iter 500, batch loss 0.0675, batch acc 0.9848
18:57:53.634   Training iter 550, batch loss 0.0631, batch acc 0.9840
18:57:53.778   Training iter 600, batch loss 0.0677, batch acc 0.9806
18:57:53.779 Training @ 79 epoch...
18:57:53.862   Training iter 50, batch loss 0.0678, batch acc 0.9800
18:57:53.970   Training iter 100, batch loss 0.0642, batch acc 0.9830
18:57:54.116   Training iter 150, batch loss 0.0613, batch acc 0.9844
18:57:54.252   Training iter 200, batch loss 0.0660, batch acc 0.9812
18:57:54.464   Training iter 250, batch loss 0.0622, batch acc 0.9832
18:57:54.620   Training iter 300, batch loss 0.0694, batch acc 0.9810
18:57:54.751   Training iter 350, batch loss 0.0618, batch acc 0.9848
18:57:54.928   Training iter 400, batch loss 0.0663, batch acc 0.9838
18:57:55.051   Training iter 450, batch loss 0.0678, batch acc 0.9836
18:57:55.171   Training iter 500, batch loss 0.0629, batch acc 0.9868
18:57:55.281   Training iter 550, batch loss 0.0667, batch acc 0.9826
18:57:55.376   Training iter 600, batch loss 0.0685, batch acc 0.9810
18:57:55.377 Training @ 80 epoch...
18:57:55.484   Training iter 50, batch loss 0.0631, batch acc 0.9846
18:57:55.582   Training iter 100, batch loss 0.0656, batch acc 0.9842
18:57:55.710   Training iter 150, batch loss 0.0668, batch acc 0.9816
18:57:55.838   Training iter 200, batch loss 0.0623, batch acc 0.9848
18:57:55.937   Training iter 250, batch loss 0.0621, batch acc 0.9838
18:57:56.059   Training iter 300, batch loss 0.0654, batch acc 0.9828
18:57:56.141   Training iter 350, batch loss 0.0683, batch acc 0.9816
18:57:56.252   Training iter 400, batch loss 0.0654, batch acc 0.9848
18:57:56.359   Training iter 450, batch loss 0.0666, batch acc 0.9830
18:57:56.480   Training iter 500, batch loss 0.0668, batch acc 0.9812
18:57:56.611   Training iter 550, batch loss 0.0653, batch acc 0.9854
18:57:56.745   Training iter 600, batch loss 0.0657, batch acc 0.9808
18:57:56.747 Testing @ 80 epoch...
18:57:56.871     Testing, total mean loss 0.07888, total acc 0.97470
18:57:56.871 Training @ 81 epoch...
18:57:57.033   Training iter 50, batch loss 0.0650, batch acc 0.9832
18:57:57.211   Training iter 100, batch loss 0.0614, batch acc 0.9888
18:57:57.347   Training iter 150, batch loss 0.0646, batch acc 0.9822
18:57:57.488   Training iter 200, batch loss 0.0584, batch acc 0.9886
18:57:57.571   Training iter 250, batch loss 0.0652, batch acc 0.9810
18:57:57.689   Training iter 300, batch loss 0.0631, batch acc 0.9864
18:57:57.795   Training iter 350, batch loss 0.0712, batch acc 0.9810
18:57:57.917   Training iter 400, batch loss 0.0649, batch acc 0.9852
18:57:58.012   Training iter 450, batch loss 0.0687, batch acc 0.9808
18:57:58.121   Training iter 500, batch loss 0.0698, batch acc 0.9810
18:57:58.242   Training iter 550, batch loss 0.0686, batch acc 0.9804
18:57:58.330   Training iter 600, batch loss 0.0661, batch acc 0.9820
18:57:58.333 Training @ 82 epoch...
18:57:58.485   Training iter 50, batch loss 0.0620, batch acc 0.9834
18:57:58.574   Training iter 100, batch loss 0.0629, batch acc 0.9868
18:57:58.663   Training iter 150, batch loss 0.0641, batch acc 0.9830
18:57:58.751   Training iter 200, batch loss 0.0633, batch acc 0.9840
18:57:58.840   Training iter 250, batch loss 0.0647, batch acc 0.9854
18:57:58.969   Training iter 300, batch loss 0.0655, batch acc 0.9836
18:57:59.052   Training iter 350, batch loss 0.0624, batch acc 0.9840
18:57:59.146   Training iter 400, batch loss 0.0654, batch acc 0.9834
18:57:59.237   Training iter 450, batch loss 0.0677, batch acc 0.9816
18:57:59.354   Training iter 500, batch loss 0.0655, batch acc 0.9834
18:57:59.443   Training iter 550, batch loss 0.0717, batch acc 0.9800
18:57:59.557   Training iter 600, batch loss 0.0666, batch acc 0.9796
18:57:59.558 Training @ 83 epoch...
18:57:59.679   Training iter 50, batch loss 0.0660, batch acc 0.9820
18:57:59.808   Training iter 100, batch loss 0.0611, batch acc 0.9864
18:57:59.910   Training iter 150, batch loss 0.0663, batch acc 0.9838
18:58:00.050   Training iter 200, batch loss 0.0662, batch acc 0.9832
18:58:00.163   Training iter 250, batch loss 0.0635, batch acc 0.9842
18:58:00.279   Training iter 300, batch loss 0.0620, batch acc 0.9846
18:58:00.364   Training iter 350, batch loss 0.0654, batch acc 0.9830
18:58:00.447   Training iter 400, batch loss 0.0674, batch acc 0.9812
18:58:00.530   Training iter 450, batch loss 0.0615, batch acc 0.9868
18:58:00.616   Training iter 500, batch loss 0.0628, batch acc 0.9862
18:58:00.777   Training iter 550, batch loss 0.0657, batch acc 0.9828
18:58:00.964   Training iter 600, batch loss 0.0685, batch acc 0.9782
18:58:00.965 Training @ 84 epoch...
18:58:01.120   Training iter 50, batch loss 0.0656, batch acc 0.9826
18:58:01.278   Training iter 100, batch loss 0.0640, batch acc 0.9840
18:58:01.461   Training iter 150, batch loss 0.0687, batch acc 0.9816
18:58:01.586   Training iter 200, batch loss 0.0630, batch acc 0.9836
18:58:01.719   Training iter 250, batch loss 0.0682, batch acc 0.9826
18:58:01.880   Training iter 300, batch loss 0.0638, batch acc 0.9854
18:58:02.063   Training iter 350, batch loss 0.0613, batch acc 0.9860
18:58:02.187   Training iter 400, batch loss 0.0626, batch acc 0.9854
18:58:02.330   Training iter 450, batch loss 0.0631, batch acc 0.9830
18:58:02.536   Training iter 500, batch loss 0.0666, batch acc 0.9826
18:58:02.746   Training iter 550, batch loss 0.0676, batch acc 0.9832
18:58:02.938   Training iter 600, batch loss 0.0675, batch acc 0.9808
18:58:02.943 Training @ 85 epoch...
18:58:03.084   Training iter 50, batch loss 0.0617, batch acc 0.9854
18:58:03.230   Training iter 100, batch loss 0.0633, batch acc 0.9860
18:58:03.477   Training iter 150, batch loss 0.0623, batch acc 0.9854
18:58:03.576   Training iter 200, batch loss 0.0670, batch acc 0.9824
18:58:03.702   Training iter 250, batch loss 0.0634, batch acc 0.9838
18:58:03.829   Training iter 300, batch loss 0.0645, batch acc 0.9850
18:58:03.966   Training iter 350, batch loss 0.0661, batch acc 0.9832
18:58:04.100   Training iter 400, batch loss 0.0625, batch acc 0.9866
18:58:04.233   Training iter 450, batch loss 0.0657, batch acc 0.9816
18:58:04.353   Training iter 500, batch loss 0.0674, batch acc 0.9818
18:58:04.481   Training iter 550, batch loss 0.0669, batch acc 0.9830
18:58:04.596   Training iter 600, batch loss 0.0688, batch acc 0.9806
18:58:04.597 Testing @ 85 epoch...
18:58:04.659     Testing, total mean loss 0.07679, total acc 0.97500
18:58:04.659 Training @ 86 epoch...
18:58:04.757   Training iter 50, batch loss 0.0641, batch acc 0.9828
18:58:04.850   Training iter 100, batch loss 0.0598, batch acc 0.9846
18:58:04.959   Training iter 150, batch loss 0.0623, batch acc 0.9846
18:58:05.053   Training iter 200, batch loss 0.0679, batch acc 0.9800
18:58:05.139   Training iter 250, batch loss 0.0625, batch acc 0.9842
18:58:05.243   Training iter 300, batch loss 0.0630, batch acc 0.9854
18:58:05.356   Training iter 350, batch loss 0.0654, batch acc 0.9840
18:58:05.467   Training iter 400, batch loss 0.0656, batch acc 0.9842
18:58:05.581   Training iter 450, batch loss 0.0634, batch acc 0.9838
18:58:05.686   Training iter 500, batch loss 0.0689, batch acc 0.9806
18:58:05.800   Training iter 550, batch loss 0.0640, batch acc 0.9844
18:58:05.912   Training iter 600, batch loss 0.0636, batch acc 0.9840
18:58:05.913 Training @ 87 epoch...
18:58:06.117   Training iter 50, batch loss 0.0634, batch acc 0.9840
18:58:06.260   Training iter 100, batch loss 0.0623, batch acc 0.9836
18:58:06.401   Training iter 150, batch loss 0.0625, batch acc 0.9836
18:58:06.536   Training iter 200, batch loss 0.0655, batch acc 0.9850
18:58:06.651   Training iter 250, batch loss 0.0616, batch acc 0.9856
18:58:06.745   Training iter 300, batch loss 0.0639, batch acc 0.9834
18:58:06.892   Training iter 350, batch loss 0.0670, batch acc 0.9816
18:58:06.990   Training iter 400, batch loss 0.0645, batch acc 0.9828
18:58:07.079   Training iter 450, batch loss 0.0632, batch acc 0.9826
18:58:07.159   Training iter 500, batch loss 0.0660, batch acc 0.9836
18:58:07.265   Training iter 550, batch loss 0.0634, batch acc 0.9826
18:58:07.373   Training iter 600, batch loss 0.0676, batch acc 0.9828
18:58:07.375 Training @ 88 epoch...
18:58:07.466   Training iter 50, batch loss 0.0626, batch acc 0.9852
18:58:07.559   Training iter 100, batch loss 0.0658, batch acc 0.9820
18:58:07.754   Training iter 150, batch loss 0.0626, batch acc 0.9844
18:58:07.868   Training iter 200, batch loss 0.0610, batch acc 0.9852
18:58:07.982   Training iter 250, batch loss 0.0655, batch acc 0.9820
18:58:08.098   Training iter 300, batch loss 0.0644, batch acc 0.9846
18:58:08.210   Training iter 350, batch loss 0.0676, batch acc 0.9828
18:58:08.331   Training iter 400, batch loss 0.0620, batch acc 0.9852
18:58:08.443   Training iter 450, batch loss 0.0690, batch acc 0.9814
18:58:08.573   Training iter 500, batch loss 0.0681, batch acc 0.9824
18:58:08.693   Training iter 550, batch loss 0.0626, batch acc 0.9834
18:58:08.835   Training iter 600, batch loss 0.0637, batch acc 0.9836
18:58:08.835 Training @ 89 epoch...
18:58:08.941   Training iter 50, batch loss 0.0607, batch acc 0.9842
18:58:09.097   Training iter 100, batch loss 0.0630, batch acc 0.9846
18:58:09.187   Training iter 150, batch loss 0.0666, batch acc 0.9802
18:58:09.336   Training iter 200, batch loss 0.0644, batch acc 0.9836
18:58:09.429   Training iter 250, batch loss 0.0650, batch acc 0.9854
18:58:09.542   Training iter 300, batch loss 0.0597, batch acc 0.9872
18:58:09.678   Training iter 350, batch loss 0.0680, batch acc 0.9832
18:58:09.837   Training iter 400, batch loss 0.0672, batch acc 0.9818
18:58:09.941   Training iter 450, batch loss 0.0664, batch acc 0.9814
18:58:10.040   Training iter 500, batch loss 0.0639, batch acc 0.9848
18:58:10.154   Training iter 550, batch loss 0.0653, batch acc 0.9834
18:58:10.291   Training iter 600, batch loss 0.0631, batch acc 0.9836
18:58:10.293 Training @ 90 epoch...
18:58:10.391   Training iter 50, batch loss 0.0695, batch acc 0.9834
18:58:10.492   Training iter 100, batch loss 0.0611, batch acc 0.9862
18:58:10.609   Training iter 150, batch loss 0.0643, batch acc 0.9854
18:58:10.702   Training iter 200, batch loss 0.0644, batch acc 0.9824
18:58:10.861   Training iter 250, batch loss 0.0618, batch acc 0.9858
18:58:10.974   Training iter 300, batch loss 0.0632, batch acc 0.9828
18:58:11.104   Training iter 350, batch loss 0.0676, batch acc 0.9814
18:58:11.220   Training iter 400, batch loss 0.0631, batch acc 0.9852
18:58:11.330   Training iter 450, batch loss 0.0643, batch acc 0.9836
18:58:11.428   Training iter 500, batch loss 0.0645, batch acc 0.9830
18:58:11.562   Training iter 550, batch loss 0.0654, batch acc 0.9846
18:58:11.651   Training iter 600, batch loss 0.0647, batch acc 0.9820
18:58:11.652 Testing @ 90 epoch...
18:58:11.722     Testing, total mean loss 0.07974, total acc 0.97320
18:58:11.722 Training @ 91 epoch...
18:58:11.816   Training iter 50, batch loss 0.0620, batch acc 0.9836
18:58:11.909   Training iter 100, batch loss 0.0645, batch acc 0.9830
18:58:12.003   Training iter 150, batch loss 0.0642, batch acc 0.9848
18:58:12.089   Training iter 200, batch loss 0.0629, batch acc 0.9836
18:58:12.181   Training iter 250, batch loss 0.0659, batch acc 0.9834
18:58:12.270   Training iter 300, batch loss 0.0618, batch acc 0.9850
18:58:12.358   Training iter 350, batch loss 0.0695, batch acc 0.9812
18:58:12.457   Training iter 400, batch loss 0.0651, batch acc 0.9804
18:58:12.545   Training iter 450, batch loss 0.0616, batch acc 0.9848
18:58:12.645   Training iter 500, batch loss 0.0644, batch acc 0.9866
18:58:12.737   Training iter 550, batch loss 0.0651, batch acc 0.9840
18:58:12.822   Training iter 600, batch loss 0.0683, batch acc 0.9818
18:58:12.824 Training @ 92 epoch...
18:58:13.083   Training iter 50, batch loss 0.0645, batch acc 0.9830
18:58:13.300   Training iter 100, batch loss 0.0625, batch acc 0.9846
18:58:13.437   Training iter 150, batch loss 0.0670, batch acc 0.9830
18:58:13.735   Training iter 200, batch loss 0.0676, batch acc 0.9844
18:58:13.866   Training iter 250, batch loss 0.0647, batch acc 0.9842
18:58:13.988   Training iter 300, batch loss 0.0632, batch acc 0.9848
18:58:14.169   Training iter 350, batch loss 0.0664, batch acc 0.9816
18:58:14.300   Training iter 400, batch loss 0.0620, batch acc 0.9836
18:58:14.459   Training iter 450, batch loss 0.0650, batch acc 0.9840
18:58:14.554   Training iter 500, batch loss 0.0653, batch acc 0.9812
18:58:14.638   Training iter 550, batch loss 0.0614, batch acc 0.9854
18:58:14.741   Training iter 600, batch loss 0.0657, batch acc 0.9818
18:58:14.742 Training @ 93 epoch...
18:58:14.840   Training iter 50, batch loss 0.0618, batch acc 0.9844
18:58:15.002   Training iter 100, batch loss 0.0633, batch acc 0.9818
18:58:15.188   Training iter 150, batch loss 0.0648, batch acc 0.9830
18:58:15.317   Training iter 200, batch loss 0.0624, batch acc 0.9852
18:58:15.429   Training iter 250, batch loss 0.0626, batch acc 0.9872
18:58:15.554   Training iter 300, batch loss 0.0671, batch acc 0.9838
18:58:15.679   Training iter 350, batch loss 0.0652, batch acc 0.9852
18:58:15.816   Training iter 400, batch loss 0.0611, batch acc 0.9850
18:58:16.019   Training iter 450, batch loss 0.0655, batch acc 0.9832
18:58:16.201   Training iter 500, batch loss 0.0692, batch acc 0.9798
18:58:16.334   Training iter 550, batch loss 0.0641, batch acc 0.9836
18:58:16.568   Training iter 600, batch loss 0.0636, batch acc 0.9832
18:58:16.568 Training @ 94 epoch...
18:58:16.754   Training iter 50, batch loss 0.0633, batch acc 0.9830
18:58:16.921   Training iter 100, batch loss 0.0656, batch acc 0.9818
18:58:17.117   Training iter 150, batch loss 0.0625, batch acc 0.9854
18:58:17.289   Training iter 200, batch loss 0.0641, batch acc 0.9844
18:58:17.430   Training iter 250, batch loss 0.0666, batch acc 0.9818
18:58:17.539   Training iter 300, batch loss 0.0631, batch acc 0.9844
18:58:17.645   Training iter 350, batch loss 0.0630, batch acc 0.9840
18:58:17.747   Training iter 400, batch loss 0.0627, batch acc 0.9828
18:58:17.839   Training iter 450, batch loss 0.0648, batch acc 0.9832
18:58:17.968   Training iter 500, batch loss 0.0676, batch acc 0.9812
18:58:18.153   Training iter 550, batch loss 0.0610, batch acc 0.9858
18:58:18.239   Training iter 600, batch loss 0.0636, batch acc 0.9844
18:58:18.240 Training @ 95 epoch...
18:58:18.324   Training iter 50, batch loss 0.0606, batch acc 0.9878
18:58:18.452   Training iter 100, batch loss 0.0646, batch acc 0.9854
18:58:18.553   Training iter 150, batch loss 0.0625, batch acc 0.9826
18:58:18.671   Training iter 200, batch loss 0.0582, batch acc 0.9866
18:58:18.782   Training iter 250, batch loss 0.0643, batch acc 0.9836
18:58:18.875   Training iter 300, batch loss 0.0640, batch acc 0.9822
18:58:18.967   Training iter 350, batch loss 0.0653, batch acc 0.9816
18:58:19.136   Training iter 400, batch loss 0.0656, batch acc 0.9826
18:58:19.276   Training iter 450, batch loss 0.0624, batch acc 0.9858
18:58:19.380   Training iter 500, batch loss 0.0638, batch acc 0.9848
18:58:19.494   Training iter 550, batch loss 0.0667, batch acc 0.9822
18:58:19.619   Training iter 600, batch loss 0.0673, batch acc 0.9784
18:58:19.620 Testing @ 95 epoch...
18:58:19.681     Testing, total mean loss 0.07979, total acc 0.97310
18:58:19.681 Training @ 96 epoch...
18:58:19.828   Training iter 50, batch loss 0.0647, batch acc 0.9820
18:58:19.970   Training iter 100, batch loss 0.0624, batch acc 0.9868
18:58:20.174   Training iter 150, batch loss 0.0631, batch acc 0.9870
18:58:20.363   Training iter 200, batch loss 0.0659, batch acc 0.9844
18:58:20.505   Training iter 250, batch loss 0.0648, batch acc 0.9872
18:58:20.670   Training iter 300, batch loss 0.0651, batch acc 0.9808
18:58:20.866   Training iter 350, batch loss 0.0669, batch acc 0.9840
18:58:20.984   Training iter 400, batch loss 0.0621, batch acc 0.9858
18:58:21.076   Training iter 450, batch loss 0.0621, batch acc 0.9882
18:58:21.171   Training iter 500, batch loss 0.0667, batch acc 0.9800
18:58:21.296   Training iter 550, batch loss 0.0651, batch acc 0.9836
18:58:21.397   Training iter 600, batch loss 0.0627, batch acc 0.9856
18:58:21.399 Training @ 97 epoch...
18:58:21.507   Training iter 50, batch loss 0.0625, batch acc 0.9850
18:58:21.584   Training iter 100, batch loss 0.0623, batch acc 0.9834
18:58:21.685   Training iter 150, batch loss 0.0644, batch acc 0.9820
18:58:21.844   Training iter 200, batch loss 0.0661, batch acc 0.9856
18:58:21.936   Training iter 250, batch loss 0.0624, batch acc 0.9850
18:58:22.027   Training iter 300, batch loss 0.0647, batch acc 0.9840
18:58:22.139   Training iter 350, batch loss 0.0623, batch acc 0.9842
18:58:22.251   Training iter 400, batch loss 0.0627, batch acc 0.9846
18:58:22.402   Training iter 450, batch loss 0.0656, batch acc 0.9854
18:58:22.512   Training iter 500, batch loss 0.0653, batch acc 0.9840
18:58:22.697   Training iter 550, batch loss 0.0690, batch acc 0.9808
18:58:22.815   Training iter 600, batch loss 0.0664, batch acc 0.9824
18:58:22.816 Training @ 98 epoch...
18:58:22.967   Training iter 50, batch loss 0.0635, batch acc 0.9850
18:58:23.096   Training iter 100, batch loss 0.0649, batch acc 0.9830
18:58:23.189   Training iter 150, batch loss 0.0618, batch acc 0.9854
18:58:23.301   Training iter 200, batch loss 0.0632, batch acc 0.9862
18:58:23.403   Training iter 250, batch loss 0.0637, batch acc 0.9830
18:58:23.502   Training iter 300, batch loss 0.0631, batch acc 0.9830
18:58:23.585   Training iter 350, batch loss 0.0619, batch acc 0.9870
18:58:23.680   Training iter 400, batch loss 0.0620, batch acc 0.9830
18:58:23.764   Training iter 450, batch loss 0.0619, batch acc 0.9858
18:58:23.960   Training iter 500, batch loss 0.0666, batch acc 0.9828
18:58:24.053   Training iter 550, batch loss 0.0665, batch acc 0.9814
18:58:24.165   Training iter 600, batch loss 0.0653, batch acc 0.9840
18:58:24.166 Training @ 99 epoch...
18:58:24.277   Training iter 50, batch loss 0.0635, batch acc 0.9846
18:58:24.388   Training iter 100, batch loss 0.0641, batch acc 0.9826
18:58:24.488   Training iter 150, batch loss 0.0606, batch acc 0.9872
18:58:24.605   Training iter 200, batch loss 0.0612, batch acc 0.9846
18:58:24.745   Training iter 250, batch loss 0.0599, batch acc 0.9864
18:58:24.845   Training iter 300, batch loss 0.0619, batch acc 0.9850
18:58:24.956   Training iter 350, batch loss 0.0651, batch acc 0.9808
18:58:25.067   Training iter 400, batch loss 0.0646, batch acc 0.9824
18:58:25.193   Training iter 450, batch loss 0.0661, batch acc 0.9814
18:58:25.309   Training iter 500, batch loss 0.0680, batch acc 0.9814
18:58:25.422   Training iter 550, batch loss 0.0632, batch acc 0.9848
18:58:25.536   Training iter 600, batch loss 0.0630, batch acc 0.9828
18:58:25.538 Testing @ 99 epoch...
18:58:25.619     Testing, total mean loss 0.07792, total acc 0.97350