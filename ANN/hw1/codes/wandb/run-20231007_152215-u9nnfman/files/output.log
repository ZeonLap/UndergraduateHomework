15:22:19.488 Training @ 0 epoch...
15:22:19.644   Training iter 50, batch loss 25.7825, batch acc 0.3852
15:22:19.788   Training iter 100, batch loss 4.1873, batch acc 0.8184
15:22:19.942   Training iter 150, batch loss 3.1648, batch acc 0.8640
15:22:20.104   Training iter 200, batch loss 2.6489, batch acc 0.8834
15:22:20.265   Training iter 250, batch loss 2.4312, batch acc 0.8946
15:22:20.365   Training iter 300, batch loss 2.0720, batch acc 0.9050
15:22:20.480   Training iter 350, batch loss 2.1273, batch acc 0.9088
15:22:20.585   Training iter 400, batch loss 1.8221, batch acc 0.9148
15:22:20.709   Training iter 450, batch loss 1.7790, batch acc 0.9176
15:22:20.829   Training iter 500, batch loss 1.7621, batch acc 0.9192
15:22:21.059   Training iter 550, batch loss 1.5258, batch acc 0.9268
15:22:21.178   Training iter 600, batch loss 1.5903, batch acc 0.9276
15:22:21.179 Testing @ 0 epoch...
15:22:21.317     Testing, total mean loss 1.30754, total acc 0.93890
15:22:21.317 Training @ 1 epoch...
15:22:21.486   Training iter 50, batch loss 1.4194, batch acc 0.9352
15:22:21.634   Training iter 100, batch loss 1.2449, batch acc 0.9414
15:22:21.760   Training iter 150, batch loss 1.2424, batch acc 0.9434
15:22:21.893   Training iter 200, batch loss 1.1129, batch acc 0.9482
15:22:22.067   Training iter 250, batch loss 1.2667, batch acc 0.9356
15:22:22.183   Training iter 300, batch loss 1.1230, batch acc 0.9454
15:22:22.305   Training iter 350, batch loss 1.1319, batch acc 0.9460
15:22:22.445   Training iter 400, batch loss 1.2027, batch acc 0.9454
15:22:22.553   Training iter 450, batch loss 0.9704, batch acc 0.9498
15:22:22.696   Training iter 500, batch loss 1.1511, batch acc 0.9470
15:22:22.813   Training iter 550, batch loss 0.9509, batch acc 0.9550
15:22:22.990   Training iter 600, batch loss 1.0220, batch acc 0.9484
15:22:22.992 Training @ 2 epoch...
15:22:23.110   Training iter 50, batch loss 1.0641, batch acc 0.9552
15:22:23.239   Training iter 100, batch loss 0.9172, batch acc 0.9546
15:22:23.354   Training iter 150, batch loss 0.9317, batch acc 0.9540
15:22:23.458   Training iter 200, batch loss 0.9744, batch acc 0.9500
15:22:23.662   Training iter 250, batch loss 0.7162, batch acc 0.9632
15:22:23.796   Training iter 300, batch loss 0.8603, batch acc 0.9602
15:22:23.938   Training iter 350, batch loss 0.7546, batch acc 0.9592
15:22:24.062   Training iter 400, batch loss 0.7611, batch acc 0.9646
15:22:24.176   Training iter 450, batch loss 0.7908, batch acc 0.9620
15:22:24.310   Training iter 500, batch loss 0.7428, batch acc 0.9608
15:22:24.873   Training iter 550, batch loss 0.8027, batch acc 0.9584
15:22:24.986   Training iter 600, batch loss 0.7446, batch acc 0.9640
15:22:24.987 Training @ 3 epoch...
15:22:25.096   Training iter 50, batch loss 0.6710, batch acc 0.9656
15:22:25.187   Training iter 100, batch loss 0.6987, batch acc 0.9626
15:22:25.291   Training iter 150, batch loss 0.7002, batch acc 0.9608
15:22:25.395   Training iter 200, batch loss 0.7122, batch acc 0.9652
15:22:25.527   Training iter 250, batch loss 0.6937, batch acc 0.9612
15:22:25.656   Training iter 300, batch loss 0.6522, batch acc 0.9658
15:22:25.773   Training iter 350, batch loss 0.7715, batch acc 0.9646
15:22:25.931   Training iter 400, batch loss 0.6417, batch acc 0.9638
15:22:26.019   Training iter 450, batch loss 0.7304, batch acc 0.9656
15:22:26.108   Training iter 500, batch loss 0.6520, batch acc 0.9652
15:22:26.199   Training iter 550, batch loss 0.6290, batch acc 0.9646
15:22:26.344   Training iter 600, batch loss 0.5650, batch acc 0.9692
15:22:26.348 Training @ 4 epoch...
15:22:26.470   Training iter 50, batch loss 0.5418, batch acc 0.9700
15:22:26.595   Training iter 100, batch loss 0.5155, batch acc 0.9728
15:22:26.728   Training iter 150, batch loss 0.5384, batch acc 0.9712
15:22:26.860   Training iter 200, batch loss 0.5728, batch acc 0.9678
15:22:27.039   Training iter 250, batch loss 0.5755, batch acc 0.9724
15:22:27.159   Training iter 300, batch loss 0.4742, batch acc 0.9720
15:22:27.288   Training iter 350, batch loss 0.6293, batch acc 0.9696
15:22:27.430   Training iter 400, batch loss 0.5653, batch acc 0.9708
15:22:27.558   Training iter 450, batch loss 0.6656, batch acc 0.9658
15:22:27.665   Training iter 500, batch loss 0.5614, batch acc 0.9712
15:22:27.846   Training iter 550, batch loss 0.5906, batch acc 0.9684
15:22:28.018   Training iter 600, batch loss 0.6042, batch acc 0.9680
15:22:28.021 Training @ 5 epoch...
15:22:28.192   Training iter 50, batch loss 0.5222, batch acc 0.9716
15:22:28.334   Training iter 100, batch loss 0.4794, batch acc 0.9744
15:22:28.461   Training iter 150, batch loss 0.4307, batch acc 0.9762
15:22:28.600   Training iter 200, batch loss 0.4479, batch acc 0.9750
15:22:28.732   Training iter 250, batch loss 0.4975, batch acc 0.9724
15:22:28.847   Training iter 300, batch loss 0.5075, batch acc 0.9740
15:22:28.994   Training iter 350, batch loss 0.4762, batch acc 0.9734
15:22:29.439   Training iter 400, batch loss 0.5066, batch acc 0.9740
15:22:29.634   Training iter 450, batch loss 0.5833, batch acc 0.9694
15:22:30.018   Training iter 500, batch loss 0.4677, batch acc 0.9726
15:22:30.210   Training iter 550, batch loss 0.5026, batch acc 0.9730
15:22:30.326   Training iter 600, batch loss 0.5367, batch acc 0.9710
15:22:30.327 Testing @ 5 epoch...
15:22:30.423     Testing, total mean loss 0.59469, total acc 0.97110
15:22:30.423 Training @ 6 epoch...
15:22:30.545   Training iter 50, batch loss 0.4411, batch acc 0.9770
15:22:30.650   Training iter 100, batch loss 0.4126, batch acc 0.9770
15:22:30.767   Training iter 150, batch loss 0.4395, batch acc 0.9754
15:22:30.876   Training iter 200, batch loss 0.4759, batch acc 0.9732
15:22:30.987   Training iter 250, batch loss 0.4230, batch acc 0.9754
15:22:31.157   Training iter 300, batch loss 0.4258, batch acc 0.9758
15:22:31.282   Training iter 350, batch loss 0.4053, batch acc 0.9770
15:22:31.398   Training iter 400, batch loss 0.4628, batch acc 0.9764
15:22:31.490   Training iter 450, batch loss 0.4684, batch acc 0.9744
15:22:31.594   Training iter 500, batch loss 0.4219, batch acc 0.9774
15:22:31.699   Training iter 550, batch loss 0.4445, batch acc 0.9752
15:22:31.795   Training iter 600, batch loss 0.3919, batch acc 0.9782
15:22:31.795 Training @ 7 epoch...
15:22:31.899   Training iter 50, batch loss 0.3871, batch acc 0.9808
15:22:32.104   Training iter 100, batch loss 0.4145, batch acc 0.9768
15:22:32.215   Training iter 150, batch loss 0.4183, batch acc 0.9808
15:22:32.293   Training iter 200, batch loss 0.3779, batch acc 0.9758
15:22:32.395   Training iter 250, batch loss 0.3491, batch acc 0.9798
15:22:32.488   Training iter 300, batch loss 0.3552, batch acc 0.9784
15:22:32.575   Training iter 350, batch loss 0.3864, batch acc 0.9756
15:22:32.691   Training iter 400, batch loss 0.3586, batch acc 0.9804
15:22:32.873   Training iter 450, batch loss 0.3839, batch acc 0.9764
15:22:32.999   Training iter 500, batch loss 0.4232, batch acc 0.9760
15:22:33.112   Training iter 550, batch loss 0.4456, batch acc 0.9742
15:22:33.206   Training iter 600, batch loss 0.4183, batch acc 0.9780
15:22:33.207 Training @ 8 epoch...
15:22:33.300   Training iter 50, batch loss 0.3378, batch acc 0.9828
15:22:33.414   Training iter 100, batch loss 0.3457, batch acc 0.9800
15:22:33.514   Training iter 150, batch loss 0.2950, batch acc 0.9832
15:22:33.631   Training iter 200, batch loss 0.3460, batch acc 0.9768
15:22:33.801   Training iter 250, batch loss 0.4231, batch acc 0.9774
15:22:33.945   Training iter 300, batch loss 0.3673, batch acc 0.9784
15:22:34.075   Training iter 350, batch loss 0.3771, batch acc 0.9786
15:22:34.224   Training iter 400, batch loss 0.4118, batch acc 0.9794
15:22:34.329   Training iter 450, batch loss 0.3163, batch acc 0.9808
15:22:34.425   Training iter 500, batch loss 0.3719, batch acc 0.9808
15:22:34.529   Training iter 550, batch loss 0.3367, batch acc 0.9814
15:22:34.651   Training iter 600, batch loss 0.3629, batch acc 0.9800
15:22:34.651 Training @ 9 epoch...
15:22:34.788   Training iter 50, batch loss 0.3296, batch acc 0.9824
15:22:34.924   Training iter 100, batch loss 0.3210, batch acc 0.9808
15:22:35.042   Training iter 150, batch loss 0.3013, batch acc 0.9836
15:22:35.150   Training iter 200, batch loss 0.3159, batch acc 0.9824
15:22:35.280   Training iter 250, batch loss 0.3485, batch acc 0.9818
15:22:35.391   Training iter 300, batch loss 0.3239, batch acc 0.9830
15:22:35.505   Training iter 350, batch loss 0.3169, batch acc 0.9826
15:22:35.627   Training iter 400, batch loss 0.3268, batch acc 0.9814
15:22:35.770   Training iter 450, batch loss 0.3509, batch acc 0.9796
15:22:35.917   Training iter 500, batch loss 0.3355, batch acc 0.9812
15:22:36.052   Training iter 550, batch loss 0.3267, batch acc 0.9814
15:22:36.157   Training iter 600, batch loss 0.3577, batch acc 0.9796
15:22:36.158 Training @ 10 epoch...
15:22:36.255   Training iter 50, batch loss 0.2835, batch acc 0.9850
15:22:36.360   Training iter 100, batch loss 0.2549, batch acc 0.9854
15:22:36.462   Training iter 150, batch loss 0.2677, batch acc 0.9834
15:22:36.564   Training iter 200, batch loss 0.3023, batch acc 0.9832
15:22:36.665   Training iter 250, batch loss 0.3306, batch acc 0.9826
15:22:36.776   Training iter 300, batch loss 0.3357, batch acc 0.9814
15:22:36.891   Training iter 350, batch loss 0.3195, batch acc 0.9836
15:22:37.006   Training iter 400, batch loss 0.3212, batch acc 0.9828
15:22:37.112   Training iter 450, batch loss 0.2823, batch acc 0.9840
15:22:37.225   Training iter 500, batch loss 0.3593, batch acc 0.9796
15:22:37.324   Training iter 550, batch loss 0.3195, batch acc 0.9820
15:22:37.435   Training iter 600, batch loss 0.3316, batch acc 0.9822
15:22:37.436 Testing @ 10 epoch...
15:22:37.503     Testing, total mean loss 0.43585, total acc 0.97710
15:22:37.504 Training @ 11 epoch...
15:22:37.644   Training iter 50, batch loss 0.2975, batch acc 0.9842
15:22:37.744   Training iter 100, batch loss 0.2964, batch acc 0.9830
15:22:37.868   Training iter 150, batch loss 0.2629, batch acc 0.9842
15:22:37.987   Training iter 200, batch loss 0.2605, batch acc 0.9858
15:22:38.102   Training iter 250, batch loss 0.2918, batch acc 0.9840
15:22:38.217   Training iter 300, batch loss 0.2800, batch acc 0.9818
15:22:38.326   Training iter 350, batch loss 0.3138, batch acc 0.9826
15:22:38.450   Training iter 400, batch loss 0.2624, batch acc 0.9844
15:22:38.636   Training iter 450, batch loss 0.3267, batch acc 0.9816
15:22:38.798   Training iter 500, batch loss 0.2960, batch acc 0.9836
15:22:38.895   Training iter 550, batch loss 0.2778, batch acc 0.9854
15:22:39.017   Training iter 600, batch loss 0.2937, batch acc 0.9830
15:22:39.018 Training @ 12 epoch...
15:22:39.124   Training iter 50, batch loss 0.2307, batch acc 0.9852
15:22:39.247   Training iter 100, batch loss 0.2515, batch acc 0.9862
15:22:39.377   Training iter 150, batch loss 0.2544, batch acc 0.9842
15:22:39.477   Training iter 200, batch loss 0.1942, batch acc 0.9892
15:22:39.579   Training iter 250, batch loss 0.2462, batch acc 0.9876
15:22:39.713   Training iter 300, batch loss 0.2476, batch acc 0.9838
15:22:39.808   Training iter 350, batch loss 0.2713, batch acc 0.9856
15:22:39.931   Training iter 400, batch loss 0.2393, batch acc 0.9886
15:22:40.037   Training iter 450, batch loss 0.2598, batch acc 0.9850
15:22:40.165   Training iter 500, batch loss 0.2818, batch acc 0.9860
15:22:40.295   Training iter 550, batch loss 0.3161, batch acc 0.9834
15:22:40.424   Training iter 600, batch loss 0.2945, batch acc 0.9836
15:22:40.424 Training @ 13 epoch...
15:22:40.534   Training iter 50, batch loss 0.2925, batch acc 0.9834
15:22:40.645   Training iter 100, batch loss 0.2207, batch acc 0.9852
15:22:40.776   Training iter 150, batch loss 0.2210, batch acc 0.9878
15:22:40.902   Training iter 200, batch loss 0.3089, batch acc 0.9842
15:22:41.024   Training iter 250, batch loss 0.2141, batch acc 0.9890
15:22:41.157   Training iter 300, batch loss 0.2434, batch acc 0.9864
15:22:41.295   Training iter 350, batch loss 0.2333, batch acc 0.9862
15:22:41.464   Training iter 400, batch loss 0.2342, batch acc 0.9876
15:22:41.621   Training iter 450, batch loss 0.2343, batch acc 0.9858
15:22:41.746   Training iter 500, batch loss 0.2721, batch acc 0.9836
15:22:41.858   Training iter 550, batch loss 0.2480, batch acc 0.9856
15:22:41.964   Training iter 600, batch loss 0.2294, batch acc 0.9872
15:22:41.965 Training @ 14 epoch...
15:22:42.127   Training iter 50, batch loss 0.2135, batch acc 0.9884
15:22:42.251   Training iter 100, batch loss 0.2115, batch acc 0.9882
15:22:42.364   Training iter 150, batch loss 0.2193, batch acc 0.9888
15:22:42.492   Training iter 200, batch loss 0.2638, batch acc 0.9848
15:22:42.629   Training iter 250, batch loss 0.2052, batch acc 0.9904
15:22:42.726   Training iter 300, batch loss 0.2654, batch acc 0.9848
15:22:42.864   Training iter 350, batch loss 0.2686, batch acc 0.9832
15:22:42.974   Training iter 400, batch loss 0.3082, batch acc 0.9840
15:22:43.074   Training iter 450, batch loss 0.2343, batch acc 0.9868
15:22:43.183   Training iter 500, batch loss 0.2445, batch acc 0.9878
15:22:43.286   Training iter 550, batch loss 0.2314, batch acc 0.9866
15:22:43.451   Training iter 600, batch loss 0.2359, batch acc 0.9864
15:22:43.451 Training @ 15 epoch...
15:22:43.549   Training iter 50, batch loss 0.2125, batch acc 0.9900
15:22:43.652   Training iter 100, batch loss 0.1951, batch acc 0.9894
15:22:43.768   Training iter 150, batch loss 0.1892, batch acc 0.9900
15:22:43.886   Training iter 200, batch loss 0.2263, batch acc 0.9880
15:22:44.006   Training iter 250, batch loss 0.2050, batch acc 0.9874
15:22:44.125   Training iter 300, batch loss 0.2025, batch acc 0.9898
15:22:44.255   Training iter 350, batch loss 0.2334, batch acc 0.9884
15:22:44.376   Training iter 400, batch loss 0.1739, batch acc 0.9904
15:22:44.491   Training iter 450, batch loss 0.2131, batch acc 0.9878
15:22:44.639   Training iter 500, batch loss 0.2470, batch acc 0.9856
15:22:44.738   Training iter 550, batch loss 0.3272, batch acc 0.9816
15:22:44.839   Training iter 600, batch loss 0.2660, batch acc 0.9844
15:22:44.839 Testing @ 15 epoch...
15:22:44.938     Testing, total mean loss 0.46015, total acc 0.97380
15:22:44.938 Training @ 16 epoch...
15:22:45.051   Training iter 50, batch loss 0.2054, batch acc 0.9862
15:22:45.178   Training iter 100, batch loss 0.1983, batch acc 0.9892
15:22:45.304   Training iter 150, batch loss 0.1789, batch acc 0.9916
15:22:45.430   Training iter 200, batch loss 0.2046, batch acc 0.9898
15:22:45.543   Training iter 250, batch loss 0.1939, batch acc 0.9894
15:22:45.663   Training iter 300, batch loss 0.1925, batch acc 0.9908
15:22:45.774   Training iter 350, batch loss 0.2327, batch acc 0.9888
15:22:45.873   Training iter 400, batch loss 0.2185, batch acc 0.9878
15:22:46.059   Training iter 450, batch loss 0.2056, batch acc 0.9894
15:22:46.200   Training iter 500, batch loss 0.2294, batch acc 0.9866
15:22:46.302   Training iter 550, batch loss 0.2225, batch acc 0.9884
15:22:46.416   Training iter 600, batch loss 0.2586, batch acc 0.9844
15:22:46.417 Training @ 17 epoch...
15:22:46.551   Training iter 50, batch loss 0.1686, batch acc 0.9902
15:22:46.914   Training iter 100, batch loss 0.2181, batch acc 0.9870
15:22:47.068   Training iter 150, batch loss 0.2293, batch acc 0.9880
15:22:47.200   Training iter 200, batch loss 0.2040, batch acc 0.9898
15:22:47.331   Training iter 250, batch loss 0.1967, batch acc 0.9884
15:22:47.460   Training iter 300, batch loss 0.2451, batch acc 0.9838
15:22:47.740   Training iter 350, batch loss 0.1899, batch acc 0.9898
15:22:47.939   Training iter 400, batch loss 0.2167, batch acc 0.9876
15:22:48.037   Training iter 450, batch loss 0.1767, batch acc 0.9908
15:22:48.140   Training iter 500, batch loss 0.2052, batch acc 0.9884
15:22:48.383   Training iter 550, batch loss 0.2102, batch acc 0.9904
15:22:48.529   Training iter 600, batch loss 0.2001, batch acc 0.9894
15:22:48.531 Training @ 18 epoch...
15:22:48.655   Training iter 50, batch loss 0.1538, batch acc 0.9918
15:22:48.771   Training iter 100, batch loss 0.1682, batch acc 0.9912
15:22:48.952   Training iter 150, batch loss 0.2134, batch acc 0.9886
15:22:49.091   Training iter 200, batch loss 0.2056, batch acc 0.9896
15:22:49.220   Training iter 250, batch loss 0.1971, batch acc 0.9890
15:22:49.323   Training iter 300, batch loss 0.2054, batch acc 0.9894
15:22:49.442   Training iter 350, batch loss 0.2017, batch acc 0.9886
15:22:49.574   Training iter 400, batch loss 0.2138, batch acc 0.9898
15:22:49.685   Training iter 450, batch loss 0.1755, batch acc 0.9910
15:22:49.813   Training iter 500, batch loss 0.2397, batch acc 0.9878
15:22:49.953   Training iter 550, batch loss 0.2222, batch acc 0.9868
15:22:50.138   Training iter 600, batch loss 0.1708, batch acc 0.9924
15:22:50.139 Training @ 19 epoch...
15:22:50.276   Training iter 50, batch loss 0.1994, batch acc 0.9882
15:22:50.408   Training iter 100, batch loss 0.1707, batch acc 0.9908
15:22:50.512   Training iter 150, batch loss 0.2233, batch acc 0.9878
15:22:50.634   Training iter 200, batch loss 0.1782, batch acc 0.9900
15:22:50.748   Training iter 250, batch loss 0.1737, batch acc 0.9904
15:22:50.851   Training iter 300, batch loss 0.1603, batch acc 0.9912
15:22:51.002   Training iter 350, batch loss 0.2149, batch acc 0.9908
15:22:51.118   Training iter 400, batch loss 0.1813, batch acc 0.9904
15:22:51.218   Training iter 450, batch loss 0.1900, batch acc 0.9888
15:22:51.334   Training iter 500, batch loss 0.1409, batch acc 0.9922
15:22:51.456   Training iter 550, batch loss 0.2193, batch acc 0.9876
15:22:51.557   Training iter 600, batch loss 0.2036, batch acc 0.9886
15:22:51.558 Training @ 20 epoch...
15:22:51.657   Training iter 50, batch loss 0.1535, batch acc 0.9936
15:22:51.759   Training iter 100, batch loss 0.1402, batch acc 0.9938
15:22:51.875   Training iter 150, batch loss 0.1777, batch acc 0.9892
15:22:51.983   Training iter 200, batch loss 0.1839, batch acc 0.9912
15:22:52.087   Training iter 250, batch loss 0.1921, batch acc 0.9886
15:22:52.189   Training iter 300, batch loss 0.1749, batch acc 0.9904
15:22:52.295   Training iter 350, batch loss 0.1758, batch acc 0.9902
15:22:52.416   Training iter 400, batch loss 0.1818, batch acc 0.9902
15:22:52.540   Training iter 450, batch loss 0.1917, batch acc 0.9896
15:22:52.665   Training iter 500, batch loss 0.1807, batch acc 0.9908
15:22:52.801   Training iter 550, batch loss 0.1975, batch acc 0.9892
15:22:52.987   Training iter 600, batch loss 0.1807, batch acc 0.9896
15:22:52.988 Testing @ 20 epoch...
15:22:53.084     Testing, total mean loss 0.39535, total acc 0.97910
15:22:53.084 Training @ 21 epoch...
15:22:53.226   Training iter 50, batch loss 0.1939, batch acc 0.9884
15:22:53.333   Training iter 100, batch loss 0.1557, batch acc 0.9916
15:22:53.440   Training iter 150, batch loss 0.1765, batch acc 0.9908
15:22:53.541   Training iter 200, batch loss 0.1785, batch acc 0.9898
15:22:53.644   Training iter 250, batch loss 0.1615, batch acc 0.9916
15:22:53.757   Training iter 300, batch loss 0.2058, batch acc 0.9888
15:22:53.860   Training iter 350, batch loss 0.1838, batch acc 0.9910
15:22:54.006   Training iter 400, batch loss 0.1672, batch acc 0.9918
15:22:54.116   Training iter 450, batch loss 0.1531, batch acc 0.9914
15:22:54.217   Training iter 500, batch loss 0.1387, batch acc 0.9930
15:22:54.325   Training iter 550, batch loss 0.1558, batch acc 0.9902
15:22:54.432   Training iter 600, batch loss 0.2248, batch acc 0.9886
15:22:54.433 Training @ 22 epoch...
15:22:54.534   Training iter 50, batch loss 0.1756, batch acc 0.9898
15:22:54.642   Training iter 100, batch loss 0.1655, batch acc 0.9914
15:22:54.756   Training iter 150, batch loss 0.1675, batch acc 0.9914
15:22:54.870   Training iter 200, batch loss 0.1461, batch acc 0.9926
15:22:54.977   Training iter 250, batch loss 0.1893, batch acc 0.9890
15:22:55.086   Training iter 300, batch loss 0.1871, batch acc 0.9914
15:22:55.198   Training iter 350, batch loss 0.1614, batch acc 0.9908
15:22:55.324   Training iter 400, batch loss 0.1642, batch acc 0.9924
15:22:55.446   Training iter 450, batch loss 0.1803, batch acc 0.9894
15:22:55.573   Training iter 500, batch loss 0.1450, batch acc 0.9916
15:22:55.703   Training iter 550, batch loss 0.1656, batch acc 0.9910
15:22:55.828   Training iter 600, batch loss 0.1633, batch acc 0.9908
15:22:55.830 Training @ 23 epoch...
15:22:55.998   Training iter 50, batch loss 0.1250, batch acc 0.9934
15:22:56.109   Training iter 100, batch loss 0.1364, batch acc 0.9930
15:22:56.208   Training iter 150, batch loss 0.1304, batch acc 0.9930
15:22:56.315   Training iter 200, batch loss 0.1481, batch acc 0.9928
15:22:56.415   Training iter 250, batch loss 0.1285, batch acc 0.9944
15:22:56.515   Training iter 300, batch loss 0.1710, batch acc 0.9910
15:22:56.621   Training iter 350, batch loss 0.1843, batch acc 0.9904
15:22:56.736   Training iter 400, batch loss 0.1863, batch acc 0.9898
15:22:56.844   Training iter 450, batch loss 0.1683, batch acc 0.9914
15:22:56.951   Training iter 500, batch loss 0.1694, batch acc 0.9900
15:22:57.055   Training iter 550, batch loss 0.2008, batch acc 0.9886
15:22:57.167   Training iter 600, batch loss 0.1600, batch acc 0.9916
15:22:57.167 Training @ 24 epoch...
15:22:57.271   Training iter 50, batch loss 0.1328, batch acc 0.9944
15:22:57.379   Training iter 100, batch loss 0.1496, batch acc 0.9922
15:22:57.488   Training iter 150, batch loss 0.1321, batch acc 0.9934
15:22:57.587   Training iter 200, batch loss 0.1824, batch acc 0.9910
15:22:57.688   Training iter 250, batch loss 0.1324, batch acc 0.9942
15:22:57.806   Training iter 300, batch loss 0.1687, batch acc 0.9920
15:22:57.937   Training iter 350, batch loss 0.1773, batch acc 0.9902
15:22:58.064   Training iter 400, batch loss 0.1877, batch acc 0.9898
15:22:58.171   Training iter 450, batch loss 0.1597, batch acc 0.9916
15:22:58.284   Training iter 500, batch loss 0.1378, batch acc 0.9934
15:22:58.404   Training iter 550, batch loss 0.1725, batch acc 0.9920
15:22:58.526   Training iter 600, batch loss 0.1851, batch acc 0.9900
15:22:58.527 Training @ 25 epoch...
15:22:58.650   Training iter 50, batch loss 0.1373, batch acc 0.9932
15:22:58.785   Training iter 100, batch loss 0.1371, batch acc 0.9934
15:22:58.998   Training iter 150, batch loss 0.1298, batch acc 0.9928
15:22:59.093   Training iter 200, batch loss 0.1452, batch acc 0.9922
15:22:59.235   Training iter 250, batch loss 0.1686, batch acc 0.9910
15:22:59.334   Training iter 300, batch loss 0.1714, batch acc 0.9908
15:22:59.438   Training iter 350, batch loss 0.1962, batch acc 0.9902
15:22:59.553   Training iter 400, batch loss 0.1578, batch acc 0.9932
15:22:59.656   Training iter 450, batch loss 0.1707, batch acc 0.9892
15:22:59.773   Training iter 500, batch loss 0.2047, batch acc 0.9890
15:22:59.880   Training iter 550, batch loss 0.1495, batch acc 0.9922
15:22:59.995   Training iter 600, batch loss 0.1755, batch acc 0.9900
15:22:59.997 Testing @ 25 epoch...
15:23:00.086     Testing, total mean loss 0.45455, total acc 0.97480
15:23:00.086 Training @ 26 epoch...
15:23:00.188   Training iter 50, batch loss 0.1371, batch acc 0.9946
15:23:00.300   Training iter 100, batch loss 0.1408, batch acc 0.9916
15:23:00.406   Training iter 150, batch loss 0.1480, batch acc 0.9932
15:23:00.520   Training iter 200, batch loss 0.1347, batch acc 0.9926
15:23:00.622   Training iter 250, batch loss 0.1344, batch acc 0.9930
15:23:00.747   Training iter 300, batch loss 0.1384, batch acc 0.9938
15:23:00.876   Training iter 350, batch loss 0.1596, batch acc 0.9920
15:23:01.016   Training iter 400, batch loss 0.1607, batch acc 0.9900
15:23:01.166   Training iter 450, batch loss 0.1641, batch acc 0.9918
15:23:01.292   Training iter 500, batch loss 0.1811, batch acc 0.9902
15:23:01.411   Training iter 550, batch loss 0.2061, batch acc 0.9890
15:23:01.539   Training iter 600, batch loss 0.1599, batch acc 0.9912
15:23:01.541 Training @ 27 epoch...
15:23:01.691   Training iter 50, batch loss 0.1790, batch acc 0.9910
15:23:01.832   Training iter 100, batch loss 0.1161, batch acc 0.9946
15:23:01.996   Training iter 150, batch loss 0.1467, batch acc 0.9928
15:23:02.122   Training iter 200, batch loss 0.1337, batch acc 0.9922
15:23:02.245   Training iter 250, batch loss 0.1527, batch acc 0.9926
15:23:02.354   Training iter 300, batch loss 0.1575, batch acc 0.9930
15:23:02.467   Training iter 350, batch loss 0.1259, batch acc 0.9938
15:23:02.572   Training iter 400, batch loss 0.1240, batch acc 0.9940
15:23:02.689   Training iter 450, batch loss 0.1709, batch acc 0.9898
15:23:02.806   Training iter 500, batch loss 0.1767, batch acc 0.9904
15:23:02.924   Training iter 550, batch loss 0.1966, batch acc 0.9888
15:23:03.031   Training iter 600, batch loss 0.1862, batch acc 0.9896
15:23:03.031 Training @ 28 epoch...
15:23:03.137   Training iter 50, batch loss 0.1259, batch acc 0.9924
15:23:03.245   Training iter 100, batch loss 0.1171, batch acc 0.9948
15:23:03.357   Training iter 150, batch loss 0.1373, batch acc 0.9936
15:23:03.467   Training iter 200, batch loss 0.1374, batch acc 0.9930
15:23:03.573   Training iter 250, batch loss 0.1483, batch acc 0.9930
15:23:03.677   Training iter 300, batch loss 0.1405, batch acc 0.9924
15:23:03.810   Training iter 350, batch loss 0.1358, batch acc 0.9918
15:23:03.933   Training iter 400, batch loss 0.1557, batch acc 0.9930
15:23:04.071   Training iter 450, batch loss 0.1689, batch acc 0.9910
15:23:04.203   Training iter 500, batch loss 0.1527, batch acc 0.9916
15:23:04.325   Training iter 550, batch loss 0.1629, batch acc 0.9914
15:23:04.458   Training iter 600, batch loss 0.1371, batch acc 0.9930
15:23:04.459 Training @ 29 epoch...
15:23:04.600   Training iter 50, batch loss 0.1197, batch acc 0.9940
15:23:04.706   Training iter 100, batch loss 0.1306, batch acc 0.9936
15:23:04.810   Training iter 150, batch loss 0.1329, batch acc 0.9936
15:23:04.968   Training iter 200, batch loss 0.1545, batch acc 0.9914
15:23:05.077   Training iter 250, batch loss 0.1451, batch acc 0.9938
15:23:05.176   Training iter 300, batch loss 0.1507, batch acc 0.9916
15:23:05.278   Training iter 350, batch loss 0.1529, batch acc 0.9912
15:23:05.415   Training iter 400, batch loss 0.1337, batch acc 0.9938
15:23:05.529   Training iter 450, batch loss 0.1822, batch acc 0.9910
15:23:05.633   Training iter 500, batch loss 0.1186, batch acc 0.9928
15:23:05.750   Training iter 550, batch loss 0.1655, batch acc 0.9906
15:23:05.853   Training iter 600, batch loss 0.1708, batch acc 0.9932
15:23:05.854 Training @ 30 epoch...
15:23:05.973   Training iter 50, batch loss 0.1383, batch acc 0.9934
15:23:06.088   Training iter 100, batch loss 0.1262, batch acc 0.9952
15:23:06.198   Training iter 150, batch loss 0.1631, batch acc 0.9904
15:23:06.302   Training iter 200, batch loss 0.1250, batch acc 0.9938
15:23:06.409   Training iter 250, batch loss 0.1179, batch acc 0.9934
15:23:06.513   Training iter 300, batch loss 0.1633, batch acc 0.9926
15:23:06.632   Training iter 350, batch loss 0.1248, batch acc 0.9938
15:23:06.752   Training iter 400, batch loss 0.1471, batch acc 0.9922
15:23:06.876   Training iter 450, batch loss 0.1665, batch acc 0.9920
15:23:07.007   Training iter 500, batch loss 0.1406, batch acc 0.9932
15:23:07.139   Training iter 550, batch loss 0.1550, batch acc 0.9920
15:23:07.251   Training iter 600, batch loss 0.1406, batch acc 0.9928
15:23:07.251 Testing @ 30 epoch...
15:23:07.342     Testing, total mean loss 0.38562, total acc 0.98040
15:23:07.343 Training @ 31 epoch...
15:23:07.482   Training iter 50, batch loss 0.1216, batch acc 0.9928
15:23:07.633   Training iter 100, batch loss 0.1311, batch acc 0.9938
15:23:07.743   Training iter 150, batch loss 0.1110, batch acc 0.9954
15:23:07.851   Training iter 200, batch loss 0.1281, batch acc 0.9936
15:23:07.962   Training iter 250, batch loss 0.1395, batch acc 0.9934
15:23:08.060   Training iter 300, batch loss 0.1227, batch acc 0.9940
15:23:08.179   Training iter 350, batch loss 0.1406, batch acc 0.9932
15:23:08.285   Training iter 400, batch loss 0.1400, batch acc 0.9932
15:23:08.398   Training iter 450, batch loss 0.1500, batch acc 0.9942
15:23:08.504   Training iter 500, batch loss 0.1510, batch acc 0.9912
15:23:08.600   Training iter 550, batch loss 0.1476, batch acc 0.9912
15:23:08.708   Training iter 600, batch loss 0.1985, batch acc 0.9900
15:23:08.709 Training @ 32 epoch...
15:23:08.822   Training iter 50, batch loss 0.1527, batch acc 0.9920
15:23:08.938   Training iter 100, batch loss 0.1537, batch acc 0.9916
15:23:09.047   Training iter 150, batch loss 0.1096, batch acc 0.9940
15:23:09.153   Training iter 200, batch loss 0.1171, batch acc 0.9954
15:23:09.321   Training iter 250, batch loss 0.1327, batch acc 0.9944
15:23:09.457   Training iter 300, batch loss 0.1191, batch acc 0.9936
15:23:09.597   Training iter 350, batch loss 0.1280, batch acc 0.9932
15:23:09.725   Training iter 400, batch loss 0.1327, batch acc 0.9934
15:23:09.868   Training iter 450, batch loss 0.1404, batch acc 0.9918
15:23:10.006   Training iter 500, batch loss 0.1536, batch acc 0.9924
15:23:10.148   Training iter 550, batch loss 0.1217, batch acc 0.9938
15:23:10.271   Training iter 600, batch loss 0.1410, batch acc 0.9934
15:23:10.272 Training @ 33 epoch...
15:23:10.458   Training iter 50, batch loss 0.1059, batch acc 0.9954
15:23:10.560   Training iter 100, batch loss 0.1298, batch acc 0.9942
15:23:10.664   Training iter 150, batch loss 0.1081, batch acc 0.9948
15:23:10.766   Training iter 200, batch loss 0.1444, batch acc 0.9922
15:23:10.939   Training iter 250, batch loss 0.1369, batch acc 0.9944
15:23:11.052   Training iter 300, batch loss 0.1194, batch acc 0.9936
15:23:11.167   Training iter 350, batch loss 0.1409, batch acc 0.9930
15:23:11.268   Training iter 400, batch loss 0.1447, batch acc 0.9930
15:23:11.373   Training iter 450, batch loss 0.1563, batch acc 0.9914
15:23:11.540   Training iter 500, batch loss 0.1119, batch acc 0.9950
15:23:11.649   Training iter 550, batch loss 0.1415, batch acc 0.9926
15:23:11.762   Training iter 600, batch loss 0.1332, batch acc 0.9944
15:23:11.764 Training @ 34 epoch...
15:23:11.886   Training iter 50, batch loss 0.1065, batch acc 0.9950
15:23:11.994   Training iter 100, batch loss 0.1304, batch acc 0.9922
15:23:12.095   Training iter 150, batch loss 0.1402, batch acc 0.9928
15:23:12.213   Training iter 200, batch loss 0.1308, batch acc 0.9922
15:23:12.322   Training iter 250, batch loss 0.1695, batch acc 0.9912
15:23:12.455   Training iter 300, batch loss 0.1298, batch acc 0.9936
15:23:12.575   Training iter 350, batch loss 0.1264, batch acc 0.9946
15:23:12.706   Training iter 400, batch loss 0.1409, batch acc 0.9926
15:23:12.831   Training iter 450, batch loss 0.1660, batch acc 0.9916
15:23:12.957   Training iter 500, batch loss 0.1386, batch acc 0.9934
15:23:13.090   Training iter 550, batch loss 0.1519, batch acc 0.9914
15:23:13.226   Training iter 600, batch loss 0.1339, batch acc 0.9942
15:23:13.228 Training @ 35 epoch...
15:23:13.343   Training iter 50, batch loss 0.1332, batch acc 0.9942
15:23:13.450   Training iter 100, batch loss 0.1432, batch acc 0.9934
15:23:13.556   Training iter 150, batch loss 0.1197, batch acc 0.9938
15:23:13.667   Training iter 200, batch loss 0.1224, batch acc 0.9940
15:23:13.778   Training iter 250, batch loss 0.1239, batch acc 0.9938
15:23:13.883   Training iter 300, batch loss 0.1271, batch acc 0.9930
15:23:14.016   Training iter 350, batch loss 0.1355, batch acc 0.9938
15:23:14.124   Training iter 400, batch loss 0.1182, batch acc 0.9960
15:23:14.244   Training iter 450, batch loss 0.1558, batch acc 0.9912
15:23:14.345   Training iter 500, batch loss 0.1141, batch acc 0.9948
15:23:14.449   Training iter 550, batch loss 0.1068, batch acc 0.9946
15:23:14.555   Training iter 600, batch loss 0.1216, batch acc 0.9930
15:23:14.556 Testing @ 35 epoch...
15:23:14.630     Testing, total mean loss 0.38600, total acc 0.97960
15:23:14.630 Training @ 36 epoch...
15:23:14.759   Training iter 50, batch loss 0.1384, batch acc 0.9922
15:23:14.863   Training iter 100, batch loss 0.1112, batch acc 0.9952
15:23:14.964   Training iter 150, batch loss 0.1112, batch acc 0.9952
15:23:15.067   Training iter 200, batch loss 0.1236, batch acc 0.9944
15:23:15.173   Training iter 250, batch loss 0.1373, batch acc 0.9930
15:23:15.318   Training iter 300, batch loss 0.1164, batch acc 0.9954
15:23:15.449   Training iter 350, batch loss 0.1328, batch acc 0.9942
15:23:15.581   Training iter 400, batch loss 0.1391, batch acc 0.9934
15:23:15.702   Training iter 450, batch loss 0.1211, batch acc 0.9946
15:23:15.826   Training iter 500, batch loss 0.1626, batch acc 0.9924
15:23:15.976   Training iter 550, batch loss 0.1298, batch acc 0.9936
15:23:16.088   Training iter 600, batch loss 0.1477, batch acc 0.9928
15:23:16.090 Training @ 37 epoch...
15:23:16.203   Training iter 50, batch loss 0.1381, batch acc 0.9936
15:23:16.306   Training iter 100, batch loss 0.1221, batch acc 0.9942
15:23:16.417   Training iter 150, batch loss 0.1110, batch acc 0.9956
15:23:16.519   Training iter 200, batch loss 0.1215, batch acc 0.9954
15:23:16.618   Training iter 250, batch loss 0.1247, batch acc 0.9944
15:23:16.728   Training iter 300, batch loss 0.1147, batch acc 0.9938
15:23:16.850   Training iter 350, batch loss 0.1367, batch acc 0.9942
15:23:16.959   Training iter 400, batch loss 0.1044, batch acc 0.9956
15:23:17.056   Training iter 450, batch loss 0.1072, batch acc 0.9956
15:23:17.166   Training iter 500, batch loss 0.1346, batch acc 0.9936
15:23:17.269   Training iter 550, batch loss 0.1324, batch acc 0.9948
15:23:17.362   Training iter 600, batch loss 0.1720, batch acc 0.9912
15:23:17.363 Training @ 38 epoch...
15:23:17.460   Training iter 50, batch loss 0.1339, batch acc 0.9934
15:23:17.565   Training iter 100, batch loss 0.1204, batch acc 0.9956
15:23:17.686   Training iter 150, batch loss 0.0969, batch acc 0.9964
15:23:17.791   Training iter 200, batch loss 0.1206, batch acc 0.9932
15:23:17.903   Training iter 250, batch loss 0.1131, batch acc 0.9948
15:23:18.050   Training iter 300, batch loss 0.1355, batch acc 0.9928
15:23:18.181   Training iter 350, batch loss 0.1417, batch acc 0.9934
15:23:18.294   Training iter 400, batch loss 0.1244, batch acc 0.9948
15:23:18.422   Training iter 450, batch loss 0.1146, batch acc 0.9952
15:23:18.549   Training iter 500, batch loss 0.1329, batch acc 0.9936
15:23:18.659   Training iter 550, batch loss 0.1278, batch acc 0.9948
15:23:18.800   Training iter 600, batch loss 0.1318, batch acc 0.9942
15:23:18.802 Training @ 39 epoch...
15:23:18.955   Training iter 50, batch loss 0.0912, batch acc 0.9954
15:23:19.071   Training iter 100, batch loss 0.0975, batch acc 0.9956
15:23:19.177   Training iter 150, batch loss 0.1043, batch acc 0.9948
15:23:19.289   Training iter 200, batch loss 0.1241, batch acc 0.9954
15:23:19.400   Training iter 250, batch loss 0.1047, batch acc 0.9950
15:23:19.499   Training iter 300, batch loss 0.1499, batch acc 0.9920
15:23:19.615   Training iter 350, batch loss 0.1346, batch acc 0.9942
15:23:19.718   Training iter 400, batch loss 0.1056, batch acc 0.9958
15:23:19.838   Training iter 450, batch loss 0.1374, batch acc 0.9934
15:23:19.973   Training iter 500, batch loss 0.1332, batch acc 0.9938
15:23:20.081   Training iter 550, batch loss 0.1439, batch acc 0.9924
15:23:20.190   Training iter 600, batch loss 0.1144, batch acc 0.9954
15:23:20.190 Training @ 40 epoch...
15:23:20.296   Training iter 50, batch loss 0.1012, batch acc 0.9960
15:23:20.393   Training iter 100, batch loss 0.1040, batch acc 0.9954
15:23:20.506   Training iter 150, batch loss 0.0964, batch acc 0.9942
15:23:20.610   Training iter 200, batch loss 0.1227, batch acc 0.9942
15:23:20.716   Training iter 250, batch loss 0.1174, batch acc 0.9944
15:23:20.828   Training iter 300, batch loss 0.1237, batch acc 0.9940
15:23:20.943   Training iter 350, batch loss 0.1153, batch acc 0.9946
15:23:21.063   Training iter 400, batch loss 0.1335, batch acc 0.9928
15:23:21.167   Training iter 450, batch loss 0.1528, batch acc 0.9928
15:23:21.279   Training iter 500, batch loss 0.1613, batch acc 0.9914
15:23:21.392   Training iter 550, batch loss 0.0892, batch acc 0.9958
15:23:21.498   Training iter 600, batch loss 0.1373, batch acc 0.9926
15:23:21.500 Testing @ 40 epoch...
15:23:21.614     Testing, total mean loss 0.38953, total acc 0.98000
15:23:21.614 Training @ 41 epoch...
15:23:21.713   Training iter 50, batch loss 0.1031, batch acc 0.9960
15:23:21.836   Training iter 100, batch loss 0.1131, batch acc 0.9954
15:23:21.942   Training iter 150, batch loss 0.1188, batch acc 0.9950
15:23:22.055   Training iter 200, batch loss 0.1174, batch acc 0.9952
15:23:22.173   Training iter 250, batch loss 0.1358, batch acc 0.9930
15:23:22.273   Training iter 300, batch loss 0.1317, batch acc 0.9934
15:23:22.375   Training iter 350, batch loss 0.1202, batch acc 0.9938
15:23:22.474   Training iter 400, batch loss 0.1144, batch acc 0.9944
15:23:22.584   Training iter 450, batch loss 0.1346, batch acc 0.9948
15:23:22.685   Training iter 500, batch loss 0.1292, batch acc 0.9950
15:23:22.804   Training iter 550, batch loss 0.0992, batch acc 0.9960
15:23:22.916   Training iter 600, batch loss 0.1204, batch acc 0.9948
15:23:22.918 Training @ 42 epoch...
15:23:23.026   Training iter 50, batch loss 0.0834, batch acc 0.9966
15:23:23.129   Training iter 100, batch loss 0.1004, batch acc 0.9948
15:23:23.232   Training iter 150, batch loss 0.1302, batch acc 0.9952
15:23:23.347   Training iter 200, batch loss 0.1197, batch acc 0.9954
15:23:23.487   Training iter 250, batch loss 0.1208, batch acc 0.9944
15:23:23.588   Training iter 300, batch loss 0.1331, batch acc 0.9934
15:23:23.720   Training iter 350, batch loss 0.1180, batch acc 0.9950
15:23:23.838   Training iter 400, batch loss 0.1146, batch acc 0.9948
15:23:23.970   Training iter 450, batch loss 0.1119, batch acc 0.9946
15:23:24.108   Training iter 500, batch loss 0.1287, batch acc 0.9936
15:23:24.259   Training iter 550, batch loss 0.1505, batch acc 0.9946
15:23:24.413   Training iter 600, batch loss 0.1288, batch acc 0.9950
15:23:24.414 Training @ 43 epoch...
15:23:24.544   Training iter 50, batch loss 0.1014, batch acc 0.9954
15:23:24.649   Training iter 100, batch loss 0.1104, batch acc 0.9950
15:23:24.776   Training iter 150, batch loss 0.1073, batch acc 0.9956
15:23:24.908   Training iter 200, batch loss 0.1001, batch acc 0.9966
15:23:25.073   Training iter 250, batch loss 0.1058, batch acc 0.9956
15:23:25.188   Training iter 300, batch loss 0.1281, batch acc 0.9944
15:23:25.299   Training iter 350, batch loss 0.1093, batch acc 0.9956
15:23:25.442   Training iter 400, batch loss 0.1033, batch acc 0.9952
15:23:25.589   Training iter 450, batch loss 0.1112, batch acc 0.9938
15:23:25.689   Training iter 500, batch loss 0.1295, batch acc 0.9944
15:23:25.805   Training iter 550, batch loss 0.1382, batch acc 0.9938
15:23:25.930   Training iter 600, batch loss 0.1278, batch acc 0.9938
15:23:25.930 Training @ 44 epoch...
15:23:26.053   Training iter 50, batch loss 0.0912, batch acc 0.9944
15:23:26.164   Training iter 100, batch loss 0.1271, batch acc 0.9944
15:23:26.260   Training iter 150, batch loss 0.0971, batch acc 0.9968
15:23:26.390   Training iter 200, batch loss 0.1190, batch acc 0.9942
15:23:26.518   Training iter 250, batch loss 0.1339, batch acc 0.9936
15:23:26.653   Training iter 300, batch loss 0.1267, batch acc 0.9942
15:23:26.780   Training iter 350, batch loss 0.0964, batch acc 0.9954
15:23:26.903   Training iter 400, batch loss 0.1294, batch acc 0.9946
15:23:27.070   Training iter 450, batch loss 0.0949, batch acc 0.9956
15:23:27.221   Training iter 500, batch loss 0.1198, batch acc 0.9948
15:23:27.329   Training iter 550, batch loss 0.1401, batch acc 0.9946
15:23:27.439   Training iter 600, batch loss 0.1443, batch acc 0.9934
15:23:27.440 Training @ 45 epoch...
15:23:27.544   Training iter 50, batch loss 0.0997, batch acc 0.9962
15:23:27.646   Training iter 100, batch loss 0.1159, batch acc 0.9958
15:23:27.755   Training iter 150, batch loss 0.1463, batch acc 0.9922
15:23:27.868   Training iter 200, batch loss 0.1185, batch acc 0.9946
15:23:27.985   Training iter 250, batch loss 0.1048, batch acc 0.9964
15:23:28.089   Training iter 300, batch loss 0.1325, batch acc 0.9950
15:23:28.195   Training iter 350, batch loss 0.1079, batch acc 0.9956
15:23:28.291   Training iter 400, batch loss 0.1043, batch acc 0.9958
15:23:28.404   Training iter 450, batch loss 0.1176, batch acc 0.9938
15:23:28.509   Training iter 500, batch loss 0.1484, batch acc 0.9936
15:23:28.615   Training iter 550, batch loss 0.1104, batch acc 0.9956
15:23:28.716   Training iter 600, batch loss 0.1080, batch acc 0.9948
15:23:28.717 Testing @ 45 epoch...
15:23:28.795     Testing, total mean loss 0.36859, total acc 0.98100
15:23:28.795 Training @ 46 epoch...
15:23:28.911   Training iter 50, batch loss 0.1030, batch acc 0.9950
15:23:29.009   Training iter 100, batch loss 0.0935, batch acc 0.9962
15:23:29.115   Training iter 150, batch loss 0.1195, batch acc 0.9938
15:23:29.252   Training iter 200, batch loss 0.1066, batch acc 0.9954
15:23:29.438   Training iter 250, batch loss 0.1041, batch acc 0.9950
15:23:29.560   Training iter 300, batch loss 0.1228, batch acc 0.9952
15:23:29.698   Training iter 350, batch loss 0.1188, batch acc 0.9936
15:23:29.860   Training iter 400, batch loss 0.1200, batch acc 0.9964
15:23:30.013   Training iter 450, batch loss 0.1196, batch acc 0.9950
15:23:30.118   Training iter 500, batch loss 0.1455, batch acc 0.9928
15:23:30.242   Training iter 550, batch loss 0.1145, batch acc 0.9962
15:23:30.376   Training iter 600, batch loss 0.1492, batch acc 0.9924
15:23:30.377 Training @ 47 epoch...
15:23:30.488   Training iter 50, batch loss 0.1060, batch acc 0.9958
15:23:30.600   Training iter 100, batch loss 0.1026, batch acc 0.9944
15:23:30.709   Training iter 150, batch loss 0.1195, batch acc 0.9946
15:23:30.837   Training iter 200, batch loss 0.1035, batch acc 0.9956
15:23:30.955   Training iter 250, batch loss 0.1077, batch acc 0.9952
15:23:31.072   Training iter 300, batch loss 0.1183, batch acc 0.9942
15:23:31.178   Training iter 350, batch loss 0.1265, batch acc 0.9946
15:23:31.292   Training iter 400, batch loss 0.1232, batch acc 0.9968
15:23:31.401   Training iter 450, batch loss 0.1375, batch acc 0.9936
15:23:31.508   Training iter 500, batch loss 0.1076, batch acc 0.9950
15:23:31.625   Training iter 550, batch loss 0.1259, batch acc 0.9946
15:23:31.729   Training iter 600, batch loss 0.1209, batch acc 0.9934
15:23:31.731 Training @ 48 epoch...
15:23:31.837   Training iter 50, batch loss 0.1177, batch acc 0.9940
15:23:31.971   Training iter 100, batch loss 0.1202, batch acc 0.9952
15:23:32.096   Training iter 150, batch loss 0.1086, batch acc 0.9954
15:23:32.225   Training iter 200, batch loss 0.1356, batch acc 0.9938
15:23:32.340   Training iter 250, batch loss 0.1215, batch acc 0.9950
15:23:32.472   Training iter 300, batch loss 0.0862, batch acc 0.9970
15:23:32.600   Training iter 350, batch loss 0.1249, batch acc 0.9940
15:23:32.716   Training iter 400, batch loss 0.1078, batch acc 0.9956
15:23:32.842   Training iter 450, batch loss 0.1217, batch acc 0.9958
15:23:33.039   Training iter 500, batch loss 0.1476, batch acc 0.9934
15:23:33.159   Training iter 550, batch loss 0.1124, batch acc 0.9946
15:23:33.274   Training iter 600, batch loss 0.1188, batch acc 0.9940
15:23:33.275 Training @ 49 epoch...
15:23:33.389   Training iter 50, batch loss 0.1087, batch acc 0.9962
15:23:33.517   Training iter 100, batch loss 0.1340, batch acc 0.9942
15:23:33.621   Training iter 150, batch loss 0.1097, batch acc 0.9950
15:23:33.728   Training iter 200, batch loss 0.1174, batch acc 0.9950
15:23:33.831   Training iter 250, batch loss 0.1106, batch acc 0.9946
15:23:33.953   Training iter 300, batch loss 0.1131, batch acc 0.9952
15:23:34.058   Training iter 350, batch loss 0.1075, batch acc 0.9950
15:23:34.164   Training iter 400, batch loss 0.1262, batch acc 0.9932
15:23:34.269   Training iter 450, batch loss 0.1148, batch acc 0.9948
15:23:34.416   Training iter 500, batch loss 0.0928, batch acc 0.9946
15:23:34.537   Training iter 550, batch loss 0.1344, batch acc 0.9932
15:23:34.645   Training iter 600, batch loss 0.1030, batch acc 0.9954
15:23:34.645 Training @ 50 epoch...
15:23:34.747   Training iter 50, batch loss 0.0923, batch acc 0.9954
15:23:34.885   Training iter 100, batch loss 0.1010, batch acc 0.9962
15:23:35.005   Training iter 150, batch loss 0.1127, batch acc 0.9954
15:23:35.125   Training iter 200, batch loss 0.0986, batch acc 0.9966
15:23:35.301   Training iter 250, batch loss 0.0877, batch acc 0.9960
15:23:35.425   Training iter 300, batch loss 0.1183, batch acc 0.9934
15:23:35.555   Training iter 350, batch loss 0.1277, batch acc 0.9952
15:23:35.689   Training iter 400, batch loss 0.1105, batch acc 0.9948
15:23:35.834   Training iter 450, batch loss 0.1170, batch acc 0.9942
15:23:35.947   Training iter 500, batch loss 0.1052, batch acc 0.9950
15:23:36.052   Training iter 550, batch loss 0.1174, batch acc 0.9948
15:23:36.164   Training iter 600, batch loss 0.1228, batch acc 0.9944
15:23:36.165 Testing @ 50 epoch...
15:23:36.232     Testing, total mean loss 0.35935, total acc 0.98180
15:23:36.233 Training @ 51 epoch...
15:23:36.332   Training iter 50, batch loss 0.0842, batch acc 0.9964
15:23:36.440   Training iter 100, batch loss 0.0992, batch acc 0.9958
15:23:36.545   Training iter 150, batch loss 0.0856, batch acc 0.9968
15:23:36.649   Training iter 200, batch loss 0.1207, batch acc 0.9948
15:23:36.756   Training iter 250, batch loss 0.1260, batch acc 0.9942
15:23:36.877   Training iter 300, batch loss 0.1183, batch acc 0.9948
15:23:36.986   Training iter 350, batch loss 0.1102, batch acc 0.9954
15:23:37.125   Training iter 400, batch loss 0.1015, batch acc 0.9964
15:23:37.231   Training iter 450, batch loss 0.1177, batch acc 0.9952
15:23:37.336   Training iter 500, batch loss 0.1092, batch acc 0.9954
15:23:37.441   Training iter 550, batch loss 0.1089, batch acc 0.9944
15:23:37.537   Training iter 600, batch loss 0.1172, batch acc 0.9946
15:23:37.538 Training @ 52 epoch...
15:23:37.685   Training iter 50, batch loss 0.1348, batch acc 0.9930
15:23:37.784   Training iter 100, batch loss 0.0877, batch acc 0.9976
15:23:37.915   Training iter 150, batch loss 0.0933, batch acc 0.9958
15:23:38.048   Training iter 200, batch loss 0.1158, batch acc 0.9954
15:23:38.185   Training iter 250, batch loss 0.1275, batch acc 0.9936
15:23:38.316   Training iter 300, batch loss 0.0947, batch acc 0.9970
15:23:38.445   Training iter 350, batch loss 0.0991, batch acc 0.9950
15:23:38.573   Training iter 400, batch loss 0.0985, batch acc 0.9962
15:23:38.709   Training iter 450, batch loss 0.1110, batch acc 0.9942
15:23:38.817   Training iter 500, batch loss 0.1260, batch acc 0.9950
15:23:38.929   Training iter 550, batch loss 0.1274, batch acc 0.9952
15:23:39.033   Training iter 600, batch loss 0.1279, batch acc 0.9944
15:23:39.035 Training @ 53 epoch...
15:23:39.156   Training iter 50, batch loss 0.0951, batch acc 0.9958
15:23:39.286   Training iter 100, batch loss 0.1032, batch acc 0.9958
15:23:39.400   Training iter 150, batch loss 0.1134, batch acc 0.9944
15:23:39.518   Training iter 200, batch loss 0.1063, batch acc 0.9952
15:23:39.629   Training iter 250, batch loss 0.0901, batch acc 0.9952
15:23:39.752   Training iter 300, batch loss 0.1024, batch acc 0.9972
15:23:39.867   Training iter 350, batch loss 0.1275, batch acc 0.9936
15:23:39.986   Training iter 400, batch loss 0.1225, batch acc 0.9944
15:23:40.091   Training iter 450, batch loss 0.1028, batch acc 0.9962
15:23:40.195   Training iter 500, batch loss 0.1118, batch acc 0.9952
15:23:40.295   Training iter 550, batch loss 0.1131, batch acc 0.9956
15:23:40.398   Training iter 600, batch loss 0.1284, batch acc 0.9954
15:23:40.399 Training @ 54 epoch...
15:23:40.550   Training iter 50, batch loss 0.0838, batch acc 0.9972
15:23:40.680   Training iter 100, batch loss 0.0907, batch acc 0.9966
15:23:40.805   Training iter 150, batch loss 0.0798, batch acc 0.9974
15:23:40.944   Training iter 200, batch loss 0.0900, batch acc 0.9968
15:23:41.075   Training iter 250, batch loss 0.1070, batch acc 0.9946
15:23:41.209   Training iter 300, batch loss 0.1101, batch acc 0.9960
15:23:41.325   Training iter 350, batch loss 0.1168, batch acc 0.9954
15:23:41.466   Training iter 400, batch loss 0.0989, batch acc 0.9962
15:23:41.568   Training iter 450, batch loss 0.1103, batch acc 0.9948
15:23:41.676   Training iter 500, batch loss 0.1381, batch acc 0.9934
15:23:41.785   Training iter 550, batch loss 0.1382, batch acc 0.9954
15:23:41.901   Training iter 600, batch loss 0.1361, batch acc 0.9940
15:23:41.902 Training @ 55 epoch...
15:23:42.008   Training iter 50, batch loss 0.1084, batch acc 0.9964
15:23:42.118   Training iter 100, batch loss 0.1064, batch acc 0.9944
15:23:42.225   Training iter 150, batch loss 0.0906, batch acc 0.9960
15:23:42.327   Training iter 200, batch loss 0.0771, batch acc 0.9976
15:23:42.437   Training iter 250, batch loss 0.0983, batch acc 0.9956
15:23:42.543   Training iter 300, batch loss 0.1004, batch acc 0.9960
15:23:42.653   Training iter 350, batch loss 0.1185, batch acc 0.9958
15:23:42.760   Training iter 400, batch loss 0.1407, batch acc 0.9938
15:23:42.875   Training iter 450, batch loss 0.1461, batch acc 0.9932
15:23:42.994   Training iter 500, batch loss 0.1162, batch acc 0.9940
15:23:43.100   Training iter 550, batch loss 0.1058, batch acc 0.9960
15:23:43.207   Training iter 600, batch loss 0.1156, batch acc 0.9942
15:23:43.207 Testing @ 55 epoch...
15:23:43.278     Testing, total mean loss 0.35842, total acc 0.98070
15:23:43.278 Training @ 56 epoch...
15:23:43.387   Training iter 50, batch loss 0.1055, batch acc 0.9946
15:23:43.530   Training iter 100, batch loss 0.1002, batch acc 0.9956
15:23:43.659   Training iter 150, batch loss 0.0795, batch acc 0.9982
15:23:43.788   Training iter 200, batch loss 0.0950, batch acc 0.9960
15:23:43.908   Training iter 250, batch loss 0.0930, batch acc 0.9958
15:23:44.054   Training iter 300, batch loss 0.1023, batch acc 0.9958
15:23:44.191   Training iter 350, batch loss 0.1100, batch acc 0.9950
15:23:44.336   Training iter 400, batch loss 0.0902, batch acc 0.9962
15:23:44.449   Training iter 450, batch loss 0.1139, batch acc 0.9956
15:23:44.556   Training iter 500, batch loss 0.1131, batch acc 0.9958
15:23:44.658   Training iter 550, batch loss 0.1180, batch acc 0.9938
15:23:44.769   Training iter 600, batch loss 0.1056, batch acc 0.9954
15:23:44.771 Training @ 57 epoch...
15:23:44.902   Training iter 50, batch loss 0.1034, batch acc 0.9962
15:23:45.045   Training iter 100, batch loss 0.0724, batch acc 0.9968
15:23:45.165   Training iter 150, batch loss 0.0807, batch acc 0.9976
15:23:45.262   Training iter 200, batch loss 0.0890, batch acc 0.9968
15:23:45.359   Training iter 250, batch loss 0.0895, batch acc 0.9960
15:23:45.509   Training iter 300, batch loss 0.1146, batch acc 0.9968
15:23:45.618   Training iter 350, batch loss 0.1402, batch acc 0.9932
15:23:45.721   Training iter 400, batch loss 0.1073, batch acc 0.9960
15:23:45.838   Training iter 450, batch loss 0.1024, batch acc 0.9966
15:23:45.982   Training iter 500, batch loss 0.0935, batch acc 0.9956
15:23:46.096   Training iter 550, batch loss 0.0963, batch acc 0.9958
15:23:46.227   Training iter 600, batch loss 0.1109, batch acc 0.9956
15:23:46.229 Training @ 58 epoch...
15:23:46.376   Training iter 50, batch loss 0.1107, batch acc 0.9960
15:23:46.510   Training iter 100, batch loss 0.0786, batch acc 0.9984
15:23:46.634   Training iter 150, batch loss 0.0980, batch acc 0.9954
15:23:46.756   Training iter 200, batch loss 0.1099, batch acc 0.9950
15:23:46.953   Training iter 250, batch loss 0.1196, batch acc 0.9958
15:23:47.133   Training iter 300, batch loss 0.1009, batch acc 0.9960
15:23:47.241   Training iter 350, batch loss 0.1123, batch acc 0.9958
15:23:47.345   Training iter 400, batch loss 0.1020, batch acc 0.9952
15:23:47.466   Training iter 450, batch loss 0.1187, batch acc 0.9960
15:23:47.568   Training iter 500, batch loss 0.1146, batch acc 0.9942
15:23:47.700   Training iter 550, batch loss 0.0954, batch acc 0.9954
15:23:47.818   Training iter 600, batch loss 0.1073, batch acc 0.9948
15:23:47.818 Training @ 59 epoch...
15:23:47.936   Training iter 50, batch loss 0.1042, batch acc 0.9968
15:23:48.051   Training iter 100, batch loss 0.0947, batch acc 0.9962
15:23:48.157   Training iter 150, batch loss 0.0929, batch acc 0.9968
15:23:48.274   Training iter 200, batch loss 0.1050, batch acc 0.9954
15:23:48.375   Training iter 250, batch loss 0.1086, batch acc 0.9948
15:23:48.483   Training iter 300, batch loss 0.0887, batch acc 0.9964
15:23:48.585   Training iter 350, batch loss 0.1061, batch acc 0.9958
15:23:48.693   Training iter 400, batch loss 0.0964, batch acc 0.9954
15:23:48.802   Training iter 450, batch loss 0.1393, batch acc 0.9934
15:23:48.930   Training iter 500, batch loss 0.1245, batch acc 0.9946
15:23:49.047   Training iter 550, batch loss 0.0978, batch acc 0.9960
15:23:49.164   Training iter 600, batch loss 0.1037, batch acc 0.9960
15:23:49.164 Training @ 60 epoch...
15:23:49.275   Training iter 50, batch loss 0.1023, batch acc 0.9966
15:23:49.403   Training iter 100, batch loss 0.0873, batch acc 0.9968
15:23:49.547   Training iter 150, batch loss 0.0908, batch acc 0.9958
15:23:49.673   Training iter 200, batch loss 0.0723, batch acc 0.9976
15:23:49.816   Training iter 250, batch loss 0.1058, batch acc 0.9962
15:23:50.004   Training iter 300, batch loss 0.1133, batch acc 0.9960
15:23:50.121   Training iter 350, batch loss 0.1101, batch acc 0.9934
15:23:50.236   Training iter 400, batch loss 0.1007, batch acc 0.9952
15:23:50.346   Training iter 450, batch loss 0.1101, batch acc 0.9956
15:23:50.451   Training iter 500, batch loss 0.1072, batch acc 0.9944
15:23:50.554   Training iter 550, batch loss 0.1080, batch acc 0.9956
15:23:50.659   Training iter 600, batch loss 0.1257, batch acc 0.9954
15:23:50.659 Testing @ 60 epoch...
15:23:50.726     Testing, total mean loss 0.36702, total acc 0.98070
15:23:50.727 Training @ 61 epoch...
15:23:50.854   Training iter 50, batch loss 0.0966, batch acc 0.9958
15:23:50.958   Training iter 100, batch loss 0.0827, batch acc 0.9966
15:23:51.066   Training iter 150, batch loss 0.0979, batch acc 0.9962
15:23:51.183   Training iter 200, batch loss 0.0839, batch acc 0.9966
15:23:51.297   Training iter 250, batch loss 0.0848, batch acc 0.9970
15:23:51.401   Training iter 300, batch loss 0.0877, batch acc 0.9964
15:23:51.506   Training iter 350, batch loss 0.1415, batch acc 0.9936
15:23:51.619   Training iter 400, batch loss 0.0891, batch acc 0.9966
15:23:51.731   Training iter 450, batch loss 0.0898, batch acc 0.9968
15:23:51.843   Training iter 500, batch loss 0.1422, batch acc 0.9950
15:23:51.964   Training iter 550, batch loss 0.1430, batch acc 0.9940
15:23:52.100   Training iter 600, batch loss 0.1208, batch acc 0.9940
15:23:52.102 Training @ 62 epoch...
15:23:52.238   Training iter 50, batch loss 0.0791, batch acc 0.9964
15:23:52.360   Training iter 100, batch loss 0.0810, batch acc 0.9982
15:23:52.486   Training iter 150, batch loss 0.1018, batch acc 0.9968
15:23:52.601   Training iter 200, batch loss 0.1015, batch acc 0.9952
15:23:52.724   Training iter 250, batch loss 0.0983, batch acc 0.9946
15:23:52.889   Training iter 300, batch loss 0.1189, batch acc 0.9960
15:23:52.993   Training iter 350, batch loss 0.1262, batch acc 0.9934
15:23:53.109   Training iter 400, batch loss 0.1203, batch acc 0.9938
15:23:53.218   Training iter 450, batch loss 0.1185, batch acc 0.9948
15:23:53.371   Training iter 500, batch loss 0.1004, batch acc 0.9956
15:23:53.467   Training iter 550, batch loss 0.0988, batch acc 0.9964
15:23:53.579   Training iter 600, batch loss 0.1135, batch acc 0.9950
15:23:53.580 Training @ 63 epoch...
15:23:53.688   Training iter 50, batch loss 0.0958, batch acc 0.9964
15:23:53.795   Training iter 100, batch loss 0.1133, batch acc 0.9960
15:23:53.907   Training iter 150, batch loss 0.0984, batch acc 0.9960
15:23:54.017   Training iter 200, batch loss 0.0979, batch acc 0.9956
15:23:54.117   Training iter 250, batch loss 0.0829, batch acc 0.9978
15:23:54.230   Training iter 300, batch loss 0.1272, batch acc 0.9944
15:23:54.335   Training iter 350, batch loss 0.1018, batch acc 0.9972
15:23:54.444   Training iter 400, batch loss 0.1103, batch acc 0.9958
15:23:54.559   Training iter 450, batch loss 0.1243, batch acc 0.9956
15:23:54.678   Training iter 500, batch loss 0.0942, batch acc 0.9968
15:23:54.814   Training iter 550, batch loss 0.1134, batch acc 0.9944
15:23:54.952   Training iter 600, batch loss 0.1093, batch acc 0.9950
15:23:54.954 Training @ 64 epoch...
15:23:55.095   Training iter 50, batch loss 0.0811, batch acc 0.9968
15:23:55.242   Training iter 100, batch loss 0.0822, batch acc 0.9956
15:23:55.363   Training iter 150, batch loss 0.0823, batch acc 0.9968
15:23:55.464   Training iter 200, batch loss 0.0882, batch acc 0.9976
15:23:55.556   Training iter 250, batch loss 0.1029, batch acc 0.9960
15:23:55.724   Training iter 300, batch loss 0.1217, batch acc 0.9932
15:23:55.837   Training iter 350, batch loss 0.1252, batch acc 0.9948
15:23:55.950   Training iter 400, batch loss 0.0912, batch acc 0.9964
15:23:56.103   Training iter 450, batch loss 0.0924, batch acc 0.9972
15:23:56.227   Training iter 500, batch loss 0.1056, batch acc 0.9956
15:23:56.335   Training iter 550, batch loss 0.0924, batch acc 0.9974
15:23:56.473   Training iter 600, batch loss 0.1119, batch acc 0.9950
15:23:56.474 Training @ 65 epoch...
15:23:56.610   Training iter 50, batch loss 0.1061, batch acc 0.9962
15:23:56.740   Training iter 100, batch loss 0.0892, batch acc 0.9968
15:23:56.855   Training iter 150, batch loss 0.0961, batch acc 0.9972
15:23:56.991   Training iter 200, batch loss 0.0799, batch acc 0.9970
15:23:57.094   Training iter 250, batch loss 0.1042, batch acc 0.9954
15:23:57.215   Training iter 300, batch loss 0.1228, batch acc 0.9954
15:23:57.340   Training iter 350, batch loss 0.1107, batch acc 0.9946
15:23:57.488   Training iter 400, batch loss 0.1020, batch acc 0.9952
15:23:57.604   Training iter 450, batch loss 0.1083, batch acc 0.9962
15:23:57.739   Training iter 500, batch loss 0.1110, batch acc 0.9950
15:23:57.866   Training iter 550, batch loss 0.1209, batch acc 0.9950
15:23:57.990   Training iter 600, batch loss 0.0940, batch acc 0.9970
15:23:57.991 Testing @ 65 epoch...
15:23:58.087     Testing, total mean loss 0.35424, total acc 0.98130
15:23:58.087 Training @ 66 epoch...
15:23:58.218   Training iter 50, batch loss 0.0919, batch acc 0.9962
15:23:58.341   Training iter 100, batch loss 0.1026, batch acc 0.9960
15:23:58.497   Training iter 150, batch loss 0.0799, batch acc 0.9956
15:23:58.604   Training iter 200, batch loss 0.0962, batch acc 0.9962
15:23:58.709   Training iter 250, batch loss 0.0864, batch acc 0.9960
15:23:58.809   Training iter 300, batch loss 0.1073, batch acc 0.9948
15:23:58.921   Training iter 350, batch loss 0.0893, batch acc 0.9958
15:23:59.036   Training iter 400, batch loss 0.1263, batch acc 0.9940
15:23:59.139   Training iter 450, batch loss 0.1292, batch acc 0.9940
15:23:59.248   Training iter 500, batch loss 0.0992, batch acc 0.9970
15:23:59.348   Training iter 550, batch loss 0.0931, batch acc 0.9964
15:23:59.465   Training iter 600, batch loss 0.1082, batch acc 0.9958
15:23:59.466 Training @ 67 epoch...
15:23:59.572   Training iter 50, batch loss 0.0988, batch acc 0.9958
15:23:59.678   Training iter 100, batch loss 0.0702, batch acc 0.9972
15:23:59.804   Training iter 150, batch loss 0.0781, batch acc 0.9970
15:23:59.913   Training iter 200, batch loss 0.0842, batch acc 0.9968
15:24:00.045   Training iter 250, batch loss 0.1013, batch acc 0.9962
15:24:00.152   Training iter 300, batch loss 0.1095, batch acc 0.9958
15:24:00.259   Training iter 350, batch loss 0.1085, batch acc 0.9954
15:24:00.365   Training iter 400, batch loss 0.1237, batch acc 0.9950
15:24:00.475   Training iter 450, batch loss 0.1323, batch acc 0.9934
15:24:00.605   Training iter 500, batch loss 0.1223, batch acc 0.9952
15:24:00.719   Training iter 550, batch loss 0.0962, batch acc 0.9964
15:24:00.859   Training iter 600, batch loss 0.1004, batch acc 0.9956
15:24:00.860 Training @ 68 epoch...
15:24:01.000   Training iter 50, batch loss 0.0831, batch acc 0.9976
15:24:01.131   Training iter 100, batch loss 0.1007, batch acc 0.9960
15:24:01.252   Training iter 150, batch loss 0.1066, batch acc 0.9970
15:24:01.387   Training iter 200, batch loss 0.1027, batch acc 0.9956
15:24:01.505   Training iter 250, batch loss 0.0999, batch acc 0.9954
15:24:01.607   Training iter 300, batch loss 0.1152, batch acc 0.9950
15:24:01.718   Training iter 350, batch loss 0.1158, batch acc 0.9944
15:24:01.948   Training iter 400, batch loss 0.1093, batch acc 0.9958
15:24:02.389   Training iter 450, batch loss 0.0893, batch acc 0.9962
15:24:02.492   Training iter 500, batch loss 0.0911, batch acc 0.9976
15:24:02.596   Training iter 550, batch loss 0.1176, batch acc 0.9950
15:24:02.709   Training iter 600, batch loss 0.1065, batch acc 0.9952
15:24:02.712 Training @ 69 epoch...
15:24:02.825   Training iter 50, batch loss 0.0781, batch acc 0.9970
15:24:02.958   Training iter 100, batch loss 0.0813, batch acc 0.9974
15:24:03.074   Training iter 150, batch loss 0.0842, batch acc 0.9964
15:24:03.177   Training iter 200, batch loss 0.0830, batch acc 0.9972
15:24:03.303   Training iter 250, batch loss 0.1002, batch acc 0.9960
15:24:03.432   Training iter 300, batch loss 0.1024, batch acc 0.9970
15:24:03.564   Training iter 350, batch loss 0.0713, batch acc 0.9980
15:24:03.702   Training iter 400, batch loss 0.0890, batch acc 0.9966
15:24:03.835   Training iter 450, batch loss 0.0843, batch acc 0.9972
15:24:04.063   Training iter 500, batch loss 0.0925, batch acc 0.9960
15:24:04.224   Training iter 550, batch loss 0.1080, batch acc 0.9944
15:24:04.350   Training iter 600, batch loss 0.1069, batch acc 0.9946
15:24:04.352 Training @ 70 epoch...
15:24:04.456   Training iter 50, batch loss 0.0875, batch acc 0.9966
15:24:04.585   Training iter 100, batch loss 0.0887, batch acc 0.9960
15:24:04.680   Training iter 150, batch loss 0.0837, batch acc 0.9964
15:24:04.790   Training iter 200, batch loss 0.0908, batch acc 0.9964
15:24:04.907   Training iter 250, batch loss 0.0890, batch acc 0.9968
15:24:05.023   Training iter 300, batch loss 0.0988, batch acc 0.9966
15:24:05.136   Training iter 350, batch loss 0.1106, batch acc 0.9966
15:24:05.243   Training iter 400, batch loss 0.1141, batch acc 0.9946
15:24:05.345   Training iter 450, batch loss 0.0950, batch acc 0.9974
15:24:05.453   Training iter 500, batch loss 0.0840, batch acc 0.9974
15:24:05.557   Training iter 550, batch loss 0.1089, batch acc 0.9958
15:24:05.670   Training iter 600, batch loss 0.1043, batch acc 0.9972
15:24:05.670 Testing @ 70 epoch...
15:24:05.748     Testing, total mean loss 0.37742, total acc 0.98060
15:24:05.748 Training @ 71 epoch...
15:24:05.851   Training iter 50, batch loss 0.0867, batch acc 0.9962
15:24:05.959   Training iter 100, batch loss 0.0798, batch acc 0.9968
15:24:06.062   Training iter 150, batch loss 0.0947, batch acc 0.9968
15:24:06.169   Training iter 200, batch loss 0.1010, batch acc 0.9948
15:24:06.292   Training iter 250, batch loss 0.0944, batch acc 0.9970
15:24:06.409   Training iter 300, batch loss 0.1012, batch acc 0.9954
15:24:06.532   Training iter 350, batch loss 0.0873, batch acc 0.9962
15:24:06.655   Training iter 400, batch loss 0.0827, batch acc 0.9972
15:24:06.772   Training iter 450, batch loss 0.1001, batch acc 0.9944
15:24:06.895   Training iter 500, batch loss 0.0924, batch acc 0.9970
15:24:07.029   Training iter 550, batch loss 0.1025, batch acc 0.9956
15:24:07.172   Training iter 600, batch loss 0.0979, batch acc 0.9972
15:24:07.173 Training @ 72 epoch...
15:24:07.284   Training iter 50, batch loss 0.0819, batch acc 0.9968
15:24:07.391   Training iter 100, batch loss 0.1115, batch acc 0.9958
15:24:07.491   Training iter 150, batch loss 0.0964, batch acc 0.9960
15:24:07.652   Training iter 200, batch loss 0.0942, batch acc 0.9964
15:24:07.746   Training iter 250, batch loss 0.0951, batch acc 0.9964
15:24:07.867   Training iter 300, batch loss 0.0976, batch acc 0.9972
15:24:07.972   Training iter 350, batch loss 0.0953, batch acc 0.9972
15:24:08.078   Training iter 400, batch loss 0.1303, batch acc 0.9942
15:24:08.182   Training iter 450, batch loss 0.1235, batch acc 0.9944
15:24:08.299   Training iter 500, batch loss 0.1057, batch acc 0.9954
15:24:08.407   Training iter 550, batch loss 0.0851, batch acc 0.9972
15:24:08.508   Training iter 600, batch loss 0.0850, batch acc 0.9974
15:24:08.509 Training @ 73 epoch...
15:24:08.608   Training iter 50, batch loss 0.0925, batch acc 0.9970
15:24:08.725   Training iter 100, batch loss 0.0907, batch acc 0.9968
15:24:08.836   Training iter 150, batch loss 0.0990, batch acc 0.9954
15:24:08.944   Training iter 200, batch loss 0.0735, batch acc 0.9972
15:24:09.053   Training iter 250, batch loss 0.0832, batch acc 0.9966
15:24:09.158   Training iter 300, batch loss 0.1289, batch acc 0.9948
15:24:09.279   Training iter 350, batch loss 0.1009, batch acc 0.9958
15:24:09.404   Training iter 400, batch loss 0.1094, batch acc 0.9960
15:24:09.526   Training iter 450, batch loss 0.0997, batch acc 0.9966
15:24:09.646   Training iter 500, batch loss 0.0876, batch acc 0.9960
15:24:09.786   Training iter 550, batch loss 0.1106, batch acc 0.9956
15:24:09.923   Training iter 600, batch loss 0.0984, batch acc 0.9962
15:24:09.924 Training @ 74 epoch...
15:24:10.066   Training iter 50, batch loss 0.0881, batch acc 0.9966
15:24:10.167   Training iter 100, batch loss 0.0850, batch acc 0.9968
15:24:10.272   Training iter 150, batch loss 0.0805, batch acc 0.9974
15:24:10.396   Training iter 200, batch loss 0.0921, batch acc 0.9960
15:24:10.495   Training iter 250, batch loss 0.0863, batch acc 0.9970
15:24:10.593   Training iter 300, batch loss 0.0853, batch acc 0.9980
15:24:10.701   Training iter 350, batch loss 0.0853, batch acc 0.9978
15:24:10.815   Training iter 400, batch loss 0.1223, batch acc 0.9950
15:24:10.924   Training iter 450, batch loss 0.1269, batch acc 0.9940
15:24:11.038   Training iter 500, batch loss 0.1018, batch acc 0.9964
15:24:11.148   Training iter 550, batch loss 0.1178, batch acc 0.9948
15:24:11.251   Training iter 600, batch loss 0.1108, batch acc 0.9956
15:24:11.253 Training @ 75 epoch...
15:24:11.369   Training iter 50, batch loss 0.0862, batch acc 0.9970
15:24:11.477   Training iter 100, batch loss 0.0948, batch acc 0.9960
15:24:11.576   Training iter 150, batch loss 0.0875, batch acc 0.9970
15:24:11.687   Training iter 200, batch loss 0.0939, batch acc 0.9958
15:24:11.830   Training iter 250, batch loss 0.0907, batch acc 0.9968
15:24:11.949   Training iter 300, batch loss 0.0760, batch acc 0.9978
15:24:12.077   Training iter 350, batch loss 0.1008, batch acc 0.9956
15:24:12.203   Training iter 400, batch loss 0.0882, batch acc 0.9972
15:24:12.326   Training iter 450, batch loss 0.1495, batch acc 0.9944
15:24:12.453   Training iter 500, batch loss 0.1231, batch acc 0.9936
15:24:12.589   Training iter 550, batch loss 0.1012, batch acc 0.9964
15:24:12.731   Training iter 600, batch loss 0.1084, batch acc 0.9960
15:24:12.732 Testing @ 75 epoch...
15:24:12.843     Testing, total mean loss 0.36564, total acc 0.98120
15:24:12.843 Training @ 76 epoch...
15:24:12.965   Training iter 50, batch loss 0.0977, batch acc 0.9960
15:24:13.072   Training iter 100, batch loss 0.0859, batch acc 0.9960
15:24:13.174   Training iter 150, batch loss 0.0918, batch acc 0.9964
15:24:13.364   Training iter 200, batch loss 0.0996, batch acc 0.9952
15:24:13.488   Training iter 250, batch loss 0.0884, batch acc 0.9964
15:24:13.590   Training iter 300, batch loss 0.0918, batch acc 0.9978
15:24:13.708   Training iter 350, batch loss 0.0896, batch acc 0.9956
15:24:13.828   Training iter 400, batch loss 0.0959, batch acc 0.9964
15:24:13.995   Training iter 450, batch loss 0.0842, batch acc 0.9974
15:24:14.095   Training iter 500, batch loss 0.0869, batch acc 0.9970
15:24:14.217   Training iter 550, batch loss 0.1080, batch acc 0.9954
15:24:14.335   Training iter 600, batch loss 0.1017, batch acc 0.9968
15:24:14.336 Training @ 77 epoch...
15:24:14.442   Training iter 50, batch loss 0.0808, batch acc 0.9960
15:24:14.546   Training iter 100, batch loss 0.0785, batch acc 0.9974
15:24:14.653   Training iter 150, batch loss 0.0959, batch acc 0.9962
15:24:14.754   Training iter 200, batch loss 0.0970, batch acc 0.9960
15:24:14.880   Training iter 250, batch loss 0.0825, batch acc 0.9964
15:24:15.008   Training iter 300, batch loss 0.0958, batch acc 0.9962
15:24:15.132   Training iter 350, batch loss 0.1187, batch acc 0.9960
15:24:15.257   Training iter 400, batch loss 0.0965, batch acc 0.9962
15:24:15.387   Training iter 450, batch loss 0.1023, batch acc 0.9962
15:24:15.527   Training iter 500, batch loss 0.1019, batch acc 0.9958
15:24:15.690   Training iter 550, batch loss 0.1106, batch acc 0.9966
15:24:15.885   Training iter 600, batch loss 0.1350, batch acc 0.9932
15:24:15.886 Training @ 78 epoch...
15:24:16.025   Training iter 50, batch loss 0.0963, batch acc 0.9966
15:24:16.150   Training iter 100, batch loss 0.0784, batch acc 0.9962
15:24:16.268   Training iter 150, batch loss 0.0849, batch acc 0.9958
15:24:16.393   Training iter 200, batch loss 0.0909, batch acc 0.9956
15:24:16.505   Training iter 250, batch loss 0.0794, batch acc 0.9974
15:24:16.615   Training iter 300, batch loss 0.1120, batch acc 0.9968
15:24:16.728   Training iter 350, batch loss 0.0985, batch acc 0.9966
15:24:16.837   Training iter 400, batch loss 0.0837, batch acc 0.9970
15:24:16.951   Training iter 450, batch loss 0.1125, batch acc 0.9970
15:24:17.062   Training iter 500, batch loss 0.0965, batch acc 0.9974
15:24:17.163   Training iter 550, batch loss 0.0869, batch acc 0.9966
15:24:17.274   Training iter 600, batch loss 0.0996, batch acc 0.9960
15:24:17.274 Training @ 79 epoch...
15:24:17.374   Training iter 50, batch loss 0.0936, batch acc 0.9964
15:24:17.479   Training iter 100, batch loss 0.0929, batch acc 0.9962
15:24:17.575   Training iter 150, batch loss 0.1059, batch acc 0.9962
15:24:17.693   Training iter 200, batch loss 0.0988, batch acc 0.9956
15:24:17.816   Training iter 250, batch loss 0.0869, batch acc 0.9964
15:24:17.945   Training iter 300, batch loss 0.1030, batch acc 0.9968
15:24:18.080   Training iter 350, batch loss 0.1097, batch acc 0.9952
15:24:18.202   Training iter 400, batch loss 0.0780, batch acc 0.9968
15:24:18.324   Training iter 450, batch loss 0.0812, batch acc 0.9974
15:24:18.450   Training iter 500, batch loss 0.1291, batch acc 0.9948
15:24:18.580   Training iter 550, batch loss 0.1146, batch acc 0.9948
15:24:18.728   Training iter 600, batch loss 0.1123, batch acc 0.9952
15:24:18.731 Training @ 80 epoch...
15:24:18.841   Training iter 50, batch loss 0.0941, batch acc 0.9964
15:24:18.956   Training iter 100, batch loss 0.0854, batch acc 0.9968
15:24:19.069   Training iter 150, batch loss 0.0651, batch acc 0.9980
15:24:19.167   Training iter 200, batch loss 0.0798, batch acc 0.9966
15:24:19.276   Training iter 250, batch loss 0.0930, batch acc 0.9968
15:24:19.387   Training iter 300, batch loss 0.0990, batch acc 0.9964
15:24:19.491   Training iter 350, batch loss 0.1191, batch acc 0.9948
15:24:19.610   Training iter 400, batch loss 0.1113, batch acc 0.9958
15:24:19.708   Training iter 450, batch loss 0.0893, batch acc 0.9954
15:24:19.813   Training iter 500, batch loss 0.1029, batch acc 0.9960
15:24:19.951   Training iter 550, batch loss 0.1067, batch acc 0.9964
15:24:20.067   Training iter 600, batch loss 0.1159, batch acc 0.9948
15:24:20.069 Testing @ 80 epoch...
15:24:20.139     Testing, total mean loss 0.36725, total acc 0.98200
15:24:20.139 Training @ 81 epoch...
15:24:20.256   Training iter 50, batch loss 0.1059, batch acc 0.9962
15:24:20.371   Training iter 100, batch loss 0.0887, batch acc 0.9974
15:24:20.485   Training iter 150, batch loss 0.0746, batch acc 0.9980
15:24:20.587   Training iter 200, batch loss 0.0725, batch acc 0.9972
15:24:20.718   Training iter 250, batch loss 0.0706, batch acc 0.9976
15:24:20.841   Training iter 300, batch loss 0.0890, batch acc 0.9968
15:24:20.970   Training iter 350, batch loss 0.1173, batch acc 0.9960
15:24:21.103   Training iter 400, batch loss 0.1080, batch acc 0.9964
15:24:21.224   Training iter 450, batch loss 0.0911, batch acc 0.9960
15:24:21.340   Training iter 500, batch loss 0.0876, batch acc 0.9972
15:24:21.478   Training iter 550, batch loss 0.1034, batch acc 0.9956
15:24:21.633   Training iter 600, batch loss 0.1488, batch acc 0.9926
15:24:21.635 Training @ 82 epoch...
15:24:21.727   Training iter 50, batch loss 0.0959, batch acc 0.9958
15:24:21.875   Training iter 100, batch loss 0.0799, batch acc 0.9970
15:24:21.990   Training iter 150, batch loss 0.0936, batch acc 0.9968
15:24:22.091   Training iter 200, batch loss 0.0834, batch acc 0.9968
15:24:22.199   Training iter 250, batch loss 0.1017, batch acc 0.9958
15:24:22.307   Training iter 300, batch loss 0.0885, batch acc 0.9970
15:24:22.407   Training iter 350, batch loss 0.1090, batch acc 0.9950
15:24:22.520   Training iter 400, batch loss 0.1144, batch acc 0.9956
15:24:22.674   Training iter 450, batch loss 0.0966, batch acc 0.9958
15:24:22.774   Training iter 500, batch loss 0.0916, batch acc 0.9968
15:24:22.876   Training iter 550, batch loss 0.0972, batch acc 0.9978
15:24:23.013   Training iter 600, batch loss 0.0822, batch acc 0.9964
15:24:23.016 Training @ 83 epoch...
15:24:23.122   Training iter 50, batch loss 0.0775, batch acc 0.9972
15:24:23.227   Training iter 100, batch loss 0.1073, batch acc 0.9960
15:24:23.344   Training iter 150, batch loss 0.1007, batch acc 0.9956
15:24:23.449   Training iter 200, batch loss 0.0873, batch acc 0.9966
15:24:23.557   Training iter 250, batch loss 0.0796, batch acc 0.9968
15:24:23.691   Training iter 300, batch loss 0.0940, batch acc 0.9966
15:24:23.824   Training iter 350, batch loss 0.0856, batch acc 0.9964
15:24:23.971   Training iter 400, batch loss 0.0857, batch acc 0.9954
15:24:24.104   Training iter 450, batch loss 0.0879, batch acc 0.9966
15:24:24.245   Training iter 500, batch loss 0.1133, batch acc 0.9958
15:24:24.391   Training iter 550, batch loss 0.0984, batch acc 0.9960
15:24:24.507   Training iter 600, batch loss 0.1313, batch acc 0.9956
15:24:24.508 Training @ 84 epoch...
15:24:24.616   Training iter 50, batch loss 0.0794, batch acc 0.9972
15:24:24.726   Training iter 100, batch loss 0.0789, batch acc 0.9972
15:24:24.828   Training iter 150, batch loss 0.0661, batch acc 0.9982
15:24:24.942   Training iter 200, batch loss 0.0902, batch acc 0.9970
15:24:25.059   Training iter 250, batch loss 0.0770, batch acc 0.9968
15:24:25.155   Training iter 300, batch loss 0.1025, batch acc 0.9966
15:24:25.275   Training iter 350, batch loss 0.0900, batch acc 0.9964
15:24:25.390   Training iter 400, batch loss 0.1120, batch acc 0.9954
15:24:25.548   Training iter 450, batch loss 0.0850, batch acc 0.9964
15:24:25.652   Training iter 500, batch loss 0.0926, batch acc 0.9962
15:24:25.755   Training iter 550, batch loss 0.0773, batch acc 0.9964
15:24:25.873   Training iter 600, batch loss 0.1112, batch acc 0.9948
15:24:25.874 Training @ 85 epoch...
15:24:25.988   Training iter 50, batch loss 0.0826, batch acc 0.9970
15:24:26.103   Training iter 100, batch loss 0.0845, batch acc 0.9978
15:24:26.209   Training iter 150, batch loss 0.0883, batch acc 0.9972
15:24:26.317   Training iter 200, batch loss 0.0820, batch acc 0.9972
15:24:26.441   Training iter 250, batch loss 0.0929, batch acc 0.9962
15:24:26.564   Training iter 300, batch loss 0.0947, batch acc 0.9960
15:24:26.685   Training iter 350, batch loss 0.0928, batch acc 0.9962
15:24:26.802   Training iter 400, batch loss 0.0983, batch acc 0.9964
15:24:26.928   Training iter 450, batch loss 0.0903, batch acc 0.9966
15:24:27.069   Training iter 500, batch loss 0.1130, batch acc 0.9962
15:24:27.209   Training iter 550, batch loss 0.0960, batch acc 0.9974
15:24:27.322   Training iter 600, batch loss 0.0877, batch acc 0.9964
15:24:27.324 Testing @ 85 epoch...
15:24:27.407     Testing, total mean loss 0.39659, total acc 0.97980
15:24:27.408 Training @ 86 epoch...
15:24:27.553   Training iter 50, batch loss 0.0832, batch acc 0.9968
15:24:27.652   Training iter 100, batch loss 0.0916, batch acc 0.9958
15:24:27.758   Training iter 150, batch loss 0.0971, batch acc 0.9964
15:24:27.867   Training iter 200, batch loss 0.0815, batch acc 0.9978
15:24:27.977   Training iter 250, batch loss 0.0865, batch acc 0.9958
15:24:28.089   Training iter 300, batch loss 0.0909, batch acc 0.9968
15:24:28.201   Training iter 350, batch loss 0.0876, batch acc 0.9964
15:24:28.306   Training iter 400, batch loss 0.0979, batch acc 0.9968
15:24:28.419   Training iter 450, batch loss 0.0952, batch acc 0.9960
15:24:28.522   Training iter 500, batch loss 0.0861, batch acc 0.9970
15:24:28.637   Training iter 550, batch loss 0.0970, batch acc 0.9980
15:24:28.738   Training iter 600, batch loss 0.1072, batch acc 0.9956
15:24:28.744 Training @ 87 epoch...
15:24:28.863   Training iter 50, batch loss 0.0732, batch acc 0.9972
15:24:28.968   Training iter 100, batch loss 0.0975, batch acc 0.9972
15:24:29.073   Training iter 150, batch loss 0.0954, batch acc 0.9956
15:24:29.175   Training iter 200, batch loss 0.1019, batch acc 0.9958
15:24:29.286   Training iter 250, batch loss 0.0920, batch acc 0.9958
15:24:29.391   Training iter 300, batch loss 0.1023, batch acc 0.9966
15:24:29.504   Training iter 350, batch loss 0.1081, batch acc 0.9962
15:24:29.608   Training iter 400, batch loss 0.0970, batch acc 0.9956
15:24:29.737   Training iter 450, batch loss 0.1279, batch acc 0.9956
15:24:29.864   Training iter 500, batch loss 0.1005, batch acc 0.9962
15:24:29.988   Training iter 550, batch loss 0.0718, batch acc 0.9974
15:24:30.113   Training iter 600, batch loss 0.1397, batch acc 0.9962
15:24:30.114 Training @ 88 epoch...
15:24:30.281   Training iter 50, batch loss 0.0833, batch acc 0.9968
15:24:30.439   Training iter 100, batch loss 0.0877, batch acc 0.9976
15:24:30.542   Training iter 150, batch loss 0.1049, batch acc 0.9960
15:24:30.652   Training iter 200, batch loss 0.1015, batch acc 0.9962
15:24:30.798   Training iter 250, batch loss 0.0934, batch acc 0.9962
15:24:30.922   Training iter 300, batch loss 0.0889, batch acc 0.9974
15:24:31.025   Training iter 350, batch loss 0.1109, batch acc 0.9954
15:24:31.139   Training iter 400, batch loss 0.1051, batch acc 0.9960
15:24:31.247   Training iter 450, batch loss 0.0828, batch acc 0.9976
15:24:31.354   Training iter 500, batch loss 0.1000, batch acc 0.9964
15:24:31.460   Training iter 550, batch loss 0.0982, batch acc 0.9964
15:24:31.571   Training iter 600, batch loss 0.0894, batch acc 0.9970
15:24:31.572 Training @ 89 epoch...
15:24:31.683   Training iter 50, batch loss 0.0735, batch acc 0.9978
15:24:31.797   Training iter 100, batch loss 0.0677, batch acc 0.9974
15:24:31.918   Training iter 150, batch loss 0.0715, batch acc 0.9974
15:24:32.020   Training iter 200, batch loss 0.0832, batch acc 0.9974
15:24:32.129   Training iter 250, batch loss 0.0921, batch acc 0.9960
15:24:32.243   Training iter 300, batch loss 0.1038, batch acc 0.9954
15:24:32.356   Training iter 350, batch loss 0.0901, batch acc 0.9968
15:24:32.487   Training iter 400, batch loss 0.1406, batch acc 0.9924
15:24:32.626   Training iter 450, batch loss 0.0988, batch acc 0.9962
15:24:32.746   Training iter 500, batch loss 0.1000, batch acc 0.9974
15:24:32.873   Training iter 550, batch loss 0.0995, batch acc 0.9962
15:24:33.009   Training iter 600, batch loss 0.1091, batch acc 0.9944
15:24:33.010 Training @ 90 epoch...
15:24:33.132   Training iter 50, batch loss 0.0745, batch acc 0.9972
15:24:33.259   Training iter 100, batch loss 0.0666, batch acc 0.9986
15:24:33.376   Training iter 150, batch loss 0.0907, batch acc 0.9964
15:24:33.484   Training iter 200, batch loss 0.0780, batch acc 0.9982
15:24:33.588   Training iter 250, batch loss 0.0880, batch acc 0.9966
15:24:33.691   Training iter 300, batch loss 0.0772, batch acc 0.9972
15:24:33.808   Training iter 350, batch loss 0.0829, batch acc 0.9972
15:24:33.934   Training iter 400, batch loss 0.1074, batch acc 0.9966
15:24:34.050   Training iter 450, batch loss 0.0850, batch acc 0.9974
15:24:34.167   Training iter 500, batch loss 0.0980, batch acc 0.9962
15:24:34.265   Training iter 550, batch loss 0.1078, batch acc 0.9956
15:24:34.389   Training iter 600, batch loss 0.1187, batch acc 0.9950
15:24:34.390 Testing @ 90 epoch...
15:24:34.463     Testing, total mean loss 0.39256, total acc 0.97970
15:24:34.463 Training @ 91 epoch...
15:24:34.581   Training iter 50, batch loss 0.1001, batch acc 0.9960
15:24:34.695   Training iter 100, batch loss 0.1046, batch acc 0.9952
15:24:34.862   Training iter 150, batch loss 0.0799, batch acc 0.9972
15:24:35.011   Training iter 200, batch loss 0.0822, batch acc 0.9962
15:24:35.123   Training iter 250, batch loss 0.0795, batch acc 0.9978
15:24:35.246   Training iter 300, batch loss 0.1118, batch acc 0.9958
15:24:35.371   Training iter 350, batch loss 0.1129, batch acc 0.9960
15:24:35.502   Training iter 400, batch loss 0.0834, batch acc 0.9974
15:24:35.619   Training iter 450, batch loss 0.0959, batch acc 0.9960
15:24:35.747   Training iter 500, batch loss 0.0995, batch acc 0.9962
15:24:35.871   Training iter 550, batch loss 0.1052, batch acc 0.9956
15:24:36.008   Training iter 600, batch loss 0.1155, batch acc 0.9950
15:24:36.009 Training @ 92 epoch...
15:24:36.166   Training iter 50, batch loss 0.1003, batch acc 0.9960
15:24:36.274   Training iter 100, batch loss 0.1016, batch acc 0.9958
15:24:36.385   Training iter 150, batch loss 0.0817, batch acc 0.9982
15:24:36.524   Training iter 200, batch loss 0.0902, batch acc 0.9966
15:24:36.630   Training iter 250, batch loss 0.0779, batch acc 0.9974
15:24:36.739   Training iter 300, batch loss 0.0722, batch acc 0.9974
15:24:36.850   Training iter 350, batch loss 0.0796, batch acc 0.9976
15:24:36.965   Training iter 400, batch loss 0.0885, batch acc 0.9966
15:24:37.065   Training iter 450, batch loss 0.1015, batch acc 0.9974
15:24:37.175   Training iter 500, batch loss 0.0886, batch acc 0.9958
15:24:37.275   Training iter 550, batch loss 0.1284, batch acc 0.9938
15:24:37.387   Training iter 600, batch loss 0.1129, batch acc 0.9954
15:24:37.387 Training @ 93 epoch...
15:24:37.496   Training iter 50, batch loss 0.1215, batch acc 0.9938
15:24:37.647   Training iter 100, batch loss 0.0954, batch acc 0.9966
15:24:37.744   Training iter 150, batch loss 0.0868, batch acc 0.9976
15:24:37.852   Training iter 200, batch loss 0.0831, batch acc 0.9972
15:24:37.966   Training iter 250, batch loss 0.0787, batch acc 0.9970
15:24:38.131   Training iter 300, batch loss 0.0929, batch acc 0.9960
15:24:38.248   Training iter 350, batch loss 0.0933, batch acc 0.9968
15:24:38.375   Training iter 400, batch loss 0.0936, batch acc 0.9960
15:24:38.501   Training iter 450, batch loss 0.0976, batch acc 0.9968
15:24:38.634   Training iter 500, batch loss 0.0833, batch acc 0.9974
15:24:38.817   Training iter 550, batch loss 0.1120, batch acc 0.9962
15:24:38.948   Training iter 600, batch loss 0.0938, batch acc 0.9964
15:24:38.949 Training @ 94 epoch...
15:24:39.093   Training iter 50, batch loss 0.0854, batch acc 0.9962
15:24:39.194   Training iter 100, batch loss 0.0957, batch acc 0.9958
15:24:39.299   Training iter 150, batch loss 0.0662, batch acc 0.9986
15:24:39.393   Training iter 200, batch loss 0.0809, batch acc 0.9978
15:24:39.496   Training iter 250, batch loss 0.0874, batch acc 0.9972
15:24:39.605   Training iter 300, batch loss 0.0881, batch acc 0.9970
15:24:39.704   Training iter 350, batch loss 0.0896, batch acc 0.9972
15:24:39.830   Training iter 400, batch loss 0.0875, batch acc 0.9972
15:24:39.946   Training iter 450, batch loss 0.1317, batch acc 0.9936
15:24:40.057   Training iter 500, batch loss 0.1249, batch acc 0.9954
15:24:40.163   Training iter 550, batch loss 0.1141, batch acc 0.9944
15:24:40.265   Training iter 600, batch loss 0.0950, batch acc 0.9966
15:24:40.267 Training @ 95 epoch...
15:24:40.369   Training iter 50, batch loss 0.0761, batch acc 0.9976
15:24:40.482   Training iter 100, batch loss 0.0853, batch acc 0.9976
15:24:40.587   Training iter 150, batch loss 0.0872, batch acc 0.9972
15:24:40.708   Training iter 200, batch loss 0.1091, batch acc 0.9958
15:24:40.842   Training iter 250, batch loss 0.1021, batch acc 0.9950
15:24:40.992   Training iter 300, batch loss 0.0772, batch acc 0.9974
15:24:41.115   Training iter 350, batch loss 0.0924, batch acc 0.9964
15:24:41.234   Training iter 400, batch loss 0.1134, batch acc 0.9958
15:24:41.366   Training iter 450, batch loss 0.0921, batch acc 0.9960
15:24:41.497   Training iter 500, batch loss 0.0999, batch acc 0.9948
15:24:41.618   Training iter 550, batch loss 0.1069, batch acc 0.9958
15:24:41.744   Training iter 600, batch loss 0.0961, batch acc 0.9966
15:24:41.747 Testing @ 95 epoch...
15:24:41.848     Testing, total mean loss 0.36405, total acc 0.98140
15:24:41.848 Training @ 96 epoch...
15:24:41.958   Training iter 50, batch loss 0.0924, batch acc 0.9970
15:24:42.089   Training iter 100, batch loss 0.0835, batch acc 0.9966
15:24:42.189   Training iter 150, batch loss 0.0920, batch acc 0.9968
15:24:42.291   Training iter 200, batch loss 0.0805, batch acc 0.9964
15:24:42.387   Training iter 250, batch loss 0.0845, batch acc 0.9972
15:24:42.498   Training iter 300, batch loss 0.0941, batch acc 0.9958
15:24:42.602   Training iter 350, batch loss 0.0636, batch acc 0.9986
15:24:42.708   Training iter 400, batch loss 0.1003, batch acc 0.9962
15:24:42.835   Training iter 450, batch loss 0.1022, batch acc 0.9964
15:24:42.942   Training iter 500, batch loss 0.1112, batch acc 0.9946
15:24:43.044   Training iter 550, batch loss 0.1217, batch acc 0.9936
15:24:43.154   Training iter 600, batch loss 0.0790, batch acc 0.9970
15:24:43.154 Training @ 97 epoch...
15:24:43.257   Training iter 50, batch loss 0.0717, batch acc 0.9976
15:24:43.368   Training iter 100, batch loss 0.0813, batch acc 0.9968
15:24:43.484   Training iter 150, batch loss 0.0952, batch acc 0.9960
15:24:43.590   Training iter 200, batch loss 0.0749, batch acc 0.9974
15:24:43.693   Training iter 250, batch loss 0.0796, batch acc 0.9966
15:24:43.800   Training iter 300, batch loss 0.1214, batch acc 0.9950
15:24:43.942   Training iter 350, batch loss 0.0934, batch acc 0.9972
15:24:44.063   Training iter 400, batch loss 0.1067, batch acc 0.9960
15:24:44.175   Training iter 450, batch loss 0.0985, batch acc 0.9960
15:24:44.293   Training iter 500, batch loss 0.0905, batch acc 0.9972
15:24:44.427   Training iter 550, batch loss 0.0840, batch acc 0.9972
15:24:44.548   Training iter 600, batch loss 0.0994, batch acc 0.9958
15:24:44.548 Training @ 98 epoch...
15:24:44.670   Training iter 50, batch loss 0.0742, batch acc 0.9982
15:24:44.822   Training iter 100, batch loss 0.0934, batch acc 0.9962
15:24:44.930   Training iter 150, batch loss 0.0904, batch acc 0.9966
15:24:45.048   Training iter 200, batch loss 0.0820, batch acc 0.9966
15:24:45.149   Training iter 250, batch loss 0.0839, batch acc 0.9972
15:24:45.252   Training iter 300, batch loss 0.0701, batch acc 0.9972
15:24:45.363   Training iter 350, batch loss 0.1024, batch acc 0.9958
15:24:45.473   Training iter 400, batch loss 0.0881, batch acc 0.9962
15:24:45.577   Training iter 450, batch loss 0.0858, batch acc 0.9966
15:24:45.683   Training iter 500, batch loss 0.0989, batch acc 0.9962
15:24:45.803   Training iter 550, batch loss 0.0852, batch acc 0.9972
15:24:45.912   Training iter 600, batch loss 0.0723, batch acc 0.9984
15:24:45.912 Training @ 99 epoch...
15:24:46.020   Training iter 50, batch loss 0.0883, batch acc 0.9966
15:24:46.127   Training iter 100, batch loss 0.0824, batch acc 0.9966
15:24:46.234   Training iter 150, batch loss 0.0666, batch acc 0.9976
15:24:46.346   Training iter 200, batch loss 0.0928, batch acc 0.9966
15:24:46.452   Training iter 250, batch loss 0.1049, batch acc 0.9946
15:24:46.558   Training iter 300, batch loss 0.0941, batch acc 0.9970
15:24:46.666   Training iter 350, batch loss 0.0995, batch acc 0.9958
15:24:46.779   Training iter 400, batch loss 0.0937, batch acc 0.9966
15:24:46.915   Training iter 450, batch loss 0.0860, batch acc 0.9968
15:24:47.071   Training iter 500, batch loss 0.0930, batch acc 0.9970
15:24:47.203   Training iter 550, batch loss 0.1054, batch acc 0.9960
15:24:47.326   Training iter 600, batch loss 0.0918, batch acc 0.9976