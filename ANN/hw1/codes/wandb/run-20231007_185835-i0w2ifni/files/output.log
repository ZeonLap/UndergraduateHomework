18:58:39.886 Training @ 0 epoch...
18:58:40.022   Training iter 50, batch loss 2.2685, batch acc 0.1582
18:58:40.116   Training iter 100, batch loss 1.7584, batch acc 0.4692
18:58:40.303   Training iter 150, batch loss 0.9103, batch acc 0.7694
18:58:40.492   Training iter 200, batch loss 0.6168, batch acc 0.8280
18:58:40.680   Training iter 250, batch loss 0.5046, batch acc 0.8548
18:58:40.791   Training iter 300, batch loss 0.4343, batch acc 0.8740
18:58:40.944   Training iter 350, batch loss 0.4186, batch acc 0.8788
18:58:41.095   Training iter 400, batch loss 0.3859, batch acc 0.8902
18:58:41.211   Training iter 450, batch loss 0.3786, batch acc 0.8922
18:58:41.316   Training iter 500, batch loss 0.3662, batch acc 0.8968
18:58:41.401   Training iter 550, batch loss 0.3431, batch acc 0.8988
18:58:41.513   Training iter 600, batch loss 0.3887, batch acc 0.8898
18:58:41.514 Testing @ 0 epoch...
18:58:41.579     Testing, total mean loss 0.32786, total acc 0.90470
18:58:41.579 Training @ 1 epoch...
18:58:41.652   Training iter 50, batch loss 0.3214, batch acc 0.9014
18:58:41.839   Training iter 100, batch loss 0.3082, batch acc 0.9084
18:58:41.942   Training iter 150, batch loss 0.3168, batch acc 0.9098
18:58:42.053   Training iter 200, batch loss 0.3235, batch acc 0.9032
18:58:42.248   Training iter 250, batch loss 0.3203, batch acc 0.9050
18:58:42.336   Training iter 300, batch loss 0.3052, batch acc 0.9106
18:58:42.418   Training iter 350, batch loss 0.3024, batch acc 0.9154
18:58:42.515   Training iter 400, batch loss 0.3055, batch acc 0.9134
18:58:42.624   Training iter 450, batch loss 0.3066, batch acc 0.9128
18:58:42.709   Training iter 500, batch loss 0.3079, batch acc 0.9098
18:58:42.797   Training iter 550, batch loss 0.2752, batch acc 0.9194
18:58:42.889   Training iter 600, batch loss 0.2685, batch acc 0.9232
18:58:42.890 Training @ 2 epoch...
18:58:43.011   Training iter 50, batch loss 0.2667, batch acc 0.9198
18:58:43.123   Training iter 100, batch loss 0.2497, batch acc 0.9256
18:58:43.220   Training iter 150, batch loss 0.2698, batch acc 0.9204
18:58:43.317   Training iter 200, batch loss 0.2597, batch acc 0.9270
18:58:43.450   Training iter 250, batch loss 0.2732, batch acc 0.9200
18:58:43.560   Training iter 300, batch loss 0.2508, batch acc 0.9292
18:58:43.656   Training iter 350, batch loss 0.2314, batch acc 0.9338
18:58:43.755   Training iter 400, batch loss 0.2443, batch acc 0.9342
18:58:43.864   Training iter 450, batch loss 0.2499, batch acc 0.9290
18:58:43.957   Training iter 500, batch loss 0.2327, batch acc 0.9348
18:58:44.042   Training iter 550, batch loss 0.2282, batch acc 0.9308
18:58:44.169   Training iter 600, batch loss 0.2418, batch acc 0.9254
18:58:44.170 Training @ 3 epoch...
18:58:44.275   Training iter 50, batch loss 0.2040, batch acc 0.9392
18:58:44.374   Training iter 100, batch loss 0.2189, batch acc 0.9370
18:58:44.463   Training iter 150, batch loss 0.2254, batch acc 0.9322
18:58:44.558   Training iter 200, batch loss 0.2157, batch acc 0.9358
18:58:44.647   Training iter 250, batch loss 0.2095, batch acc 0.9392
18:58:44.795   Training iter 300, batch loss 0.2204, batch acc 0.9380
18:58:45.014   Training iter 350, batch loss 0.2054, batch acc 0.9416
18:58:45.145   Training iter 400, batch loss 0.2121, batch acc 0.9412
18:58:45.270   Training iter 450, batch loss 0.1956, batch acc 0.9446
18:58:45.393   Training iter 500, batch loss 0.2003, batch acc 0.9414
18:58:45.519   Training iter 550, batch loss 0.1944, batch acc 0.9428
18:58:45.611   Training iter 600, batch loss 0.2172, batch acc 0.9410
18:58:45.612 Training @ 4 epoch...
18:58:45.701   Training iter 50, batch loss 0.1907, batch acc 0.9470
18:58:45.808   Training iter 100, batch loss 0.1802, batch acc 0.9528
18:58:45.888   Training iter 150, batch loss 0.1943, batch acc 0.9428
18:58:45.986   Training iter 200, batch loss 0.1952, batch acc 0.9416
18:58:46.115   Training iter 250, batch loss 0.1889, batch acc 0.9440
18:58:46.217   Training iter 300, batch loss 0.1767, batch acc 0.9468
18:58:46.304   Training iter 350, batch loss 0.1765, batch acc 0.9480
18:58:46.400   Training iter 400, batch loss 0.1808, batch acc 0.9484
18:58:46.512   Training iter 450, batch loss 0.1684, batch acc 0.9538
18:58:46.633   Training iter 500, batch loss 0.1640, batch acc 0.9546
18:58:46.733   Training iter 550, batch loss 0.1781, batch acc 0.9476
18:58:46.837   Training iter 600, batch loss 0.1769, batch acc 0.9504
18:58:46.838 Training @ 5 epoch...
18:58:46.916   Training iter 50, batch loss 0.1621, batch acc 0.9572
18:58:47.000   Training iter 100, batch loss 0.1483, batch acc 0.9586
18:58:47.075   Training iter 150, batch loss 0.1722, batch acc 0.9532
18:58:47.196   Training iter 200, batch loss 0.1611, batch acc 0.9578
18:58:47.291   Training iter 250, batch loss 0.1635, batch acc 0.9560
18:58:47.376   Training iter 300, batch loss 0.1515, batch acc 0.9530
18:58:47.462   Training iter 350, batch loss 0.1566, batch acc 0.9566
18:58:47.544   Training iter 400, batch loss 0.1653, batch acc 0.9490
18:58:47.622   Training iter 450, batch loss 0.1545, batch acc 0.9540
18:58:47.699   Training iter 500, batch loss 0.1628, batch acc 0.9542
18:58:47.791   Training iter 550, batch loss 0.1509, batch acc 0.9570
18:58:47.888   Training iter 600, batch loss 0.1478, batch acc 0.9558
18:58:47.890 Testing @ 5 epoch...
18:58:47.935     Testing, total mean loss 0.14894, total acc 0.95640
18:58:47.936 Training @ 6 epoch...
18:58:48.041   Training iter 50, batch loss 0.1408, batch acc 0.9612
18:58:48.132   Training iter 100, batch loss 0.1394, batch acc 0.9594
18:58:48.215   Training iter 150, batch loss 0.1461, batch acc 0.9582
18:58:48.304   Training iter 200, batch loss 0.1498, batch acc 0.9548
18:58:48.393   Training iter 250, batch loss 0.1444, batch acc 0.9562
18:58:48.480   Training iter 300, batch loss 0.1380, batch acc 0.9626
18:58:48.570   Training iter 350, batch loss 0.1420, batch acc 0.9602
18:58:48.655   Training iter 400, batch loss 0.1452, batch acc 0.9580
18:58:48.749   Training iter 450, batch loss 0.1471, batch acc 0.9586
18:58:48.837   Training iter 500, batch loss 0.1460, batch acc 0.9614
18:58:48.927   Training iter 550, batch loss 0.1269, batch acc 0.9622
18:58:49.016   Training iter 600, batch loss 0.1521, batch acc 0.9564
18:58:49.017 Training @ 7 epoch...
18:58:49.094   Training iter 50, batch loss 0.1347, batch acc 0.9588
18:58:49.183   Training iter 100, batch loss 0.1394, batch acc 0.9592
18:58:49.289   Training iter 150, batch loss 0.1341, batch acc 0.9626
18:58:49.392   Training iter 200, batch loss 0.1370, batch acc 0.9604
18:58:49.487   Training iter 250, batch loss 0.1245, batch acc 0.9648
18:58:49.584   Training iter 300, batch loss 0.1287, batch acc 0.9666
18:58:49.690   Training iter 350, batch loss 0.1339, batch acc 0.9638
18:58:49.818   Training iter 400, batch loss 0.1227, batch acc 0.9632
18:58:50.003   Training iter 450, batch loss 0.1193, batch acc 0.9676
18:58:50.118   Training iter 500, batch loss 0.1305, batch acc 0.9654
18:58:50.233   Training iter 550, batch loss 0.1387, batch acc 0.9624
18:58:50.347   Training iter 600, batch loss 0.1264, batch acc 0.9646
18:58:50.347 Training @ 8 epoch...
18:58:50.456   Training iter 50, batch loss 0.1323, batch acc 0.9658
18:58:50.597   Training iter 100, batch loss 0.1253, batch acc 0.9608
18:58:50.743   Training iter 150, batch loss 0.1279, batch acc 0.9646
18:58:50.839   Training iter 200, batch loss 0.1171, batch acc 0.9660
18:58:50.963   Training iter 250, batch loss 0.1247, batch acc 0.9628
18:58:51.095   Training iter 300, batch loss 0.1213, batch acc 0.9654
18:58:51.185   Training iter 350, batch loss 0.1143, batch acc 0.9686
18:58:51.270   Training iter 400, batch loss 0.1231, batch acc 0.9640
18:58:51.372   Training iter 450, batch loss 0.1172, batch acc 0.9658
18:58:51.451   Training iter 500, batch loss 0.1286, batch acc 0.9650
18:58:51.530   Training iter 550, batch loss 0.1029, batch acc 0.9710
18:58:51.629   Training iter 600, batch loss 0.1110, batch acc 0.9704
18:58:51.631 Training @ 9 epoch...
18:58:51.725   Training iter 50, batch loss 0.1078, batch acc 0.9710
18:58:51.811   Training iter 100, batch loss 0.1253, batch acc 0.9654
18:58:51.896   Training iter 150, batch loss 0.1105, batch acc 0.9700
18:58:52.001   Training iter 200, batch loss 0.1124, batch acc 0.9664
18:58:52.117   Training iter 250, batch loss 0.1131, batch acc 0.9682
18:58:52.223   Training iter 300, batch loss 0.1003, batch acc 0.9706
18:58:52.321   Training iter 350, batch loss 0.1121, batch acc 0.9654
18:58:52.418   Training iter 400, batch loss 0.1157, batch acc 0.9694
18:58:52.563   Training iter 450, batch loss 0.1015, batch acc 0.9720
18:58:52.657   Training iter 500, batch loss 0.1133, batch acc 0.9670
18:58:52.766   Training iter 550, batch loss 0.1100, batch acc 0.9706
18:58:52.905   Training iter 600, batch loss 0.1191, batch acc 0.9662
18:58:52.906 Training @ 10 epoch...
18:58:53.013   Training iter 50, batch loss 0.0959, batch acc 0.9708
18:58:53.108   Training iter 100, batch loss 0.0959, batch acc 0.9748
18:58:53.211   Training iter 150, batch loss 0.1016, batch acc 0.9694
18:58:53.298   Training iter 200, batch loss 0.1175, batch acc 0.9664
18:58:53.383   Training iter 250, batch loss 0.1137, batch acc 0.9662
18:58:53.563   Training iter 300, batch loss 0.1103, batch acc 0.9706
18:58:53.657   Training iter 350, batch loss 0.1084, batch acc 0.9674
18:58:53.745   Training iter 400, batch loss 0.1111, batch acc 0.9676
18:58:53.842   Training iter 450, batch loss 0.1069, batch acc 0.9718
18:58:53.932   Training iter 500, batch loss 0.0965, batch acc 0.9734
18:58:54.019   Training iter 550, batch loss 0.0978, batch acc 0.9720
18:58:54.113   Training iter 600, batch loss 0.1015, batch acc 0.9708
18:58:54.113 Testing @ 10 epoch...
18:58:54.157     Testing, total mean loss 0.11252, total acc 0.96540
18:58:54.157 Training @ 11 epoch...
18:58:54.261   Training iter 50, batch loss 0.0856, batch acc 0.9744
18:58:54.346   Training iter 100, batch loss 0.0961, batch acc 0.9740
18:58:54.427   Training iter 150, batch loss 0.0929, batch acc 0.9730
18:58:54.513   Training iter 200, batch loss 0.1002, batch acc 0.9726
18:58:54.616   Training iter 250, batch loss 0.0997, batch acc 0.9704
18:58:54.714   Training iter 300, batch loss 0.1069, batch acc 0.9688
18:58:54.800   Training iter 350, batch loss 0.1065, batch acc 0.9722
18:58:54.907   Training iter 400, batch loss 0.0983, batch acc 0.9736
18:58:55.019   Training iter 450, batch loss 0.0973, batch acc 0.9740
18:58:55.136   Training iter 500, batch loss 0.0994, batch acc 0.9710
18:58:55.242   Training iter 550, batch loss 0.0948, batch acc 0.9728
18:58:55.344   Training iter 600, batch loss 0.1050, batch acc 0.9706
18:58:55.344 Training @ 12 epoch...
18:58:55.443   Training iter 50, batch loss 0.0886, batch acc 0.9766
18:58:55.560   Training iter 100, batch loss 0.0854, batch acc 0.9794
18:58:55.696   Training iter 150, batch loss 0.0913, batch acc 0.9738
18:58:55.781   Training iter 200, batch loss 0.0920, batch acc 0.9752
18:58:55.883   Training iter 250, batch loss 0.0935, batch acc 0.9728
18:58:55.970   Training iter 300, batch loss 0.0877, batch acc 0.9754
18:58:56.097   Training iter 350, batch loss 0.1006, batch acc 0.9734
18:58:56.239   Training iter 400, batch loss 0.0910, batch acc 0.9742
18:58:56.395   Training iter 450, batch loss 0.0959, batch acc 0.9746
18:58:56.482   Training iter 500, batch loss 0.0990, batch acc 0.9718
18:58:56.573   Training iter 550, batch loss 0.1031, batch acc 0.9722
18:58:56.660   Training iter 600, batch loss 0.0994, batch acc 0.9708
18:58:56.660 Training @ 13 epoch...
18:58:56.761   Training iter 50, batch loss 0.0889, batch acc 0.9742
18:58:56.852   Training iter 100, batch loss 0.0887, batch acc 0.9750
18:58:56.964   Training iter 150, batch loss 0.0905, batch acc 0.9760
18:58:57.059   Training iter 200, batch loss 0.0955, batch acc 0.9740
18:58:57.149   Training iter 250, batch loss 0.0796, batch acc 0.9760
18:58:57.251   Training iter 300, batch loss 0.0946, batch acc 0.9730
18:58:57.331   Training iter 350, batch loss 0.0953, batch acc 0.9708
18:58:57.412   Training iter 400, batch loss 0.0907, batch acc 0.9764
18:58:57.510   Training iter 450, batch loss 0.0925, batch acc 0.9720
18:58:57.593   Training iter 500, batch loss 0.0842, batch acc 0.9760
18:58:57.694   Training iter 550, batch loss 0.0872, batch acc 0.9772
18:58:57.796   Training iter 600, batch loss 0.0892, batch acc 0.9752
18:58:57.797 Training @ 14 epoch...
18:58:57.910   Training iter 50, batch loss 0.0879, batch acc 0.9756
18:58:58.032   Training iter 100, batch loss 0.0929, batch acc 0.9756
18:58:58.135   Training iter 150, batch loss 0.0899, batch acc 0.9746
18:58:58.254   Training iter 200, batch loss 0.0775, batch acc 0.9778
18:58:58.370   Training iter 250, batch loss 0.0862, batch acc 0.9754
18:58:58.474   Training iter 300, batch loss 0.0871, batch acc 0.9774
18:58:58.602   Training iter 350, batch loss 0.0844, batch acc 0.9776
18:58:58.709   Training iter 400, batch loss 0.0876, batch acc 0.9740
18:58:58.792   Training iter 450, batch loss 0.0839, batch acc 0.9764
18:58:58.886   Training iter 500, batch loss 0.0819, batch acc 0.9778
18:58:58.975   Training iter 550, batch loss 0.0917, batch acc 0.9752
18:58:59.082   Training iter 600, batch loss 0.0735, batch acc 0.9782
18:58:59.083 Training @ 15 epoch...
18:58:59.164   Training iter 50, batch loss 0.0832, batch acc 0.9786
18:58:59.264   Training iter 100, batch loss 0.0830, batch acc 0.9778
18:58:59.353   Training iter 150, batch loss 0.0766, batch acc 0.9786
18:58:59.442   Training iter 200, batch loss 0.0811, batch acc 0.9790
18:58:59.534   Training iter 250, batch loss 0.0818, batch acc 0.9776
18:58:59.627   Training iter 300, batch loss 0.0900, batch acc 0.9768
18:58:59.718   Training iter 350, batch loss 0.0731, batch acc 0.9814
18:58:59.842   Training iter 400, batch loss 0.0788, batch acc 0.9786
18:58:59.924   Training iter 450, batch loss 0.0773, batch acc 0.9790
18:59:00.036   Training iter 500, batch loss 0.0886, batch acc 0.9756
18:59:00.167   Training iter 550, batch loss 0.0855, batch acc 0.9744
18:59:00.298   Training iter 600, batch loss 0.0804, batch acc 0.9762
18:59:00.301 Testing @ 15 epoch...
18:59:00.367     Testing, total mean loss 0.10440, total acc 0.96810
18:59:00.367 Training @ 16 epoch...
18:59:00.477   Training iter 50, batch loss 0.0789, batch acc 0.9778
18:59:00.622   Training iter 100, batch loss 0.0791, batch acc 0.9782
18:59:00.733   Training iter 150, batch loss 0.0926, batch acc 0.9756
18:59:00.869   Training iter 200, batch loss 0.0826, batch acc 0.9764
18:59:01.105   Training iter 250, batch loss 0.0790, batch acc 0.9790
18:59:01.304   Training iter 300, batch loss 0.0759, batch acc 0.9810
18:59:01.422   Training iter 350, batch loss 0.0834, batch acc 0.9744
18:59:01.515   Training iter 400, batch loss 0.0759, batch acc 0.9786
18:59:01.665   Training iter 450, batch loss 0.0733, batch acc 0.9802
18:59:01.782   Training iter 500, batch loss 0.0798, batch acc 0.9782
18:59:01.919   Training iter 550, batch loss 0.0719, batch acc 0.9800
18:59:02.051   Training iter 600, batch loss 0.0734, batch acc 0.9806
18:59:02.051 Training @ 17 epoch...
18:59:02.170   Training iter 50, batch loss 0.0692, batch acc 0.9824
18:59:02.256   Training iter 100, batch loss 0.0698, batch acc 0.9794
18:59:02.348   Training iter 150, batch loss 0.0760, batch acc 0.9780
18:59:02.452   Training iter 200, batch loss 0.0759, batch acc 0.9786
18:59:02.614   Training iter 250, batch loss 0.0843, batch acc 0.9748
18:59:02.920   Training iter 300, batch loss 0.0805, batch acc 0.9776
18:59:03.119   Training iter 350, batch loss 0.0652, batch acc 0.9832
18:59:03.296   Training iter 400, batch loss 0.0844, batch acc 0.9750
18:59:03.484   Training iter 450, batch loss 0.0784, batch acc 0.9794
18:59:03.643   Training iter 500, batch loss 0.0779, batch acc 0.9776
18:59:03.850   Training iter 550, batch loss 0.0684, batch acc 0.9816
18:59:04.117   Training iter 600, batch loss 0.0798, batch acc 0.9770
18:59:04.119 Training @ 18 epoch...
18:59:04.346   Training iter 50, batch loss 0.0691, batch acc 0.9820
18:59:04.460   Training iter 100, batch loss 0.0767, batch acc 0.9800
18:59:04.602   Training iter 150, batch loss 0.0670, batch acc 0.9826
18:59:04.865   Training iter 200, batch loss 0.0793, batch acc 0.9790
18:59:05.053   Training iter 250, batch loss 0.0702, batch acc 0.9798
18:59:05.182   Training iter 300, batch loss 0.0698, batch acc 0.9828
18:59:05.303   Training iter 350, batch loss 0.0827, batch acc 0.9754
18:59:05.438   Training iter 400, batch loss 0.0714, batch acc 0.9792
18:59:05.580   Training iter 450, batch loss 0.0719, batch acc 0.9780
18:59:05.834   Training iter 500, batch loss 0.0760, batch acc 0.9808
18:59:06.138   Training iter 550, batch loss 0.0776, batch acc 0.9762
18:59:06.319   Training iter 600, batch loss 0.0768, batch acc 0.9810
18:59:06.321 Training @ 19 epoch...
18:59:06.489   Training iter 50, batch loss 0.0729, batch acc 0.9814
18:59:07.001   Training iter 100, batch loss 0.0699, batch acc 0.9802
18:59:07.942   Training iter 150, batch loss 0.0761, batch acc 0.9802
18:59:08.824   Training iter 200, batch loss 0.0699, batch acc 0.9834
18:59:09.717   Training iter 250, batch loss 0.0709, batch acc 0.9810
18:59:10.650   Training iter 300, batch loss 0.0721, batch acc 0.9796
18:59:11.266   Training iter 350, batch loss 0.0751, batch acc 0.9808
18:59:11.916   Training iter 400, batch loss 0.0765, batch acc 0.9784
18:59:13.093   Training iter 450, batch loss 0.0605, batch acc 0.9844
18:59:13.294   Training iter 500, batch loss 0.0808, batch acc 0.9754
18:59:13.520   Training iter 550, batch loss 0.0726, batch acc 0.9794
18:59:13.714   Training iter 600, batch loss 0.0664, batch acc 0.9796
18:59:13.715 Training @ 20 epoch...
18:59:13.880   Training iter 50, batch loss 0.0777, batch acc 0.9792
18:59:14.049   Training iter 100, batch loss 0.0718, batch acc 0.9798
18:59:14.222   Training iter 150, batch loss 0.0696, batch acc 0.9814
18:59:14.372   Training iter 200, batch loss 0.0663, batch acc 0.9822
18:59:14.474   Training iter 250, batch loss 0.0686, batch acc 0.9810
18:59:14.734   Training iter 300, batch loss 0.0634, batch acc 0.9838
18:59:14.913   Training iter 350, batch loss 0.0645, batch acc 0.9848
18:59:15.136   Training iter 400, batch loss 0.0623, batch acc 0.9848
18:59:15.278   Training iter 450, batch loss 0.0701, batch acc 0.9816
18:59:15.405   Training iter 500, batch loss 0.0715, batch acc 0.9802
18:59:15.673   Training iter 550, batch loss 0.0818, batch acc 0.9772
18:59:15.792   Training iter 600, batch loss 0.0680, batch acc 0.9834
18:59:15.792 Testing @ 20 epoch...
18:59:15.951     Testing, total mean loss 0.08608, total acc 0.97430
18:59:15.951 Training @ 21 epoch...
18:59:16.074   Training iter 50, batch loss 0.0579, batch acc 0.9872
18:59:16.298   Training iter 100, batch loss 0.0625, batch acc 0.9832
18:59:16.466   Training iter 150, batch loss 0.0665, batch acc 0.9826
18:59:16.669   Training iter 200, batch loss 0.0658, batch acc 0.9846
18:59:16.868   Training iter 250, batch loss 0.0636, batch acc 0.9826
18:59:17.126   Training iter 300, batch loss 0.0607, batch acc 0.9830
18:59:17.250   Training iter 350, batch loss 0.0767, batch acc 0.9794
18:59:17.420   Training iter 400, batch loss 0.0682, batch acc 0.9796
18:59:17.501   Training iter 450, batch loss 0.0741, batch acc 0.9788
18:59:17.598   Training iter 500, batch loss 0.0756, batch acc 0.9796
18:59:17.755   Training iter 550, batch loss 0.0694, batch acc 0.9820
18:59:17.953   Training iter 600, batch loss 0.0708, batch acc 0.9796
18:59:17.954 Training @ 22 epoch...
18:59:18.101   Training iter 50, batch loss 0.0659, batch acc 0.9838
18:59:18.225   Training iter 100, batch loss 0.0690, batch acc 0.9820
18:59:18.368   Training iter 150, batch loss 0.0653, batch acc 0.9822
18:59:18.645   Training iter 200, batch loss 0.0652, batch acc 0.9840
18:59:18.760   Training iter 250, batch loss 0.0685, batch acc 0.9810
18:59:18.862   Training iter 300, batch loss 0.0645, batch acc 0.9824
18:59:18.979   Training iter 350, batch loss 0.0665, batch acc 0.9832
18:59:19.168   Training iter 400, batch loss 0.0661, batch acc 0.9828
18:59:19.291   Training iter 450, batch loss 0.0674, batch acc 0.9800
18:59:19.396   Training iter 500, batch loss 0.0690, batch acc 0.9798
18:59:19.524   Training iter 550, batch loss 0.0627, batch acc 0.9810
18:59:19.640   Training iter 600, batch loss 0.0656, batch acc 0.9814
18:59:19.642 Training @ 23 epoch...
18:59:19.769   Training iter 50, batch loss 0.0539, batch acc 0.9872
18:59:19.905   Training iter 100, batch loss 0.0627, batch acc 0.9840
18:59:20.061   Training iter 150, batch loss 0.0683, batch acc 0.9822
18:59:20.181   Training iter 200, batch loss 0.0629, batch acc 0.9842
18:59:20.289   Training iter 250, batch loss 0.0695, batch acc 0.9820
18:59:20.510   Training iter 300, batch loss 0.0606, batch acc 0.9838
18:59:20.661   Training iter 350, batch loss 0.0615, batch acc 0.9850
18:59:20.801   Training iter 400, batch loss 0.0612, batch acc 0.9840
18:59:20.962   Training iter 450, batch loss 0.0745, batch acc 0.9794
18:59:21.116   Training iter 500, batch loss 0.0681, batch acc 0.9810
18:59:21.266   Training iter 550, batch loss 0.0637, batch acc 0.9852
18:59:21.446   Training iter 600, batch loss 0.0632, batch acc 0.9848
18:59:21.446 Training @ 24 epoch...
18:59:21.585   Training iter 50, batch loss 0.0576, batch acc 0.9852
18:59:21.687   Training iter 100, batch loss 0.0527, batch acc 0.9860
18:59:21.784   Training iter 150, batch loss 0.0579, batch acc 0.9828
18:59:21.884   Training iter 200, batch loss 0.0615, batch acc 0.9832
18:59:21.973   Training iter 250, batch loss 0.0654, batch acc 0.9822
18:59:22.069   Training iter 300, batch loss 0.0622, batch acc 0.9844
18:59:22.156   Training iter 350, batch loss 0.0581, batch acc 0.9838
18:59:22.252   Training iter 400, batch loss 0.0669, batch acc 0.9834
18:59:22.351   Training iter 450, batch loss 0.0609, batch acc 0.9844
18:59:22.445   Training iter 500, batch loss 0.0758, batch acc 0.9792
18:59:22.543   Training iter 550, batch loss 0.0731, batch acc 0.9790
18:59:22.633   Training iter 600, batch loss 0.0587, batch acc 0.9846
18:59:22.635 Training @ 25 epoch...
18:59:22.725   Training iter 50, batch loss 0.0563, batch acc 0.9880
18:59:22.865   Training iter 100, batch loss 0.0604, batch acc 0.9828
18:59:22.947   Training iter 150, batch loss 0.0570, batch acc 0.9850
18:59:23.037   Training iter 200, batch loss 0.0671, batch acc 0.9808
18:59:23.134   Training iter 250, batch loss 0.0631, batch acc 0.9830
18:59:23.222   Training iter 300, batch loss 0.0622, batch acc 0.9856
18:59:23.308   Training iter 350, batch loss 0.0596, batch acc 0.9848
18:59:23.417   Training iter 400, batch loss 0.0587, batch acc 0.9838
18:59:23.530   Training iter 450, batch loss 0.0631, batch acc 0.9834
18:59:23.686   Training iter 500, batch loss 0.0621, batch acc 0.9830
18:59:23.801   Training iter 550, batch loss 0.0648, batch acc 0.9816
18:59:23.937   Training iter 600, batch loss 0.0630, batch acc 0.9830
18:59:23.938 Testing @ 25 epoch...
18:59:24.017     Testing, total mean loss 0.08288, total acc 0.97510
18:59:24.017 Training @ 26 epoch...
18:59:24.145   Training iter 50, batch loss 0.0648, batch acc 0.9834
18:59:24.272   Training iter 100, batch loss 0.0655, batch acc 0.9820
18:59:24.366   Training iter 150, batch loss 0.0553, batch acc 0.9860
18:59:24.559   Training iter 200, batch loss 0.0585, batch acc 0.9856
18:59:24.696   Training iter 250, batch loss 0.0603, batch acc 0.9826
18:59:24.848   Training iter 300, batch loss 0.0529, batch acc 0.9858
18:59:24.987   Training iter 350, batch loss 0.0541, batch acc 0.9856
18:59:25.119   Training iter 400, batch loss 0.0596, batch acc 0.9854
18:59:25.212   Training iter 450, batch loss 0.0596, batch acc 0.9856
18:59:25.310   Training iter 500, batch loss 0.0613, batch acc 0.9830
18:59:25.430   Training iter 550, batch loss 0.0695, batch acc 0.9824
18:59:25.671   Training iter 600, batch loss 0.0637, batch acc 0.9832
18:59:25.672 Training @ 27 epoch...
18:59:25.788   Training iter 50, batch loss 0.0569, batch acc 0.9874
18:59:25.936   Training iter 100, batch loss 0.0597, batch acc 0.9822
18:59:26.051   Training iter 150, batch loss 0.0605, batch acc 0.9834
18:59:26.155   Training iter 200, batch loss 0.0578, batch acc 0.9852
18:59:26.297   Training iter 250, batch loss 0.0556, batch acc 0.9858
18:59:26.401   Training iter 300, batch loss 0.0516, batch acc 0.9856
18:59:26.518   Training iter 350, batch loss 0.0558, batch acc 0.9874
18:59:26.681   Training iter 400, batch loss 0.0596, batch acc 0.9822
18:59:26.838   Training iter 450, batch loss 0.0643, batch acc 0.9828
18:59:27.014   Training iter 500, batch loss 0.0636, batch acc 0.9828
18:59:27.210   Training iter 550, batch loss 0.0651, batch acc 0.9846
18:59:27.352   Training iter 600, batch loss 0.0605, batch acc 0.9850
18:59:27.354 Training @ 28 epoch...
18:59:27.487   Training iter 50, batch loss 0.0582, batch acc 0.9842
18:59:27.571   Training iter 100, batch loss 0.0549, batch acc 0.9854
18:59:27.676   Training iter 150, batch loss 0.0608, batch acc 0.9838
18:59:27.758   Training iter 200, batch loss 0.0586, batch acc 0.9868
18:59:27.909   Training iter 250, batch loss 0.0554, batch acc 0.9856
18:59:28.116   Training iter 300, batch loss 0.0498, batch acc 0.9886
18:59:28.289   Training iter 350, batch loss 0.0678, batch acc 0.9826
18:59:28.450   Training iter 400, batch loss 0.0549, batch acc 0.9868
18:59:28.574   Training iter 450, batch loss 0.0548, batch acc 0.9860
18:59:28.678   Training iter 500, batch loss 0.0646, batch acc 0.9836
18:59:28.769   Training iter 550, batch loss 0.0585, batch acc 0.9854
18:59:28.876   Training iter 600, batch loss 0.0583, batch acc 0.9844
18:59:28.876 Training @ 29 epoch...
18:59:28.966   Training iter 50, batch loss 0.0510, batch acc 0.9870
18:59:29.074   Training iter 100, batch loss 0.0584, batch acc 0.9866
18:59:29.202   Training iter 150, batch loss 0.0583, batch acc 0.9850
18:59:29.298   Training iter 200, batch loss 0.0557, batch acc 0.9864
18:59:29.406   Training iter 250, batch loss 0.0625, batch acc 0.9826
18:59:29.551   Training iter 300, batch loss 0.0629, batch acc 0.9844
18:59:29.665   Training iter 350, batch loss 0.0598, batch acc 0.9858
18:59:29.771   Training iter 400, batch loss 0.0533, batch acc 0.9862
18:59:29.917   Training iter 450, batch loss 0.0603, batch acc 0.9838
18:59:30.086   Training iter 500, batch loss 0.0520, batch acc 0.9872
18:59:30.186   Training iter 550, batch loss 0.0585, batch acc 0.9848
18:59:30.273   Training iter 600, batch loss 0.0516, batch acc 0.9876
18:59:30.276 Training @ 30 epoch...
18:59:30.402   Training iter 50, batch loss 0.0598, batch acc 0.9858
18:59:30.554   Training iter 100, batch loss 0.0589, batch acc 0.9870
18:59:30.688   Training iter 150, batch loss 0.0593, batch acc 0.9860
18:59:30.868   Training iter 200, batch loss 0.0507, batch acc 0.9874
18:59:31.032   Training iter 250, batch loss 0.0508, batch acc 0.9876
18:59:31.155   Training iter 300, batch loss 0.0509, batch acc 0.9886
18:59:31.288   Training iter 350, batch loss 0.0588, batch acc 0.9844
18:59:31.460   Training iter 400, batch loss 0.0603, batch acc 0.9836
18:59:31.560   Training iter 450, batch loss 0.0560, batch acc 0.9848
18:59:31.657   Training iter 500, batch loss 0.0496, batch acc 0.9878
18:59:31.747   Training iter 550, batch loss 0.0567, batch acc 0.9844
18:59:31.836   Training iter 600, batch loss 0.0553, batch acc 0.9844
18:59:31.836 Testing @ 30 epoch...
18:59:31.895     Testing, total mean loss 0.07886, total acc 0.97600
18:59:31.895 Training @ 31 epoch...
18:59:31.989   Training iter 50, batch loss 0.0516, batch acc 0.9888
18:59:32.075   Training iter 100, batch loss 0.0570, batch acc 0.9866
18:59:32.193   Training iter 150, batch loss 0.0580, batch acc 0.9858
18:59:32.320   Training iter 200, batch loss 0.0513, batch acc 0.9866
18:59:32.461   Training iter 250, batch loss 0.0570, batch acc 0.9844
18:59:32.608   Training iter 300, batch loss 0.0525, batch acc 0.9866
18:59:32.761   Training iter 350, batch loss 0.0561, batch acc 0.9864
18:59:32.943   Training iter 400, batch loss 0.0544, batch acc 0.9876
18:59:33.045   Training iter 450, batch loss 0.0531, batch acc 0.9858
18:59:33.140   Training iter 500, batch loss 0.0606, batch acc 0.9818
18:59:33.261   Training iter 550, batch loss 0.0567, batch acc 0.9854
18:59:33.355   Training iter 600, batch loss 0.0569, batch acc 0.9862
18:59:33.356 Training @ 32 epoch...
18:59:33.461   Training iter 50, batch loss 0.0574, batch acc 0.9846
18:59:33.564   Training iter 100, batch loss 0.0546, batch acc 0.9858
18:59:33.665   Training iter 150, batch loss 0.0548, batch acc 0.9840
18:59:33.802   Training iter 200, batch loss 0.0543, batch acc 0.9854
18:59:33.951   Training iter 250, batch loss 0.0517, batch acc 0.9876
18:59:34.071   Training iter 300, batch loss 0.0539, batch acc 0.9850
18:59:34.308   Training iter 350, batch loss 0.0520, batch acc 0.9870
18:59:34.471   Training iter 400, batch loss 0.0560, batch acc 0.9862
18:59:34.701   Training iter 450, batch loss 0.0561, batch acc 0.9864
18:59:34.873   Training iter 500, batch loss 0.0533, batch acc 0.9874
18:59:35.050   Training iter 550, batch loss 0.0502, batch acc 0.9878
18:59:35.214   Training iter 600, batch loss 0.0595, batch acc 0.9828
18:59:35.215 Training @ 33 epoch...
18:59:35.389   Training iter 50, batch loss 0.0485, batch acc 0.9890
18:59:35.537   Training iter 100, batch loss 0.0629, batch acc 0.9846
18:59:35.787   Training iter 150, batch loss 0.0515, batch acc 0.9890
18:59:35.987   Training iter 200, batch loss 0.0500, batch acc 0.9886
18:59:36.184   Training iter 250, batch loss 0.0506, batch acc 0.9868
18:59:36.335   Training iter 300, batch loss 0.0540, batch acc 0.9856
18:59:36.514   Training iter 350, batch loss 0.0512, batch acc 0.9874
18:59:36.697   Training iter 400, batch loss 0.0563, batch acc 0.9858
18:59:36.888   Training iter 450, batch loss 0.0492, batch acc 0.9872
18:59:37.044   Training iter 500, batch loss 0.0506, batch acc 0.9872
18:59:37.180   Training iter 550, batch loss 0.0533, batch acc 0.9852
18:59:37.340   Training iter 600, batch loss 0.0648, batch acc 0.9844
18:59:37.345 Training @ 34 epoch...
18:59:37.484   Training iter 50, batch loss 0.0590, batch acc 0.9860
18:59:37.644   Training iter 100, batch loss 0.0544, batch acc 0.9862
18:59:37.901   Training iter 150, batch loss 0.0492, batch acc 0.9878
18:59:38.099   Training iter 200, batch loss 0.0526, batch acc 0.9850
18:59:38.247   Training iter 250, batch loss 0.0513, batch acc 0.9872
18:59:38.393   Training iter 300, batch loss 0.0555, batch acc 0.9850
18:59:38.596   Training iter 350, batch loss 0.0585, batch acc 0.9860
18:59:39.001   Training iter 400, batch loss 0.0542, batch acc 0.9868
18:59:39.236   Training iter 450, batch loss 0.0494, batch acc 0.9902
18:59:39.463   Training iter 500, batch loss 0.0467, batch acc 0.9872
18:59:39.644   Training iter 550, batch loss 0.0558, batch acc 0.9858
18:59:39.779   Training iter 600, batch loss 0.0487, batch acc 0.9890
18:59:39.780 Training @ 35 epoch...
18:59:39.923   Training iter 50, batch loss 0.0479, batch acc 0.9876
18:59:40.037   Training iter 100, batch loss 0.0511, batch acc 0.9862
18:59:41.029   Training iter 150, batch loss 0.0519, batch acc 0.9866
18:59:41.770   Training iter 200, batch loss 0.0517, batch acc 0.9866
18:59:42.939   Training iter 250, batch loss 0.0566, batch acc 0.9850
18:59:43.695   Training iter 300, batch loss 0.0579, batch acc 0.9854
18:59:44.994   Training iter 350, batch loss 0.0499, batch acc 0.9890
18:59:46.119   Training iter 400, batch loss 0.0516, batch acc 0.9856
18:59:47.980   Training iter 450, batch loss 0.0557, batch acc 0.9860
18:59:48.619   Training iter 500, batch loss 0.0494, batch acc 0.9886
18:59:48.904   Training iter 550, batch loss 0.0512, batch acc 0.9898
18:59:49.333   Training iter 600, batch loss 0.0558, batch acc 0.9860
18:59:49.334 Testing @ 35 epoch...
18:59:49.425     Testing, total mean loss 0.07658, total acc 0.97700
18:59:49.425 Training @ 36 epoch...
18:59:50.163   Training iter 50, batch loss 0.0519, batch acc 0.9872
18:59:50.569   Training iter 100, batch loss 0.0505, batch acc 0.9868
18:59:51.566   Training iter 150, batch loss 0.0461, batch acc 0.9888
18:59:51.777   Training iter 200, batch loss 0.0520, batch acc 0.9864
18:59:51.908   Training iter 250, batch loss 0.0488, batch acc 0.9890
18:59:52.155   Training iter 300, batch loss 0.0466, batch acc 0.9888
18:59:52.566   Training iter 350, batch loss 0.0589, batch acc 0.9860
18:59:52.819   Training iter 400, batch loss 0.0486, batch acc 0.9888
18:59:53.043   Training iter 450, batch loss 0.0509, batch acc 0.9886
18:59:53.482   Training iter 500, batch loss 0.0572, batch acc 0.9840
18:59:53.746   Training iter 550, batch loss 0.0555, batch acc 0.9852
18:59:53.933   Training iter 600, batch loss 0.0534, batch acc 0.9862
18:59:53.934 Training @ 37 epoch...
18:59:54.123   Training iter 50, batch loss 0.0490, batch acc 0.9886
18:59:54.522   Training iter 100, batch loss 0.0473, batch acc 0.9876
18:59:54.693   Training iter 150, batch loss 0.0514, batch acc 0.9882
18:59:54.887   Training iter 200, batch loss 0.0502, batch acc 0.9890
18:59:55.094   Training iter 250, batch loss 0.0595, batch acc 0.9838
18:59:55.345   Training iter 300, batch loss 0.0457, batch acc 0.9880
18:59:55.480   Training iter 350, batch loss 0.0503, batch acc 0.9874
18:59:55.721   Training iter 400, batch loss 0.0461, batch acc 0.9884
18:59:55.888   Training iter 450, batch loss 0.0530, batch acc 0.9870
18:59:56.116   Training iter 500, batch loss 0.0495, batch acc 0.9894
18:59:56.319   Training iter 550, batch loss 0.0551, batch acc 0.9850
18:59:56.439   Training iter 600, batch loss 0.0542, batch acc 0.9874
18:59:56.441 Training @ 38 epoch...
18:59:56.701   Training iter 50, batch loss 0.0518, batch acc 0.9880
18:59:56.823   Training iter 100, batch loss 0.0493, batch acc 0.9892
18:59:56.997   Training iter 150, batch loss 0.0498, batch acc 0.9872
18:59:57.168   Training iter 200, batch loss 0.0470, batch acc 0.9888
18:59:57.346   Training iter 250, batch loss 0.0513, batch acc 0.9870
18:59:57.506   Training iter 300, batch loss 0.0492, batch acc 0.9878
18:59:57.615   Training iter 350, batch loss 0.0546, batch acc 0.9860
18:59:57.717   Training iter 400, batch loss 0.0476, batch acc 0.9878
18:59:57.937   Training iter 450, batch loss 0.0477, batch acc 0.9882
18:59:58.176   Training iter 500, batch loss 0.0488, batch acc 0.9878
18:59:58.421   Training iter 550, batch loss 0.0549, batch acc 0.9852
18:59:58.572   Training iter 600, batch loss 0.0521, batch acc 0.9858
18:59:58.573 Training @ 39 epoch...
18:59:58.698   Training iter 50, batch loss 0.0467, batch acc 0.9880
18:59:58.820   Training iter 100, batch loss 0.0488, batch acc 0.9894
18:59:59.139   Training iter 150, batch loss 0.0474, batch acc 0.9884
18:59:59.271   Training iter 200, batch loss 0.0451, batch acc 0.9882
18:59:59.433   Training iter 250, batch loss 0.0467, batch acc 0.9892
19:00:00.433   Training iter 300, batch loss 0.0583, batch acc 0.9856
19:00:00.717   Training iter 350, batch loss 0.0483, batch acc 0.9888
19:00:00.964   Training iter 400, batch loss 0.0540, batch acc 0.9864
19:00:01.157   Training iter 450, batch loss 0.0488, batch acc 0.9894
19:00:01.505   Training iter 500, batch loss 0.0510, batch acc 0.9882
19:00:01.865   Training iter 550, batch loss 0.0492, batch acc 0.9884
19:00:02.213   Training iter 600, batch loss 0.0513, batch acc 0.9860
19:00:02.214 Training @ 40 epoch...
19:00:02.646   Training iter 50, batch loss 0.0451, batch acc 0.9894
19:00:02.858   Training iter 100, batch loss 0.0438, batch acc 0.9908
19:00:03.179   Training iter 150, batch loss 0.0473, batch acc 0.9892
19:00:03.575   Training iter 200, batch loss 0.0484, batch acc 0.9880
19:00:03.778   Training iter 250, batch loss 0.0476, batch acc 0.9882
19:00:03.969   Training iter 300, batch loss 0.0630, batch acc 0.9820
19:00:04.135   Training iter 350, batch loss 0.0498, batch acc 0.9888
19:00:04.269   Training iter 400, batch loss 0.0466, batch acc 0.9896
19:00:04.429   Training iter 450, batch loss 0.0464, batch acc 0.9908
19:00:04.560   Training iter 500, batch loss 0.0525, batch acc 0.9876
19:00:04.706   Training iter 550, batch loss 0.0551, batch acc 0.9852
19:00:04.836   Training iter 600, batch loss 0.0500, batch acc 0.9884
19:00:04.839 Testing @ 40 epoch...
19:00:04.947     Testing, total mean loss 0.07535, total acc 0.97720
19:00:04.947 Training @ 41 epoch...
19:00:05.143   Training iter 50, batch loss 0.0486, batch acc 0.9896
19:00:05.317   Training iter 100, batch loss 0.0503, batch acc 0.9856
19:00:05.488   Training iter 150, batch loss 0.0486, batch acc 0.9884
19:00:05.631   Training iter 200, batch loss 0.0518, batch acc 0.9876
19:00:05.947   Training iter 250, batch loss 0.0485, batch acc 0.9882
19:00:06.102   Training iter 300, batch loss 0.0525, batch acc 0.9860
19:00:06.298   Training iter 350, batch loss 0.0448, batch acc 0.9902
19:00:06.435   Training iter 400, batch loss 0.0448, batch acc 0.9892
19:00:06.590   Training iter 450, batch loss 0.0565, batch acc 0.9850
19:00:06.787   Training iter 500, batch loss 0.0514, batch acc 0.9880
19:00:06.935   Training iter 550, batch loss 0.0438, batch acc 0.9896
19:00:07.115   Training iter 600, batch loss 0.0431, batch acc 0.9914
19:00:07.116 Training @ 42 epoch...
19:00:07.247   Training iter 50, batch loss 0.0394, batch acc 0.9896
19:00:07.382   Training iter 100, batch loss 0.0432, batch acc 0.9888
19:00:07.512   Training iter 150, batch loss 0.0530, batch acc 0.9856
19:00:07.834   Training iter 200, batch loss 0.0544, batch acc 0.9868
19:00:08.054   Training iter 250, batch loss 0.0499, batch acc 0.9872
19:00:08.307   Training iter 300, batch loss 0.0447, batch acc 0.9906
19:00:08.533   Training iter 350, batch loss 0.0435, batch acc 0.9878
19:00:08.644   Training iter 400, batch loss 0.0514, batch acc 0.9870
19:00:08.902   Training iter 450, batch loss 0.0501, batch acc 0.9876
19:00:09.062   Training iter 500, batch loss 0.0507, batch acc 0.9870
19:00:09.180   Training iter 550, batch loss 0.0516, batch acc 0.9864
19:00:09.366   Training iter 600, batch loss 0.0502, batch acc 0.9890
19:00:09.368 Training @ 43 epoch...
19:00:09.543   Training iter 50, batch loss 0.0396, batch acc 0.9908
19:00:09.767   Training iter 100, batch loss 0.0452, batch acc 0.9896
19:00:09.909   Training iter 150, batch loss 0.0442, batch acc 0.9902
19:00:10.073   Training iter 200, batch loss 0.0439, batch acc 0.9898
19:00:10.222   Training iter 250, batch loss 0.0463, batch acc 0.9890
19:00:10.372   Training iter 300, batch loss 0.0519, batch acc 0.9868
19:00:10.568   Training iter 350, batch loss 0.0513, batch acc 0.9880
19:00:10.949   Training iter 400, batch loss 0.0455, batch acc 0.9906
19:00:11.263   Training iter 450, batch loss 0.0534, batch acc 0.9874
19:00:11.394   Training iter 500, batch loss 0.0496, batch acc 0.9878
19:00:11.786   Training iter 550, batch loss 0.0514, batch acc 0.9886
19:00:12.064   Training iter 600, batch loss 0.0479, batch acc 0.9896
19:00:12.067 Training @ 44 epoch...
19:00:12.388   Training iter 50, batch loss 0.0398, batch acc 0.9932
19:00:12.623   Training iter 100, batch loss 0.0460, batch acc 0.9896
19:00:12.837   Training iter 150, batch loss 0.0487, batch acc 0.9870
19:00:13.138   Training iter 200, batch loss 0.0458, batch acc 0.9900
19:00:13.434   Training iter 250, batch loss 0.0468, batch acc 0.9886
19:00:13.601   Training iter 300, batch loss 0.0488, batch acc 0.9884
19:00:13.804   Training iter 350, batch loss 0.0468, batch acc 0.9884
19:00:14.031   Training iter 400, batch loss 0.0507, batch acc 0.9884
19:00:14.194   Training iter 450, batch loss 0.0527, batch acc 0.9880
19:00:14.345   Training iter 500, batch loss 0.0469, batch acc 0.9888
19:00:14.474   Training iter 550, batch loss 0.0447, batch acc 0.9880
19:00:14.611   Training iter 600, batch loss 0.0484, batch acc 0.9866
19:00:14.612 Training @ 45 epoch...
19:00:14.818   Training iter 50, batch loss 0.0440, batch acc 0.9908
19:00:15.013   Training iter 100, batch loss 0.0474, batch acc 0.9888
19:00:15.276   Training iter 150, batch loss 0.0547, batch acc 0.9874
19:00:15.437   Training iter 200, batch loss 0.0434, batch acc 0.9910
19:00:15.672   Training iter 250, batch loss 0.0507, batch acc 0.9848
19:00:15.826   Training iter 300, batch loss 0.0438, batch acc 0.9904
19:00:16.032   Training iter 350, batch loss 0.0469, batch acc 0.9894
19:00:16.177   Training iter 400, batch loss 0.0439, batch acc 0.9882
19:00:16.295   Training iter 450, batch loss 0.0476, batch acc 0.9874
19:00:16.551   Training iter 500, batch loss 0.0479, batch acc 0.9886
19:00:16.720   Training iter 550, batch loss 0.0525, batch acc 0.9858
19:00:16.962   Training iter 600, batch loss 0.0420, batch acc 0.9906
19:00:16.963 Testing @ 45 epoch...
19:00:17.121     Testing, total mean loss 0.07694, total acc 0.97750
19:00:17.121 Training @ 46 epoch...
19:00:17.327   Training iter 50, batch loss 0.0431, batch acc 0.9910
19:00:17.576   Training iter 100, batch loss 0.0450, batch acc 0.9896
19:00:17.831   Training iter 150, batch loss 0.0471, batch acc 0.9890
19:00:18.082   Training iter 200, batch loss 0.0433, batch acc 0.9900
19:00:18.210   Training iter 250, batch loss 0.0460, batch acc 0.9886
19:00:18.316   Training iter 300, batch loss 0.0439, batch acc 0.9922
19:00:18.452   Training iter 350, batch loss 0.0442, batch acc 0.9894
19:00:18.588   Training iter 400, batch loss 0.0522, batch acc 0.9870
19:00:18.764   Training iter 450, batch loss 0.0494, batch acc 0.9878
19:00:18.939   Training iter 500, batch loss 0.0479, batch acc 0.9894
19:00:19.054   Training iter 550, batch loss 0.0484, batch acc 0.9882
19:00:19.354   Training iter 600, batch loss 0.0479, batch acc 0.9890
19:00:19.355 Training @ 47 epoch...
19:00:19.479   Training iter 50, batch loss 0.0394, batch acc 0.9914
19:00:19.599   Training iter 100, batch loss 0.0471, batch acc 0.9886
19:00:19.722   Training iter 150, batch loss 0.0516, batch acc 0.9862
19:00:19.881   Training iter 200, batch loss 0.0464, batch acc 0.9898
19:00:19.988   Training iter 250, batch loss 0.0355, batch acc 0.9932
19:00:20.144   Training iter 300, batch loss 0.0542, batch acc 0.9864
19:00:20.316   Training iter 350, batch loss 0.0443, batch acc 0.9898
19:00:20.514   Training iter 400, batch loss 0.0471, batch acc 0.9888
19:00:20.661   Training iter 450, batch loss 0.0449, batch acc 0.9896
19:00:20.910   Training iter 500, batch loss 0.0478, batch acc 0.9880
19:00:21.039   Training iter 550, batch loss 0.0449, batch acc 0.9884
19:00:21.146   Training iter 600, batch loss 0.0501, batch acc 0.9878
19:00:21.147 Training @ 48 epoch...
19:00:21.247   Training iter 50, batch loss 0.0480, batch acc 0.9892
19:00:21.356   Training iter 100, batch loss 0.0464, batch acc 0.9880
19:00:21.491   Training iter 150, batch loss 0.0462, batch acc 0.9906
19:00:21.601   Training iter 200, batch loss 0.0459, batch acc 0.9904
19:00:21.766   Training iter 250, batch loss 0.0447, batch acc 0.9906
19:00:21.920   Training iter 300, batch loss 0.0496, batch acc 0.9892
19:00:22.082   Training iter 350, batch loss 0.0457, batch acc 0.9884
19:00:22.220   Training iter 400, batch loss 0.0442, batch acc 0.9888
19:00:22.349   Training iter 450, batch loss 0.0420, batch acc 0.9910
19:00:22.463   Training iter 500, batch loss 0.0510, batch acc 0.9876
19:00:22.578   Training iter 550, batch loss 0.0485, batch acc 0.9870
19:00:22.710   Training iter 600, batch loss 0.0439, batch acc 0.9916
19:00:22.710 Training @ 49 epoch...
19:00:22.916   Training iter 50, batch loss 0.0463, batch acc 0.9888
19:00:23.155   Training iter 100, batch loss 0.0484, batch acc 0.9886
19:00:23.332   Training iter 150, batch loss 0.0495, batch acc 0.9890
19:00:23.467   Training iter 200, batch loss 0.0456, batch acc 0.9904
19:00:24.000   Training iter 250, batch loss 0.0462, batch acc 0.9890
19:00:24.234   Training iter 300, batch loss 0.0438, batch acc 0.9896
19:00:24.518   Training iter 350, batch loss 0.0420, batch acc 0.9906
19:00:24.847   Training iter 400, batch loss 0.0473, batch acc 0.9902
19:00:25.110   Training iter 450, batch loss 0.0430, batch acc 0.9904
19:00:25.352   Training iter 500, batch loss 0.0452, batch acc 0.9886
19:00:25.450   Training iter 550, batch loss 0.0448, batch acc 0.9896
19:00:25.571   Training iter 600, batch loss 0.0473, batch acc 0.9898
19:00:25.572 Training @ 50 epoch...
19:00:25.736   Training iter 50, batch loss 0.0438, batch acc 0.9922
19:00:25.878   Training iter 100, batch loss 0.0466, batch acc 0.9882
19:00:26.142   Training iter 150, batch loss 0.0459, batch acc 0.9894
19:00:26.289   Training iter 200, batch loss 0.0475, batch acc 0.9882
19:00:26.495   Training iter 250, batch loss 0.0431, batch acc 0.9896
19:00:26.680   Training iter 300, batch loss 0.0476, batch acc 0.9878
19:00:26.870   Training iter 350, batch loss 0.0444, batch acc 0.9900
19:00:27.050   Training iter 400, batch loss 0.0456, batch acc 0.9892
19:00:27.226   Training iter 450, batch loss 0.0439, batch acc 0.9898
19:00:27.304   Training iter 500, batch loss 0.0519, batch acc 0.9868
19:00:27.464   Training iter 550, batch loss 0.0436, batch acc 0.9906
19:00:27.639   Training iter 600, batch loss 0.0417, batch acc 0.9906
19:00:27.641 Testing @ 50 epoch...
19:00:27.784     Testing, total mean loss 0.07294, total acc 0.97820
19:00:27.784 Training @ 51 epoch...
19:00:27.904   Training iter 50, batch loss 0.0411, batch acc 0.9910
19:00:28.016   Training iter 100, batch loss 0.0443, batch acc 0.9894
19:00:28.142   Training iter 150, batch loss 0.0434, batch acc 0.9916
19:00:28.388   Training iter 200, batch loss 0.0493, batch acc 0.9888
19:00:28.581   Training iter 250, batch loss 0.0450, batch acc 0.9896
19:00:28.781   Training iter 300, batch loss 0.0458, batch acc 0.9866
19:00:28.898   Training iter 350, batch loss 0.0423, batch acc 0.9902
19:00:29.030   Training iter 400, batch loss 0.0469, batch acc 0.9898
19:00:29.157   Training iter 450, batch loss 0.0547, batch acc 0.9856
19:00:29.276   Training iter 500, batch loss 0.0486, batch acc 0.9888
19:00:29.428   Training iter 550, batch loss 0.0430, batch acc 0.9900
19:00:29.662   Training iter 600, batch loss 0.0419, batch acc 0.9896
19:00:29.662 Training @ 52 epoch...
19:00:29.768   Training iter 50, batch loss 0.0408, batch acc 0.9902
19:00:29.920   Training iter 100, batch loss 0.0439, batch acc 0.9898
19:00:30.020   Training iter 150, batch loss 0.0478, batch acc 0.9876
19:00:30.178   Training iter 200, batch loss 0.0415, batch acc 0.9908
19:00:30.357   Training iter 250, batch loss 0.0528, batch acc 0.9860
19:00:30.433   Training iter 300, batch loss 0.0407, batch acc 0.9910
19:00:30.534   Training iter 350, batch loss 0.0441, batch acc 0.9914
19:00:30.644   Training iter 400, batch loss 0.0477, batch acc 0.9902
19:00:30.767   Training iter 450, batch loss 0.0401, batch acc 0.9900
19:00:30.886   Training iter 500, batch loss 0.0408, batch acc 0.9898
19:00:31.053   Training iter 550, batch loss 0.0492, batch acc 0.9876
19:00:31.270   Training iter 600, batch loss 0.0476, batch acc 0.9882
19:00:31.271 Training @ 53 epoch...
19:00:31.445   Training iter 50, batch loss 0.0431, batch acc 0.9896
19:00:31.540   Training iter 100, batch loss 0.0443, batch acc 0.9886
19:00:31.718   Training iter 150, batch loss 0.0432, batch acc 0.9908
19:00:31.827   Training iter 200, batch loss 0.0455, batch acc 0.9888
19:00:31.971   Training iter 250, batch loss 0.0478, batch acc 0.9876
19:00:32.145   Training iter 300, batch loss 0.0447, batch acc 0.9910
19:00:32.244   Training iter 350, batch loss 0.0431, batch acc 0.9898
19:00:32.330   Training iter 400, batch loss 0.0514, batch acc 0.9870
19:00:32.410   Training iter 450, batch loss 0.0431, batch acc 0.9904
19:00:32.492   Training iter 500, batch loss 0.0445, batch acc 0.9912
19:00:32.635   Training iter 550, batch loss 0.0424, batch acc 0.9902
19:00:32.719   Training iter 600, batch loss 0.0438, batch acc 0.9906
19:00:32.720 Training @ 54 epoch...
19:00:32.921   Training iter 50, batch loss 0.0428, batch acc 0.9896
19:00:33.018   Training iter 100, batch loss 0.0404, batch acc 0.9918
19:00:33.098   Training iter 150, batch loss 0.0417, batch acc 0.9888
19:00:33.308   Training iter 200, batch loss 0.0426, batch acc 0.9926
19:00:33.400   Training iter 250, batch loss 0.0470, batch acc 0.9888
19:00:33.518   Training iter 300, batch loss 0.0431, batch acc 0.9896
19:00:33.675   Training iter 350, batch loss 0.0463, batch acc 0.9878
19:00:33.835   Training iter 400, batch loss 0.0486, batch acc 0.9896
19:00:33.949   Training iter 450, batch loss 0.0426, batch acc 0.9890
19:00:34.077   Training iter 500, batch loss 0.0442, batch acc 0.9900
19:00:34.272   Training iter 550, batch loss 0.0459, batch acc 0.9888
19:00:34.383   Training iter 600, batch loss 0.0448, batch acc 0.9902
19:00:34.385 Training @ 55 epoch...
19:00:34.510   Training iter 50, batch loss 0.0425, batch acc 0.9906
19:00:34.618   Training iter 100, batch loss 0.0423, batch acc 0.9896
19:00:34.704   Training iter 150, batch loss 0.0438, batch acc 0.9898
19:00:34.862   Training iter 200, batch loss 0.0439, batch acc 0.9894
19:00:34.982   Training iter 250, batch loss 0.0459, batch acc 0.9888
19:00:35.071   Training iter 300, batch loss 0.0455, batch acc 0.9892
19:00:35.151   Training iter 350, batch loss 0.0423, batch acc 0.9916
19:00:35.232   Training iter 400, batch loss 0.0426, batch acc 0.9904
19:00:35.461   Training iter 450, batch loss 0.0429, batch acc 0.9908
19:00:35.539   Training iter 500, batch loss 0.0456, batch acc 0.9916
19:00:35.621   Training iter 550, batch loss 0.0436, batch acc 0.9902
19:00:35.714   Training iter 600, batch loss 0.0475, batch acc 0.9878
19:00:35.714 Testing @ 55 epoch...
19:00:35.786     Testing, total mean loss 0.06952, total acc 0.97910
19:00:35.786 Training @ 56 epoch...
19:00:35.872   Training iter 50, batch loss 0.0424, batch acc 0.9906
19:00:36.073   Training iter 100, batch loss 0.0437, batch acc 0.9902
19:00:36.155   Training iter 150, batch loss 0.0419, batch acc 0.9902
19:00:36.318   Training iter 200, batch loss 0.0441, batch acc 0.9908
19:00:36.455   Training iter 250, batch loss 0.0482, batch acc 0.9884
19:00:36.690   Training iter 300, batch loss 0.0445, batch acc 0.9906
19:00:36.884   Training iter 350, batch loss 0.0433, batch acc 0.9908
19:00:37.031   Training iter 400, batch loss 0.0399, batch acc 0.9916
19:00:37.242   Training iter 450, batch loss 0.0441, batch acc 0.9912
19:00:37.511   Training iter 500, batch loss 0.0456, batch acc 0.9884
19:00:37.741   Training iter 550, batch loss 0.0431, batch acc 0.9898
19:00:38.151   Training iter 600, batch loss 0.0425, batch acc 0.9900
19:00:38.151 Training @ 57 epoch...
19:00:38.340   Training iter 50, batch loss 0.0401, batch acc 0.9912
19:00:38.437   Training iter 100, batch loss 0.0442, batch acc 0.9908
19:00:38.578   Training iter 150, batch loss 0.0395, batch acc 0.9910
19:00:38.723   Training iter 200, batch loss 0.0429, batch acc 0.9898
19:00:38.901   Training iter 250, batch loss 0.0421, batch acc 0.9906
19:00:39.305   Training iter 300, batch loss 0.0445, batch acc 0.9896
19:00:39.492   Training iter 350, batch loss 0.0451, batch acc 0.9894
19:00:39.641   Training iter 400, batch loss 0.0417, batch acc 0.9906
19:00:39.816   Training iter 450, batch loss 0.0459, batch acc 0.9914
19:00:39.942   Training iter 500, batch loss 0.0457, batch acc 0.9896
19:00:40.101   Training iter 550, batch loss 0.0413, batch acc 0.9904
19:00:40.214   Training iter 600, batch loss 0.0494, batch acc 0.9866
19:00:40.215 Training @ 58 epoch...
19:00:40.450   Training iter 50, batch loss 0.0442, batch acc 0.9914
19:00:40.618   Training iter 100, batch loss 0.0438, batch acc 0.9890
19:00:40.816   Training iter 150, batch loss 0.0393, batch acc 0.9922
19:00:40.955   Training iter 200, batch loss 0.0430, batch acc 0.9884
19:00:41.126   Training iter 250, batch loss 0.0463, batch acc 0.9902
19:00:41.281   Training iter 300, batch loss 0.0408, batch acc 0.9918
19:00:41.373   Training iter 350, batch loss 0.0441, batch acc 0.9898
19:00:41.554   Training iter 400, batch loss 0.0440, batch acc 0.9890
19:00:41.789   Training iter 450, batch loss 0.0460, batch acc 0.9904
19:00:42.077   Training iter 500, batch loss 0.0476, batch acc 0.9878
19:00:42.235   Training iter 550, batch loss 0.0397, batch acc 0.9910
19:00:42.362   Training iter 600, batch loss 0.0442, batch acc 0.9888
19:00:42.365 Training @ 59 epoch...
19:00:42.556   Training iter 50, batch loss 0.0438, batch acc 0.9906
19:00:42.687   Training iter 100, batch loss 0.0408, batch acc 0.9898
19:00:42.839   Training iter 150, batch loss 0.0438, batch acc 0.9894
19:00:43.012   Training iter 200, batch loss 0.0412, batch acc 0.9920
19:00:43.121   Training iter 250, batch loss 0.0419, batch acc 0.9916
19:00:43.365   Training iter 300, batch loss 0.0441, batch acc 0.9906
19:00:43.573   Training iter 350, batch loss 0.0436, batch acc 0.9920
19:00:43.740   Training iter 400, batch loss 0.0463, batch acc 0.9884
19:00:44.022   Training iter 450, batch loss 0.0490, batch acc 0.9856
19:00:44.203   Training iter 500, batch loss 0.0417, batch acc 0.9914
19:00:44.331   Training iter 550, batch loss 0.0460, batch acc 0.9892
19:00:44.474   Training iter 600, batch loss 0.0397, batch acc 0.9926
19:00:44.478 Training @ 60 epoch...
19:00:44.588   Training iter 50, batch loss 0.0419, batch acc 0.9908
19:00:44.731   Training iter 100, batch loss 0.0394, batch acc 0.9912
19:00:44.817   Training iter 150, batch loss 0.0457, batch acc 0.9906
19:00:44.902   Training iter 200, batch loss 0.0419, batch acc 0.9894
19:00:45.064   Training iter 250, batch loss 0.0386, batch acc 0.9922
19:00:45.178   Training iter 300, batch loss 0.0441, batch acc 0.9896
19:00:45.330   Training iter 350, batch loss 0.0438, batch acc 0.9902
19:00:45.599   Training iter 400, batch loss 0.0431, batch acc 0.9886
19:00:45.767   Training iter 450, batch loss 0.0415, batch acc 0.9904
19:00:45.939   Training iter 500, batch loss 0.0450, batch acc 0.9902
19:00:46.218   Training iter 550, batch loss 0.0435, batch acc 0.9900
19:00:46.414   Training iter 600, batch loss 0.0449, batch acc 0.9900
19:00:46.414 Testing @ 60 epoch...
19:00:46.597     Testing, total mean loss 0.07007, total acc 0.97850
19:00:46.597 Training @ 61 epoch...
19:00:47.072   Training iter 50, batch loss 0.0369, batch acc 0.9922
19:00:47.216   Training iter 100, batch loss 0.0409, batch acc 0.9906
19:00:47.612   Training iter 150, batch loss 0.0375, batch acc 0.9924
19:00:47.777   Training iter 200, batch loss 0.0418, batch acc 0.9918
19:00:47.927   Training iter 250, batch loss 0.0431, batch acc 0.9898
19:00:48.095   Training iter 300, batch loss 0.0455, batch acc 0.9894
19:00:48.231   Training iter 350, batch loss 0.0462, batch acc 0.9898
19:00:48.414   Training iter 400, batch loss 0.0417, batch acc 0.9902
19:00:48.660   Training iter 450, batch loss 0.0455, batch acc 0.9906
19:00:48.938   Training iter 500, batch loss 0.0501, batch acc 0.9880
19:00:49.539   Training iter 550, batch loss 0.0448, batch acc 0.9904
19:00:49.737   Training iter 600, batch loss 0.0414, batch acc 0.9902
19:00:49.738 Training @ 62 epoch...
19:00:49.996   Training iter 50, batch loss 0.0435, batch acc 0.9900
19:00:50.221   Training iter 100, batch loss 0.0377, batch acc 0.9926
19:00:50.435   Training iter 150, batch loss 0.0434, batch acc 0.9910
19:00:50.646   Training iter 200, batch loss 0.0401, batch acc 0.9898
19:00:50.772   Training iter 250, batch loss 0.0440, batch acc 0.9908
19:00:51.160   Training iter 300, batch loss 0.0422, batch acc 0.9912
19:00:51.363   Training iter 350, batch loss 0.0471, batch acc 0.9862
19:00:51.488   Training iter 400, batch loss 0.0415, batch acc 0.9910
19:00:51.715   Training iter 450, batch loss 0.0427, batch acc 0.9908
19:00:51.918   Training iter 500, batch loss 0.0426, batch acc 0.9908
19:00:52.233   Training iter 550, batch loss 0.0414, batch acc 0.9892
19:00:52.420   Training iter 600, batch loss 0.0403, batch acc 0.9908
19:00:52.421 Training @ 63 epoch...
19:00:53.054   Training iter 50, batch loss 0.0420, batch acc 0.9906
19:00:53.927   Training iter 100, batch loss 0.0431, batch acc 0.9898
19:00:54.766   Training iter 150, batch loss 0.0365, batch acc 0.9932
19:00:56.165   Training iter 200, batch loss 0.0402, batch acc 0.9918
19:00:56.715   Training iter 250, batch loss 0.0408, batch acc 0.9922
19:00:57.219   Training iter 300, batch loss 0.0447, batch acc 0.9902
19:00:58.312   Training iter 350, batch loss 0.0430, batch acc 0.9890
19:00:58.919   Training iter 400, batch loss 0.0466, batch acc 0.9890
19:00:59.121   Training iter 450, batch loss 0.0442, batch acc 0.9906
19:00:59.289   Training iter 500, batch loss 0.0416, batch acc 0.9902
19:00:59.547   Training iter 550, batch loss 0.0425, batch acc 0.9906
19:00:59.738   Training iter 600, batch loss 0.0447, batch acc 0.9894
19:00:59.739 Training @ 64 epoch...
19:00:59.900   Training iter 50, batch loss 0.0415, batch acc 0.9916
19:01:00.121   Training iter 100, batch loss 0.0433, batch acc 0.9908
19:01:00.253   Training iter 150, batch loss 0.0461, batch acc 0.9904
19:01:00.462   Training iter 200, batch loss 0.0402, batch acc 0.9926
19:01:00.672   Training iter 250, batch loss 0.0407, batch acc 0.9898
19:01:00.815   Training iter 300, batch loss 0.0387, batch acc 0.9914
19:01:00.959   Training iter 350, batch loss 0.0401, batch acc 0.9916
19:01:01.135   Training iter 400, batch loss 0.0416, batch acc 0.9920
19:01:01.223   Training iter 450, batch loss 0.0419, batch acc 0.9914
19:01:01.306   Training iter 500, batch loss 0.0419, batch acc 0.9900
19:01:01.404   Training iter 550, batch loss 0.0453, batch acc 0.9894
19:01:01.498   Training iter 600, batch loss 0.0458, batch acc 0.9878
19:01:01.500 Training @ 65 epoch...
19:01:01.669   Training iter 50, batch loss 0.0405, batch acc 0.9930
19:01:01.781   Training iter 100, batch loss 0.0403, batch acc 0.9912
19:01:01.932   Training iter 150, batch loss 0.0388, batch acc 0.9910
19:01:02.023   Training iter 200, batch loss 0.0422, batch acc 0.9910
19:01:02.207   Training iter 250, batch loss 0.0406, batch acc 0.9926
19:01:02.313   Training iter 300, batch loss 0.0404, batch acc 0.9902
19:01:02.412   Training iter 350, batch loss 0.0425, batch acc 0.9882
19:01:02.505   Training iter 400, batch loss 0.0455, batch acc 0.9884
19:01:02.684   Training iter 450, batch loss 0.0417, batch acc 0.9918
19:01:02.833   Training iter 500, batch loss 0.0383, batch acc 0.9930
19:01:02.932   Training iter 550, batch loss 0.0481, batch acc 0.9892
19:01:03.080   Training iter 600, batch loss 0.0470, batch acc 0.9892
19:01:03.080 Testing @ 65 epoch...
19:01:03.245     Testing, total mean loss 0.07083, total acc 0.97910
19:01:03.246 Training @ 66 epoch...
19:01:03.364   Training iter 50, batch loss 0.0392, batch acc 0.9906
19:01:03.615   Training iter 100, batch loss 0.0391, batch acc 0.9902
19:01:03.753   Training iter 150, batch loss 0.0431, batch acc 0.9908
19:01:03.867   Training iter 200, batch loss 0.0379, batch acc 0.9932
19:01:04.244   Training iter 250, batch loss 0.0453, batch acc 0.9874
19:01:04.482   Training iter 300, batch loss 0.0422, batch acc 0.9906
19:01:04.686   Training iter 350, batch loss 0.0440, batch acc 0.9910
19:01:04.789   Training iter 400, batch loss 0.0424, batch acc 0.9908
19:01:04.945   Training iter 450, batch loss 0.0468, batch acc 0.9902
19:01:05.126   Training iter 500, batch loss 0.0395, batch acc 0.9918
19:01:05.255   Training iter 550, batch loss 0.0402, batch acc 0.9902
19:01:05.418   Training iter 600, batch loss 0.0410, batch acc 0.9914
19:01:05.419 Training @ 67 epoch...
19:01:05.655   Training iter 50, batch loss 0.0370, batch acc 0.9932
19:01:05.790   Training iter 100, batch loss 0.0398, batch acc 0.9908
19:01:05.875   Training iter 150, batch loss 0.0477, batch acc 0.9886
19:01:05.969   Training iter 200, batch loss 0.0403, batch acc 0.9906
19:01:06.091   Training iter 250, batch loss 0.0397, batch acc 0.9904
19:01:06.252   Training iter 300, batch loss 0.0428, batch acc 0.9908
19:01:06.445   Training iter 350, batch loss 0.0367, batch acc 0.9936
19:01:06.592   Training iter 400, batch loss 0.0431, batch acc 0.9908
19:01:06.757   Training iter 450, batch loss 0.0397, batch acc 0.9924
19:01:06.990   Training iter 500, batch loss 0.0444, batch acc 0.9884
19:01:07.444   Training iter 550, batch loss 0.0481, batch acc 0.9884
19:01:07.766   Training iter 600, batch loss 0.0452, batch acc 0.9896
19:01:07.768 Training @ 68 epoch...
19:01:07.928   Training iter 50, batch loss 0.0422, batch acc 0.9924
19:01:08.424   Training iter 100, batch loss 0.0364, batch acc 0.9948
19:01:09.275   Training iter 150, batch loss 0.0443, batch acc 0.9902
19:01:10.491   Training iter 200, batch loss 0.0416, batch acc 0.9910
19:01:11.066   Training iter 250, batch loss 0.0416, batch acc 0.9906
19:01:11.886   Training iter 300, batch loss 0.0403, batch acc 0.9926
19:01:13.031   Training iter 350, batch loss 0.0417, batch acc 0.9894
19:01:13.615   Training iter 400, batch loss 0.0395, batch acc 0.9906
19:01:13.978   Training iter 450, batch loss 0.0430, batch acc 0.9912
19:01:14.601   Training iter 500, batch loss 0.0371, batch acc 0.9926
19:01:15.487   Training iter 550, batch loss 0.0442, batch acc 0.9894
19:01:16.161   Training iter 600, batch loss 0.0442, batch acc 0.9900
19:01:16.165 Training @ 69 epoch...
19:01:16.552   Training iter 50, batch loss 0.0408, batch acc 0.9898
19:01:16.687   Training iter 100, batch loss 0.0390, batch acc 0.9922
19:01:16.934   Training iter 150, batch loss 0.0435, batch acc 0.9900
19:01:17.182   Training iter 200, batch loss 0.0401, batch acc 0.9912
19:01:17.329   Training iter 250, batch loss 0.0435, batch acc 0.9900
19:01:17.638   Training iter 300, batch loss 0.0407, batch acc 0.9902
19:01:17.808   Training iter 350, batch loss 0.0393, batch acc 0.9914
19:01:17.939   Training iter 400, batch loss 0.0462, batch acc 0.9920
19:01:18.090   Training iter 450, batch loss 0.0367, batch acc 0.9928
19:01:18.256   Training iter 500, batch loss 0.0417, batch acc 0.9922
19:01:18.390   Training iter 550, batch loss 0.0422, batch acc 0.9906
19:01:18.531   Training iter 600, batch loss 0.0430, batch acc 0.9914
19:01:18.531 Training @ 70 epoch...
19:01:18.686   Training iter 50, batch loss 0.0399, batch acc 0.9924
19:01:18.907   Training iter 100, batch loss 0.0390, batch acc 0.9936
19:01:19.315   Training iter 150, batch loss 0.0400, batch acc 0.9910
19:01:19.493   Training iter 200, batch loss 0.0382, batch acc 0.9920
19:01:19.613   Training iter 250, batch loss 0.0427, batch acc 0.9898
19:01:19.725   Training iter 300, batch loss 0.0441, batch acc 0.9908
19:01:20.569   Training iter 350, batch loss 0.0401, batch acc 0.9896
19:01:21.462   Training iter 400, batch loss 0.0435, batch acc 0.9906
19:01:22.660   Training iter 450, batch loss 0.0451, batch acc 0.9886
19:01:23.336   Training iter 500, batch loss 0.0381, batch acc 0.9916
19:01:24.277   Training iter 550, batch loss 0.0437, batch acc 0.9892
19:01:25.211   Training iter 600, batch loss 0.0407, batch acc 0.9928
19:01:25.211 Testing @ 70 epoch...
19:01:25.909     Testing, total mean loss 0.06974, total acc 0.97850
19:01:25.909 Training @ 71 epoch...
19:01:26.521   Training iter 50, batch loss 0.0417, batch acc 0.9938
19:01:27.413   Training iter 100, batch loss 0.0379, batch acc 0.9914
19:01:27.789   Training iter 150, batch loss 0.0402, batch acc 0.9908
19:01:27.939   Training iter 200, batch loss 0.0390, batch acc 0.9922
19:01:28.138   Training iter 250, batch loss 0.0410, batch acc 0.9910
19:01:28.250   Training iter 300, batch loss 0.0418, batch acc 0.9896
19:01:28.407   Training iter 350, batch loss 0.0424, batch acc 0.9906
19:01:28.503   Training iter 400, batch loss 0.0417, batch acc 0.9912
19:01:28.669   Training iter 450, batch loss 0.0402, batch acc 0.9920
19:01:28.962   Training iter 500, batch loss 0.0447, batch acc 0.9902
19:01:29.144   Training iter 550, batch loss 0.0441, batch acc 0.9894
19:01:29.248   Training iter 600, batch loss 0.0417, batch acc 0.9914
19:01:29.248 Training @ 72 epoch...
19:01:29.328   Training iter 50, batch loss 0.0384, batch acc 0.9916
19:01:29.512   Training iter 100, batch loss 0.0393, batch acc 0.9928
19:01:29.655   Training iter 150, batch loss 0.0392, batch acc 0.9912
19:01:29.759   Training iter 200, batch loss 0.0409, batch acc 0.9900
19:01:29.888   Training iter 250, batch loss 0.0420, batch acc 0.9916
19:01:30.019   Training iter 300, batch loss 0.0385, batch acc 0.9920
19:01:30.169   Training iter 350, batch loss 0.0394, batch acc 0.9928
19:01:30.354   Training iter 400, batch loss 0.0418, batch acc 0.9914
19:01:30.486   Training iter 450, batch loss 0.0457, batch acc 0.9890
19:01:30.586   Training iter 500, batch loss 0.0375, batch acc 0.9922
19:01:30.718   Training iter 550, batch loss 0.0451, batch acc 0.9894
19:01:30.875   Training iter 600, batch loss 0.0427, batch acc 0.9900
19:01:30.876 Training @ 73 epoch...
19:01:31.091   Training iter 50, batch loss 0.0442, batch acc 0.9910
19:01:31.270   Training iter 100, batch loss 0.0358, batch acc 0.9936
19:01:31.347   Training iter 150, batch loss 0.0384, batch acc 0.9910
19:01:31.444   Training iter 200, batch loss 0.0398, batch acc 0.9920
19:01:31.537   Training iter 250, batch loss 0.0404, batch acc 0.9922
19:01:31.682   Training iter 300, batch loss 0.0395, batch acc 0.9918
19:01:31.764   Training iter 350, batch loss 0.0362, batch acc 0.9928
19:01:31.853   Training iter 400, batch loss 0.0426, batch acc 0.9904
19:01:32.000   Training iter 450, batch loss 0.0410, batch acc 0.9912
19:01:32.100   Training iter 500, batch loss 0.0415, batch acc 0.9902
19:01:32.261   Training iter 550, batch loss 0.0429, batch acc 0.9888
19:01:32.356   Training iter 600, batch loss 0.0469, batch acc 0.9874
19:01:32.357 Training @ 74 epoch...
19:01:32.483   Training iter 50, batch loss 0.0392, batch acc 0.9920
19:01:32.619   Training iter 100, batch loss 0.0385, batch acc 0.9930
19:01:32.720   Training iter 150, batch loss 0.0387, batch acc 0.9916
19:01:32.876   Training iter 200, batch loss 0.0390, batch acc 0.9914
19:01:32.974   Training iter 250, batch loss 0.0396, batch acc 0.9908
19:01:33.156   Training iter 300, batch loss 0.0362, batch acc 0.9926
19:01:33.360   Training iter 350, batch loss 0.0414, batch acc 0.9912
19:01:33.463   Training iter 400, batch loss 0.0445, batch acc 0.9900
19:01:33.578   Training iter 450, batch loss 0.0454, batch acc 0.9896
19:01:33.738   Training iter 500, batch loss 0.0398, batch acc 0.9910
19:01:34.014   Training iter 550, batch loss 0.0413, batch acc 0.9910
19:01:34.218   Training iter 600, batch loss 0.0450, batch acc 0.9904
19:01:34.218 Training @ 75 epoch...
19:01:34.393   Training iter 50, batch loss 0.0391, batch acc 0.9920
19:01:34.507   Training iter 100, batch loss 0.0427, batch acc 0.9924
19:01:34.588   Training iter 150, batch loss 0.0419, batch acc 0.9918
19:01:34.752   Training iter 200, batch loss 0.0372, batch acc 0.9926
19:01:34.888   Training iter 250, batch loss 0.0376, batch acc 0.9928
19:01:35.011   Training iter 300, batch loss 0.0379, batch acc 0.9924
19:01:35.106   Training iter 350, batch loss 0.0412, batch acc 0.9894
19:01:35.261   Training iter 400, batch loss 0.0395, batch acc 0.9918
19:01:35.406   Training iter 450, batch loss 0.0419, batch acc 0.9904
19:01:35.484   Training iter 500, batch loss 0.0414, batch acc 0.9912
19:01:35.566   Training iter 550, batch loss 0.0403, batch acc 0.9912
19:01:35.752   Training iter 600, batch loss 0.0426, batch acc 0.9904
19:01:35.753 Testing @ 75 epoch...
19:01:35.835     Testing, total mean loss 0.06891, total acc 0.97930
19:01:35.835 Training @ 76 epoch...
19:01:35.996   Training iter 50, batch loss 0.0390, batch acc 0.9912
19:01:36.103   Training iter 100, batch loss 0.0365, batch acc 0.9942
19:01:36.224   Training iter 150, batch loss 0.0376, batch acc 0.9920
19:01:36.355   Training iter 200, batch loss 0.0422, batch acc 0.9898
19:01:36.468   Training iter 250, batch loss 0.0437, batch acc 0.9900
19:01:36.601   Training iter 300, batch loss 0.0369, batch acc 0.9924
19:01:36.753   Training iter 350, batch loss 0.0413, batch acc 0.9926
19:01:36.954   Training iter 400, batch loss 0.0464, batch acc 0.9894
19:01:37.113   Training iter 450, batch loss 0.0430, batch acc 0.9894
19:01:37.198   Training iter 500, batch loss 0.0444, batch acc 0.9896
19:01:37.297   Training iter 550, batch loss 0.0358, batch acc 0.9942
19:01:37.416   Training iter 600, batch loss 0.0394, batch acc 0.9898
19:01:37.418 Training @ 77 epoch...
19:01:37.527   Training iter 50, batch loss 0.0387, batch acc 0.9920
19:01:37.779   Training iter 100, batch loss 0.0355, batch acc 0.9930
19:01:37.881   Training iter 150, batch loss 0.0395, batch acc 0.9912
19:01:38.007   Training iter 200, batch loss 0.0423, batch acc 0.9914
19:01:38.100   Training iter 250, batch loss 0.0390, batch acc 0.9900
19:01:38.204   Training iter 300, batch loss 0.0401, batch acc 0.9908
19:01:38.363   Training iter 350, batch loss 0.0405, batch acc 0.9914
19:01:38.477   Training iter 400, batch loss 0.0376, batch acc 0.9926
19:01:38.608   Training iter 450, batch loss 0.0482, batch acc 0.9880
19:01:38.735   Training iter 500, batch loss 0.0380, batch acc 0.9930
19:01:38.874   Training iter 550, batch loss 0.0413, batch acc 0.9926
19:01:39.019   Training iter 600, batch loss 0.0435, batch acc 0.9910
19:01:39.020 Training @ 78 epoch...
19:01:39.210   Training iter 50, batch loss 0.0377, batch acc 0.9920
19:01:39.332   Training iter 100, batch loss 0.0402, batch acc 0.9922
19:01:39.457   Training iter 150, batch loss 0.0382, batch acc 0.9916
19:01:39.612   Training iter 200, batch loss 0.0379, batch acc 0.9922
19:01:39.704   Training iter 250, batch loss 0.0392, batch acc 0.9924
19:01:39.824   Training iter 300, batch loss 0.0416, batch acc 0.9920
19:01:40.086   Training iter 350, batch loss 0.0375, batch acc 0.9918
19:01:40.289   Training iter 400, batch loss 0.0409, batch acc 0.9912
19:01:40.406   Training iter 450, batch loss 0.0420, batch acc 0.9904
19:01:40.538   Training iter 500, batch loss 0.0421, batch acc 0.9892
19:01:40.718   Training iter 550, batch loss 0.0424, batch acc 0.9906
19:01:41.050   Training iter 600, batch loss 0.0409, batch acc 0.9910
19:01:41.052 Training @ 79 epoch...
19:01:41.248   Training iter 50, batch loss 0.0403, batch acc 0.9920
19:01:41.422   Training iter 100, batch loss 0.0399, batch acc 0.9916
19:01:41.551   Training iter 150, batch loss 0.0381, batch acc 0.9926
19:01:41.701   Training iter 200, batch loss 0.0333, batch acc 0.9932
19:01:41.853   Training iter 250, batch loss 0.0344, batch acc 0.9936
19:01:41.987   Training iter 300, batch loss 0.0379, batch acc 0.9930
19:01:42.148   Training iter 350, batch loss 0.0433, batch acc 0.9900
19:01:42.316   Training iter 400, batch loss 0.0402, batch acc 0.9916
19:01:42.485   Training iter 450, batch loss 0.0429, batch acc 0.9890
19:01:42.591   Training iter 500, batch loss 0.0434, batch acc 0.9908
19:01:42.685   Training iter 550, batch loss 0.0435, batch acc 0.9902
19:01:42.839   Training iter 600, batch loss 0.0426, batch acc 0.9902
19:01:42.839 Training @ 80 epoch...
19:01:42.929   Training iter 50, batch loss 0.0383, batch acc 0.9936
19:01:43.034   Training iter 100, batch loss 0.0345, batch acc 0.9944
19:01:43.128   Training iter 150, batch loss 0.0366, batch acc 0.9924
19:01:43.221   Training iter 200, batch loss 0.0411, batch acc 0.9916
19:01:43.389   Training iter 250, batch loss 0.0439, batch acc 0.9898
19:01:43.531   Training iter 300, batch loss 0.0415, batch acc 0.9902
19:01:43.676   Training iter 350, batch loss 0.0402, batch acc 0.9914
19:01:43.812   Training iter 400, batch loss 0.0389, batch acc 0.9908
19:01:43.982   Training iter 450, batch loss 0.0398, batch acc 0.9914
19:01:44.071   Training iter 500, batch loss 0.0392, batch acc 0.9916
19:01:44.205   Training iter 550, batch loss 0.0415, batch acc 0.9916
19:01:44.368   Training iter 600, batch loss 0.0438, batch acc 0.9896
19:01:44.368 Testing @ 80 epoch...
19:01:44.467     Testing, total mean loss 0.06556, total acc 0.97990
19:01:44.467 Training @ 81 epoch...
19:01:44.604   Training iter 50, batch loss 0.0415, batch acc 0.9908
19:01:44.756   Training iter 100, batch loss 0.0397, batch acc 0.9926
19:01:45.103   Training iter 150, batch loss 0.0430, batch acc 0.9902
19:01:45.297   Training iter 200, batch loss 0.0407, batch acc 0.9908
19:01:45.502   Training iter 250, batch loss 0.0359, batch acc 0.9940
19:01:45.714   Training iter 300, batch loss 0.0372, batch acc 0.9922
19:01:45.919   Training iter 350, batch loss 0.0439, batch acc 0.9906
19:01:46.640   Training iter 400, batch loss 0.0397, batch acc 0.9926
19:01:47.116   Training iter 450, batch loss 0.0388, batch acc 0.9920
19:01:48.316   Training iter 500, batch loss 0.0403, batch acc 0.9916
19:01:48.994   Training iter 550, batch loss 0.0369, batch acc 0.9918
19:01:49.994   Training iter 600, batch loss 0.0397, batch acc 0.9900
19:01:49.996 Training @ 82 epoch...
19:01:50.993   Training iter 50, batch loss 0.0385, batch acc 0.9922
19:01:51.559   Training iter 100, batch loss 0.0371, batch acc 0.9920
19:01:52.148   Training iter 150, batch loss 0.0403, batch acc 0.9914
19:01:53.056   Training iter 200, batch loss 0.0400, batch acc 0.9914
19:01:53.528   Training iter 250, batch loss 0.0401, batch acc 0.9918
19:01:53.658   Training iter 300, batch loss 0.0408, batch acc 0.9920
19:01:53.796   Training iter 350, batch loss 0.0351, batch acc 0.9940
19:01:53.946   Training iter 400, batch loss 0.0402, batch acc 0.9934
19:01:54.088   Training iter 450, batch loss 0.0412, batch acc 0.9902
19:01:54.216   Training iter 500, batch loss 0.0414, batch acc 0.9910
19:01:54.349   Training iter 550, batch loss 0.0406, batch acc 0.9910
19:01:54.466   Training iter 600, batch loss 0.0424, batch acc 0.9898
19:01:54.467 Training @ 83 epoch...
19:01:54.553   Training iter 50, batch loss 0.0352, batch acc 0.9930
19:01:54.669   Training iter 100, batch loss 0.0332, batch acc 0.9944
19:01:54.900   Training iter 150, batch loss 0.0393, batch acc 0.9916
19:01:54.992   Training iter 200, batch loss 0.0404, batch acc 0.9916
19:01:55.095   Training iter 250, batch loss 0.0369, batch acc 0.9922
19:01:55.181   Training iter 300, batch loss 0.0418, batch acc 0.9898
19:01:55.397   Training iter 350, batch loss 0.0449, batch acc 0.9890
19:01:55.721   Training iter 400, batch loss 0.0404, batch acc 0.9908
19:01:55.831   Training iter 450, batch loss 0.0399, batch acc 0.9910
19:01:55.940   Training iter 500, batch loss 0.0402, batch acc 0.9906
19:01:56.047   Training iter 550, batch loss 0.0423, batch acc 0.9914
19:01:56.164   Training iter 600, batch loss 0.0450, batch acc 0.9908
19:01:56.165 Training @ 84 epoch...
19:01:56.331   Training iter 50, batch loss 0.0419, batch acc 0.9914
19:01:56.418   Training iter 100, batch loss 0.0364, batch acc 0.9940
19:01:56.528   Training iter 150, batch loss 0.0398, batch acc 0.9918
19:01:56.690   Training iter 200, batch loss 0.0403, batch acc 0.9930
19:01:56.805   Training iter 250, batch loss 0.0399, batch acc 0.9914
19:01:56.894   Training iter 300, batch loss 0.0360, batch acc 0.9916
19:01:57.037   Training iter 350, batch loss 0.0383, batch acc 0.9904
19:01:57.142   Training iter 400, batch loss 0.0403, batch acc 0.9910
19:01:57.235   Training iter 450, batch loss 0.0395, batch acc 0.9926
19:01:57.335   Training iter 500, batch loss 0.0407, batch acc 0.9904
19:01:57.420   Training iter 550, batch loss 0.0391, batch acc 0.9926
19:01:57.565   Training iter 600, batch loss 0.0414, batch acc 0.9910
19:01:57.573 Training @ 85 epoch...
19:01:57.725   Training iter 50, batch loss 0.0350, batch acc 0.9934
19:01:57.838   Training iter 100, batch loss 0.0362, batch acc 0.9936
19:01:57.958   Training iter 150, batch loss 0.0370, batch acc 0.9922
19:01:58.078   Training iter 200, batch loss 0.0420, batch acc 0.9900
19:01:58.172   Training iter 250, batch loss 0.0377, batch acc 0.9930
19:01:58.267   Training iter 300, batch loss 0.0381, batch acc 0.9930
19:01:58.349   Training iter 350, batch loss 0.0429, batch acc 0.9892
19:01:58.454   Training iter 400, batch loss 0.0417, batch acc 0.9918
19:01:58.581   Training iter 450, batch loss 0.0391, batch acc 0.9920
19:01:58.721   Training iter 500, batch loss 0.0426, batch acc 0.9900
19:01:58.812   Training iter 550, batch loss 0.0412, batch acc 0.9908
19:01:58.908   Training iter 600, batch loss 0.0427, batch acc 0.9894
19:01:58.908 Testing @ 85 epoch...
19:01:58.969     Testing, total mean loss 0.06669, total acc 0.97930
19:01:58.969 Training @ 86 epoch...
19:01:59.086   Training iter 50, batch loss 0.0382, batch acc 0.9920
19:01:59.223   Training iter 100, batch loss 0.0356, batch acc 0.9928
19:01:59.396   Training iter 150, batch loss 0.0369, batch acc 0.9926
19:01:59.534   Training iter 200, batch loss 0.0391, batch acc 0.9920
19:01:59.715   Training iter 250, batch loss 0.0375, batch acc 0.9914
19:01:59.878   Training iter 300, batch loss 0.0406, batch acc 0.9916
19:01:59.983   Training iter 350, batch loss 0.0416, batch acc 0.9900
19:02:00.088   Training iter 400, batch loss 0.0414, batch acc 0.9914
19:02:00.217   Training iter 450, batch loss 0.0376, batch acc 0.9924
19:02:00.329   Training iter 500, batch loss 0.0423, batch acc 0.9918
19:02:00.413   Training iter 550, batch loss 0.0381, batch acc 0.9912
19:02:00.508   Training iter 600, batch loss 0.0475, batch acc 0.9876
19:02:00.509 Training @ 87 epoch...
19:02:00.592   Training iter 50, batch loss 0.0365, batch acc 0.9912
19:02:00.682   Training iter 100, batch loss 0.0404, batch acc 0.9910
19:02:00.779   Training iter 150, batch loss 0.0368, batch acc 0.9916
19:02:00.864   Training iter 200, batch loss 0.0425, batch acc 0.9912
19:02:00.993   Training iter 250, batch loss 0.0395, batch acc 0.9920
19:02:01.085   Training iter 300, batch loss 0.0382, batch acc 0.9908
19:02:01.170   Training iter 350, batch loss 0.0386, batch acc 0.9922
19:02:01.386   Training iter 400, batch loss 0.0381, batch acc 0.9932
19:02:01.482   Training iter 450, batch loss 0.0389, batch acc 0.9926
19:02:01.622   Training iter 500, batch loss 0.0345, batch acc 0.9930
19:02:01.731   Training iter 550, batch loss 0.0425, batch acc 0.9906
19:02:01.855   Training iter 600, batch loss 0.0451, batch acc 0.9896
19:02:01.856 Training @ 88 epoch...
19:02:01.967   Training iter 50, batch loss 0.0380, batch acc 0.9930
19:02:02.072   Training iter 100, batch loss 0.0374, batch acc 0.9904
19:02:02.245   Training iter 150, batch loss 0.0419, batch acc 0.9900
19:02:02.405   Training iter 200, batch loss 0.0373, batch acc 0.9934
19:02:02.557   Training iter 250, batch loss 0.0377, batch acc 0.9928
19:02:02.769   Training iter 300, batch loss 0.0401, batch acc 0.9896
19:02:02.922   Training iter 350, batch loss 0.0362, batch acc 0.9940
19:02:03.141   Training iter 400, batch loss 0.0435, batch acc 0.9906
19:02:03.270   Training iter 450, batch loss 0.0393, batch acc 0.9928
19:02:03.397   Training iter 500, batch loss 0.0406, batch acc 0.9916
19:02:03.519   Training iter 550, batch loss 0.0407, batch acc 0.9922
19:02:03.631   Training iter 600, batch loss 0.0373, batch acc 0.9918
19:02:03.631 Training @ 89 epoch...
19:02:03.781   Training iter 50, batch loss 0.0382, batch acc 0.9932
19:02:03.936   Training iter 100, batch loss 0.0415, batch acc 0.9912
19:02:04.091   Training iter 150, batch loss 0.0361, batch acc 0.9928
19:02:04.256   Training iter 200, batch loss 0.0379, batch acc 0.9916
19:02:04.386   Training iter 250, batch loss 0.0330, batch acc 0.9938
19:02:04.473   Training iter 300, batch loss 0.0370, batch acc 0.9916
19:02:04.569   Training iter 350, batch loss 0.0418, batch acc 0.9916
19:02:04.735   Training iter 400, batch loss 0.0364, batch acc 0.9926
19:02:04.906   Training iter 450, batch loss 0.0375, batch acc 0.9926
19:02:05.030   Training iter 500, batch loss 0.0403, batch acc 0.9936
19:02:05.164   Training iter 550, batch loss 0.0415, batch acc 0.9912
19:02:05.275   Training iter 600, batch loss 0.0489, batch acc 0.9874
19:02:05.276 Training @ 90 epoch...
19:02:05.411   Training iter 50, batch loss 0.0414, batch acc 0.9900
19:02:05.665   Training iter 100, batch loss 0.0395, batch acc 0.9924
19:02:05.831   Training iter 150, batch loss 0.0429, batch acc 0.9908
19:02:06.005   Training iter 200, batch loss 0.0391, batch acc 0.9926
19:02:06.203   Training iter 250, batch loss 0.0356, batch acc 0.9918
19:02:06.283   Training iter 300, batch loss 0.0377, batch acc 0.9930
19:02:06.379   Training iter 350, batch loss 0.0363, batch acc 0.9926
19:02:06.470   Training iter 400, batch loss 0.0404, batch acc 0.9932
19:02:06.664   Training iter 450, batch loss 0.0396, batch acc 0.9936
19:02:06.894   Training iter 500, batch loss 0.0340, batch acc 0.9926
19:02:07.051   Training iter 550, batch loss 0.0417, batch acc 0.9904
19:02:07.464   Training iter 600, batch loss 0.0397, batch acc 0.9918
19:02:07.465 Testing @ 90 epoch...
19:02:07.570     Testing, total mean loss 0.06853, total acc 0.97940
19:02:07.570 Training @ 91 epoch...
19:02:07.778   Training iter 50, batch loss 0.0366, batch acc 0.9934
19:02:07.962   Training iter 100, batch loss 0.0377, batch acc 0.9906
19:02:08.118   Training iter 150, batch loss 0.0392, batch acc 0.9910
19:02:08.852   Training iter 200, batch loss 0.0408, batch acc 0.9918
19:02:09.429   Training iter 250, batch loss 0.0353, batch acc 0.9938
19:02:10.997   Training iter 300, batch loss 0.0410, batch acc 0.9920
19:02:12.227   Training iter 350, batch loss 0.0449, batch acc 0.9894
19:02:13.031   Training iter 400, batch loss 0.0389, batch acc 0.9916
19:02:13.488   Training iter 450, batch loss 0.0378, batch acc 0.9918
19:02:14.600   Training iter 500, batch loss 0.0389, batch acc 0.9916
19:02:15.365   Training iter 550, batch loss 0.0425, batch acc 0.9906
19:02:15.902   Training iter 600, batch loss 0.0349, batch acc 0.9932
19:02:15.903 Training @ 92 epoch...
19:02:16.181   Training iter 50, batch loss 0.0337, batch acc 0.9944
19:02:16.417   Training iter 100, batch loss 0.0383, batch acc 0.9916
19:02:16.561   Training iter 150, batch loss 0.0369, batch acc 0.9920
19:02:16.718   Training iter 200, batch loss 0.0383, batch acc 0.9916
19:02:16.919   Training iter 250, batch loss 0.0353, batch acc 0.9940
19:02:17.114   Training iter 300, batch loss 0.0429, batch acc 0.9892
19:02:17.303   Training iter 350, batch loss 0.0492, batch acc 0.9864
19:02:17.466   Training iter 400, batch loss 0.0369, batch acc 0.9924
19:02:17.593   Training iter 450, batch loss 0.0392, batch acc 0.9910
19:02:17.739   Training iter 500, batch loss 0.0355, batch acc 0.9928
19:02:17.838   Training iter 550, batch loss 0.0417, batch acc 0.9914
19:02:17.941   Training iter 600, batch loss 0.0450, batch acc 0.9896
19:02:17.943 Training @ 93 epoch...
19:02:18.095   Training iter 50, batch loss 0.0363, batch acc 0.9928
19:02:18.218   Training iter 100, batch loss 0.0375, batch acc 0.9914
19:02:18.318   Training iter 150, batch loss 0.0371, batch acc 0.9924
19:02:18.456   Training iter 200, batch loss 0.0437, batch acc 0.9912
19:02:18.557   Training iter 250, batch loss 0.0370, batch acc 0.9926
19:02:18.667   Training iter 300, batch loss 0.0406, batch acc 0.9912
19:02:18.746   Training iter 350, batch loss 0.0389, batch acc 0.9912
19:02:18.852   Training iter 400, batch loss 0.0373, batch acc 0.9940
19:02:19.069   Training iter 450, batch loss 0.0423, batch acc 0.9902
19:02:19.180   Training iter 500, batch loss 0.0424, batch acc 0.9912
19:02:19.286   Training iter 550, batch loss 0.0381, batch acc 0.9926
19:02:19.405   Training iter 600, batch loss 0.0391, batch acc 0.9922
19:02:19.405 Training @ 94 epoch...
19:02:19.506   Training iter 50, batch loss 0.0360, batch acc 0.9930
19:02:19.616   Training iter 100, batch loss 0.0338, batch acc 0.9932
19:02:19.742   Training iter 150, batch loss 0.0374, batch acc 0.9926
19:02:19.885   Training iter 200, batch loss 0.0373, batch acc 0.9922
19:02:20.036   Training iter 250, batch loss 0.0408, batch acc 0.9900
19:02:20.136   Training iter 300, batch loss 0.0433, batch acc 0.9896
19:02:20.399   Training iter 350, batch loss 0.0387, batch acc 0.9920
19:02:20.499   Training iter 400, batch loss 0.0369, batch acc 0.9930
19:02:20.584   Training iter 450, batch loss 0.0396, batch acc 0.9912
19:02:20.737   Training iter 500, batch loss 0.0413, batch acc 0.9904
19:02:20.928   Training iter 550, batch loss 0.0416, batch acc 0.9920
19:02:21.041   Training iter 600, batch loss 0.0395, batch acc 0.9916
19:02:21.042 Training @ 95 epoch...
19:02:21.202   Training iter 50, batch loss 0.0355, batch acc 0.9942
19:02:21.365   Training iter 100, batch loss 0.0399, batch acc 0.9910
19:02:21.538   Training iter 150, batch loss 0.0373, batch acc 0.9926
19:02:21.666   Training iter 200, batch loss 0.0436, batch acc 0.9914
19:02:21.788   Training iter 250, batch loss 0.0375, batch acc 0.9918
19:02:22.004   Training iter 300, batch loss 0.0372, batch acc 0.9942
19:02:22.121   Training iter 350, batch loss 0.0368, batch acc 0.9912
19:02:22.247   Training iter 400, batch loss 0.0386, batch acc 0.9918
19:02:22.366   Training iter 450, batch loss 0.0391, batch acc 0.9920
19:02:22.506   Training iter 500, batch loss 0.0405, batch acc 0.9900
19:02:22.678   Training iter 550, batch loss 0.0389, batch acc 0.9914
19:02:22.796   Training iter 600, batch loss 0.0437, batch acc 0.9878
19:02:22.798 Testing @ 95 epoch...
19:02:22.926     Testing, total mean loss 0.06729, total acc 0.98000
19:02:22.926 Training @ 96 epoch...
19:02:23.017   Training iter 50, batch loss 0.0394, batch acc 0.9930
19:02:23.107   Training iter 100, batch loss 0.0396, batch acc 0.9914
19:02:23.208   Training iter 150, batch loss 0.0367, batch acc 0.9912
19:02:23.319   Training iter 200, batch loss 0.0395, batch acc 0.9940
19:02:23.400   Training iter 250, batch loss 0.0363, batch acc 0.9926
19:02:23.482   Training iter 300, batch loss 0.0379, batch acc 0.9908
19:02:23.560   Training iter 350, batch loss 0.0417, batch acc 0.9906
19:02:23.682   Training iter 400, batch loss 0.0362, batch acc 0.9926
19:02:23.784   Training iter 450, batch loss 0.0403, batch acc 0.9908
19:02:23.912   Training iter 500, batch loss 0.0376, batch acc 0.9922
19:02:24.006   Training iter 550, batch loss 0.0426, batch acc 0.9910
19:02:24.120   Training iter 600, batch loss 0.0379, batch acc 0.9920
19:02:24.122 Training @ 97 epoch...
19:02:24.206   Training iter 50, batch loss 0.0392, batch acc 0.9926
19:02:24.320   Training iter 100, batch loss 0.0381, batch acc 0.9924
19:02:24.411   Training iter 150, batch loss 0.0355, batch acc 0.9938
19:02:24.513   Training iter 200, batch loss 0.0365, batch acc 0.9914
19:02:24.598   Training iter 250, batch loss 0.0358, batch acc 0.9944
19:02:24.703   Training iter 300, batch loss 0.0386, batch acc 0.9924
19:02:24.799   Training iter 350, batch loss 0.0397, batch acc 0.9908
19:02:24.900   Training iter 400, batch loss 0.0373, batch acc 0.9934
19:02:25.018   Training iter 450, batch loss 0.0436, batch acc 0.9900
19:02:25.129   Training iter 500, batch loss 0.0431, batch acc 0.9904
19:02:25.246   Training iter 550, batch loss 0.0433, batch acc 0.9890
19:02:25.351   Training iter 600, batch loss 0.0338, batch acc 0.9940
19:02:25.352 Training @ 98 epoch...
19:02:25.448   Training iter 50, batch loss 0.0391, batch acc 0.9916
19:02:25.589   Training iter 100, batch loss 0.0367, batch acc 0.9930
19:02:25.736   Training iter 150, batch loss 0.0360, batch acc 0.9904
19:02:25.838   Training iter 200, batch loss 0.0378, batch acc 0.9914
19:02:25.914   Training iter 250, batch loss 0.0339, batch acc 0.9938
19:02:26.023   Training iter 300, batch loss 0.0446, batch acc 0.9890
19:02:26.113   Training iter 350, batch loss 0.0428, batch acc 0.9904
19:02:26.215   Training iter 400, batch loss 0.0393, batch acc 0.9914
19:02:26.300   Training iter 450, batch loss 0.0415, batch acc 0.9926
19:02:26.391   Training iter 500, batch loss 0.0357, batch acc 0.9938
19:02:26.484   Training iter 550, batch loss 0.0373, batch acc 0.9932
19:02:26.567   Training iter 600, batch loss 0.0395, batch acc 0.9908
19:02:26.569 Training @ 99 epoch...
19:02:26.656   Training iter 50, batch loss 0.0377, batch acc 0.9928
19:02:26.746   Training iter 100, batch loss 0.0354, batch acc 0.9934
19:02:26.879   Training iter 150, batch loss 0.0360, batch acc 0.9928
19:02:26.970   Training iter 200, batch loss 0.0389, batch acc 0.9914
19:02:27.087   Training iter 250, batch loss 0.0433, batch acc 0.9908
19:02:27.190   Training iter 300, batch loss 0.0406, batch acc 0.9928
19:02:27.282   Training iter 350, batch loss 0.0404, batch acc 0.9922
19:02:27.381   Training iter 400, batch loss 0.0401, batch acc 0.9906
19:02:27.460   Training iter 450, batch loss 0.0394, batch acc 0.9908
19:02:27.567   Training iter 500, batch loss 0.0354, batch acc 0.9926
19:02:27.662   Training iter 550, batch loss 0.0383, batch acc 0.9900
19:02:27.754   Training iter 600, batch loss 0.0365, batch acc 0.9924
19:02:27.754 Testing @ 99 epoch...
19:02:27.812     Testing, total mean loss 0.06707, total acc 0.97880