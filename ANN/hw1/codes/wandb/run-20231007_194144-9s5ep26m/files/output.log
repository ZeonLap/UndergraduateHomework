19:41:48.001 Training @ 0 epoch...
19:41:48.242   Training iter 50, batch loss 0.9145, batch acc 0.1136
19:41:48.515   Training iter 100, batch loss 0.8997, batch acc 0.1204
19:41:48.735   Training iter 150, batch loss 0.8982, batch acc 0.1260
19:41:48.945   Training iter 200, batch loss 0.8960, batch acc 0.1212
19:41:49.163   Training iter 250, batch loss 0.8907, batch acc 0.2130
19:41:49.396   Training iter 300, batch loss 0.8733, batch acc 0.3596
19:41:49.599   Training iter 350, batch loss 0.7954, batch acc 0.3488
19:41:49.788   Training iter 400, batch loss 0.7164, batch acc 0.4002
19:41:50.009   Training iter 450, batch loss 0.6619, batch acc 0.4962
19:41:50.190   Training iter 500, batch loss 0.6256, batch acc 0.5634
19:41:50.361   Training iter 550, batch loss 0.5714, batch acc 0.6500
19:41:50.525   Training iter 600, batch loss 0.5133, batch acc 0.7188
19:41:50.526 Testing @ 0 epoch...
19:41:50.649     Testing, total mean loss 0.49019, total acc 0.74300
19:41:50.649 Training @ 1 epoch...
19:41:50.833   Training iter 50, batch loss 0.4825, batch acc 0.7580
19:41:51.017   Training iter 100, batch loss 0.4411, batch acc 0.7876
19:41:51.210   Training iter 150, batch loss 0.4170, batch acc 0.7904
19:41:51.387   Training iter 200, batch loss 0.3977, batch acc 0.8118
19:41:51.552   Training iter 250, batch loss 0.3821, batch acc 0.8296
19:41:51.719   Training iter 300, batch loss 0.3491, batch acc 0.8578
19:41:51.886   Training iter 350, batch loss 0.3277, batch acc 0.8774
19:41:52.108   Training iter 400, batch loss 0.3046, batch acc 0.8858
19:41:52.334   Training iter 450, batch loss 0.2957, batch acc 0.8836
19:41:52.536   Training iter 500, batch loss 0.2824, batch acc 0.8860
19:41:52.724   Training iter 550, batch loss 0.2713, batch acc 0.8906
19:41:52.937   Training iter 600, batch loss 0.2505, batch acc 0.8986
19:41:52.939 Training @ 2 epoch...
19:41:53.168   Training iter 50, batch loss 0.2535, batch acc 0.8944
19:41:53.346   Training iter 100, batch loss 0.2453, batch acc 0.9004
19:41:53.507   Training iter 150, batch loss 0.2370, batch acc 0.9068
19:41:53.677   Training iter 200, batch loss 0.2394, batch acc 0.8994
19:41:53.904   Training iter 250, batch loss 0.2409, batch acc 0.8934
19:41:54.092   Training iter 300, batch loss 0.2253, batch acc 0.9032
19:41:54.270   Training iter 350, batch loss 0.2265, batch acc 0.9070
19:41:54.451   Training iter 400, batch loss 0.2259, batch acc 0.8976
19:41:54.616   Training iter 450, batch loss 0.2214, batch acc 0.9050
19:41:54.800   Training iter 500, batch loss 0.2147, batch acc 0.9042
19:41:55.033   Training iter 550, batch loss 0.2147, batch acc 0.9068
19:41:55.241   Training iter 600, batch loss 0.2073, batch acc 0.9156
19:41:55.243 Training @ 3 epoch...
19:41:55.446   Training iter 50, batch loss 0.2160, batch acc 0.9030
19:41:55.687   Training iter 100, batch loss 0.2096, batch acc 0.9088
19:41:55.852   Training iter 150, batch loss 0.2068, batch acc 0.9128
19:41:56.042   Training iter 200, batch loss 0.2084, batch acc 0.9118
19:41:56.222   Training iter 250, batch loss 0.1956, batch acc 0.9164
19:41:56.396   Training iter 300, batch loss 0.2000, batch acc 0.9118
19:41:56.560   Training iter 350, batch loss 0.1953, batch acc 0.9136
19:41:56.735   Training iter 400, batch loss 0.1953, batch acc 0.9128
19:41:56.911   Training iter 450, batch loss 0.1916, batch acc 0.9176
19:41:57.098   Training iter 500, batch loss 0.1875, batch acc 0.9174
19:41:57.277   Training iter 550, batch loss 0.1840, batch acc 0.9254
19:41:57.454   Training iter 600, batch loss 0.1888, batch acc 0.9184
19:41:57.456 Training @ 4 epoch...
19:41:57.645   Training iter 50, batch loss 0.1881, batch acc 0.9168
19:41:57.856   Training iter 100, batch loss 0.1876, batch acc 0.9132
19:41:58.074   Training iter 150, batch loss 0.1842, batch acc 0.9198
19:41:58.314   Training iter 200, batch loss 0.1862, batch acc 0.9192
19:41:58.522   Training iter 250, batch loss 0.1848, batch acc 0.9218
19:41:58.698   Training iter 300, batch loss 0.1772, batch acc 0.9226
19:41:58.878   Training iter 350, batch loss 0.1765, batch acc 0.9252
19:41:59.058   Training iter 400, batch loss 0.1726, batch acc 0.9292
19:41:59.242   Training iter 450, batch loss 0.1759, batch acc 0.9246
19:41:59.422   Training iter 500, batch loss 0.1722, batch acc 0.9240
19:41:59.608   Training iter 550, batch loss 0.1693, batch acc 0.9252
19:41:59.790   Training iter 600, batch loss 0.1652, batch acc 0.9282
19:41:59.790 Training @ 5 epoch...
19:41:59.989   Training iter 50, batch loss 0.1674, batch acc 0.9304
19:42:00.203   Training iter 100, batch loss 0.1669, batch acc 0.9270
19:42:00.413   Training iter 150, batch loss 0.1672, batch acc 0.9258
19:42:00.662   Training iter 200, batch loss 0.1612, batch acc 0.9316
19:42:00.920   Training iter 250, batch loss 0.1660, batch acc 0.9240
19:42:01.182   Training iter 300, batch loss 0.1635, batch acc 0.9306
19:42:01.386   Training iter 350, batch loss 0.1627, batch acc 0.9284
19:42:01.563   Training iter 400, batch loss 0.1575, batch acc 0.9314
19:42:01.742   Training iter 450, batch loss 0.1601, batch acc 0.9286
19:42:01.932   Training iter 500, batch loss 0.1519, batch acc 0.9310
19:42:02.139   Training iter 550, batch loss 0.1542, batch acc 0.9354
19:42:02.321   Training iter 600, batch loss 0.1529, batch acc 0.9370
19:42:02.321 Testing @ 5 epoch...
19:42:02.419     Testing, total mean loss 0.15231, total acc 0.93670
19:42:02.420 Training @ 6 epoch...
19:42:02.618   Training iter 50, batch loss 0.1532, batch acc 0.9344
19:42:02.799   Training iter 100, batch loss 0.1528, batch acc 0.9306
19:42:03.004   Training iter 150, batch loss 0.1471, batch acc 0.9384
19:42:03.225   Training iter 200, batch loss 0.1495, batch acc 0.9342
19:42:03.440   Training iter 250, batch loss 0.1459, batch acc 0.9356
19:42:03.668   Training iter 300, batch loss 0.1497, batch acc 0.9310
19:42:03.908   Training iter 350, batch loss 0.1483, batch acc 0.9338
19:42:04.144   Training iter 400, batch loss 0.1463, batch acc 0.9356
19:42:04.324   Training iter 450, batch loss 0.1443, batch acc 0.9400
19:42:04.507   Training iter 500, batch loss 0.1396, batch acc 0.9412
19:42:04.693   Training iter 550, batch loss 0.1460, batch acc 0.9384
19:42:04.872   Training iter 600, batch loss 0.1428, batch acc 0.9394
19:42:04.873 Training @ 7 epoch...
19:42:05.071   Training iter 50, batch loss 0.1472, batch acc 0.9354
19:42:05.263   Training iter 100, batch loss 0.1351, batch acc 0.9428
19:42:05.450   Training iter 150, batch loss 0.1391, batch acc 0.9394
19:42:05.641   Training iter 200, batch loss 0.1455, batch acc 0.9380
19:42:05.830   Training iter 250, batch loss 0.1319, batch acc 0.9464
19:42:06.057   Training iter 300, batch loss 0.1357, batch acc 0.9398
19:42:06.292   Training iter 350, batch loss 0.1309, batch acc 0.9460
19:42:06.521   Training iter 400, batch loss 0.1324, batch acc 0.9436
19:42:06.770   Training iter 450, batch loss 0.1290, batch acc 0.9460
19:42:06.968   Training iter 500, batch loss 0.1308, batch acc 0.9442
19:42:07.169   Training iter 550, batch loss 0.1313, batch acc 0.9446
19:42:07.384   Training iter 600, batch loss 0.1320, batch acc 0.9424
19:42:07.386 Training @ 8 epoch...
19:42:07.591   Training iter 50, batch loss 0.1273, batch acc 0.9460
19:42:07.854   Training iter 100, batch loss 0.1293, batch acc 0.9434
19:42:08.055   Training iter 150, batch loss 0.1263, batch acc 0.9458
19:42:08.281   Training iter 200, batch loss 0.1293, batch acc 0.9440
19:42:08.474   Training iter 250, batch loss 0.1264, batch acc 0.9512
19:42:08.669   Training iter 300, batch loss 0.1211, batch acc 0.9494
19:42:08.889   Training iter 350, batch loss 0.1184, batch acc 0.9498
19:42:09.154   Training iter 400, batch loss 0.1223, batch acc 0.9510
19:42:09.442   Training iter 450, batch loss 0.1158, batch acc 0.9544
19:42:09.696   Training iter 500, batch loss 0.1311, batch acc 0.9400
19:42:09.876   Training iter 550, batch loss 0.1265, batch acc 0.9456
19:42:10.080   Training iter 600, batch loss 0.1300, batch acc 0.9440
19:42:10.082 Training @ 9 epoch...
19:42:10.256   Training iter 50, batch loss 0.1195, batch acc 0.9486
19:42:10.448   Training iter 100, batch loss 0.1236, batch acc 0.9480
19:42:10.651   Training iter 150, batch loss 0.1148, batch acc 0.9510
19:42:10.839   Training iter 200, batch loss 0.1172, batch acc 0.9522
19:42:11.020   Training iter 250, batch loss 0.1203, batch acc 0.9518
19:42:11.211   Training iter 300, batch loss 0.1145, batch acc 0.9522
19:42:11.402   Training iter 350, batch loss 0.1197, batch acc 0.9504
19:42:11.608   Training iter 400, batch loss 0.1199, batch acc 0.9490
19:42:11.833   Training iter 450, batch loss 0.1199, batch acc 0.9470
19:42:12.088   Training iter 500, batch loss 0.1179, batch acc 0.9494
19:42:12.300   Training iter 550, batch loss 0.1121, batch acc 0.9544
19:42:12.528   Training iter 600, batch loss 0.1160, batch acc 0.9524
19:42:12.529 Training @ 10 epoch...
19:42:12.723   Training iter 50, batch loss 0.1124, batch acc 0.9552
19:42:12.906   Training iter 100, batch loss 0.1185, batch acc 0.9484
19:42:13.101   Training iter 150, batch loss 0.1173, batch acc 0.9492
19:42:13.293   Training iter 200, batch loss 0.1120, batch acc 0.9534
19:42:13.487   Training iter 250, batch loss 0.1081, batch acc 0.9582
19:42:13.687   Training iter 300, batch loss 0.1138, batch acc 0.9508
19:42:13.878   Training iter 350, batch loss 0.1131, batch acc 0.9520
19:42:14.073   Training iter 400, batch loss 0.1061, batch acc 0.9566
19:42:14.267   Training iter 450, batch loss 0.1100, batch acc 0.9538
19:42:14.507   Training iter 500, batch loss 0.1155, batch acc 0.9486
19:42:14.751   Training iter 550, batch loss 0.1033, batch acc 0.9610
19:42:14.987   Training iter 600, batch loss 0.1068, batch acc 0.9540
19:42:14.988 Testing @ 10 epoch...
19:42:15.184     Testing, total mean loss 0.10740, total acc 0.95610
19:42:15.184 Training @ 11 epoch...
19:42:15.402   Training iter 50, batch loss 0.1042, batch acc 0.9588
19:42:15.606   Training iter 100, batch loss 0.1138, batch acc 0.9526
19:42:15.813   Training iter 150, batch loss 0.1120, batch acc 0.9524
19:42:16.018   Training iter 200, batch loss 0.1062, batch acc 0.9564
19:42:16.212   Training iter 250, batch loss 0.1092, batch acc 0.9538
19:42:16.401   Training iter 300, batch loss 0.1034, batch acc 0.9582
19:42:16.594   Training iter 350, batch loss 0.1027, batch acc 0.9606
19:42:16.799   Training iter 400, batch loss 0.1033, batch acc 0.9612
19:42:16.991   Training iter 450, batch loss 0.1032, batch acc 0.9588
19:42:17.212   Training iter 500, batch loss 0.1082, batch acc 0.9534
19:42:17.445   Training iter 550, batch loss 0.1013, batch acc 0.9590
19:42:17.677   Training iter 600, batch loss 0.1059, batch acc 0.9542
19:42:17.679 Training @ 12 epoch...
19:42:17.928   Training iter 50, batch loss 0.1021, batch acc 0.9568
19:42:18.179   Training iter 100, batch loss 0.1035, batch acc 0.9560
19:42:18.375   Training iter 150, batch loss 0.0997, batch acc 0.9570
19:42:18.561   Training iter 200, batch loss 0.1020, batch acc 0.9606
19:42:18.755   Training iter 250, batch loss 0.1042, batch acc 0.9546
19:42:18.958   Training iter 300, batch loss 0.1051, batch acc 0.9570
19:42:19.161   Training iter 350, batch loss 0.1052, batch acc 0.9552
19:42:19.367   Training iter 400, batch loss 0.0967, batch acc 0.9648
19:42:19.558   Training iter 450, batch loss 0.0974, batch acc 0.9622
19:42:19.750   Training iter 500, batch loss 0.1026, batch acc 0.9592
19:42:19.955   Training iter 550, batch loss 0.1056, batch acc 0.9548
19:42:20.202   Training iter 600, batch loss 0.0961, batch acc 0.9606
19:42:20.204 Training @ 13 epoch...
19:42:20.435   Training iter 50, batch loss 0.0955, batch acc 0.9620
19:42:20.712   Training iter 100, batch loss 0.0968, batch acc 0.9610
19:42:20.948   Training iter 150, batch loss 0.0993, batch acc 0.9612
19:42:21.189   Training iter 200, batch loss 0.1013, batch acc 0.9590
19:42:21.379   Training iter 250, batch loss 0.0943, batch acc 0.9658
19:42:21.572   Training iter 300, batch loss 0.1036, batch acc 0.9544
19:42:21.764   Training iter 350, batch loss 0.0978, batch acc 0.9608
19:42:21.973   Training iter 400, batch loss 0.0953, batch acc 0.9632
19:42:22.181   Training iter 450, batch loss 0.1029, batch acc 0.9558
19:42:22.379   Training iter 500, batch loss 0.0992, batch acc 0.9572
19:42:22.561   Training iter 550, batch loss 0.0995, batch acc 0.9610
19:42:22.762   Training iter 600, batch loss 0.0915, batch acc 0.9666
19:42:22.763 Training @ 14 epoch...
19:42:23.033   Training iter 50, batch loss 0.0962, batch acc 0.9600
19:42:23.281   Training iter 100, batch loss 0.0997, batch acc 0.9582
19:42:23.515   Training iter 150, batch loss 0.0894, batch acc 0.9642
19:42:23.743   Training iter 200, batch loss 0.0934, batch acc 0.9656
19:42:23.943   Training iter 250, batch loss 0.0914, batch acc 0.9650
19:42:24.138   Training iter 300, batch loss 0.0957, batch acc 0.9620
19:42:24.392   Training iter 350, batch loss 0.0952, batch acc 0.9624
19:42:24.636   Training iter 400, batch loss 0.0961, batch acc 0.9618
19:42:24.836   Training iter 450, batch loss 0.0947, batch acc 0.9620
19:42:25.071   Training iter 500, batch loss 0.0971, batch acc 0.9584
19:42:25.272   Training iter 550, batch loss 0.0931, batch acc 0.9640
19:42:25.488   Training iter 600, batch loss 0.0968, batch acc 0.9616
19:42:25.489 Training @ 15 epoch...
19:42:25.787   Training iter 50, batch loss 0.0934, batch acc 0.9634
19:42:26.088   Training iter 100, batch loss 0.0948, batch acc 0.9662
19:42:26.384   Training iter 150, batch loss 0.0923, batch acc 0.9652
19:42:26.606   Training iter 200, batch loss 0.0870, batch acc 0.9658
19:42:26.810   Training iter 250, batch loss 0.0885, batch acc 0.9642
19:42:27.007   Training iter 300, batch loss 0.0912, batch acc 0.9626
19:42:27.207   Training iter 350, batch loss 0.0966, batch acc 0.9588
19:42:27.412   Training iter 400, batch loss 0.0995, batch acc 0.9594
19:42:27.583   Training iter 450, batch loss 0.0933, batch acc 0.9634
19:42:27.774   Training iter 500, batch loss 0.0898, batch acc 0.9654
19:42:27.971   Training iter 550, batch loss 0.0911, batch acc 0.9656
19:42:28.174   Training iter 600, batch loss 0.0890, batch acc 0.9664
19:42:28.175 Testing @ 15 epoch...
19:42:28.294     Testing, total mean loss 0.09320, total acc 0.96330
19:42:28.294 Training @ 16 epoch...
19:42:28.527   Training iter 50, batch loss 0.0946, batch acc 0.9616
19:42:28.765   Training iter 100, batch loss 0.0846, batch acc 0.9690
19:42:29.016   Training iter 150, batch loss 0.0950, batch acc 0.9610
19:42:29.278   Training iter 200, batch loss 0.0866, batch acc 0.9672
19:42:29.477   Training iter 250, batch loss 0.0915, batch acc 0.9592
19:42:29.657   Training iter 300, batch loss 0.0832, batch acc 0.9698
19:42:29.855   Training iter 350, batch loss 0.0952, batch acc 0.9588
19:42:30.053   Training iter 400, batch loss 0.0890, batch acc 0.9646
19:42:30.255   Training iter 450, batch loss 0.0924, batch acc 0.9632
19:42:30.454   Training iter 500, batch loss 0.0898, batch acc 0.9656
19:42:30.658   Training iter 550, batch loss 0.0911, batch acc 0.9630
19:42:30.850   Training iter 600, batch loss 0.0853, batch acc 0.9672
19:42:30.852 Training @ 17 epoch...
19:42:31.072   Training iter 50, batch loss 0.0891, batch acc 0.9650
19:42:31.308   Training iter 100, batch loss 0.0934, batch acc 0.9620
19:42:31.573   Training iter 150, batch loss 0.0869, batch acc 0.9658
19:42:31.825   Training iter 200, batch loss 0.0874, batch acc 0.9656
19:42:32.059   Training iter 250, batch loss 0.0892, batch acc 0.9644
19:42:32.335   Training iter 300, batch loss 0.0856, batch acc 0.9658
19:42:32.522   Training iter 350, batch loss 0.0830, batch acc 0.9716
19:42:32.716   Training iter 400, batch loss 0.0900, batch acc 0.9620
19:42:32.910   Training iter 450, batch loss 0.0843, batch acc 0.9706
19:42:33.128   Training iter 500, batch loss 0.0871, batch acc 0.9666
19:42:33.318   Training iter 550, batch loss 0.0867, batch acc 0.9650
19:42:33.515   Training iter 600, batch loss 0.0909, batch acc 0.9618
19:42:33.516 Training @ 18 epoch...
19:42:33.709   Training iter 50, batch loss 0.0865, batch acc 0.9652
19:42:33.905   Training iter 100, batch loss 0.0832, batch acc 0.9696
19:42:34.113   Training iter 150, batch loss 0.0860, batch acc 0.9642
19:42:34.346   Training iter 200, batch loss 0.0851, batch acc 0.9668
19:42:34.582   Training iter 250, batch loss 0.0894, batch acc 0.9644
19:42:34.829   Training iter 300, batch loss 0.0822, batch acc 0.9694
19:42:35.095   Training iter 350, batch loss 0.0856, batch acc 0.9664
19:42:35.288   Training iter 400, batch loss 0.0857, batch acc 0.9652
19:42:35.481   Training iter 450, batch loss 0.0813, batch acc 0.9690
19:42:35.672   Training iter 500, batch loss 0.0865, batch acc 0.9652
19:42:35.866   Training iter 550, batch loss 0.0868, batch acc 0.9660
19:42:36.071   Training iter 600, batch loss 0.0885, batch acc 0.9636
19:42:36.072 Training @ 19 epoch...
19:42:36.274   Training iter 50, batch loss 0.0909, batch acc 0.9616
19:42:36.479   Training iter 100, batch loss 0.0846, batch acc 0.9704
19:42:36.669   Training iter 150, batch loss 0.0833, batch acc 0.9664
19:42:36.859   Training iter 200, batch loss 0.0832, batch acc 0.9680
19:42:37.096   Training iter 250, batch loss 0.0837, batch acc 0.9682
19:42:37.362   Training iter 300, batch loss 0.0790, batch acc 0.9734
19:42:37.631   Training iter 350, batch loss 0.0863, batch acc 0.9666
19:42:37.964   Training iter 400, batch loss 0.0848, batch acc 0.9684
19:42:38.177   Training iter 450, batch loss 0.0877, batch acc 0.9630
19:42:38.378   Training iter 500, batch loss 0.0843, batch acc 0.9674
19:42:38.595   Training iter 550, batch loss 0.0836, batch acc 0.9676
19:42:38.893   Training iter 600, batch loss 0.0818, batch acc 0.9702
19:42:38.895 Training @ 20 epoch...
19:42:39.127   Training iter 50, batch loss 0.0877, batch acc 0.9660
19:42:39.322   Training iter 100, batch loss 0.0803, batch acc 0.9702
19:42:39.523   Training iter 150, batch loss 0.0828, batch acc 0.9650
19:42:39.726   Training iter 200, batch loss 0.0796, batch acc 0.9716
19:42:39.932   Training iter 250, batch loss 0.0823, batch acc 0.9692
19:42:40.176   Training iter 300, batch loss 0.0847, batch acc 0.9686
19:42:40.408   Training iter 350, batch loss 0.0804, batch acc 0.9696
19:42:40.654   Training iter 400, batch loss 0.0821, batch acc 0.9710
19:42:40.887   Training iter 450, batch loss 0.0844, batch acc 0.9658
19:42:41.087   Training iter 500, batch loss 0.0784, batch acc 0.9676
19:42:41.326   Training iter 550, batch loss 0.0844, batch acc 0.9652
19:42:41.534   Training iter 600, batch loss 0.0838, batch acc 0.9686
19:42:41.534 Testing @ 20 epoch...
19:42:41.658     Testing, total mean loss 0.08508, total acc 0.96750
19:42:41.658 Training @ 21 epoch...
19:42:41.853   Training iter 50, batch loss 0.0804, batch acc 0.9688
19:42:42.071   Training iter 100, batch loss 0.0785, batch acc 0.9692
19:42:42.273   Training iter 150, batch loss 0.0837, batch acc 0.9684
19:42:42.478   Training iter 200, batch loss 0.0817, batch acc 0.9696
19:42:42.673   Training iter 250, batch loss 0.0808, batch acc 0.9694
19:42:42.885   Training iter 300, batch loss 0.0780, batch acc 0.9694
19:42:43.212   Training iter 350, batch loss 0.0825, batch acc 0.9690
19:42:43.492   Training iter 400, batch loss 0.0799, batch acc 0.9696
19:42:43.734   Training iter 450, batch loss 0.0806, batch acc 0.9688
19:42:43.937   Training iter 500, batch loss 0.0827, batch acc 0.9676
19:42:44.153   Training iter 550, batch loss 0.0830, batch acc 0.9664
19:42:44.351   Training iter 600, batch loss 0.0815, batch acc 0.9688
19:42:44.351 Training @ 22 epoch...
19:42:44.546   Training iter 50, batch loss 0.0781, batch acc 0.9686
19:42:44.737   Training iter 100, batch loss 0.0815, batch acc 0.9666
19:42:44.949   Training iter 150, batch loss 0.0799, batch acc 0.9676
19:42:45.153   Training iter 200, batch loss 0.0756, batch acc 0.9720
19:42:45.357   Training iter 250, batch loss 0.0807, batch acc 0.9672
19:42:45.570   Training iter 300, batch loss 0.0761, batch acc 0.9754
19:42:45.812   Training iter 350, batch loss 0.0811, batch acc 0.9688
19:42:46.059   Training iter 400, batch loss 0.0818, batch acc 0.9678
19:42:46.322   Training iter 450, batch loss 0.0800, batch acc 0.9710
19:42:46.576   Training iter 500, batch loss 0.0788, batch acc 0.9716
19:42:46.779   Training iter 550, batch loss 0.0843, batch acc 0.9676
19:42:46.986   Training iter 600, batch loss 0.0793, batch acc 0.9698
19:42:46.987 Training @ 23 epoch...
19:42:47.188   Training iter 50, batch loss 0.0792, batch acc 0.9710
19:42:47.389   Training iter 100, batch loss 0.0753, batch acc 0.9722
19:42:47.590   Training iter 150, batch loss 0.0818, batch acc 0.9674
19:42:47.779   Training iter 200, batch loss 0.0802, batch acc 0.9692
19:42:47.973   Training iter 250, batch loss 0.0776, batch acc 0.9716
19:42:48.187   Training iter 300, batch loss 0.0776, batch acc 0.9710
19:42:48.385   Training iter 350, batch loss 0.0808, batch acc 0.9690
19:42:48.598   Training iter 400, batch loss 0.0833, batch acc 0.9656
19:42:48.838   Training iter 450, batch loss 0.0770, batch acc 0.9700
19:42:49.085   Training iter 500, batch loss 0.0787, batch acc 0.9714
19:42:49.334   Training iter 550, batch loss 0.0747, batch acc 0.9714
19:42:49.544   Training iter 600, batch loss 0.0741, batch acc 0.9754
19:42:49.545 Training @ 24 epoch...
19:42:49.741   Training iter 50, batch loss 0.0748, batch acc 0.9712
19:42:49.943   Training iter 100, batch loss 0.0769, batch acc 0.9704
19:42:50.152   Training iter 150, batch loss 0.0806, batch acc 0.9684
19:42:50.342   Training iter 200, batch loss 0.0810, batch acc 0.9714
19:42:50.553   Training iter 250, batch loss 0.0794, batch acc 0.9706
19:42:50.751   Training iter 300, batch loss 0.0797, batch acc 0.9684
19:42:50.944   Training iter 350, batch loss 0.0732, batch acc 0.9748
19:42:51.166   Training iter 400, batch loss 0.0776, batch acc 0.9744
19:42:51.382   Training iter 450, batch loss 0.0774, batch acc 0.9732
19:42:51.622   Training iter 500, batch loss 0.0776, batch acc 0.9676
19:42:51.866   Training iter 550, batch loss 0.0773, batch acc 0.9714
19:42:52.125   Training iter 600, batch loss 0.0750, batch acc 0.9714
19:42:52.126 Training @ 25 epoch...
19:42:52.345   Training iter 50, batch loss 0.0726, batch acc 0.9716
19:42:52.547   Training iter 100, batch loss 0.0779, batch acc 0.9706
19:42:52.742   Training iter 150, batch loss 0.0746, batch acc 0.9746
19:42:52.949   Training iter 200, batch loss 0.0793, batch acc 0.9708
19:42:53.160   Training iter 250, batch loss 0.0761, batch acc 0.9706
19:42:53.355   Training iter 300, batch loss 0.0749, batch acc 0.9732
19:42:53.562   Training iter 350, batch loss 0.0792, batch acc 0.9690
19:42:53.765   Training iter 400, batch loss 0.0754, batch acc 0.9710
19:42:53.955   Training iter 450, batch loss 0.0702, batch acc 0.9768
19:42:54.177   Training iter 500, batch loss 0.0810, batch acc 0.9676
19:42:54.422   Training iter 550, batch loss 0.0800, batch acc 0.9672
19:42:54.635   Training iter 600, batch loss 0.0771, batch acc 0.9716
19:42:54.635 Testing @ 25 epoch...
19:42:54.785     Testing, total mean loss 0.08030, total acc 0.97030
19:42:54.785 Training @ 26 epoch...
19:42:55.098   Training iter 50, batch loss 0.0710, batch acc 0.9770
19:42:55.313   Training iter 100, batch loss 0.0698, batch acc 0.9770
19:42:55.568   Training iter 150, batch loss 0.0774, batch acc 0.9702
19:42:55.791   Training iter 200, batch loss 0.0766, batch acc 0.9718
19:42:56.018   Training iter 250, batch loss 0.0725, batch acc 0.9710
19:42:56.214   Training iter 300, batch loss 0.0779, batch acc 0.9686
19:42:56.411   Training iter 350, batch loss 0.0768, batch acc 0.9714
19:42:56.614   Training iter 400, batch loss 0.0782, batch acc 0.9682
19:42:56.812   Training iter 450, batch loss 0.0757, batch acc 0.9714
19:42:57.012   Training iter 500, batch loss 0.0749, batch acc 0.9726
19:42:57.259   Training iter 550, batch loss 0.0761, batch acc 0.9728
19:42:57.499   Training iter 600, batch loss 0.0796, batch acc 0.9680
19:42:57.501 Training @ 27 epoch...
19:42:57.765   Training iter 50, batch loss 0.0778, batch acc 0.9708
19:42:58.009   Training iter 100, batch loss 0.0762, batch acc 0.9710
19:42:58.218   Training iter 150, batch loss 0.0708, batch acc 0.9752
19:42:58.419   Training iter 200, batch loss 0.0734, batch acc 0.9724
19:42:58.617   Training iter 250, batch loss 0.0751, batch acc 0.9728
19:42:58.816   Training iter 300, batch loss 0.0736, batch acc 0.9708
19:42:59.024   Training iter 350, batch loss 0.0743, batch acc 0.9748
19:42:59.234   Training iter 400, batch loss 0.0776, batch acc 0.9716
19:42:59.431   Training iter 450, batch loss 0.0751, batch acc 0.9718
19:42:59.633   Training iter 500, batch loss 0.0729, batch acc 0.9734
19:42:59.828   Training iter 550, batch loss 0.0742, batch acc 0.9728
19:43:00.086   Training iter 600, batch loss 0.0734, batch acc 0.9732
19:43:00.086 Training @ 28 epoch...
19:43:00.341   Training iter 50, batch loss 0.0684, batch acc 0.9740
19:43:00.577   Training iter 100, batch loss 0.0775, batch acc 0.9690
19:43:00.840   Training iter 150, batch loss 0.0742, batch acc 0.9746
19:43:01.051   Training iter 200, batch loss 0.0703, batch acc 0.9782
19:43:01.252   Training iter 250, batch loss 0.0742, batch acc 0.9738
19:43:01.451   Training iter 300, batch loss 0.0752, batch acc 0.9698
19:43:01.655   Training iter 350, batch loss 0.0753, batch acc 0.9698
19:43:01.859   Training iter 400, batch loss 0.0744, batch acc 0.9760
19:43:02.062   Training iter 450, batch loss 0.0742, batch acc 0.9720
19:43:02.261   Training iter 500, batch loss 0.0716, batch acc 0.9754
19:43:02.466   Training iter 550, batch loss 0.0765, batch acc 0.9718
19:43:02.656   Training iter 600, batch loss 0.0726, batch acc 0.9748
19:43:02.658 Training @ 29 epoch...
19:43:02.916   Training iter 50, batch loss 0.0716, batch acc 0.9740
19:43:03.177   Training iter 100, batch loss 0.0729, batch acc 0.9762
19:43:03.414   Training iter 150, batch loss 0.0765, batch acc 0.9720
19:43:03.660   Training iter 200, batch loss 0.0746, batch acc 0.9708
19:43:03.859   Training iter 250, batch loss 0.0737, batch acc 0.9712
19:43:04.069   Training iter 300, batch loss 0.0751, batch acc 0.9736
19:43:04.277   Training iter 350, batch loss 0.0695, batch acc 0.9766
19:43:04.471   Training iter 400, batch loss 0.0710, batch acc 0.9748
19:43:04.667   Training iter 450, batch loss 0.0738, batch acc 0.9748
19:43:04.873   Training iter 500, batch loss 0.0717, batch acc 0.9758
19:43:05.078   Training iter 550, batch loss 0.0720, batch acc 0.9732
19:43:05.273   Training iter 600, batch loss 0.0737, batch acc 0.9728
19:43:05.274 Training @ 30 epoch...
19:43:05.474   Training iter 50, batch loss 0.0715, batch acc 0.9746
19:43:05.719   Training iter 100, batch loss 0.0736, batch acc 0.9744
19:43:05.976   Training iter 150, batch loss 0.0741, batch acc 0.9728
19:43:06.217   Training iter 200, batch loss 0.0703, batch acc 0.9764
19:43:06.449   Training iter 250, batch loss 0.0729, batch acc 0.9732
19:43:06.649   Training iter 300, batch loss 0.0682, batch acc 0.9762
19:43:06.848   Training iter 350, batch loss 0.0651, batch acc 0.9772
19:43:07.050   Training iter 400, batch loss 0.0728, batch acc 0.9720
19:43:07.259   Training iter 450, batch loss 0.0729, batch acc 0.9730
19:43:07.486   Training iter 500, batch loss 0.0744, batch acc 0.9736
19:43:07.693   Training iter 550, batch loss 0.0744, batch acc 0.9720
19:43:08.019   Training iter 600, batch loss 0.0712, batch acc 0.9746
19:43:08.021 Testing @ 30 epoch...
19:43:08.125     Testing, total mean loss 0.07524, total acc 0.97210
19:43:08.125 Training @ 31 epoch...
19:43:08.344   Training iter 50, batch loss 0.0734, batch acc 0.9730
19:43:08.636   Training iter 100, batch loss 0.0744, batch acc 0.9724
19:43:08.883   Training iter 150, batch loss 0.0736, batch acc 0.9730
19:43:09.112   Training iter 200, batch loss 0.0714, batch acc 0.9758
19:43:09.343   Training iter 250, batch loss 0.0693, batch acc 0.9772
19:43:09.529   Training iter 300, batch loss 0.0705, batch acc 0.9736
19:43:09.717   Training iter 350, batch loss 0.0693, batch acc 0.9742
19:43:09.929   Training iter 400, batch loss 0.0721, batch acc 0.9740
19:43:10.130   Training iter 450, batch loss 0.0687, batch acc 0.9760
19:43:10.335   Training iter 500, batch loss 0.0688, batch acc 0.9760
19:43:10.532   Training iter 550, batch loss 0.0724, batch acc 0.9714
19:43:10.738   Training iter 600, batch loss 0.0726, batch acc 0.9736
19:43:10.739 Training @ 32 epoch...
19:43:10.944   Training iter 50, batch loss 0.0695, batch acc 0.9754
19:43:11.161   Training iter 100, batch loss 0.0706, batch acc 0.9760
19:43:11.377   Training iter 150, batch loss 0.0746, batch acc 0.9694
19:43:11.605   Training iter 200, batch loss 0.0718, batch acc 0.9742
19:43:11.845   Training iter 250, batch loss 0.0689, batch acc 0.9754
19:43:12.114   Training iter 300, batch loss 0.0735, batch acc 0.9726
19:43:12.314   Training iter 350, batch loss 0.0665, batch acc 0.9758
19:43:12.506   Training iter 400, batch loss 0.0696, batch acc 0.9788
19:43:12.707   Training iter 450, batch loss 0.0718, batch acc 0.9746
19:43:12.911   Training iter 500, batch loss 0.0723, batch acc 0.9734
19:43:13.111   Training iter 550, batch loss 0.0702, batch acc 0.9746
19:43:13.300   Training iter 600, batch loss 0.0687, batch acc 0.9770
19:43:13.301 Training @ 33 epoch...
19:43:13.494   Training iter 50, batch loss 0.0724, batch acc 0.9738
19:43:13.711   Training iter 100, batch loss 0.0713, batch acc 0.9744
19:43:13.908   Training iter 150, batch loss 0.0675, batch acc 0.9772
19:43:14.128   Training iter 200, batch loss 0.0678, batch acc 0.9780
19:43:14.393   Training iter 250, batch loss 0.0728, batch acc 0.9724
19:43:14.657   Training iter 300, batch loss 0.0710, batch acc 0.9736
19:43:14.917   Training iter 350, batch loss 0.0731, batch acc 0.9748
19:43:15.139   Training iter 400, batch loss 0.0689, batch acc 0.9754
19:43:15.349   Training iter 450, batch loss 0.0695, batch acc 0.9758
19:43:15.554   Training iter 500, batch loss 0.0695, batch acc 0.9752
19:43:15.751   Training iter 550, batch loss 0.0670, batch acc 0.9760
19:43:15.948   Training iter 600, batch loss 0.0688, batch acc 0.9752
19:43:15.950 Training @ 34 epoch...
19:43:16.153   Training iter 50, batch loss 0.0689, batch acc 0.9766
19:43:16.356   Training iter 100, batch loss 0.0681, batch acc 0.9772
19:43:16.559   Training iter 150, batch loss 0.0681, batch acc 0.9766
19:43:16.762   Training iter 200, batch loss 0.0690, batch acc 0.9766
19:43:16.990   Training iter 250, batch loss 0.0672, batch acc 0.9786
19:43:17.245   Training iter 300, batch loss 0.0691, batch acc 0.9764
19:43:17.489   Training iter 350, batch loss 0.0734, batch acc 0.9736
19:43:17.737   Training iter 400, batch loss 0.0729, batch acc 0.9736
19:43:17.973   Training iter 450, batch loss 0.0695, batch acc 0.9760
19:43:18.181   Training iter 500, batch loss 0.0676, batch acc 0.9758
19:43:18.377   Training iter 550, batch loss 0.0690, batch acc 0.9746
19:43:18.569   Training iter 600, batch loss 0.0700, batch acc 0.9736
19:43:18.569 Training @ 35 epoch...
19:43:18.774   Training iter 50, batch loss 0.0671, batch acc 0.9774
19:43:18.975   Training iter 100, batch loss 0.0677, batch acc 0.9774
19:43:19.184   Training iter 150, batch loss 0.0642, batch acc 0.9792
19:43:19.380   Training iter 200, batch loss 0.0666, batch acc 0.9780
19:43:19.579   Training iter 250, batch loss 0.0664, batch acc 0.9774
19:43:19.782   Training iter 300, batch loss 0.0691, batch acc 0.9772
19:43:20.031   Training iter 350, batch loss 0.0688, batch acc 0.9766
19:43:20.274   Training iter 400, batch loss 0.0701, batch acc 0.9728
19:43:20.522   Training iter 450, batch loss 0.0707, batch acc 0.9732
19:43:20.760   Training iter 500, batch loss 0.0711, batch acc 0.9724
19:43:20.961   Training iter 550, batch loss 0.0705, batch acc 0.9750
19:43:21.163   Training iter 600, batch loss 0.0708, batch acc 0.9760
19:43:21.165 Testing @ 35 epoch...
19:43:21.305     Testing, total mean loss 0.07275, total acc 0.97380
19:43:21.305 Training @ 36 epoch...
19:43:21.512   Training iter 50, batch loss 0.0668, batch acc 0.9772
19:43:21.710   Training iter 100, batch loss 0.0688, batch acc 0.9760
19:43:21.990   Training iter 150, batch loss 0.0682, batch acc 0.9754
19:43:22.192   Training iter 200, batch loss 0.0673, batch acc 0.9790
19:43:22.386   Training iter 250, batch loss 0.0701, batch acc 0.9724
19:43:22.595   Training iter 300, batch loss 0.0660, batch acc 0.9774
19:43:22.810   Training iter 350, batch loss 0.0659, batch acc 0.9762
19:43:23.057   Training iter 400, batch loss 0.0668, batch acc 0.9784
19:43:23.307   Training iter 450, batch loss 0.0666, batch acc 0.9796
19:43:23.551   Training iter 500, batch loss 0.0700, batch acc 0.9754
19:43:23.792   Training iter 550, batch loss 0.0699, batch acc 0.9736
19:43:23.999   Training iter 600, batch loss 0.0675, batch acc 0.9774
19:43:24.000 Training @ 37 epoch...
19:43:24.216   Training iter 50, batch loss 0.0690, batch acc 0.9744
19:43:24.415   Training iter 100, batch loss 0.0674, batch acc 0.9764
19:43:24.614   Training iter 150, batch loss 0.0638, batch acc 0.9772
19:43:24.813   Training iter 200, batch loss 0.0701, batch acc 0.9754
19:43:25.029   Training iter 250, batch loss 0.0660, batch acc 0.9796
19:43:25.408   Training iter 300, batch loss 0.0679, batch acc 0.9754
19:43:25.755   Training iter 350, batch loss 0.0673, batch acc 0.9786
19:43:26.098   Training iter 400, batch loss 0.0693, batch acc 0.9754
19:43:26.356   Training iter 450, batch loss 0.0663, batch acc 0.9774
19:43:26.629   Training iter 500, batch loss 0.0694, batch acc 0.9740
19:43:26.836   Training iter 550, batch loss 0.0657, batch acc 0.9796
19:43:27.054   Training iter 600, batch loss 0.0689, batch acc 0.9768
19:43:27.055 Training @ 38 epoch...
19:43:27.315   Training iter 50, batch loss 0.0664, batch acc 0.9778
19:43:27.523   Training iter 100, batch loss 0.0632, batch acc 0.9796
19:43:27.808   Training iter 150, batch loss 0.0663, batch acc 0.9764
19:43:28.038   Training iter 200, batch loss 0.0645, batch acc 0.9796
19:43:28.239   Training iter 250, batch loss 0.0674, batch acc 0.9748
19:43:28.432   Training iter 300, batch loss 0.0641, batch acc 0.9796
19:43:28.683   Training iter 350, batch loss 0.0686, batch acc 0.9758
19:43:28.952   Training iter 400, batch loss 0.0646, batch acc 0.9784
19:43:29.208   Training iter 450, batch loss 0.0697, batch acc 0.9756
19:43:29.438   Training iter 500, batch loss 0.0671, batch acc 0.9776
19:43:29.643   Training iter 550, batch loss 0.0723, batch acc 0.9740
19:43:29.929   Training iter 600, batch loss 0.0648, batch acc 0.9764
19:43:29.931 Training @ 39 epoch...
19:43:30.179   Training iter 50, batch loss 0.0671, batch acc 0.9762
19:43:30.406   Training iter 100, batch loss 0.0650, batch acc 0.9772
19:43:30.645   Training iter 150, batch loss 0.0622, batch acc 0.9794
19:43:30.845   Training iter 200, batch loss 0.0634, batch acc 0.9782
19:43:31.053   Training iter 250, batch loss 0.0662, batch acc 0.9782
19:43:31.255   Training iter 300, batch loss 0.0672, batch acc 0.9790
19:43:31.499   Training iter 350, batch loss 0.0660, batch acc 0.9776
19:43:31.759   Training iter 400, batch loss 0.0647, batch acc 0.9772
19:43:32.080   Training iter 450, batch loss 0.0673, batch acc 0.9748
19:43:32.283   Training iter 500, batch loss 0.0657, batch acc 0.9792
19:43:32.493   Training iter 550, batch loss 0.0676, batch acc 0.9760
19:43:32.696   Training iter 600, batch loss 0.0716, batch acc 0.9728
19:43:32.698 Training @ 40 epoch...
19:43:32.896   Training iter 50, batch loss 0.0636, batch acc 0.9804
19:43:33.109   Training iter 100, batch loss 0.0636, batch acc 0.9786
19:43:33.317   Training iter 150, batch loss 0.0650, batch acc 0.9802
19:43:33.530   Training iter 200, batch loss 0.0650, batch acc 0.9766
19:43:33.721   Training iter 250, batch loss 0.0663, batch acc 0.9764
19:43:33.903   Training iter 300, batch loss 0.0676, batch acc 0.9768
19:43:34.125   Training iter 350, batch loss 0.0683, batch acc 0.9746
19:43:34.361   Training iter 400, batch loss 0.0658, batch acc 0.9772
19:43:34.606   Training iter 450, batch loss 0.0632, batch acc 0.9792
19:43:34.860   Training iter 500, batch loss 0.0668, batch acc 0.9784
19:43:35.110   Training iter 550, batch loss 0.0651, batch acc 0.9790
19:43:35.318   Training iter 600, batch loss 0.0689, batch acc 0.9762
19:43:35.320 Testing @ 40 epoch...
19:43:35.436     Testing, total mean loss 0.07248, total acc 0.97420
19:43:35.437 Training @ 41 epoch...
19:43:35.663   Training iter 50, batch loss 0.0639, batch acc 0.9810
19:43:35.870   Training iter 100, batch loss 0.0631, batch acc 0.9802
19:43:36.074   Training iter 150, batch loss 0.0648, batch acc 0.9784
19:43:36.279   Training iter 200, batch loss 0.0653, batch acc 0.9766
19:43:36.492   Training iter 250, batch loss 0.0649, batch acc 0.9794
19:43:36.684   Training iter 300, batch loss 0.0672, batch acc 0.9804
19:43:36.885   Training iter 350, batch loss 0.0648, batch acc 0.9778
19:43:37.109   Training iter 400, batch loss 0.0665, batch acc 0.9746
19:43:37.375   Training iter 450, batch loss 0.0681, batch acc 0.9738
19:43:37.636   Training iter 500, batch loss 0.0661, batch acc 0.9764
19:43:37.969   Training iter 550, batch loss 0.0638, batch acc 0.9780
19:43:38.181   Training iter 600, batch loss 0.0676, batch acc 0.9784
19:43:38.183 Training @ 42 epoch...
19:43:38.416   Training iter 50, batch loss 0.0625, batch acc 0.9784
19:43:38.643   Training iter 100, batch loss 0.0608, batch acc 0.9800
19:43:38.865   Training iter 150, batch loss 0.0659, batch acc 0.9768
19:43:39.105   Training iter 200, batch loss 0.0640, batch acc 0.9780
19:43:39.372   Training iter 250, batch loss 0.0643, batch acc 0.9792
19:43:39.573   Training iter 300, batch loss 0.0662, batch acc 0.9768
19:43:39.770   Training iter 350, batch loss 0.0639, batch acc 0.9788
19:43:39.990   Training iter 400, batch loss 0.0688, batch acc 0.9770
19:43:40.242   Training iter 450, batch loss 0.0664, batch acc 0.9772
19:43:40.480   Training iter 500, batch loss 0.0645, batch acc 0.9784
19:43:40.742   Training iter 550, batch loss 0.0659, batch acc 0.9770
19:43:40.969   Training iter 600, batch loss 0.0646, batch acc 0.9782
19:43:40.970 Training @ 43 epoch...
19:43:41.175   Training iter 50, batch loss 0.0676, batch acc 0.9744
19:43:41.381   Training iter 100, batch loss 0.0626, batch acc 0.9806
19:43:41.582   Training iter 150, batch loss 0.0636, batch acc 0.9784
19:43:41.786   Training iter 200, batch loss 0.0650, batch acc 0.9780
19:43:42.002   Training iter 250, batch loss 0.0637, batch acc 0.9810
19:43:42.225   Training iter 300, batch loss 0.0612, batch acc 0.9794
19:43:42.435   Training iter 350, batch loss 0.0647, batch acc 0.9770
19:43:42.645   Training iter 400, batch loss 0.0644, batch acc 0.9790
19:43:42.857   Training iter 450, batch loss 0.0627, batch acc 0.9790
19:43:43.102   Training iter 500, batch loss 0.0631, batch acc 0.9800
19:43:43.342   Training iter 550, batch loss 0.0669, batch acc 0.9770
19:43:43.578   Training iter 600, batch loss 0.0710, batch acc 0.9760
19:43:43.581 Training @ 44 epoch...
19:43:43.829   Training iter 50, batch loss 0.0602, batch acc 0.9830
19:43:44.023   Training iter 100, batch loss 0.0629, batch acc 0.9804
19:43:44.258   Training iter 150, batch loss 0.0649, batch acc 0.9776
19:43:44.464   Training iter 200, batch loss 0.0625, batch acc 0.9802
19:43:44.674   Training iter 250, batch loss 0.0652, batch acc 0.9766
19:43:44.869   Training iter 300, batch loss 0.0626, batch acc 0.9800
19:43:45.080   Training iter 350, batch loss 0.0662, batch acc 0.9762
19:43:45.277   Training iter 400, batch loss 0.0634, batch acc 0.9784
19:43:45.467   Training iter 450, batch loss 0.0652, batch acc 0.9780
19:43:45.668   Training iter 500, batch loss 0.0665, batch acc 0.9766
19:43:45.916   Training iter 550, batch loss 0.0652, batch acc 0.9766
19:43:46.159   Training iter 600, batch loss 0.0649, batch acc 0.9774
19:43:46.160 Training @ 45 epoch...
19:43:46.408   Training iter 50, batch loss 0.0640, batch acc 0.9788
19:43:46.673   Training iter 100, batch loss 0.0637, batch acc 0.9796
19:43:46.866   Training iter 150, batch loss 0.0625, batch acc 0.9770
19:43:47.055   Training iter 200, batch loss 0.0633, batch acc 0.9802
19:43:47.246   Training iter 250, batch loss 0.0632, batch acc 0.9790
19:43:47.426   Training iter 300, batch loss 0.0629, batch acc 0.9802
19:43:47.626   Training iter 350, batch loss 0.0590, batch acc 0.9832
19:43:47.826   Training iter 400, batch loss 0.0616, batch acc 0.9806
19:43:48.013   Training iter 450, batch loss 0.0677, batch acc 0.9770
19:43:48.224   Training iter 500, batch loss 0.0710, batch acc 0.9724
19:43:48.427   Training iter 550, batch loss 0.0632, batch acc 0.9802
19:43:48.649   Training iter 600, batch loss 0.0642, batch acc 0.9776
19:43:48.650 Testing @ 45 epoch...
19:43:48.811     Testing, total mean loss 0.07045, total acc 0.97490
19:43:48.811 Training @ 46 epoch...
19:43:49.065   Training iter 50, batch loss 0.0599, batch acc 0.9812
19:43:49.295   Training iter 100, batch loss 0.0629, batch acc 0.9782
19:43:49.548   Training iter 150, batch loss 0.0661, batch acc 0.9766
19:43:49.752   Training iter 200, batch loss 0.0614, batch acc 0.9796
19:43:49.963   Training iter 250, batch loss 0.0612, batch acc 0.9818
19:43:50.183   Training iter 300, batch loss 0.0636, batch acc 0.9820
19:43:50.380   Training iter 350, batch loss 0.0647, batch acc 0.9784
19:43:50.572   Training iter 400, batch loss 0.0645, batch acc 0.9784
19:43:50.770   Training iter 450, batch loss 0.0666, batch acc 0.9746
19:43:50.970   Training iter 500, batch loss 0.0605, batch acc 0.9806
19:43:51.184   Training iter 550, batch loss 0.0657, batch acc 0.9784
19:43:51.391   Training iter 600, batch loss 0.0623, batch acc 0.9792
19:43:51.392 Training @ 47 epoch...
19:43:51.611   Training iter 50, batch loss 0.0593, batch acc 0.9810
19:43:51.866   Training iter 100, batch loss 0.0631, batch acc 0.9792
19:43:52.110   Training iter 150, batch loss 0.0611, batch acc 0.9798
19:43:52.358   Training iter 200, batch loss 0.0633, batch acc 0.9778
19:43:52.597   Training iter 250, batch loss 0.0629, batch acc 0.9788
19:43:52.803   Training iter 300, batch loss 0.0638, batch acc 0.9792
19:43:53.024   Training iter 350, batch loss 0.0628, batch acc 0.9788
19:43:53.226   Training iter 400, batch loss 0.0657, batch acc 0.9780
19:43:53.434   Training iter 450, batch loss 0.0656, batch acc 0.9788
19:43:53.631   Training iter 500, batch loss 0.0620, batch acc 0.9812
19:43:53.840   Training iter 550, batch loss 0.0652, batch acc 0.9772
19:43:54.046   Training iter 600, batch loss 0.0631, batch acc 0.9786
19:43:54.047 Training @ 48 epoch...
19:43:54.260   Training iter 50, batch loss 0.0612, batch acc 0.9804
19:43:54.476   Training iter 100, batch loss 0.0587, batch acc 0.9812
19:43:54.711   Training iter 150, batch loss 0.0635, batch acc 0.9778
19:43:54.973   Training iter 200, batch loss 0.0614, batch acc 0.9790
19:43:55.238   Training iter 250, batch loss 0.0640, batch acc 0.9776
19:43:55.455   Training iter 300, batch loss 0.0661, batch acc 0.9788
19:43:55.661   Training iter 350, batch loss 0.0620, batch acc 0.9788
19:43:55.862   Training iter 400, batch loss 0.0631, batch acc 0.9774
19:43:56.074   Training iter 450, batch loss 0.0638, batch acc 0.9776
19:43:56.270   Training iter 500, batch loss 0.0662, batch acc 0.9790
19:43:56.468   Training iter 550, batch loss 0.0635, batch acc 0.9798
19:43:56.664   Training iter 600, batch loss 0.0592, batch acc 0.9804
19:43:56.665 Training @ 49 epoch...
19:43:56.865   Training iter 50, batch loss 0.0603, batch acc 0.9802
19:43:57.070   Training iter 100, batch loss 0.0600, batch acc 0.9826
19:43:57.273   Training iter 150, batch loss 0.0613, batch acc 0.9800
19:43:57.484   Training iter 200, batch loss 0.0645, batch acc 0.9758
19:43:57.708   Training iter 250, batch loss 0.0642, batch acc 0.9776
19:43:57.971   Training iter 300, batch loss 0.0586, batch acc 0.9818
19:43:58.217   Training iter 350, batch loss 0.0630, batch acc 0.9814
19:43:58.417   Training iter 400, batch loss 0.0647, batch acc 0.9762
19:43:58.616   Training iter 450, batch loss 0.0626, batch acc 0.9800
19:43:58.815   Training iter 500, batch loss 0.0608, batch acc 0.9804
19:43:59.012   Training iter 550, batch loss 0.0620, batch acc 0.9784
19:43:59.214   Training iter 600, batch loss 0.0655, batch acc 0.9782
19:43:59.214 Training @ 50 epoch...
19:43:59.416   Training iter 50, batch loss 0.0619, batch acc 0.9798
19:43:59.618   Training iter 100, batch loss 0.0641, batch acc 0.9800
19:43:59.872   Training iter 150, batch loss 0.0600, batch acc 0.9812
19:44:00.085   Training iter 200, batch loss 0.0600, batch acc 0.9800
19:44:00.302   Training iter 250, batch loss 0.0585, batch acc 0.9812
19:44:00.540   Training iter 300, batch loss 0.0596, batch acc 0.9794
19:44:00.789   Training iter 350, batch loss 0.0666, batch acc 0.9784
19:44:01.025   Training iter 400, batch loss 0.0613, batch acc 0.9796
19:44:01.258   Training iter 450, batch loss 0.0632, batch acc 0.9794
19:44:01.470   Training iter 500, batch loss 0.0586, batch acc 0.9818
19:44:01.670   Training iter 550, batch loss 0.0650, batch acc 0.9798
19:44:01.863   Training iter 600, batch loss 0.0662, batch acc 0.9750
19:44:01.864 Testing @ 50 epoch...
19:44:01.986     Testing, total mean loss 0.07023, total acc 0.97510
19:44:01.986 Training @ 51 epoch...
19:44:02.189   Training iter 50, batch loss 0.0574, batch acc 0.9858
19:44:02.400   Training iter 100, batch loss 0.0609, batch acc 0.9802
19:44:02.601   Training iter 150, batch loss 0.0642, batch acc 0.9758
19:44:02.809   Training iter 200, batch loss 0.0591, batch acc 0.9814
19:44:03.010   Training iter 250, batch loss 0.0596, batch acc 0.9810
19:44:03.289   Training iter 300, batch loss 0.0597, batch acc 0.9812
19:44:03.526   Training iter 350, batch loss 0.0621, batch acc 0.9810
19:44:03.787   Training iter 400, batch loss 0.0625, batch acc 0.9792
19:44:04.045   Training iter 450, batch loss 0.0674, batch acc 0.9752
19:44:04.246   Training iter 500, batch loss 0.0625, batch acc 0.9802
19:44:04.444   Training iter 550, batch loss 0.0630, batch acc 0.9790
19:44:04.649   Training iter 600, batch loss 0.0596, batch acc 0.9804
19:44:04.650 Training @ 52 epoch...
19:44:04.859   Training iter 50, batch loss 0.0614, batch acc 0.9804
19:44:05.069   Training iter 100, batch loss 0.0626, batch acc 0.9796
19:44:05.277   Training iter 150, batch loss 0.0601, batch acc 0.9794
19:44:05.474   Training iter 200, batch loss 0.0633, batch acc 0.9794
19:44:05.678   Training iter 250, batch loss 0.0584, batch acc 0.9840
19:44:05.875   Training iter 300, batch loss 0.0610, batch acc 0.9800
19:44:06.115   Training iter 350, batch loss 0.0616, batch acc 0.9818
19:44:06.359   Training iter 400, batch loss 0.0578, batch acc 0.9804
19:44:06.595   Training iter 450, batch loss 0.0625, batch acc 0.9798
19:44:06.864   Training iter 500, batch loss 0.0639, batch acc 0.9790
19:44:07.064   Training iter 550, batch loss 0.0607, batch acc 0.9810
19:44:07.292   Training iter 600, batch loss 0.0614, batch acc 0.9812
19:44:07.293 Training @ 53 epoch...
19:44:07.537   Training iter 50, batch loss 0.0596, batch acc 0.9818
19:44:07.785   Training iter 100, batch loss 0.0569, batch acc 0.9852
19:44:08.004   Training iter 150, batch loss 0.0608, batch acc 0.9806
19:44:08.238   Training iter 200, batch loss 0.0636, batch acc 0.9782
19:44:08.427   Training iter 250, batch loss 0.0610, batch acc 0.9800
19:44:08.632   Training iter 300, batch loss 0.0616, batch acc 0.9796
19:44:08.888   Training iter 350, batch loss 0.0614, batch acc 0.9802
19:44:09.133   Training iter 400, batch loss 0.0651, batch acc 0.9780
19:44:09.346   Training iter 450, batch loss 0.0633, batch acc 0.9776
19:44:09.546   Training iter 500, batch loss 0.0581, batch acc 0.9840
19:44:09.795   Training iter 550, batch loss 0.0616, batch acc 0.9794
19:44:10.003   Training iter 600, batch loss 0.0629, batch acc 0.9804
19:44:10.003 Training @ 54 epoch...
19:44:10.201   Training iter 50, batch loss 0.0608, batch acc 0.9814
19:44:10.408   Training iter 100, batch loss 0.0597, batch acc 0.9806
19:44:10.610   Training iter 150, batch loss 0.0585, batch acc 0.9806
19:44:10.819   Training iter 200, batch loss 0.0573, batch acc 0.9822
19:44:11.033   Training iter 250, batch loss 0.0611, batch acc 0.9806
19:44:11.229   Training iter 300, batch loss 0.0610, batch acc 0.9804
19:44:11.422   Training iter 350, batch loss 0.0627, batch acc 0.9778
19:44:11.623   Training iter 400, batch loss 0.0583, batch acc 0.9812
19:44:11.845   Training iter 450, batch loss 0.0643, batch acc 0.9776
19:44:12.082   Training iter 500, batch loss 0.0598, batch acc 0.9828
19:44:12.306   Training iter 550, batch loss 0.0601, batch acc 0.9792
19:44:12.535   Training iter 600, batch loss 0.0620, batch acc 0.9796
19:44:12.536 Training @ 55 epoch...
19:44:12.791   Training iter 50, batch loss 0.0569, batch acc 0.9824
19:44:13.008   Training iter 100, batch loss 0.0582, batch acc 0.9816
19:44:13.209   Training iter 150, batch loss 0.0622, batch acc 0.9772
19:44:13.404   Training iter 200, batch loss 0.0604, batch acc 0.9800
19:44:13.597   Training iter 250, batch loss 0.0624, batch acc 0.9806
19:44:13.797   Training iter 300, batch loss 0.0598, batch acc 0.9826
19:44:14.006   Training iter 350, batch loss 0.0605, batch acc 0.9798
19:44:14.206   Training iter 400, batch loss 0.0617, batch acc 0.9798
19:44:14.406   Training iter 450, batch loss 0.0645, batch acc 0.9788
19:44:14.604   Training iter 500, batch loss 0.0589, batch acc 0.9812
19:44:14.833   Training iter 550, batch loss 0.0575, batch acc 0.9828
19:44:15.070   Training iter 600, batch loss 0.0620, batch acc 0.9794
19:44:15.070 Testing @ 55 epoch...
19:44:15.223     Testing, total mean loss 0.06771, total acc 0.97640
19:44:15.224 Training @ 56 epoch...
19:44:15.459   Training iter 50, batch loss 0.0594, batch acc 0.9818
19:44:15.705   Training iter 100, batch loss 0.0628, batch acc 0.9786
19:44:15.906   Training iter 150, batch loss 0.0623, batch acc 0.9780
19:44:16.113   Training iter 200, batch loss 0.0619, batch acc 0.9794
19:44:16.312   Training iter 250, batch loss 0.0617, batch acc 0.9788
19:44:16.507   Training iter 300, batch loss 0.0617, batch acc 0.9788
19:44:16.710   Training iter 350, batch loss 0.0584, batch acc 0.9820
19:44:16.922   Training iter 400, batch loss 0.0571, batch acc 0.9838
19:44:17.133   Training iter 450, batch loss 0.0568, batch acc 0.9842
19:44:17.330   Training iter 500, batch loss 0.0602, batch acc 0.9794
19:44:17.531   Training iter 550, batch loss 0.0591, batch acc 0.9812
19:44:17.771   Training iter 600, batch loss 0.0619, batch acc 0.9792
19:44:17.771 Training @ 57 epoch...
19:44:18.025   Training iter 50, batch loss 0.0583, batch acc 0.9814
19:44:18.284   Training iter 100, batch loss 0.0581, batch acc 0.9838
19:44:18.541   Training iter 150, batch loss 0.0614, batch acc 0.9794
19:44:18.740   Training iter 200, batch loss 0.0609, batch acc 0.9802
19:44:18.942   Training iter 250, batch loss 0.0617, batch acc 0.9790
19:44:19.142   Training iter 300, batch loss 0.0591, batch acc 0.9828
19:44:19.342   Training iter 350, batch loss 0.0614, batch acc 0.9804
19:44:19.545   Training iter 400, batch loss 0.0595, batch acc 0.9816
19:44:19.738   Training iter 450, batch loss 0.0598, batch acc 0.9806
19:44:19.942   Training iter 500, batch loss 0.0629, batch acc 0.9774
19:44:20.149   Training iter 550, batch loss 0.0578, batch acc 0.9826
19:44:20.342   Training iter 600, batch loss 0.0600, batch acc 0.9808
19:44:20.344 Training @ 58 epoch...
19:44:20.591   Training iter 50, batch loss 0.0584, batch acc 0.9820
19:44:20.854   Training iter 100, batch loss 0.0621, batch acc 0.9798
19:44:21.110   Training iter 150, batch loss 0.0577, batch acc 0.9818
19:44:21.344   Training iter 200, batch loss 0.0584, batch acc 0.9826
19:44:21.537   Training iter 250, batch loss 0.0577, batch acc 0.9836
19:44:21.743   Training iter 300, batch loss 0.0597, batch acc 0.9812
19:44:21.969   Training iter 350, batch loss 0.0601, batch acc 0.9798
19:44:22.171   Training iter 400, batch loss 0.0640, batch acc 0.9774
19:44:22.406   Training iter 450, batch loss 0.0567, batch acc 0.9846
19:44:22.608   Training iter 500, batch loss 0.0617, batch acc 0.9818
19:44:22.805   Training iter 550, batch loss 0.0627, batch acc 0.9796
19:44:23.012   Training iter 600, batch loss 0.0590, batch acc 0.9830
19:44:23.014 Training @ 59 epoch...
19:44:23.230   Training iter 50, batch loss 0.0556, batch acc 0.9850
19:44:23.461   Training iter 100, batch loss 0.0627, batch acc 0.9806
19:44:23.710   Training iter 150, batch loss 0.0590, batch acc 0.9828
19:44:23.958   Training iter 200, batch loss 0.0574, batch acc 0.9826
19:44:24.193   Training iter 250, batch loss 0.0611, batch acc 0.9810
19:44:24.398   Training iter 300, batch loss 0.0624, batch acc 0.9804
19:44:24.598   Training iter 350, batch loss 0.0560, batch acc 0.9830
19:44:24.797   Training iter 400, batch loss 0.0640, batch acc 0.9776
19:44:25.012   Training iter 450, batch loss 0.0552, batch acc 0.9852
19:44:25.230   Training iter 500, batch loss 0.0601, batch acc 0.9792
19:44:25.429   Training iter 550, batch loss 0.0603, batch acc 0.9798
19:44:25.631   Training iter 600, batch loss 0.0608, batch acc 0.9784
19:44:25.631 Training @ 60 epoch...
19:44:25.823   Training iter 50, batch loss 0.0528, batch acc 0.9866
19:44:26.025   Training iter 100, batch loss 0.0613, batch acc 0.9792
19:44:26.260   Training iter 150, batch loss 0.0592, batch acc 0.9822
19:44:26.492   Training iter 200, batch loss 0.0574, batch acc 0.9810
19:44:26.744   Training iter 250, batch loss 0.0612, batch acc 0.9800
19:44:27.015   Training iter 300, batch loss 0.0581, batch acc 0.9830
19:44:27.216   Training iter 350, batch loss 0.0603, batch acc 0.9804
19:44:27.421   Training iter 400, batch loss 0.0610, batch acc 0.9816
19:44:27.650   Training iter 450, batch loss 0.0585, batch acc 0.9812
19:44:27.842   Training iter 500, batch loss 0.0628, batch acc 0.9796
19:44:28.048   Training iter 550, batch loss 0.0596, batch acc 0.9828
19:44:28.259   Training iter 600, batch loss 0.0601, batch acc 0.9804
19:44:28.259 Testing @ 60 epoch...
19:44:28.379     Testing, total mean loss 0.06465, total acc 0.97660
19:44:28.379 Training @ 61 epoch...
19:44:28.576   Training iter 50, batch loss 0.0601, batch acc 0.9790
19:44:28.774   Training iter 100, batch loss 0.0582, batch acc 0.9810
19:44:28.978   Training iter 150, batch loss 0.0583, batch acc 0.9830
19:44:29.213   Training iter 200, batch loss 0.0566, batch acc 0.9828
19:44:29.422   Training iter 250, batch loss 0.0589, batch acc 0.9826
19:44:29.652   Training iter 300, batch loss 0.0571, batch acc 0.9840
19:44:29.921   Training iter 350, batch loss 0.0602, batch acc 0.9794
19:44:30.123   Training iter 400, batch loss 0.0604, batch acc 0.9812
19:44:30.331   Training iter 450, batch loss 0.0597, batch acc 0.9810
19:44:30.530   Training iter 500, batch loss 0.0603, batch acc 0.9812
19:44:30.733   Training iter 550, batch loss 0.0583, batch acc 0.9814
19:44:30.987   Training iter 600, batch loss 0.0610, batch acc 0.9798
19:44:30.988 Training @ 62 epoch...
19:44:31.202   Training iter 50, batch loss 0.0590, batch acc 0.9818
19:44:31.412   Training iter 100, batch loss 0.0575, batch acc 0.9822
19:44:31.608   Training iter 150, batch loss 0.0601, batch acc 0.9792
19:44:31.816   Training iter 200, batch loss 0.0599, batch acc 0.9822
19:44:32.059   Training iter 250, batch loss 0.0606, batch acc 0.9800
19:44:32.317   Training iter 300, batch loss 0.0590, batch acc 0.9806
19:44:32.603   Training iter 350, batch loss 0.0563, batch acc 0.9826
19:44:32.842   Training iter 400, batch loss 0.0580, batch acc 0.9830
19:44:33.056   Training iter 450, batch loss 0.0590, batch acc 0.9804
19:44:33.256   Training iter 500, batch loss 0.0586, batch acc 0.9812
19:44:33.448   Training iter 550, batch loss 0.0583, batch acc 0.9832
19:44:33.647   Training iter 600, batch loss 0.0605, batch acc 0.9802
19:44:33.648 Training @ 63 epoch...
19:44:34.034   Training iter 50, batch loss 0.0575, batch acc 0.9826
19:44:34.495   Training iter 100, batch loss 0.0589, batch acc 0.9834
19:44:34.711   Training iter 150, batch loss 0.0581, batch acc 0.9816
19:44:34.959   Training iter 200, batch loss 0.0561, batch acc 0.9836
19:44:35.230   Training iter 250, batch loss 0.0581, batch acc 0.9834
19:44:35.462   Training iter 300, batch loss 0.0602, batch acc 0.9812
19:44:35.966   Training iter 350, batch loss 0.0578, batch acc 0.9818
19:44:36.170   Training iter 400, batch loss 0.0615, batch acc 0.9808
19:44:36.375   Training iter 450, batch loss 0.0621, batch acc 0.9768
19:44:36.578   Training iter 500, batch loss 0.0576, batch acc 0.9832
19:44:36.785   Training iter 550, batch loss 0.0571, batch acc 0.9838
19:44:37.008   Training iter 600, batch loss 0.0590, batch acc 0.9806
19:44:37.010 Training @ 64 epoch...
19:44:37.224   Training iter 50, batch loss 0.0609, batch acc 0.9802
19:44:37.464   Training iter 100, batch loss 0.0565, batch acc 0.9830
19:44:37.705   Training iter 150, batch loss 0.0581, batch acc 0.9810
19:44:38.017   Training iter 200, batch loss 0.0587, batch acc 0.9826
19:44:38.260   Training iter 250, batch loss 0.0590, batch acc 0.9818
19:44:38.501   Training iter 300, batch loss 0.0652, batch acc 0.9786
19:44:38.794   Training iter 350, batch loss 0.0610, batch acc 0.9810
19:44:39.065   Training iter 400, batch loss 0.0585, batch acc 0.9840
19:44:39.285   Training iter 450, batch loss 0.0590, batch acc 0.9796
19:44:39.487   Training iter 500, batch loss 0.0551, batch acc 0.9836
19:44:39.690   Training iter 550, batch loss 0.0566, batch acc 0.9850
19:44:39.895   Training iter 600, batch loss 0.0566, batch acc 0.9850
19:44:39.895 Training @ 65 epoch...
19:44:40.098   Training iter 50, batch loss 0.0597, batch acc 0.9814
19:44:40.303   Training iter 100, batch loss 0.0545, batch acc 0.9832
19:44:40.512   Training iter 150, batch loss 0.0584, batch acc 0.9834
19:44:40.716   Training iter 200, batch loss 0.0574, batch acc 0.9820
19:44:40.968   Training iter 250, batch loss 0.0563, batch acc 0.9832
19:44:41.206   Training iter 300, batch loss 0.0610, batch acc 0.9788
19:44:41.424   Training iter 350, batch loss 0.0564, batch acc 0.9844
19:44:41.699   Training iter 400, batch loss 0.0584, batch acc 0.9816
19:44:41.900   Training iter 450, batch loss 0.0607, batch acc 0.9812
19:44:42.106   Training iter 500, batch loss 0.0574, batch acc 0.9810
19:44:42.303   Training iter 550, batch loss 0.0603, batch acc 0.9796
19:44:42.501   Training iter 600, batch loss 0.0563, batch acc 0.9826
19:44:42.501 Testing @ 65 epoch...
19:44:42.623     Testing, total mean loss 0.06468, total acc 0.97680
19:44:42.623 Training @ 66 epoch...
19:44:42.827   Training iter 50, batch loss 0.0541, batch acc 0.9858
19:44:43.024   Training iter 100, batch loss 0.0642, batch acc 0.9774
19:44:43.227   Training iter 150, batch loss 0.0569, batch acc 0.9836
19:44:43.441   Training iter 200, batch loss 0.0602, batch acc 0.9812
19:44:43.636   Training iter 250, batch loss 0.0605, batch acc 0.9810
19:44:43.886   Training iter 300, batch loss 0.0597, batch acc 0.9798
19:44:44.144   Training iter 350, batch loss 0.0533, batch acc 0.9830
19:44:44.398   Training iter 400, batch loss 0.0567, batch acc 0.9822
19:44:44.665   Training iter 450, batch loss 0.0610, batch acc 0.9804
19:44:44.861   Training iter 500, batch loss 0.0559, batch acc 0.9834
19:44:45.090   Training iter 550, batch loss 0.0569, batch acc 0.9830
19:44:45.293   Training iter 600, batch loss 0.0559, batch acc 0.9836
19:44:45.293 Training @ 67 epoch...
19:44:45.487   Training iter 50, batch loss 0.0582, batch acc 0.9824
19:44:45.697   Training iter 100, batch loss 0.0575, batch acc 0.9824
19:44:45.919   Training iter 150, batch loss 0.0608, batch acc 0.9816
19:44:46.120   Training iter 200, batch loss 0.0584, batch acc 0.9834
19:44:46.326   Training iter 250, batch loss 0.0591, batch acc 0.9822
19:44:46.521   Training iter 300, batch loss 0.0612, batch acc 0.9798
19:44:46.756   Training iter 350, batch loss 0.0566, batch acc 0.9814
19:44:47.017   Training iter 400, batch loss 0.0557, batch acc 0.9832
19:44:47.281   Training iter 450, batch loss 0.0545, batch acc 0.9836
19:44:47.504   Training iter 500, batch loss 0.0590, batch acc 0.9810
19:44:47.687   Training iter 550, batch loss 0.0566, batch acc 0.9808
19:44:47.895   Training iter 600, batch loss 0.0571, batch acc 0.9806
19:44:47.896 Training @ 68 epoch...
19:44:48.113   Training iter 50, batch loss 0.0564, batch acc 0.9818
19:44:48.314   Training iter 100, batch loss 0.0579, batch acc 0.9806
19:44:48.503   Training iter 150, batch loss 0.0594, batch acc 0.9792
19:44:48.713   Training iter 200, batch loss 0.0584, batch acc 0.9812
19:44:48.924   Training iter 250, batch loss 0.0557, batch acc 0.9844
19:44:49.131   Training iter 300, batch loss 0.0599, batch acc 0.9826
19:44:49.332   Training iter 350, batch loss 0.0577, batch acc 0.9812
19:44:49.563   Training iter 400, batch loss 0.0559, batch acc 0.9836
19:44:49.809   Training iter 450, batch loss 0.0571, batch acc 0.9820
19:44:50.075   Training iter 500, batch loss 0.0597, batch acc 0.9828
19:44:50.323   Training iter 550, batch loss 0.0565, batch acc 0.9822
19:44:50.514   Training iter 600, batch loss 0.0569, batch acc 0.9824
19:44:50.515 Training @ 69 epoch...
19:44:50.713   Training iter 50, batch loss 0.0553, batch acc 0.9842
19:44:50.921   Training iter 100, batch loss 0.0576, batch acc 0.9830
19:44:51.113   Training iter 150, batch loss 0.0580, batch acc 0.9824
19:44:51.314   Training iter 200, batch loss 0.0560, batch acc 0.9832
19:44:51.515   Training iter 250, batch loss 0.0605, batch acc 0.9804
19:44:51.715   Training iter 300, batch loss 0.0538, batch acc 0.9840
19:44:51.914   Training iter 350, batch loss 0.0612, batch acc 0.9810
19:44:52.119   Training iter 400, batch loss 0.0578, batch acc 0.9820
19:44:52.336   Training iter 450, batch loss 0.0586, batch acc 0.9818
19:44:52.579   Training iter 500, batch loss 0.0564, batch acc 0.9824
19:44:52.824   Training iter 550, batch loss 0.0589, batch acc 0.9824
19:44:53.041   Training iter 600, batch loss 0.0563, batch acc 0.9828
19:44:53.043 Training @ 70 epoch...
19:44:53.287   Training iter 50, batch loss 0.0569, batch acc 0.9850
19:44:53.486   Training iter 100, batch loss 0.0599, batch acc 0.9796
19:44:53.680   Training iter 150, batch loss 0.0576, batch acc 0.9828
19:44:53.877   Training iter 200, batch loss 0.0569, batch acc 0.9828
19:44:54.089   Training iter 250, batch loss 0.0569, batch acc 0.9844
19:44:54.285   Training iter 300, batch loss 0.0568, batch acc 0.9804
19:44:54.484   Training iter 350, batch loss 0.0576, batch acc 0.9814
19:44:54.678   Training iter 400, batch loss 0.0554, batch acc 0.9844
19:44:54.876   Training iter 450, batch loss 0.0573, batch acc 0.9820
19:44:55.071   Training iter 500, batch loss 0.0546, batch acc 0.9834
19:44:55.315   Training iter 550, batch loss 0.0562, batch acc 0.9834
19:44:55.533   Training iter 600, batch loss 0.0613, batch acc 0.9786
19:44:55.535 Testing @ 70 epoch...
19:44:55.669     Testing, total mean loss 0.06490, total acc 0.97720
19:44:55.669 Training @ 71 epoch...
19:44:55.940   Training iter 50, batch loss 0.0575, batch acc 0.9838
19:44:56.137   Training iter 100, batch loss 0.0535, batch acc 0.9848
19:44:56.342   Training iter 150, batch loss 0.0552, batch acc 0.9838
19:44:56.533   Training iter 200, batch loss 0.0595, batch acc 0.9806
19:44:56.733   Training iter 250, batch loss 0.0574, batch acc 0.9836
19:44:56.936   Training iter 300, batch loss 0.0532, batch acc 0.9872
19:44:57.139   Training iter 350, batch loss 0.0555, batch acc 0.9822
19:44:57.339   Training iter 400, batch loss 0.0622, batch acc 0.9792
19:44:57.527   Training iter 450, batch loss 0.0578, batch acc 0.9838
19:44:57.736   Training iter 500, batch loss 0.0591, batch acc 0.9794
19:44:57.952   Training iter 550, batch loss 0.0578, batch acc 0.9816
19:44:58.186   Training iter 600, batch loss 0.0589, batch acc 0.9814
19:44:58.187 Training @ 72 epoch...
19:44:58.427   Training iter 50, batch loss 0.0564, batch acc 0.9834
19:44:58.670   Training iter 100, batch loss 0.0589, batch acc 0.9824
19:44:58.925   Training iter 150, batch loss 0.0590, batch acc 0.9804
19:44:59.123   Training iter 200, batch loss 0.0568, batch acc 0.9834
19:44:59.326   Training iter 250, batch loss 0.0573, batch acc 0.9840
19:44:59.519   Training iter 300, batch loss 0.0562, batch acc 0.9830
19:44:59.724   Training iter 350, batch loss 0.0579, batch acc 0.9832
19:44:59.927   Training iter 400, batch loss 0.0575, batch acc 0.9804
19:45:00.147   Training iter 450, batch loss 0.0535, batch acc 0.9860
19:45:00.342   Training iter 500, batch loss 0.0620, batch acc 0.9794
19:45:00.537   Training iter 550, batch loss 0.0538, batch acc 0.9840
19:45:00.830   Training iter 600, batch loss 0.0548, batch acc 0.9814
19:45:00.831 Training @ 73 epoch...
19:45:01.102   Training iter 50, batch loss 0.0573, batch acc 0.9828
19:45:01.343   Training iter 100, batch loss 0.0595, batch acc 0.9814
19:45:01.599   Training iter 150, batch loss 0.0533, batch acc 0.9844
19:45:01.908   Training iter 200, batch loss 0.0580, batch acc 0.9842
19:45:02.134   Training iter 250, batch loss 0.0554, batch acc 0.9826
19:45:02.379   Training iter 300, batch loss 0.0535, batch acc 0.9840
19:45:02.597   Training iter 350, batch loss 0.0562, batch acc 0.9838
19:45:02.806   Training iter 400, batch loss 0.0561, batch acc 0.9832
19:45:03.011   Training iter 450, batch loss 0.0577, batch acc 0.9818
19:45:03.238   Training iter 500, batch loss 0.0561, batch acc 0.9828
19:45:03.433   Training iter 550, batch loss 0.0589, batch acc 0.9814
19:45:03.652   Training iter 600, batch loss 0.0580, batch acc 0.9816
19:45:03.654 Training @ 74 epoch...
19:45:03.917   Training iter 50, batch loss 0.0579, batch acc 0.9814
19:45:04.172   Training iter 100, batch loss 0.0557, batch acc 0.9842
19:45:04.409   Training iter 150, batch loss 0.0593, batch acc 0.9816
19:45:04.655   Training iter 200, batch loss 0.0539, batch acc 0.9836
19:45:04.857   Training iter 250, batch loss 0.0536, batch acc 0.9842
19:45:05.072   Training iter 300, batch loss 0.0568, batch acc 0.9838
19:45:05.325   Training iter 350, batch loss 0.0529, batch acc 0.9848
19:45:05.545   Training iter 400, batch loss 0.0567, batch acc 0.9816
19:45:05.762   Training iter 450, batch loss 0.0554, batch acc 0.9834
19:45:05.962   Training iter 500, batch loss 0.0563, batch acc 0.9820
19:45:06.177   Training iter 550, batch loss 0.0599, batch acc 0.9808
19:45:06.377   Training iter 600, batch loss 0.0602, batch acc 0.9814
19:45:06.379 Training @ 75 epoch...
19:45:06.614   Training iter 50, batch loss 0.0561, batch acc 0.9840
19:45:06.841   Training iter 100, batch loss 0.0568, batch acc 0.9822
19:45:07.111   Training iter 150, batch loss 0.0549, batch acc 0.9826
19:45:07.393   Training iter 200, batch loss 0.0559, batch acc 0.9826
19:45:07.602   Training iter 250, batch loss 0.0628, batch acc 0.9778
19:45:07.848   Training iter 300, batch loss 0.0565, batch acc 0.9828
19:45:08.087   Training iter 350, batch loss 0.0568, batch acc 0.9808
19:45:08.311   Training iter 400, batch loss 0.0535, batch acc 0.9850
19:45:08.530   Training iter 450, batch loss 0.0571, batch acc 0.9800
19:45:08.749   Training iter 500, batch loss 0.0554, batch acc 0.9842
19:45:08.976   Training iter 550, batch loss 0.0540, batch acc 0.9856
19:45:09.205   Training iter 600, batch loss 0.0549, batch acc 0.9858
19:45:09.206 Testing @ 75 epoch...
19:45:09.329     Testing, total mean loss 0.06243, total acc 0.97730
19:45:09.329 Training @ 76 epoch...
19:45:09.570   Training iter 50, batch loss 0.0523, batch acc 0.9856
19:45:09.825   Training iter 100, batch loss 0.0561, batch acc 0.9830
19:45:10.092   Training iter 150, batch loss 0.0531, batch acc 0.9840
19:45:10.329   Training iter 200, batch loss 0.0574, batch acc 0.9836
19:45:10.533   Training iter 250, batch loss 0.0571, batch acc 0.9832
19:45:10.740   Training iter 300, batch loss 0.0564, batch acc 0.9812
19:45:10.956   Training iter 350, batch loss 0.0541, batch acc 0.9842
19:45:11.163   Training iter 400, batch loss 0.0562, batch acc 0.9814
19:45:11.367   Training iter 450, batch loss 0.0572, batch acc 0.9836
19:45:11.594   Training iter 500, batch loss 0.0585, batch acc 0.9818
19:45:11.812   Training iter 550, batch loss 0.0577, batch acc 0.9810
19:45:12.029   Training iter 600, batch loss 0.0560, batch acc 0.9836
19:45:12.031 Training @ 77 epoch...
19:45:12.251   Training iter 50, batch loss 0.0565, batch acc 0.9840
19:45:12.497   Training iter 100, batch loss 0.0553, batch acc 0.9818
19:45:12.756   Training iter 150, batch loss 0.0556, batch acc 0.9836
19:45:13.003   Training iter 200, batch loss 0.0578, batch acc 0.9830
19:45:13.235   Training iter 250, batch loss 0.0583, batch acc 0.9790
19:45:13.434   Training iter 300, batch loss 0.0531, batch acc 0.9858
19:45:13.634   Training iter 350, batch loss 0.0576, batch acc 0.9824
19:45:13.840   Training iter 400, batch loss 0.0564, batch acc 0.9822
19:45:14.035   Training iter 450, batch loss 0.0520, batch acc 0.9870
19:45:14.244   Training iter 500, batch loss 0.0575, batch acc 0.9844
19:45:14.603   Training iter 550, batch loss 0.0567, batch acc 0.9824
19:45:14.801   Training iter 600, batch loss 0.0551, batch acc 0.9828
19:45:14.803 Training @ 78 epoch...
19:45:15.016   Training iter 50, batch loss 0.0549, batch acc 0.9844
19:45:15.296   Training iter 100, batch loss 0.0559, batch acc 0.9820
19:45:15.551   Training iter 150, batch loss 0.0556, batch acc 0.9840
19:45:15.767   Training iter 200, batch loss 0.0552, batch acc 0.9834
19:45:16.028   Training iter 250, batch loss 0.0547, batch acc 0.9852
19:45:16.260   Training iter 300, batch loss 0.0563, batch acc 0.9832
19:45:16.469   Training iter 350, batch loss 0.0552, batch acc 0.9850
19:45:16.663   Training iter 400, batch loss 0.0565, batch acc 0.9816
19:45:16.861   Training iter 450, batch loss 0.0548, batch acc 0.9846
19:45:17.066   Training iter 500, batch loss 0.0578, batch acc 0.9812
19:45:17.281   Training iter 550, batch loss 0.0578, batch acc 0.9816
19:45:17.488   Training iter 600, batch loss 0.0575, batch acc 0.9820
19:45:17.491 Training @ 79 epoch...
19:45:17.694   Training iter 50, batch loss 0.0531, batch acc 0.9856
19:45:17.908   Training iter 100, batch loss 0.0561, batch acc 0.9820
19:45:18.131   Training iter 150, batch loss 0.0538, batch acc 0.9840
19:45:18.376   Training iter 200, batch loss 0.0571, batch acc 0.9812
19:45:18.597   Training iter 250, batch loss 0.0514, batch acc 0.9886
19:45:18.858   Training iter 300, batch loss 0.0543, batch acc 0.9840
19:45:19.105   Training iter 350, batch loss 0.0574, batch acc 0.9836
19:45:19.317   Training iter 400, batch loss 0.0584, batch acc 0.9804
19:45:19.524   Training iter 450, batch loss 0.0571, batch acc 0.9834
19:45:19.729   Training iter 500, batch loss 0.0579, batch acc 0.9826
19:45:19.935   Training iter 550, batch loss 0.0543, batch acc 0.9832
19:45:20.139   Training iter 600, batch loss 0.0580, batch acc 0.9804
19:45:20.139 Training @ 80 epoch...
19:45:20.343   Training iter 50, batch loss 0.0560, batch acc 0.9838
19:45:20.549   Training iter 100, batch loss 0.0567, batch acc 0.9810
19:45:20.756   Training iter 150, batch loss 0.0605, batch acc 0.9804
19:45:20.970   Training iter 200, batch loss 0.0565, batch acc 0.9820
19:45:21.237   Training iter 250, batch loss 0.0535, batch acc 0.9836
19:45:21.478   Training iter 300, batch loss 0.0540, batch acc 0.9836
19:45:21.734   Training iter 350, batch loss 0.0532, batch acc 0.9860
19:45:21.984   Training iter 400, batch loss 0.0558, batch acc 0.9832
19:45:22.186   Training iter 450, batch loss 0.0554, batch acc 0.9840
19:45:22.395   Training iter 500, batch loss 0.0552, batch acc 0.9844
19:45:22.617   Training iter 550, batch loss 0.0547, batch acc 0.9856
19:45:22.824   Training iter 600, batch loss 0.0558, batch acc 0.9814
19:45:22.825 Testing @ 80 epoch...
19:45:22.983     Testing, total mean loss 0.06339, total acc 0.97810
19:45:22.984 Training @ 81 epoch...
19:45:23.186   Training iter 50, batch loss 0.0555, batch acc 0.9834
19:45:23.394   Training iter 100, batch loss 0.0538, batch acc 0.9842
19:45:23.597   Training iter 150, batch loss 0.0531, batch acc 0.9850
19:45:23.797   Training iter 200, batch loss 0.0575, batch acc 0.9832
19:45:24.076   Training iter 250, batch loss 0.0573, batch acc 0.9836
19:45:24.338   Training iter 300, batch loss 0.0550, batch acc 0.9800
19:45:24.568   Training iter 350, batch loss 0.0557, batch acc 0.9842
19:45:24.819   Training iter 400, batch loss 0.0575, batch acc 0.9824
19:45:25.020   Training iter 450, batch loss 0.0538, batch acc 0.9864
19:45:25.250   Training iter 500, batch loss 0.0536, batch acc 0.9844
19:45:25.447   Training iter 550, batch loss 0.0549, batch acc 0.9838
19:45:25.648   Training iter 600, batch loss 0.0587, batch acc 0.9828
19:45:25.650 Training @ 82 epoch...
19:45:25.848   Training iter 50, batch loss 0.0550, batch acc 0.9830
19:45:26.058   Training iter 100, batch loss 0.0549, batch acc 0.9842
19:45:26.274   Training iter 150, batch loss 0.0520, batch acc 0.9864
19:45:26.480   Training iter 200, batch loss 0.0507, batch acc 0.9882
19:45:26.675   Training iter 250, batch loss 0.0548, batch acc 0.9846
19:45:26.915   Training iter 300, batch loss 0.0528, batch acc 0.9840
19:45:27.140   Training iter 350, batch loss 0.0597, batch acc 0.9810
19:45:27.371   Training iter 400, batch loss 0.0564, batch acc 0.9822
19:45:27.593   Training iter 450, batch loss 0.0561, batch acc 0.9832
19:45:27.876   Training iter 500, batch loss 0.0561, batch acc 0.9840
19:45:28.083   Training iter 550, batch loss 0.0535, batch acc 0.9838
19:45:28.287   Training iter 600, batch loss 0.0579, batch acc 0.9794
19:45:28.289 Training @ 83 epoch...
19:45:28.496   Training iter 50, batch loss 0.0500, batch acc 0.9866
19:45:28.706   Training iter 100, batch loss 0.0545, batch acc 0.9832
19:45:28.908   Training iter 150, batch loss 0.0570, batch acc 0.9810
19:45:29.188   Training iter 200, batch loss 0.0543, batch acc 0.9854
19:45:29.398   Training iter 250, batch loss 0.0542, batch acc 0.9854
19:45:29.608   Training iter 300, batch loss 0.0540, batch acc 0.9836
19:45:29.821   Training iter 350, batch loss 0.0541, batch acc 0.9834
19:45:30.073   Training iter 400, batch loss 0.0570, batch acc 0.9836
19:45:30.327   Training iter 450, batch loss 0.0550, batch acc 0.9826
19:45:30.549   Training iter 500, batch loss 0.0559, batch acc 0.9852
19:45:30.792   Training iter 550, batch loss 0.0597, batch acc 0.9818
19:45:31.001   Training iter 600, batch loss 0.0570, batch acc 0.9822
19:45:31.001 Training @ 84 epoch...
19:45:31.207   Training iter 50, batch loss 0.0571, batch acc 0.9818
19:45:31.419   Training iter 100, batch loss 0.0534, batch acc 0.9864
19:45:31.618   Training iter 150, batch loss 0.0533, batch acc 0.9862
19:45:31.815   Training iter 200, batch loss 0.0549, batch acc 0.9838
19:45:32.022   Training iter 250, batch loss 0.0517, batch acc 0.9868
19:45:32.227   Training iter 300, batch loss 0.0547, batch acc 0.9840
19:45:32.436   Training iter 350, batch loss 0.0575, batch acc 0.9816
19:45:32.635   Training iter 400, batch loss 0.0590, batch acc 0.9818
19:45:32.855   Training iter 450, batch loss 0.0567, batch acc 0.9824
19:45:33.186   Training iter 500, batch loss 0.0545, batch acc 0.9826
19:45:33.445   Training iter 550, batch loss 0.0529, batch acc 0.9854
19:45:33.686   Training iter 600, batch loss 0.0557, batch acc 0.9842
19:45:33.686 Training @ 85 epoch...
19:45:33.886   Training iter 50, batch loss 0.0547, batch acc 0.9842
19:45:34.100   Training iter 100, batch loss 0.0548, batch acc 0.9844
19:45:34.306   Training iter 150, batch loss 0.0566, batch acc 0.9820
19:45:34.510   Training iter 200, batch loss 0.0524, batch acc 0.9856
19:45:34.714   Training iter 250, batch loss 0.0529, batch acc 0.9834
19:45:34.922   Training iter 300, batch loss 0.0544, batch acc 0.9828
19:45:35.132   Training iter 350, batch loss 0.0526, batch acc 0.9874
19:45:35.338   Training iter 400, batch loss 0.0575, batch acc 0.9834
19:45:35.549   Training iter 450, batch loss 0.0556, batch acc 0.9828
19:45:35.844   Training iter 500, batch loss 0.0556, batch acc 0.9836
19:45:36.104   Training iter 550, batch loss 0.0568, batch acc 0.9826
19:45:36.409   Training iter 600, batch loss 0.0559, batch acc 0.9842
19:45:36.409 Testing @ 85 epoch...
19:45:36.567     Testing, total mean loss 0.06216, total acc 0.97780
19:45:36.567 Training @ 86 epoch...
19:45:36.778   Training iter 50, batch loss 0.0563, batch acc 0.9836
19:45:36.983   Training iter 100, batch loss 0.0529, batch acc 0.9848
19:45:37.199   Training iter 150, batch loss 0.0576, batch acc 0.9814
19:45:37.447   Training iter 200, batch loss 0.0547, batch acc 0.9848
19:45:37.687   Training iter 250, batch loss 0.0539, batch acc 0.9824
19:45:38.179   Training iter 300, batch loss 0.0545, batch acc 0.9826
19:45:38.456   Training iter 350, batch loss 0.0555, batch acc 0.9830
19:45:38.726   Training iter 400, batch loss 0.0533, batch acc 0.9850
19:45:39.018   Training iter 450, batch loss 0.0572, batch acc 0.9840
19:45:39.256   Training iter 500, batch loss 0.0558, batch acc 0.9834
19:45:39.512   Training iter 550, batch loss 0.0536, batch acc 0.9850
19:45:39.719   Training iter 600, batch loss 0.0535, batch acc 0.9838
19:45:39.720 Training @ 87 epoch...
19:45:39.927   Training iter 50, batch loss 0.0568, batch acc 0.9826
19:45:40.163   Training iter 100, batch loss 0.0545, batch acc 0.9852
19:45:40.373   Training iter 150, batch loss 0.0543, batch acc 0.9840
19:45:40.579   Training iter 200, batch loss 0.0560, batch acc 0.9820
19:45:40.777   Training iter 250, batch loss 0.0518, batch acc 0.9870
19:45:40.992   Training iter 300, batch loss 0.0535, batch acc 0.9828
19:45:41.208   Training iter 350, batch loss 0.0570, batch acc 0.9814
19:45:41.416   Training iter 400, batch loss 0.0512, batch acc 0.9882
19:45:41.675   Training iter 450, batch loss 0.0591, batch acc 0.9820
19:45:41.946   Training iter 500, batch loss 0.0557, batch acc 0.9824
19:45:42.206   Training iter 550, batch loss 0.0568, batch acc 0.9840
19:45:42.456   Training iter 600, batch loss 0.0536, batch acc 0.9858
19:45:42.457 Training @ 88 epoch...
19:45:42.658   Training iter 50, batch loss 0.0555, batch acc 0.9824
19:45:42.864   Training iter 100, batch loss 0.0520, batch acc 0.9852
19:45:43.073   Training iter 150, batch loss 0.0556, batch acc 0.9830
19:45:43.277   Training iter 200, batch loss 0.0549, batch acc 0.9842
19:45:43.475   Training iter 250, batch loss 0.0532, batch acc 0.9868
19:45:43.685   Training iter 300, batch loss 0.0569, batch acc 0.9804
19:45:43.896   Training iter 350, batch loss 0.0514, batch acc 0.9854
19:45:44.212   Training iter 400, batch loss 0.0540, batch acc 0.9834
19:45:44.453   Training iter 450, batch loss 0.0556, batch acc 0.9856
19:45:44.749   Training iter 500, batch loss 0.0553, batch acc 0.9822
19:45:45.060   Training iter 550, batch loss 0.0535, batch acc 0.9846
19:45:45.322   Training iter 600, batch loss 0.0547, batch acc 0.9828
19:45:45.323 Training @ 89 epoch...
19:45:45.544   Training iter 50, batch loss 0.0541, batch acc 0.9816
19:45:46.081   Training iter 100, batch loss 0.0519, batch acc 0.9880
19:45:46.369   Training iter 150, batch loss 0.0544, batch acc 0.9844
19:45:46.585   Training iter 200, batch loss 0.0533, batch acc 0.9840
19:45:46.811   Training iter 250, batch loss 0.0530, batch acc 0.9836
19:45:47.117   Training iter 300, batch loss 0.0556, batch acc 0.9846
19:45:47.412   Training iter 350, batch loss 0.0554, batch acc 0.9836
19:45:47.664   Training iter 400, batch loss 0.0561, batch acc 0.9818
19:45:47.930   Training iter 450, batch loss 0.0559, batch acc 0.9816
19:45:48.360   Training iter 500, batch loss 0.0554, batch acc 0.9826
19:45:48.674   Training iter 550, batch loss 0.0561, batch acc 0.9836
19:45:48.908   Training iter 600, batch loss 0.0530, batch acc 0.9858
19:45:48.909 Training @ 90 epoch...
19:45:49.146   Training iter 50, batch loss 0.0535, batch acc 0.9844
19:45:49.380   Training iter 100, batch loss 0.0601, batch acc 0.9824
19:45:49.596   Training iter 150, batch loss 0.0526, batch acc 0.9836
19:45:49.905   Training iter 200, batch loss 0.0514, batch acc 0.9862
19:45:50.200   Training iter 250, batch loss 0.0518, batch acc 0.9856
19:45:50.595   Training iter 300, batch loss 0.0542, batch acc 0.9822
19:45:50.860   Training iter 350, batch loss 0.0523, batch acc 0.9858
19:45:51.204   Training iter 400, batch loss 0.0582, batch acc 0.9818
19:45:51.460   Training iter 450, batch loss 0.0550, batch acc 0.9852
19:45:51.709   Training iter 500, batch loss 0.0555, batch acc 0.9838
19:45:52.022   Training iter 550, batch loss 0.0542, batch acc 0.9842
19:45:52.260   Training iter 600, batch loss 0.0546, batch acc 0.9824
19:45:52.260 Testing @ 90 epoch...
19:45:52.459     Testing, total mean loss 0.06167, total acc 0.97800
19:45:52.459 Training @ 91 epoch...
19:45:52.697   Training iter 50, batch loss 0.0530, batch acc 0.9848
19:45:52.942   Training iter 100, batch loss 0.0558, batch acc 0.9824
19:45:53.203   Training iter 150, batch loss 0.0531, batch acc 0.9824
19:45:53.467   Training iter 200, batch loss 0.0532, batch acc 0.9870
19:45:53.795   Training iter 250, batch loss 0.0574, batch acc 0.9820
19:45:54.070   Training iter 300, batch loss 0.0568, batch acc 0.9804
19:45:54.296   Training iter 350, batch loss 0.0507, batch acc 0.9860
19:45:54.506   Training iter 400, batch loss 0.0524, batch acc 0.9850
19:45:54.746   Training iter 450, batch loss 0.0507, batch acc 0.9880
19:45:54.956   Training iter 500, batch loss 0.0540, batch acc 0.9852
19:45:55.170   Training iter 550, batch loss 0.0580, batch acc 0.9828
19:45:55.380   Training iter 600, batch loss 0.0539, batch acc 0.9846
19:45:55.381 Training @ 92 epoch...
19:45:55.610   Training iter 50, batch loss 0.0516, batch acc 0.9874
19:45:55.928   Training iter 100, batch loss 0.0547, batch acc 0.9850
19:45:56.219   Training iter 150, batch loss 0.0524, batch acc 0.9844
19:45:56.510   Training iter 200, batch loss 0.0550, batch acc 0.9836
19:45:56.854   Training iter 250, batch loss 0.0529, batch acc 0.9852
19:45:57.203   Training iter 300, batch loss 0.0534, batch acc 0.9844
19:45:57.510   Training iter 350, batch loss 0.0534, batch acc 0.9836
19:45:57.826   Training iter 400, batch loss 0.0515, batch acc 0.9848
19:45:58.087   Training iter 450, batch loss 0.0558, batch acc 0.9844
19:45:58.356   Training iter 500, batch loss 0.0545, batch acc 0.9844
19:45:58.569   Training iter 550, batch loss 0.0559, batch acc 0.9828
19:45:58.812   Training iter 600, batch loss 0.0585, batch acc 0.9810
19:45:58.813 Training @ 93 epoch...
19:45:59.251   Training iter 50, batch loss 0.0535, batch acc 0.9832
19:45:59.534   Training iter 100, batch loss 0.0535, batch acc 0.9834
19:45:59.790   Training iter 150, batch loss 0.0508, batch acc 0.9854
19:45:59.998   Training iter 200, batch loss 0.0541, batch acc 0.9836
19:46:00.241   Training iter 250, batch loss 0.0561, batch acc 0.9840
19:46:00.579   Training iter 300, batch loss 0.0573, batch acc 0.9830
19:46:00.815   Training iter 350, batch loss 0.0542, batch acc 0.9836
19:46:01.045   Training iter 400, batch loss 0.0550, batch acc 0.9808
19:46:01.275   Training iter 450, batch loss 0.0547, batch acc 0.9838
19:46:01.506   Training iter 500, batch loss 0.0508, batch acc 0.9880
19:46:01.825   Training iter 550, batch loss 0.0543, batch acc 0.9834
19:46:02.123   Training iter 600, batch loss 0.0512, batch acc 0.9878
19:46:02.123 Training @ 94 epoch...
19:46:02.410   Training iter 50, batch loss 0.0559, batch acc 0.9830
19:46:02.673   Training iter 100, batch loss 0.0516, batch acc 0.9870
19:46:02.991   Training iter 150, batch loss 0.0557, batch acc 0.9830
19:46:03.375   Training iter 200, batch loss 0.0546, batch acc 0.9820
19:46:03.667   Training iter 250, batch loss 0.0556, batch acc 0.9848
19:46:03.980   Training iter 300, batch loss 0.0548, batch acc 0.9834
19:46:04.376   Training iter 350, batch loss 0.0532, batch acc 0.9864
19:46:04.651   Training iter 400, batch loss 0.0549, batch acc 0.9830
19:46:04.968   Training iter 450, batch loss 0.0548, batch acc 0.9834
19:46:05.237   Training iter 500, batch loss 0.0522, batch acc 0.9836
19:46:05.582   Training iter 550, batch loss 0.0520, batch acc 0.9860
19:46:05.855   Training iter 600, batch loss 0.0526, batch acc 0.9846
19:46:05.856 Training @ 95 epoch...
19:46:06.097   Training iter 50, batch loss 0.0495, batch acc 0.9866
19:46:06.348   Training iter 100, batch loss 0.0531, batch acc 0.9840
19:46:06.574   Training iter 150, batch loss 0.0514, batch acc 0.9868
19:46:06.838   Training iter 200, batch loss 0.0563, batch acc 0.9822
19:46:07.127   Training iter 250, batch loss 0.0570, batch acc 0.9804
19:46:07.540   Training iter 300, batch loss 0.0528, batch acc 0.9846
19:46:07.846   Training iter 350, batch loss 0.0553, batch acc 0.9834
19:46:08.131   Training iter 400, batch loss 0.0519, batch acc 0.9844
19:46:08.433   Training iter 450, batch loss 0.0525, batch acc 0.9864
19:46:08.740   Training iter 500, batch loss 0.0563, batch acc 0.9828
19:46:08.976   Training iter 550, batch loss 0.0539, batch acc 0.9848
19:46:09.191   Training iter 600, batch loss 0.0548, batch acc 0.9844
19:46:09.191 Testing @ 95 epoch...
19:46:09.318     Testing, total mean loss 0.06157, total acc 0.97860
19:46:09.318 Training @ 96 epoch...
19:46:09.529   Training iter 50, batch loss 0.0531, batch acc 0.9828
19:46:09.749   Training iter 100, batch loss 0.0526, batch acc 0.9866
19:46:09.964   Training iter 150, batch loss 0.0542, batch acc 0.9834
19:46:10.172   Training iter 200, batch loss 0.0537, batch acc 0.9822
19:46:10.399   Training iter 250, batch loss 0.0550, batch acc 0.9844
19:46:10.625   Training iter 300, batch loss 0.0519, batch acc 0.9864
19:46:10.853   Training iter 350, batch loss 0.0582, batch acc 0.9812
19:46:11.102   Training iter 400, batch loss 0.0539, batch acc 0.9838
19:46:11.358   Training iter 450, batch loss 0.0551, batch acc 0.9848
19:46:11.624   Training iter 500, batch loss 0.0559, batch acc 0.9814
19:46:11.837   Training iter 550, batch loss 0.0530, batch acc 0.9842
19:46:12.055   Training iter 600, batch loss 0.0525, batch acc 0.9860
19:46:12.056 Training @ 97 epoch...
19:46:12.266   Training iter 50, batch loss 0.0523, batch acc 0.9858
19:46:12.478   Training iter 100, batch loss 0.0531, batch acc 0.9858
19:46:12.684   Training iter 150, batch loss 0.0545, batch acc 0.9842
19:46:12.902   Training iter 200, batch loss 0.0534, batch acc 0.9864
19:46:13.122   Training iter 250, batch loss 0.0536, batch acc 0.9844
19:46:13.325   Training iter 300, batch loss 0.0537, batch acc 0.9850
19:46:13.528   Training iter 350, batch loss 0.0520, batch acc 0.9864
19:46:13.833   Training iter 400, batch loss 0.0535, batch acc 0.9844
19:46:14.092   Training iter 450, batch loss 0.0519, batch acc 0.9852
19:46:14.363   Training iter 500, batch loss 0.0564, batch acc 0.9824
19:46:14.585   Training iter 550, batch loss 0.0551, batch acc 0.9844
19:46:14.802   Training iter 600, batch loss 0.0538, batch acc 0.9822
19:46:14.804 Training @ 98 epoch...
19:46:15.031   Training iter 50, batch loss 0.0512, batch acc 0.9856
19:46:15.279   Training iter 100, batch loss 0.0531, batch acc 0.9846
19:46:15.536   Training iter 150, batch loss 0.0540, batch acc 0.9856
19:46:15.746   Training iter 200, batch loss 0.0521, batch acc 0.9838
19:46:15.991   Training iter 250, batch loss 0.0572, batch acc 0.9814
19:46:16.205   Training iter 300, batch loss 0.0553, batch acc 0.9834
19:46:16.454   Training iter 350, batch loss 0.0515, batch acc 0.9848
19:46:16.726   Training iter 400, batch loss 0.0530, batch acc 0.9850
19:46:16.994   Training iter 450, batch loss 0.0553, batch acc 0.9836
19:46:17.356   Training iter 500, batch loss 0.0545, batch acc 0.9852
19:46:17.656   Training iter 550, batch loss 0.0540, batch acc 0.9846
19:46:17.895   Training iter 600, batch loss 0.0490, batch acc 0.9868
19:46:17.896 Training @ 99 epoch...
19:46:18.241   Training iter 50, batch loss 0.0558, batch acc 0.9836
19:46:18.459   Training iter 100, batch loss 0.0531, batch acc 0.9850
19:46:18.670   Training iter 150, batch loss 0.0543, batch acc 0.9840
19:46:18.891   Training iter 200, batch loss 0.0525, batch acc 0.9844
19:46:19.110   Training iter 250, batch loss 0.0550, batch acc 0.9842
19:46:19.427   Training iter 300, batch loss 0.0541, batch acc 0.9850
19:46:19.671   Training iter 350, batch loss 0.0540, batch acc 0.9846
19:46:19.911   Training iter 400, batch loss 0.0523, batch acc 0.9834
19:46:20.144   Training iter 450, batch loss 0.0537, batch acc 0.9850
19:46:20.383   Training iter 500, batch loss 0.0533, batch acc 0.9862
19:46:20.660   Training iter 550, batch loss 0.0480, batch acc 0.9872
19:46:20.885   Training iter 600, batch loss 0.0537, batch acc 0.9844
19:46:20.886 Testing @ 99 epoch...
19:46:21.016     Testing, total mean loss 0.06071, total acc 0.97870