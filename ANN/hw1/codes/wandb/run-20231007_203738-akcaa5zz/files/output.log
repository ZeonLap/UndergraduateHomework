20:37:43.263 Training @ 0 epoch...
20:37:43.563   Training iter 50, batch loss 0.9145, batch acc 0.1110
20:37:43.804   Training iter 100, batch loss 0.8959, batch acc 0.1630
20:37:44.097   Training iter 150, batch loss 0.8686, batch acc 0.3368
20:37:44.345   Training iter 200, batch loss 0.7353, batch acc 0.4404
20:37:44.660   Training iter 250, batch loss 0.6210, batch acc 0.5840
20:37:45.016   Training iter 300, batch loss 0.5220, batch acc 0.7126
20:37:45.326   Training iter 350, batch loss 0.4507, batch acc 0.7416
20:37:45.758   Training iter 400, batch loss 0.3785, batch acc 0.7872
20:37:46.335   Training iter 450, batch loss 0.3308, batch acc 0.8384
20:37:46.598   Training iter 500, batch loss 0.2845, batch acc 0.8758
20:37:46.862   Training iter 550, batch loss 0.2440, batch acc 0.8948
20:37:47.053   Training iter 600, batch loss 0.2166, batch acc 0.9000
20:37:47.053 Testing @ 0 epoch...
20:37:47.169     Testing, total mean loss 0.20586, total acc 0.90490
20:37:47.169 Training @ 1 epoch...
20:37:47.417   Training iter 50, batch loss 0.2064, batch acc 0.9044
20:37:47.614   Training iter 100, batch loss 0.2012, batch acc 0.9066
20:37:47.917   Training iter 150, batch loss 0.1872, batch acc 0.9120
20:37:48.226   Training iter 200, batch loss 0.1854, batch acc 0.9140
20:37:48.476   Training iter 250, batch loss 0.1686, batch acc 0.9190
20:37:48.710   Training iter 300, batch loss 0.1633, batch acc 0.9250
20:37:48.928   Training iter 350, batch loss 0.1524, batch acc 0.9312
20:37:49.128   Training iter 400, batch loss 0.1527, batch acc 0.9314
20:37:49.284   Training iter 450, batch loss 0.1554, batch acc 0.9260
20:37:49.506   Training iter 500, batch loss 0.1500, batch acc 0.9274
20:37:49.706   Training iter 550, batch loss 0.1351, batch acc 0.9370
20:37:49.958   Training iter 600, batch loss 0.1387, batch acc 0.9342
20:37:49.960 Training @ 2 epoch...
20:37:50.197   Training iter 50, batch loss 0.1342, batch acc 0.9356
20:37:50.449   Training iter 100, batch loss 0.1271, batch acc 0.9418
20:37:50.716   Training iter 150, batch loss 0.1230, batch acc 0.9466
20:37:50.918   Training iter 200, batch loss 0.1234, batch acc 0.9392
20:37:51.109   Training iter 250, batch loss 0.1221, batch acc 0.9436
20:37:51.324   Training iter 300, batch loss 0.1142, batch acc 0.9478
20:37:51.516   Training iter 350, batch loss 0.1143, batch acc 0.9462
20:37:51.686   Training iter 400, batch loss 0.1114, batch acc 0.9494
20:37:51.873   Training iter 450, batch loss 0.1096, batch acc 0.9488
20:37:52.076   Training iter 500, batch loss 0.1057, batch acc 0.9536
20:37:52.393   Training iter 550, batch loss 0.1034, batch acc 0.9542
20:37:52.704   Training iter 600, batch loss 0.0988, batch acc 0.9562
20:37:52.704 Training @ 3 epoch...
20:37:53.420   Training iter 50, batch loss 0.1014, batch acc 0.9544
20:37:53.712   Training iter 100, batch loss 0.0945, batch acc 0.9588
20:37:53.914   Training iter 150, batch loss 0.0938, batch acc 0.9586
20:37:54.115   Training iter 200, batch loss 0.0898, batch acc 0.9614
20:37:54.327   Training iter 250, batch loss 0.0912, batch acc 0.9596
20:37:54.505   Training iter 300, batch loss 0.0939, batch acc 0.9560
20:37:54.679   Training iter 350, batch loss 0.0903, batch acc 0.9590
20:37:54.856   Training iter 400, batch loss 0.0942, batch acc 0.9580
20:37:55.040   Training iter 450, batch loss 0.0917, batch acc 0.9552
20:37:55.222   Training iter 500, batch loss 0.0835, batch acc 0.9662
20:37:55.498   Training iter 550, batch loss 0.0805, batch acc 0.9664
20:37:55.731   Training iter 600, batch loss 0.0848, batch acc 0.9662
20:37:55.732 Training @ 4 epoch...
20:37:56.068   Training iter 50, batch loss 0.0807, batch acc 0.9664
20:37:56.616   Training iter 100, batch loss 0.0761, batch acc 0.9680
20:37:56.901   Training iter 150, batch loss 0.0774, batch acc 0.9670
20:37:57.167   Training iter 200, batch loss 0.0772, batch acc 0.9648
20:37:57.413   Training iter 250, batch loss 0.0746, batch acc 0.9710
20:37:57.623   Training iter 300, batch loss 0.0827, batch acc 0.9632
20:37:57.834   Training iter 350, batch loss 0.0795, batch acc 0.9676
20:37:58.070   Training iter 400, batch loss 0.0747, batch acc 0.9684
20:37:58.252   Training iter 450, batch loss 0.0736, batch acc 0.9666
20:37:58.499   Training iter 500, batch loss 0.0725, batch acc 0.9710
20:37:58.896   Training iter 550, batch loss 0.0780, batch acc 0.9668
20:37:59.110   Training iter 600, batch loss 0.0715, batch acc 0.9696
20:37:59.111 Training @ 5 epoch...
20:37:59.481   Training iter 50, batch loss 0.0658, batch acc 0.9756
20:37:59.702   Training iter 100, batch loss 0.0685, batch acc 0.9720
20:37:59.981   Training iter 150, batch loss 0.0690, batch acc 0.9712
20:38:00.296   Training iter 200, batch loss 0.0662, batch acc 0.9732
20:38:00.572   Training iter 250, batch loss 0.0620, batch acc 0.9776
20:38:00.953   Training iter 300, batch loss 0.0707, batch acc 0.9700
20:38:01.211   Training iter 350, batch loss 0.0715, batch acc 0.9686
20:38:01.646   Training iter 400, batch loss 0.0675, batch acc 0.9728
20:38:01.920   Training iter 450, batch loss 0.0695, batch acc 0.9704
20:38:02.227   Training iter 500, batch loss 0.0703, batch acc 0.9698
20:38:02.506   Training iter 550, batch loss 0.0658, batch acc 0.9736
20:38:02.692   Training iter 600, batch loss 0.0663, batch acc 0.9722
20:38:02.694 Testing @ 5 epoch...
20:38:02.793     Testing, total mean loss 0.06770, total acc 0.97110
20:38:02.793 Training @ 6 epoch...
20:38:03.047   Training iter 50, batch loss 0.0615, batch acc 0.9748
20:38:03.250   Training iter 100, batch loss 0.0583, batch acc 0.9768
20:38:03.477   Training iter 150, batch loss 0.0642, batch acc 0.9720
20:38:03.680   Training iter 200, batch loss 0.0599, batch acc 0.9778
20:38:04.047   Training iter 250, batch loss 0.0597, batch acc 0.9752
20:38:04.263   Training iter 300, batch loss 0.0623, batch acc 0.9754
20:38:04.523   Training iter 350, batch loss 0.0617, batch acc 0.9768
20:38:04.846   Training iter 400, batch loss 0.0589, batch acc 0.9784
20:38:05.729   Training iter 450, batch loss 0.0626, batch acc 0.9732
20:38:05.976   Training iter 500, batch loss 0.0568, batch acc 0.9780
20:38:06.282   Training iter 550, batch loss 0.0591, batch acc 0.9776
20:38:06.616   Training iter 600, batch loss 0.0604, batch acc 0.9754
20:38:06.617 Training @ 7 epoch...
20:38:06.856   Training iter 50, batch loss 0.0583, batch acc 0.9766
20:38:07.198   Training iter 100, batch loss 0.0527, batch acc 0.9828
20:38:07.850   Training iter 150, batch loss 0.0562, batch acc 0.9800
20:38:08.165   Training iter 200, batch loss 0.0525, batch acc 0.9802
20:38:08.437   Training iter 250, batch loss 0.0577, batch acc 0.9778
20:38:08.864   Training iter 300, batch loss 0.0555, batch acc 0.9794
20:38:09.146   Training iter 350, batch loss 0.0558, batch acc 0.9782
20:38:09.339   Training iter 400, batch loss 0.0555, batch acc 0.9804
20:38:11.565   Training iter 50, batch loss 0.0519, batch acc 0.98286
20:38:10.377   Training iter 500, batch loss 0.0598, batch acc 0.9760
20:38:10.875   Training iter 550, batch loss 0.0562, batch acc 0.9790
20:38:11.351   Training iter 600, batch loss 0.0565, batch acc 0.9802
20:38:11.351 Training @ 8 epoch...
20:38:11.565   Training iter 50, batch loss 0.0519, batch acc 0.98286
20:38:11.770   Training iter 100, batch loss 0.0549, batch acc 0.9786
20:38:11.970   Training iter 150, batch loss 0.0512, batch acc 0.9818
20:38:12.170   Training iter 200, batch loss 0.0526, batch acc 0.9816
20:38:12.365   Training iter 250, batch loss 0.0532, batch acc 0.9814
20:38:12.556   Training iter 300, batch loss 0.0570, batch acc 0.9772
20:38:12.725   Training iter 350, batch loss 0.0520, batch acc 0.9824
20:38:12.929   Training iter 400, batch loss 0.0528, batch acc 0.9816
20:38:13.646   Training iter 450, batch loss 0.0483, batch acc 0.9826
20:38:14.100   Training iter 500, batch loss 0.0536, batch acc 0.9800
20:38:14.407   Training iter 550, batch loss 0.0482, batch acc 0.9840
20:38:14.640   Training iter 600, batch loss 0.0559, batch acc 0.9780
20:38:14.640 Training @ 9 epoch...
20:38:14.902   Training iter 50, batch loss 0.0501, batch acc 0.9816
20:38:15.184   Training iter 100, batch loss 0.0497, batch acc 0.9830
20:38:15.380   Training iter 150, batch loss 0.0521, batch acc 0.9798
20:38:15.576   Training iter 200, batch loss 0.0495, batch acc 0.9832
20:38:15.859   Training iter 250, batch loss 0.0487, batch acc 0.9832
20:38:16.094   Training iter 300, batch loss 0.0510, batch acc 0.9808
20:38:16.314   Training iter 350, batch loss 0.0472, batch acc 0.9830
20:38:16.648   Training iter 400, batch loss 0.0444, batch acc 0.9862
20:38:16.862   Training iter 450, batch loss 0.0509, batch acc 0.9804
20:38:17.134   Training iter 500, batch loss 0.0466, batch acc 0.9840
20:38:17.385   Training iter 550, batch loss 0.0482, batch acc 0.9816
20:38:17.585   Training iter 600, batch loss 0.0513, batch acc 0.9808
20:38:17.587 Training @ 10 epoch...
20:38:18.022   Training iter 50, batch loss 0.0452, batch acc 0.9862
20:38:18.435   Training iter 100, batch loss 0.0462, batch acc 0.9838
20:38:18.714   Training iter 150, batch loss 0.0428, batch acc 0.9878
20:38:18.987   Training iter 200, batch loss 0.0437, batch acc 0.9844
20:38:19.305   Training iter 250, batch loss 0.0435, batch acc 0.9858
20:38:19.593   Training iter 300, batch loss 0.0472, batch acc 0.9844
20:38:19.922   Training iter 350, batch loss 0.0498, batch acc 0.9826
20:38:20.202   Training iter 400, batch loss 0.0491, batch acc 0.9816
20:38:20.428   Training iter 450, batch loss 0.0489, batch acc 0.9804
20:38:20.847   Training iter 500, batch loss 0.0498, batch acc 0.9820
20:38:21.193   Training iter 550, batch loss 0.0465, batch acc 0.9826
20:38:21.456   Training iter 600, batch loss 0.0443, batch acc 0.9852
20:38:21.457 Testing @ 10 epoch...
20:38:21.595     Testing, total mean loss 0.05241, total acc 0.97660
20:38:21.595 Training @ 11 epoch...
20:38:21.826   Training iter 50, batch loss 0.0458, batch acc 0.9830
20:38:22.036   Training iter 100, batch loss 0.0428, batch acc 0.9854
20:38:22.303   Training iter 150, batch loss 0.0428, batch acc 0.9846
20:38:22.568   Training iter 200, batch loss 0.0466, batch acc 0.9838
20:38:22.890   Training iter 250, batch loss 0.0443, batch acc 0.9868
20:38:23.187   Training iter 300, batch loss 0.0442, batch acc 0.9872
20:38:23.368   Training iter 350, batch loss 0.0449, batch acc 0.9842
20:38:23.587   Training iter 400, batch loss 0.0477, batch acc 0.9822
20:38:23.809   Training iter 450, batch loss 0.0421, batch acc 0.9862
20:38:24.064   Training iter 500, batch loss 0.0434, batch acc 0.9856
20:38:24.286   Training iter 550, batch loss 0.0426, batch acc 0.9856
20:38:24.542   Training iter 600, batch loss 0.0456, batch acc 0.9858
20:38:24.543 Training @ 12 epoch...
20:38:24.850   Training iter 50, batch loss 0.0408, batch acc 0.9860
20:38:25.089   Training iter 100, batch loss 0.0420, batch acc 0.9862
20:38:25.365   Training iter 150, batch loss 0.0414, batch acc 0.9874
20:38:25.594   Training iter 200, batch loss 0.0414, batch acc 0.9860
20:38:25.841   Training iter 250, batch loss 0.0429, batch acc 0.9868
20:38:26.117   Training iter 300, batch loss 0.0403, batch acc 0.9860
20:38:26.354   Training iter 350, batch loss 0.0408, batch acc 0.9866
20:38:26.577   Training iter 400, batch loss 0.0427, batch acc 0.9836
20:38:26.922   Training iter 450, batch loss 0.0431, batch acc 0.9868
20:38:27.280   Training iter 500, batch loss 0.0427, batch acc 0.9850
20:38:27.665   Training iter 550, batch loss 0.0435, batch acc 0.9840
20:38:27.873   Training iter 600, batch loss 0.0423, batch acc 0.9866
20:38:27.874 Training @ 13 epoch...
20:38:28.126   Training iter 50, batch loss 0.0374, batch acc 0.9886
20:38:28.373   Training iter 100, batch loss 0.0375, batch acc 0.9884
20:38:28.607   Training iter 150, batch loss 0.0424, batch acc 0.9850
20:38:28.863   Training iter 200, batch loss 0.0431, batch acc 0.9854
20:38:29.066   Training iter 250, batch loss 0.0370, batch acc 0.9900
20:38:29.264   Training iter 300, batch loss 0.0383, batch acc 0.9874
20:38:29.629   Training iter 350, batch loss 0.0428, batch acc 0.9852
20:38:29.946   Training iter 400, batch loss 0.0402, batch acc 0.9868
20:38:30.289   Training iter 450, batch loss 0.0393, batch acc 0.9882
20:38:30.576   Training iter 500, batch loss 0.0452, batch acc 0.9832
20:38:30.861   Training iter 550, batch loss 0.0426, batch acc 0.9852
20:38:31.168   Training iter 600, batch loss 0.0382, batch acc 0.9878
20:38:31.169 Training @ 14 epoch...
20:38:31.448   Training iter 50, batch loss 0.0350, batch acc 0.9902
20:38:31.733   Training iter 100, batch loss 0.0380, batch acc 0.9890
20:38:32.027   Training iter 150, batch loss 0.0357, batch acc 0.9882
20:38:32.267   Training iter 200, batch loss 0.0376, batch acc 0.9894
20:38:32.496   Training iter 250, batch loss 0.0399, batch acc 0.9854
20:38:32.725   Training iter 300, batch loss 0.0406, batch acc 0.9856
20:38:32.963   Training iter 350, batch loss 0.0384, batch acc 0.9888
20:38:33.519   Training iter 400, batch loss 0.0367, batch acc 0.9892
20:38:33.939   Training iter 450, batch loss 0.0393, batch acc 0.9858
20:38:34.220   Training iter 500, batch loss 0.0392, batch acc 0.9866
20:38:34.462   Training iter 550, batch loss 0.0368, batch acc 0.9878
20:38:34.721   Training iter 600, batch loss 0.0419, batch acc 0.9838
20:38:34.721 Training @ 15 epoch...
20:38:34.946   Training iter 50, batch loss 0.0375, batch acc 0.9878
20:38:35.166   Training iter 100, batch loss 0.0351, batch acc 0.9884
20:38:35.392   Training iter 150, batch loss 0.0372, batch acc 0.9878
20:38:35.602   Training iter 200, batch loss 0.0357, batch acc 0.9890
20:38:35.884   Training iter 250, batch loss 0.0368, batch acc 0.9888
20:38:36.103   Training iter 300, batch loss 0.0384, batch acc 0.9866
20:38:36.330   Training iter 350, batch loss 0.0342, batch acc 0.9904
20:38:36.523   Training iter 400, batch loss 0.0385, batch acc 0.9874
20:38:36.737   Training iter 450, batch loss 0.0399, batch acc 0.9858
20:38:37.036   Training iter 500, batch loss 0.0392, batch acc 0.9876
20:38:37.446   Training iter 550, batch loss 0.0386, batch acc 0.9870
20:38:37.667   Training iter 600, batch loss 0.0374, batch acc 0.9884
20:38:37.668 Testing @ 15 epoch...
20:38:37.976     Testing, total mean loss 0.04567, total acc 0.98090
20:38:37.976 Training @ 16 epoch...
20:38:38.350   Training iter 50, batch loss 0.0333, batch acc 0.9896
20:38:38.580   Training iter 100, batch loss 0.0344, batch acc 0.9888
20:38:38.828   Training iter 150, batch loss 0.0360, batch acc 0.9890
20:38:39.048   Training iter 200, batch loss 0.0350, batch acc 0.9892
20:38:39.254   Training iter 250, batch loss 0.0351, batch acc 0.9892
20:38:39.474   Training iter 300, batch loss 0.0351, batch acc 0.9894
20:38:39.710   Training iter 350, batch loss 0.0359, batch acc 0.9890
20:38:40.036   Training iter 400, batch loss 0.0352, batch acc 0.9896
20:38:40.300   Training iter 450, batch loss 0.0375, batch acc 0.9866
20:38:40.568   Training iter 500, batch loss 0.0365, batch acc 0.9884
20:38:40.801   Training iter 550, batch loss 0.0359, batch acc 0.9882
20:38:41.037   Training iter 600, batch loss 0.0402, batch acc 0.9850
20:38:41.039 Training @ 17 epoch...
20:38:41.300   Training iter 50, batch loss 0.0338, batch acc 0.9904
20:38:41.551   Training iter 100, batch loss 0.0329, batch acc 0.9918
20:38:41.824   Training iter 150, batch loss 0.0345, batch acc 0.9890
20:38:42.360   Training iter 200, batch loss 0.0327, batch acc 0.9916
20:38:42.735   Training iter 250, batch loss 0.0343, batch acc 0.9896
20:38:43.031   Training iter 300, batch loss 0.0362, batch acc 0.9892
20:38:43.388   Training iter 350, batch loss 0.0381, batch acc 0.9864
20:38:43.639   Training iter 400, batch loss 0.0363, batch acc 0.9894
20:38:43.864   Training iter 450, batch loss 0.0345, batch acc 0.9900
20:38:44.180   Training iter 500, batch loss 0.0320, batch acc 0.9900
20:38:44.530   Training iter 550, batch loss 0.0350, batch acc 0.9900
20:38:44.941   Training iter 600, batch loss 0.0352, batch acc 0.9896
20:38:44.941 Training @ 18 epoch...
20:38:45.486   Training iter 50, batch loss 0.0305, batch acc 0.9928
20:38:46.066   Training iter 100, batch loss 0.0302, batch acc 0.9920
20:38:46.418   Training iter 150, batch loss 0.0342, batch acc 0.9896
20:38:46.849   Training iter 200, batch loss 0.0335, batch acc 0.9910
20:38:47.102   Training iter 250, batch loss 0.0307, batch acc 0.9918
20:38:47.403   Training iter 300, batch loss 0.0339, batch acc 0.9900
20:38:47.671   Training iter 350, batch loss 0.0329, batch acc 0.9898
20:38:47.928   Training iter 400, batch loss 0.0351, batch acc 0.9886
20:38:48.148   Training iter 450, batch loss 0.0382, batch acc 0.9872
20:38:48.389   Training iter 500, batch loss 0.0335, batch acc 0.9884
20:38:48.642   Training iter 550, batch loss 0.0325, batch acc 0.9908
20:38:48.898   Training iter 600, batch loss 0.0368, batch acc 0.9870
20:38:48.899 Training @ 19 epoch...
20:38:49.158   Training iter 50, batch loss 0.0306, batch acc 0.9906
20:38:49.467   Training iter 100, batch loss 0.0323, batch acc 0.9928
20:38:49.667   Training iter 150, batch loss 0.0316, batch acc 0.9912
20:38:49.869   Training iter 200, batch loss 0.0320, batch acc 0.9904
20:38:50.078   Training iter 250, batch loss 0.0327, batch acc 0.9902
20:38:50.291   Training iter 300, batch loss 0.0316, batch acc 0.9904
20:38:50.593   Training iter 350, batch loss 0.0336, batch acc 0.9918
20:38:50.794   Training iter 400, batch loss 0.0323, batch acc 0.9910
20:38:51.008   Training iter 450, batch loss 0.0327, batch acc 0.9912
20:38:51.208   Training iter 500, batch loss 0.0323, batch acc 0.9902
20:38:51.416   Training iter 550, batch loss 0.0321, batch acc 0.9904
20:38:51.650   Training iter 600, batch loss 0.0363, batch acc 0.9884
20:38:51.653 Training @ 20 epoch...
20:38:51.928   Training iter 50, batch loss 0.0277, batch acc 0.9946
20:38:52.167   Training iter 100, batch loss 0.0297, batch acc 0.9932
20:38:52.423   Training iter 150, batch loss 0.0316, batch acc 0.9906
20:38:52.624   Training iter 200, batch loss 0.0329, batch acc 0.9900
20:38:52.813   Training iter 250, batch loss 0.0354, batch acc 0.9904
20:38:53.020   Training iter 300, batch loss 0.0344, batch acc 0.9892
20:38:53.229   Training iter 350, batch loss 0.0300, batch acc 0.9920
20:38:53.427   Training iter 400, batch loss 0.0310, batch acc 0.9910
20:38:53.626   Training iter 450, batch loss 0.0327, batch acc 0.9900
20:38:53.876   Training iter 500, batch loss 0.0307, batch acc 0.9916
20:38:54.132   Training iter 550, batch loss 0.0309, batch acc 0.9908
20:38:54.400   Training iter 600, batch loss 0.0329, batch acc 0.9892
20:38:54.400 Testing @ 20 epoch...
20:38:54.584     Testing, total mean loss 0.04508, total acc 0.98170
20:38:54.584 Training @ 21 epoch...
20:38:54.901   Training iter 50, batch loss 0.0287, batch acc 0.9914
20:38:55.240   Training iter 100, batch loss 0.0308, batch acc 0.9910
20:38:55.515   Training iter 150, batch loss 0.0274, batch acc 0.9944
20:38:55.854   Training iter 200, batch loss 0.0294, batch acc 0.9926
20:38:56.144   Training iter 250, batch loss 0.0322, batch acc 0.9904
20:38:56.401   Training iter 300, batch loss 0.0321, batch acc 0.9916
20:38:56.652   Training iter 350, batch loss 0.0342, batch acc 0.9886
20:38:56.999   Training iter 400, batch loss 0.0292, batch acc 0.9932
20:38:57.294   Training iter 450, batch loss 0.0328, batch acc 0.9916
20:38:57.661   Training iter 500, batch loss 0.0303, batch acc 0.9920
20:38:57.916   Training iter 550, batch loss 0.0305, batch acc 0.9908
20:38:58.186   Training iter 600, batch loss 0.0303, batch acc 0.9918
20:38:58.187 Training @ 22 epoch...
20:38:58.436   Training iter 50, batch loss 0.0294, batch acc 0.9902
20:38:58.686   Training iter 100, batch loss 0.0298, batch acc 0.9924
20:38:58.942   Training iter 150, batch loss 0.0297, batch acc 0.9920
20:38:59.215   Training iter 200, batch loss 0.0294, batch acc 0.9924
20:38:59.459   Training iter 250, batch loss 0.0303, batch acc 0.9912
20:38:59.656   Training iter 300, batch loss 0.0293, batch acc 0.9918
20:38:59.961   Training iter 350, batch loss 0.0277, batch acc 0.9932
20:39:00.227   Training iter 400, batch loss 0.0313, batch acc 0.9904
20:39:00.451   Training iter 450, batch loss 0.0311, batch acc 0.9902
20:39:00.734   Training iter 500, batch loss 0.0316, batch acc 0.9920
20:39:01.012   Training iter 550, batch loss 0.0300, batch acc 0.9910
20:39:01.229   Training iter 600, batch loss 0.0289, batch acc 0.9918
20:39:01.230 Training @ 23 epoch...
20:39:01.427   Training iter 50, batch loss 0.0256, batch acc 0.9944
20:39:01.614   Training iter 100, batch loss 0.0297, batch acc 0.9918
20:39:01.847   Training iter 150, batch loss 0.0294, batch acc 0.9920
20:39:02.103   Training iter 200, batch loss 0.0283, batch acc 0.9930
20:39:02.363   Training iter 250, batch loss 0.0270, batch acc 0.9922
20:39:02.563   Training iter 300, batch loss 0.0292, batch acc 0.9928
20:39:02.791   Training iter 350, batch loss 0.0324, batch acc 0.9898
20:39:03.050   Training iter 400, batch loss 0.0315, batch acc 0.9904
20:39:03.325   Training iter 450, batch loss 0.0303, batch acc 0.9902
20:39:03.585   Training iter 500, batch loss 0.0290, batch acc 0.9928
20:39:03.823   Training iter 550, batch loss 0.0287, batch acc 0.9936
20:39:04.055   Training iter 600, batch loss 0.0294, batch acc 0.9906
20:39:04.056 Training @ 24 epoch...
20:39:04.286   Training iter 50, batch loss 0.0274, batch acc 0.9932
20:39:04.507   Training iter 100, batch loss 0.0288, batch acc 0.9928
20:39:04.726   Training iter 150, batch loss 0.0273, batch acc 0.9938
20:39:04.989   Training iter 200, batch loss 0.0294, batch acc 0.9920
20:39:05.280   Training iter 250, batch loss 0.0270, batch acc 0.9942
20:39:05.521   Training iter 300, batch loss 0.0289, batch acc 0.9926
20:39:05.802   Training iter 350, batch loss 0.0282, batch acc 0.9932
20:39:06.121   Training iter 400, batch loss 0.0295, batch acc 0.9908
20:39:06.468   Training iter 450, batch loss 0.0315, batch acc 0.9906
20:39:06.772   Training iter 500, batch loss 0.0309, batch acc 0.9924
20:39:07.067   Training iter 550, batch loss 0.0302, batch acc 0.9898
20:39:07.460   Training iter 600, batch loss 0.0260, batch acc 0.9928
20:39:07.461 Training @ 25 epoch...
20:39:07.712   Training iter 50, batch loss 0.0244, batch acc 0.9944
20:39:08.061   Training iter 100, batch loss 0.0289, batch acc 0.9926
20:39:08.562   Training iter 150, batch loss 0.0266, batch acc 0.9934
20:39:08.883   Training iter 200, batch loss 0.0267, batch acc 0.9924
20:39:09.156   Training iter 250, batch loss 0.0276, batch acc 0.9920
20:39:09.379   Training iter 300, batch loss 0.0264, batch acc 0.9942
20:39:09.623   Training iter 350, batch loss 0.0281, batch acc 0.9930
20:39:09.865   Training iter 400, batch loss 0.0294, batch acc 0.9914
20:39:10.092   Training iter 450, batch loss 0.0270, batch acc 0.9940
20:39:10.275   Training iter 500, batch loss 0.0305, batch acc 0.9920
20:39:10.476   Training iter 550, batch loss 0.0322, batch acc 0.9906
20:39:10.669   Training iter 600, batch loss 0.0307, batch acc 0.9916
20:39:10.671 Testing @ 25 epoch...
20:39:10.774     Testing, total mean loss 0.04214, total acc 0.98310
20:39:10.774 Training @ 26 epoch...
20:39:10.988   Training iter 50, batch loss 0.0265, batch acc 0.9942
20:39:11.204   Training iter 100, batch loss 0.0271, batch acc 0.9934
20:39:11.391   Training iter 150, batch loss 0.0279, batch acc 0.9922
20:39:11.611   Training iter 200, batch loss 0.0275, batch acc 0.9928
20:39:11.863   Training iter 250, batch loss 0.0258, batch acc 0.9934
20:39:12.111   Training iter 300, batch loss 0.0267, batch acc 0.9926
20:39:12.399   Training iter 350, batch loss 0.0279, batch acc 0.9926
20:39:12.596   Training iter 400, batch loss 0.0253, batch acc 0.9942
20:39:12.809   Training iter 450, batch loss 0.0295, batch acc 0.9926
20:39:13.016   Training iter 500, batch loss 0.0264, batch acc 0.9936
20:39:13.236   Training iter 550, batch loss 0.0272, batch acc 0.9926
20:39:13.432   Training iter 600, batch loss 0.0294, batch acc 0.9924
20:39:13.432 Training @ 27 epoch...
20:39:13.615   Training iter 50, batch loss 0.0244, batch acc 0.9942
20:39:13.799   Training iter 100, batch loss 0.0270, batch acc 0.9932
20:39:14.014   Training iter 150, batch loss 0.0272, batch acc 0.9934
20:39:14.240   Training iter 200, batch loss 0.0250, batch acc 0.9956
20:39:14.448   Training iter 250, batch loss 0.0275, batch acc 0.9928
20:39:14.681   Training iter 300, batch loss 0.0268, batch acc 0.9936
20:39:14.927   Training iter 350, batch loss 0.0271, batch acc 0.9920
20:39:15.169   Training iter 400, batch loss 0.0263, batch acc 0.9918
20:39:15.375   Training iter 450, batch loss 0.0283, batch acc 0.9934
20:39:15.564   Training iter 500, batch loss 0.0278, batch acc 0.9920
20:39:15.737   Training iter 550, batch loss 0.0272, batch acc 0.9936
20:39:15.962   Training iter 600, batch loss 0.0291, batch acc 0.9914
20:39:15.964 Training @ 28 epoch...
20:39:16.205   Training iter 50, batch loss 0.0269, batch acc 0.9936
20:39:16.442   Training iter 100, batch loss 0.0246, batch acc 0.9940
20:39:16.711   Training iter 150, batch loss 0.0252, batch acc 0.9952
20:39:17.096   Training iter 200, batch loss 0.0251, batch acc 0.9942
20:39:18.034   Training iter 250, batch loss 0.0263, batch acc 0.9940
20:39:18.437   Training iter 300, batch loss 0.0277, batch acc 0.9930
20:39:18.941   Training iter 350, batch loss 0.0273, batch acc 0.9930
20:39:19.512   Training iter 400, batch loss 0.0271, batch acc 0.9940
20:39:19.869   Training iter 450, batch loss 0.0256, batch acc 0.9940
20:39:20.182   Training iter 500, batch loss 0.0284, batch acc 0.9924
20:39:20.390   Training iter 550, batch loss 0.0267, batch acc 0.9920
20:39:20.585   Training iter 600, batch loss 0.0286, batch acc 0.9940
20:39:20.586 Training @ 29 epoch...
20:39:20.863   Training iter 50, batch loss 0.0251, batch acc 0.9948
20:39:21.107   Training iter 100, batch loss 0.0290, batch acc 0.9908
20:39:21.371   Training iter 150, batch loss 0.0266, batch acc 0.9930
20:39:21.554   Training iter 200, batch loss 0.0277, batch acc 0.9918
20:39:21.745   Training iter 250, batch loss 0.0251, batch acc 0.9936
20:39:22.001   Training iter 300, batch loss 0.0242, batch acc 0.9948
20:39:22.313   Training iter 350, batch loss 0.0256, batch acc 0.9950
20:39:22.651   Training iter 400, batch loss 0.0276, batch acc 0.9920
20:39:22.913   Training iter 450, batch loss 0.0241, batch acc 0.9966
20:39:23.177   Training iter 500, batch loss 0.0265, batch acc 0.9940
20:39:23.428   Training iter 550, batch loss 0.0264, batch acc 0.9932
20:39:23.675   Training iter 600, batch loss 0.0266, batch acc 0.9932
20:39:23.677 Training @ 30 epoch...
20:39:23.996   Training iter 50, batch loss 0.0238, batch acc 0.9944
20:39:24.312   Training iter 100, batch loss 0.0262, batch acc 0.9940
20:39:24.544   Training iter 150, batch loss 0.0253, batch acc 0.9938
20:39:24.802   Training iter 200, batch loss 0.0265, batch acc 0.9940
20:39:25.066   Training iter 250, batch loss 0.0258, batch acc 0.9954
20:39:25.372   Training iter 300, batch loss 0.0229, batch acc 0.9950
20:39:25.613   Training iter 350, batch loss 0.0235, batch acc 0.9948
20:39:25.876   Training iter 400, batch loss 0.0285, batch acc 0.9914
20:39:26.156   Training iter 450, batch loss 0.0258, batch acc 0.9924
20:39:26.392   Training iter 500, batch loss 0.0259, batch acc 0.9940
20:39:27.549   Training iter 550, batch loss 0.0251, batch acc 0.9950
20:39:27.981   Training iter 600, batch loss 0.0259, batch acc 0.9936
20:39:27.983 Testing @ 30 epoch...
20:39:28.148     Testing, total mean loss 0.04123, total acc 0.98370
20:39:28.148 Training @ 31 epoch...
20:39:28.464   Training iter 50, batch loss 0.0236, batch acc 0.9932
20:39:28.827   Training iter 100, batch loss 0.0252, batch acc 0.9938
20:39:29.117   Training iter 150, batch loss 0.0248, batch acc 0.9948
20:39:29.413   Training iter 200, batch loss 0.0267, batch acc 0.9930
20:39:29.753   Training iter 250, batch loss 0.0259, batch acc 0.9936
20:39:30.065   Training iter 300, batch loss 0.0252, batch acc 0.9938
20:39:30.407   Training iter 350, batch loss 0.0247, batch acc 0.9936
20:39:30.841   Training iter 400, batch loss 0.0231, batch acc 0.9954
20:39:31.073   Training iter 450, batch loss 0.0275, batch acc 0.9924
20:39:31.415   Training iter 500, batch loss 0.0256, batch acc 0.9950
20:39:31.797   Training iter 550, batch loss 0.0265, batch acc 0.9942
20:39:32.049   Training iter 600, batch loss 0.0249, batch acc 0.9950
20:39:32.049 Training @ 32 epoch...
20:39:32.327   Training iter 50, batch loss 0.0267, batch acc 0.9940
20:39:32.567   Training iter 100, batch loss 0.0231, batch acc 0.9962
20:39:32.806   Training iter 150, batch loss 0.0231, batch acc 0.9956
20:39:33.110   Training iter 200, batch loss 0.0256, batch acc 0.9948
20:39:33.405   Training iter 250, batch loss 0.0271, batch acc 0.9928
20:39:33.706   Training iter 300, batch loss 0.0252, batch acc 0.9936
20:39:33.915   Training iter 350, batch loss 0.0233, batch acc 0.9950
20:39:34.150   Training iter 400, batch loss 0.0252, batch acc 0.9954
20:39:34.395   Training iter 450, batch loss 0.0244, batch acc 0.9940
20:39:34.717   Training iter 500, batch loss 0.0238, batch acc 0.9944
20:39:35.265   Training iter 550, batch loss 0.0261, batch acc 0.9950
20:39:35.645   Training iter 600, batch loss 0.0249, batch acc 0.9952
20:39:35.646 Training @ 33 epoch...
20:39:35.903   Training iter 50, batch loss 0.0239, batch acc 0.9948
20:39:36.138   Training iter 100, batch loss 0.0216, batch acc 0.9950
20:39:36.376   Training iter 150, batch loss 0.0239, batch acc 0.9952
20:39:36.603   Training iter 200, batch loss 0.0248, batch acc 0.9934
20:39:36.809   Training iter 250, batch loss 0.0227, batch acc 0.9962
20:39:37.018   Training iter 300, batch loss 0.0266, batch acc 0.9922
20:39:37.386   Training iter 350, batch loss 0.0249, batch acc 0.9936
20:39:37.694   Training iter 400, batch loss 0.0229, batch acc 0.9956
20:39:37.949   Training iter 450, batch loss 0.0241, batch acc 0.9946
20:39:38.142   Training iter 500, batch loss 0.0227, batch acc 0.9952
20:39:38.333   Training iter 550, batch loss 0.0269, batch acc 0.9934
20:39:38.550   Training iter 600, batch loss 0.0251, batch acc 0.9932
20:39:38.551 Training @ 34 epoch...
20:39:39.039   Training iter 50, batch loss 0.0234, batch acc 0.9942
20:39:39.616   Training iter 100, batch loss 0.0230, batch acc 0.9950
20:39:40.026   Training iter 150, batch loss 0.0222, batch acc 0.9958
20:39:40.469   Training iter 200, batch loss 0.0223, batch acc 0.9952
20:39:40.766   Training iter 250, batch loss 0.0238, batch acc 0.9954
20:39:41.099   Training iter 300, batch loss 0.0238, batch acc 0.9948
20:39:41.357   Training iter 350, batch loss 0.0227, batch acc 0.9938
20:39:41.618   Training iter 400, batch loss 0.0233, batch acc 0.9956
20:39:41.965   Training iter 450, batch loss 0.0253, batch acc 0.9940
20:39:42.260   Training iter 500, batch loss 0.0241, batch acc 0.9928
20:39:42.879   Training iter 550, batch loss 0.0246, batch acc 0.9958
20:39:43.228   Training iter 600, batch loss 0.0263, batch acc 0.9936
20:39:43.229 Training @ 35 epoch...
20:39:43.470   Training iter 50, batch loss 0.0235, batch acc 0.9944
20:39:43.715   Training iter 100, batch loss 0.0217, batch acc 0.9958
20:39:44.048   Training iter 150, batch loss 0.0241, batch acc 0.9940
20:39:44.408   Training iter 200, batch loss 0.0230, batch acc 0.9956
20:39:44.669   Training iter 250, batch loss 0.0230, batch acc 0.9952
20:39:44.945   Training iter 300, batch loss 0.0258, batch acc 0.9958
20:39:45.226   Training iter 350, batch loss 0.0237, batch acc 0.9952
20:39:45.465   Training iter 400, batch loss 0.0227, batch acc 0.9954
20:39:45.737   Training iter 450, batch loss 0.0227, batch acc 0.9958
20:39:46.031   Training iter 500, batch loss 0.0248, batch acc 0.9946
20:39:46.227   Training iter 550, batch loss 0.0236, batch acc 0.9948
20:39:46.473   Training iter 600, batch loss 0.0255, batch acc 0.9940
20:39:46.473 Testing @ 35 epoch...
20:39:46.569     Testing, total mean loss 0.03974, total acc 0.98320
20:39:46.569 Training @ 36 epoch...
20:39:46.807   Training iter 50, batch loss 0.0217, batch acc 0.9952
20:39:47.049   Training iter 100, batch loss 0.0224, batch acc 0.9950
20:39:47.294   Training iter 150, batch loss 0.0205, batch acc 0.9970
20:39:47.516   Training iter 200, batch loss 0.0244, batch acc 0.9938
20:39:47.761   Training iter 250, batch loss 0.0228, batch acc 0.9952
20:39:48.129   Training iter 300, batch loss 0.0249, batch acc 0.9948
20:39:48.897   Training iter 350, batch loss 0.0237, batch acc 0.9934
20:39:49.258   Training iter 400, batch loss 0.0237, batch acc 0.9954
20:39:49.651   Training iter 450, batch loss 0.0255, batch acc 0.9932
20:39:50.295   Training iter 500, batch loss 0.0227, batch acc 0.9966
20:39:50.527   Training iter 550, batch loss 0.0231, batch acc 0.9932
20:39:50.770   Training iter 600, batch loss 0.0241, batch acc 0.9942
20:39:50.770 Training @ 37 epoch...
20:39:51.166   Training iter 50, batch loss 0.0220, batch acc 0.9958
20:39:51.537   Training iter 100, batch loss 0.0235, batch acc 0.9948
20:39:51.848   Training iter 150, batch loss 0.0218, batch acc 0.9962
20:39:52.243   Training iter 200, batch loss 0.0210, batch acc 0.9970
20:39:52.599   Training iter 250, batch loss 0.0245, batch acc 0.9932
20:39:52.948   Training iter 300, batch loss 0.0226, batch acc 0.9954
20:39:53.213   Training iter 350, batch loss 0.0231, batch acc 0.9952
20:39:53.619   Training iter 400, batch loss 0.0232, batch acc 0.9948
20:39:53.911   Training iter 450, batch loss 0.0243, batch acc 0.9938
20:39:54.220   Training iter 500, batch loss 0.0224, batch acc 0.9974
20:39:54.491   Training iter 550, batch loss 0.0252, batch acc 0.9946
20:39:54.760   Training iter 600, batch loss 0.0233, batch acc 0.9958
20:39:54.762 Training @ 38 epoch...
20:39:55.035   Training iter 50, batch loss 0.0214, batch acc 0.9968
20:39:55.293   Training iter 100, batch loss 0.0217, batch acc 0.9966
20:39:55.606   Training iter 150, batch loss 0.0207, batch acc 0.9956
20:39:55.831   Training iter 200, batch loss 0.0243, batch acc 0.9948
20:39:56.091   Training iter 250, batch loss 0.0231, batch acc 0.9952
20:39:56.335   Training iter 300, batch loss 0.0234, batch acc 0.9946
20:39:56.558   Training iter 350, batch loss 0.0220, batch acc 0.9960
20:39:56.922   Training iter 400, batch loss 0.0265, batch acc 0.9926
20:39:57.416   Training iter 450, batch loss 0.0226, batch acc 0.9954
20:39:58.533   Training iter 500, batch loss 0.0229, batch acc 0.9936
20:39:58.898   Training iter 550, batch loss 0.0240, batch acc 0.9938
20:39:59.395   Training iter 600, batch loss 0.0224, batch acc 0.9956
20:39:59.398 Training @ 39 epoch...
20:39:59.655   Training iter 50, batch loss 0.0211, batch acc 0.9960
20:39:59.941   Training iter 100, batch loss 0.0222, batch acc 0.9950
20:40:00.254   Training iter 150, batch loss 0.0243, batch acc 0.9944
20:40:00.804   Training iter 200, batch loss 0.0212, batch acc 0.9964
20:40:01.318   Training iter 250, batch loss 0.0241, batch acc 0.9930
20:40:01.563   Training iter 300, batch loss 0.0224, batch acc 0.9948
20:40:01.808   Training iter 350, batch loss 0.0224, batch acc 0.9954
20:40:02.025   Training iter 400, batch loss 0.0238, batch acc 0.9962
20:40:02.666   Training iter 450, batch loss 0.0236, batch acc 0.9944
20:40:02.996   Training iter 500, batch loss 0.0220, batch acc 0.9950
20:40:03.291   Training iter 550, batch loss 0.0239, batch acc 0.9948
20:40:03.604   Training iter 600, batch loss 0.0233, batch acc 0.9944
20:40:03.607 Training @ 40 epoch...
20:40:03.897   Training iter 50, batch loss 0.0225, batch acc 0.9960
20:40:04.268   Training iter 100, batch loss 0.0207, batch acc 0.9974
20:40:04.598   Training iter 150, batch loss 0.0227, batch acc 0.9952
20:40:04.948   Training iter 200, batch loss 0.0215, batch acc 0.9956
20:40:05.331   Training iter 250, batch loss 0.0215, batch acc 0.9960
20:40:05.621   Training iter 300, batch loss 0.0238, batch acc 0.9936
20:40:05.945   Training iter 350, batch loss 0.0193, batch acc 0.9966
20:40:06.216   Training iter 400, batch loss 0.0230, batch acc 0.9952
20:40:06.461   Training iter 450, batch loss 0.0229, batch acc 0.9954
20:40:06.688   Training iter 500, batch loss 0.0206, batch acc 0.9958
20:40:07.115   Training iter 550, batch loss 0.0231, batch acc 0.9946
20:40:07.551   Training iter 600, batch loss 0.0245, batch acc 0.9930
20:40:07.553 Testing @ 40 epoch...
20:40:07.681     Testing, total mean loss 0.03867, total acc 0.98440
20:40:07.681 Training @ 41 epoch...
20:40:07.980   Training iter 50, batch loss 0.0205, batch acc 0.9958
20:40:08.260   Training iter 100, batch loss 0.0210, batch acc 0.9960
20:40:08.514   Training iter 150, batch loss 0.0215, batch acc 0.9954
20:40:08.854   Training iter 200, batch loss 0.0216, batch acc 0.9952
20:40:09.166   Training iter 250, batch loss 0.0231, batch acc 0.9964
20:40:09.674   Training iter 300, batch loss 0.0205, batch acc 0.9964
20:40:10.006   Training iter 350, batch loss 0.0223, batch acc 0.9966
20:40:10.440   Training iter 400, batch loss 0.0222, batch acc 0.9954
20:40:10.855   Training iter 450, batch loss 0.0237, batch acc 0.9928
20:40:11.335   Training iter 500, batch loss 0.0215, batch acc 0.9960
20:40:11.617   Training iter 550, batch loss 0.0240, batch acc 0.9954
20:40:11.919   Training iter 600, batch loss 0.0236, batch acc 0.9956
20:40:11.921 Training @ 42 epoch...
20:40:12.253   Training iter 50, batch loss 0.0204, batch acc 0.9958
20:40:12.586   Training iter 100, batch loss 0.0209, batch acc 0.9956
20:40:12.978   Training iter 150, batch loss 0.0219, batch acc 0.9956
20:40:13.201   Training iter 200, batch loss 0.0223, batch acc 0.9946
20:40:13.742   Training iter 250, batch loss 0.0227, batch acc 0.9954
20:40:14.015   Training iter 300, batch loss 0.0205, batch acc 0.9966
20:40:14.297   Training iter 350, batch loss 0.0216, batch acc 0.9958
20:40:14.645   Training iter 400, batch loss 0.0210, batch acc 0.9964
20:40:14.992   Training iter 450, batch loss 0.0223, batch acc 0.9934
20:40:15.332   Training iter 500, batch loss 0.0215, batch acc 0.9962
20:40:15.681   Training iter 550, batch loss 0.0213, batch acc 0.9954
20:40:15.945   Training iter 600, batch loss 0.0233, batch acc 0.9946
20:40:15.948 Training @ 43 epoch...
20:40:16.212   Training iter 50, batch loss 0.0199, batch acc 0.9962
20:40:16.469   Training iter 100, batch loss 0.0203, batch acc 0.9962
20:40:16.708   Training iter 150, batch loss 0.0212, batch acc 0.9958
20:40:16.967   Training iter 200, batch loss 0.0205, batch acc 0.9956
20:40:17.217   Training iter 250, batch loss 0.0230, batch acc 0.9940
20:40:17.504   Training iter 300, batch loss 0.0198, batch acc 0.9956
20:40:17.784   Training iter 350, batch loss 0.0248, batch acc 0.9932
20:40:18.059   Training iter 400, batch loss 0.0214, batch acc 0.9952
20:40:18.344   Training iter 450, batch loss 0.0219, batch acc 0.9962
20:40:18.589   Training iter 500, batch loss 0.0221, batch acc 0.9958
20:40:18.778   Training iter 550, batch loss 0.0225, batch acc 0.9950
20:40:18.979   Training iter 600, batch loss 0.0230, batch acc 0.9966
20:40:18.979 Training @ 44 epoch...
20:40:19.191   Training iter 50, batch loss 0.0192, batch acc 0.9952
20:40:19.436   Training iter 100, batch loss 0.0224, batch acc 0.9944
20:40:19.651   Training iter 150, batch loss 0.0190, batch acc 0.9968
20:40:19.865   Training iter 200, batch loss 0.0220, batch acc 0.9966
20:40:20.083   Training iter 250, batch loss 0.0217, batch acc 0.9946
20:40:20.296   Training iter 300, batch loss 0.0193, batch acc 0.9960
20:40:20.544   Training iter 350, batch loss 0.0237, batch acc 0.9952
20:40:20.818   Training iter 400, batch loss 0.0199, batch acc 0.9966
20:40:21.159   Training iter 450, batch loss 0.0227, batch acc 0.9960
20:40:21.445   Training iter 500, batch loss 0.0227, batch acc 0.9958
20:40:21.663   Training iter 550, batch loss 0.0226, batch acc 0.9956
20:40:21.900   Training iter 600, batch loss 0.0210, batch acc 0.9956
20:40:21.902 Training @ 45 epoch...
20:40:22.109   Training iter 50, batch loss 0.0187, batch acc 0.9984
20:40:22.324   Training iter 100, batch loss 0.0210, batch acc 0.9954
20:40:22.533   Training iter 150, batch loss 0.0212, batch acc 0.9958
20:40:22.764   Training iter 200, batch loss 0.0205, batch acc 0.9954
20:40:22.968   Training iter 250, batch loss 0.0222, batch acc 0.9946
20:40:23.207   Training iter 300, batch loss 0.0186, batch acc 0.9964
20:40:23.457   Training iter 350, batch loss 0.0228, batch acc 0.9948
20:40:23.881   Training iter 400, batch loss 0.0213, batch acc 0.9964
20:40:24.170   Training iter 450, batch loss 0.0224, batch acc 0.9944
20:40:24.414   Training iter 500, batch loss 0.0207, batch acc 0.9960
20:40:24.612   Training iter 550, batch loss 0.0204, batch acc 0.9956
20:40:24.835   Training iter 600, batch loss 0.0212, batch acc 0.9960
20:40:24.837 Testing @ 45 epoch...
20:40:24.950     Testing, total mean loss 0.03908, total acc 0.98490
20:40:24.950 Training @ 46 epoch...
20:40:25.171   Training iter 50, batch loss 0.0200, batch acc 0.9958
20:40:25.529   Training iter 100, batch loss 0.0180, batch acc 0.9970
20:40:25.767   Training iter 150, batch loss 0.0207, batch acc 0.9964
20:40:26.664   Training iter 200, batch loss 0.0199, batch acc 0.9962
20:40:27.036   Training iter 250, batch loss 0.0205, batch acc 0.9960
20:40:27.346   Training iter 300, batch loss 0.0199, batch acc 0.9952
20:40:27.602   Training iter 350, batch loss 0.0197, batch acc 0.9956
20:40:27.833   Training iter 400, batch loss 0.0218, batch acc 0.9958
20:40:28.090   Training iter 450, batch loss 0.0226, batch acc 0.9950
20:40:28.309   Training iter 500, batch loss 0.0219, batch acc 0.9950
20:40:28.515   Training iter 550, batch loss 0.0231, batch acc 0.9944
20:40:28.743   Training iter 600, batch loss 0.0219, batch acc 0.9962
20:40:28.744 Training @ 47 epoch...
20:40:28.985   Training iter 50, batch loss 0.0203, batch acc 0.9968
20:40:29.210   Training iter 100, batch loss 0.0216, batch acc 0.9948
20:40:29.452   Training iter 150, batch loss 0.0211, batch acc 0.9962
20:40:29.705   Training iter 200, batch loss 0.0205, batch acc 0.9970
20:40:29.947   Training iter 250, batch loss 0.0199, batch acc 0.9960
20:40:30.232   Training iter 300, batch loss 0.0195, batch acc 0.9964
20:40:30.465   Training iter 350, batch loss 0.0219, batch acc 0.9960
20:40:30.678   Training iter 400, batch loss 0.0218, batch acc 0.9950
20:40:30.910   Training iter 450, batch loss 0.0193, batch acc 0.9968
20:40:31.151   Training iter 500, batch loss 0.0211, batch acc 0.9952
20:40:31.379   Training iter 550, batch loss 0.0219, batch acc 0.9958
20:40:31.589   Training iter 600, batch loss 0.0217, batch acc 0.9962
20:40:31.590 Training @ 48 epoch...
20:40:31.790   Training iter 50, batch loss 0.0198, batch acc 0.9970
20:40:32.018   Training iter 100, batch loss 0.0204, batch acc 0.9962
20:40:32.226   Training iter 150, batch loss 0.0214, batch acc 0.9958
20:40:32.450   Training iter 200, batch loss 0.0209, batch acc 0.9962
20:40:32.680   Training iter 250, batch loss 0.0197, batch acc 0.9970
20:40:32.942   Training iter 300, batch loss 0.0203, batch acc 0.9964
20:40:33.221   Training iter 350, batch loss 0.0223, batch acc 0.9958
20:40:33.412   Training iter 400, batch loss 0.0215, batch acc 0.9964
20:40:33.618   Training iter 450, batch loss 0.0213, batch acc 0.9958
20:40:33.872   Training iter 500, batch loss 0.0227, batch acc 0.9950
20:40:34.085   Training iter 550, batch loss 0.0190, batch acc 0.9952
20:40:34.429   Training iter 600, batch loss 0.0200, batch acc 0.9948
20:40:34.431 Training @ 49 epoch...
20:40:34.629   Training iter 50, batch loss 0.0200, batch acc 0.9958
20:40:34.818   Training iter 100, batch loss 0.0183, batch acc 0.9972
20:40:35.014   Training iter 150, batch loss 0.0198, batch acc 0.9966
20:40:35.264   Training iter 200, batch loss 0.0187, batch acc 0.9968
20:40:35.503   Training iter 250, batch loss 0.0218, batch acc 0.9962
20:40:35.715   Training iter 300, batch loss 0.0192, batch acc 0.9968
20:40:36.037   Training iter 350, batch loss 0.0211, batch acc 0.9950
20:40:36.252   Training iter 400, batch loss 0.0196, batch acc 0.9968
20:40:36.492   Training iter 450, batch loss 0.0212, batch acc 0.9956
20:40:36.701   Training iter 500, batch loss 0.0220, batch acc 0.9956
20:40:36.929   Training iter 550, batch loss 0.0214, batch acc 0.9952
20:40:37.160   Training iter 600, batch loss 0.0214, batch acc 0.9966
20:40:37.162 Training @ 50 epoch...
20:40:37.622   Training iter 50, batch loss 0.0195, batch acc 0.9958
20:40:37.935   Training iter 100, batch loss 0.0194, batch acc 0.9962
20:40:38.212   Training iter 150, batch loss 0.0195, batch acc 0.9966
20:40:38.622   Training iter 200, batch loss 0.0189, batch acc 0.9958
20:40:39.077   Training iter 250, batch loss 0.0194, batch acc 0.9972
20:40:39.353   Training iter 300, batch loss 0.0189, batch acc 0.9970
20:40:39.557   Training iter 350, batch loss 0.0205, batch acc 0.9956
20:40:39.768   Training iter 400, batch loss 0.0223, batch acc 0.9964
20:40:40.037   Training iter 450, batch loss 0.0200, batch acc 0.9966
20:40:40.295   Training iter 500, batch loss 0.0199, batch acc 0.9970
20:40:40.571   Training iter 550, batch loss 0.0219, batch acc 0.9944
20:40:40.777   Training iter 600, batch loss 0.0201, batch acc 0.9964
20:40:40.780 Testing @ 50 epoch...
20:40:40.906     Testing, total mean loss 0.03872, total acc 0.98440
20:40:40.906 Training @ 51 epoch...
20:40:41.189   Training iter 50, batch loss 0.0177, batch acc 0.9976
20:40:41.496   Training iter 100, batch loss 0.0182, batch acc 0.9966
20:40:41.781   Training iter 150, batch loss 0.0212, batch acc 0.9958
20:40:41.986   Training iter 200, batch loss 0.0201, batch acc 0.9962
20:40:42.211   Training iter 250, batch loss 0.0201, batch acc 0.9960
20:40:42.472   Training iter 300, batch loss 0.0205, batch acc 0.9970
20:40:42.684   Training iter 350, batch loss 0.0190, batch acc 0.9972
20:40:42.920   Training iter 400, batch loss 0.0190, batch acc 0.9972
20:40:43.158   Training iter 450, batch loss 0.0210, batch acc 0.9958
20:40:43.415   Training iter 500, batch loss 0.0208, batch acc 0.9958
20:40:43.615   Training iter 550, batch loss 0.0218, batch acc 0.9960
20:40:43.831   Training iter 600, batch loss 0.0208, batch acc 0.9962
20:40:43.833 Training @ 52 epoch...
20:40:44.070   Training iter 50, batch loss 0.0192, batch acc 0.9960
20:40:45.084   Training iter 100, batch loss 0.0173, batch acc 0.9972
20:40:45.472   Training iter 150, batch loss 0.0182, batch acc 0.9970
20:40:45.676   Training iter 200, batch loss 0.0185, batch acc 0.9972
20:40:45.898   Training iter 250, batch loss 0.0190, batch acc 0.9974
20:40:46.287   Training iter 300, batch loss 0.0201, batch acc 0.9966
20:40:46.605   Training iter 350, batch loss 0.0199, batch acc 0.9960
20:40:46.842   Training iter 400, batch loss 0.0221, batch acc 0.9954
20:40:47.094   Training iter 450, batch loss 0.0211, batch acc 0.9962
20:40:47.366   Training iter 500, batch loss 0.0209, batch acc 0.9966
20:40:47.581   Training iter 550, batch loss 0.0201, batch acc 0.9968
20:40:47.813   Training iter 600, batch loss 0.0222, batch acc 0.9946
20:40:47.813 Training @ 53 epoch...
20:40:48.072   Training iter 50, batch loss 0.0164, batch acc 0.9986
20:40:48.297   Training iter 100, batch loss 0.0189, batch acc 0.9962
20:40:48.522   Training iter 150, batch loss 0.0208, batch acc 0.9958
20:40:48.726   Training iter 200, batch loss 0.0197, batch acc 0.9972
20:40:48.986   Training iter 250, batch loss 0.0209, batch acc 0.9960
20:40:49.298   Training iter 300, batch loss 0.0211, batch acc 0.9960
20:40:49.546   Training iter 350, batch loss 0.0194, batch acc 0.9972
20:40:49.791   Training iter 400, batch loss 0.0190, batch acc 0.9970
20:40:50.103   Training iter 450, batch loss 0.0202, batch acc 0.9960
20:40:50.363   Training iter 500, batch loss 0.0186, batch acc 0.9968
20:40:50.657   Training iter 550, batch loss 0.0209, batch acc 0.9956
20:40:50.883   Training iter 600, batch loss 0.0200, batch acc 0.9962
20:40:50.884 Training @ 54 epoch...
20:40:51.120   Training iter 50, batch loss 0.0193, batch acc 0.9972
20:40:51.392   Training iter 100, batch loss 0.0205, batch acc 0.9956
20:40:51.644   Training iter 150, batch loss 0.0187, batch acc 0.9960
20:40:51.853   Training iter 200, batch loss 0.0186, batch acc 0.9966
20:40:52.096   Training iter 250, batch loss 0.0197, batch acc 0.9952
20:40:52.337   Training iter 300, batch loss 0.0191, batch acc 0.9970
20:40:52.542   Training iter 350, batch loss 0.0204, batch acc 0.9960
20:40:52.768   Training iter 400, batch loss 0.0203, batch acc 0.9972
20:40:53.044   Training iter 450, batch loss 0.0191, batch acc 0.9968
20:40:53.326   Training iter 500, batch loss 0.0208, batch acc 0.9958
20:40:53.603   Training iter 550, batch loss 0.0189, batch acc 0.9972
20:40:53.857   Training iter 600, batch loss 0.0200, batch acc 0.9968
20:40:53.858 Training @ 55 epoch...
20:40:54.103   Training iter 50, batch loss 0.0199, batch acc 0.9954
20:40:54.354   Training iter 100, batch loss 0.0186, batch acc 0.9972
20:40:54.546   Training iter 150, batch loss 0.0149, batch acc 0.9984
20:40:54.736   Training iter 200, batch loss 0.0181, batch acc 0.9968
20:40:54.996   Training iter 250, batch loss 0.0194, batch acc 0.9968
20:40:55.219   Training iter 300, batch loss 0.0194, batch acc 0.9964
20:40:55.466   Training iter 350, batch loss 0.0212, batch acc 0.9952
20:40:55.717   Training iter 400, batch loss 0.0219, batch acc 0.9960
20:40:56.104   Training iter 450, batch loss 0.0217, batch acc 0.9962
20:40:56.364   Training iter 500, batch loss 0.0183, batch acc 0.9974
20:40:56.712   Training iter 550, batch loss 0.0209, batch acc 0.9954
20:40:56.973   Training iter 600, batch loss 0.0189, batch acc 0.9968
20:40:56.976 Testing @ 55 epoch...
20:40:57.101     Testing, total mean loss 0.03757, total acc 0.98550
20:40:57.101 Training @ 56 epoch...
20:40:57.313   Training iter 50, batch loss 0.0178, batch acc 0.9974
20:40:57.527   Training iter 100, batch loss 0.0188, batch acc 0.9966
20:40:57.745   Training iter 150, batch loss 0.0174, batch acc 0.9974
20:40:57.963   Training iter 200, batch loss 0.0205, batch acc 0.9960
20:40:58.213   Training iter 250, batch loss 0.0185, batch acc 0.9964
20:40:58.446   Training iter 300, batch loss 0.0202, batch acc 0.9964
20:40:58.686   Training iter 350, batch loss 0.0163, batch acc 0.9992
20:40:58.957   Training iter 400, batch loss 0.0220, batch acc 0.9944
20:40:59.350   Training iter 450, batch loss 0.0192, batch acc 0.9974
20:40:59.727   Training iter 500, batch loss 0.0182, batch acc 0.9966
20:40:59.963   Training iter 550, batch loss 0.0201, batch acc 0.9954
20:41:00.268   Training iter 600, batch loss 0.0209, batch acc 0.9956
20:41:00.270 Training @ 57 epoch...
20:41:00.523   Training iter 50, batch loss 0.0170, batch acc 0.9970
20:41:00.778   Training iter 100, batch loss 0.0179, batch acc 0.9968
20:41:01.036   Training iter 150, batch loss 0.0184, batch acc 0.9976
20:41:01.325   Training iter 200, batch loss 0.0199, batch acc 0.9956
20:41:01.604   Training iter 250, batch loss 0.0180, batch acc 0.9982
20:41:01.927   Training iter 300, batch loss 0.0176, batch acc 0.9978
20:41:02.197   Training iter 350, batch loss 0.0187, batch acc 0.9960
20:41:02.491   Training iter 400, batch loss 0.0198, batch acc 0.9968
20:41:02.781   Training iter 450, batch loss 0.0205, batch acc 0.9964
20:41:03.005   Training iter 500, batch loss 0.0196, batch acc 0.9966
20:41:03.221   Training iter 550, batch loss 0.0204, batch acc 0.9966
20:41:03.467   Training iter 600, batch loss 0.0216, batch acc 0.9950
20:41:03.467 Training @ 58 epoch...
20:41:03.692   Training iter 50, batch loss 0.0198, batch acc 0.9960
20:41:03.920   Training iter 100, batch loss 0.0167, batch acc 0.9974
20:41:04.117   Training iter 150, batch loss 0.0182, batch acc 0.9974
20:41:04.389   Training iter 200, batch loss 0.0173, batch acc 0.9982
20:41:04.667   Training iter 250, batch loss 0.0181, batch acc 0.9974
20:41:05.005   Training iter 300, batch loss 0.0200, batch acc 0.9950
20:41:05.304   Training iter 350, batch loss 0.0198, batch acc 0.9962
20:41:05.622   Training iter 400, batch loss 0.0218, batch acc 0.9952
20:41:05.847   Training iter 450, batch loss 0.0177, batch acc 0.9976
20:41:06.123   Training iter 500, batch loss 0.0202, batch acc 0.9970
20:41:06.345   Training iter 550, batch loss 0.0191, batch acc 0.9966
20:41:06.651   Training iter 600, batch loss 0.0191, batch acc 0.9956
20:41:06.652 Training @ 59 epoch...
20:41:06.886   Training iter 50, batch loss 0.0188, batch acc 0.9954
20:41:07.110   Training iter 100, batch loss 0.0187, batch acc 0.9966
20:41:08.051   Training iter 150, batch loss 0.0171, batch acc 0.9970
20:41:08.412   Training iter 200, batch loss 0.0188, batch acc 0.9966
20:41:08.691   Training iter 250, batch loss 0.0189, batch acc 0.9968
20:41:08.950   Training iter 300, batch loss 0.0191, batch acc 0.9960
20:41:09.227   Training iter 350, batch loss 0.0195, batch acc 0.9968
20:41:09.452   Training iter 400, batch loss 0.0191, batch acc 0.9960
20:41:09.771   Training iter 450, batch loss 0.0199, batch acc 0.9964
20:41:09.999   Training iter 500, batch loss 0.0183, batch acc 0.9978
20:41:10.226   Training iter 550, batch loss 0.0186, batch acc 0.9970
20:41:10.426   Training iter 600, batch loss 0.0203, batch acc 0.9966
20:41:10.428 Training @ 60 epoch...
20:41:10.723   Training iter 50, batch loss 0.0155, batch acc 0.9982
20:41:10.995   Training iter 100, batch loss 0.0170, batch acc 0.9974
20:41:11.237   Training iter 150, batch loss 0.0200, batch acc 0.9956
20:41:11.510   Training iter 200, batch loss 0.0193, batch acc 0.9972
20:41:11.739   Training iter 250, batch loss 0.0185, batch acc 0.9976
20:41:12.065   Training iter 300, batch loss 0.0183, batch acc 0.9978
20:41:12.297   Training iter 350, batch loss 0.0193, batch acc 0.9966
20:41:12.521   Training iter 400, batch loss 0.0183, batch acc 0.9970
20:41:12.765   Training iter 450, batch loss 0.0215, batch acc 0.9962
20:41:13.008   Training iter 500, batch loss 0.0213, batch acc 0.9950
20:41:13.256   Training iter 550, batch loss 0.0191, batch acc 0.9964
20:41:13.515   Training iter 600, batch loss 0.0184, batch acc 0.9972
20:41:13.516 Testing @ 60 epoch...
20:41:13.678     Testing, total mean loss 0.03794, total acc 0.98470
20:41:13.678 Training @ 61 epoch...
20:41:13.952   Training iter 50, batch loss 0.0170, batch acc 0.9976
20:41:14.238   Training iter 100, batch loss 0.0169, batch acc 0.9970
20:41:14.470   Training iter 150, batch loss 0.0178, batch acc 0.9978
20:41:14.737   Training iter 200, batch loss 0.0166, batch acc 0.9970
20:41:15.038   Training iter 250, batch loss 0.0173, batch acc 0.9976
20:41:15.252   Training iter 300, batch loss 0.0195, batch acc 0.9952
20:41:15.445   Training iter 350, batch loss 0.0194, batch acc 0.9962
20:41:15.653   Training iter 400, batch loss 0.0211, batch acc 0.9970
20:41:15.844   Training iter 450, batch loss 0.0197, batch acc 0.9960
20:41:16.039   Training iter 500, batch loss 0.0198, batch acc 0.9956
20:41:16.271   Training iter 550, batch loss 0.0194, batch acc 0.9968
20:41:16.511   Training iter 600, batch loss 0.0193, batch acc 0.9978
20:41:16.513 Training @ 62 epoch...
20:41:16.756   Training iter 50, batch loss 0.0177, batch acc 0.9964
20:41:17.031   Training iter 100, batch loss 0.0186, batch acc 0.9974
20:41:17.406   Training iter 150, batch loss 0.0169, batch acc 0.9978
20:41:17.604   Training iter 200, batch loss 0.0193, batch acc 0.9966
20:41:17.861   Training iter 250, batch loss 0.0182, batch acc 0.9980
20:41:18.083   Training iter 300, batch loss 0.0190, batch acc 0.9980
20:41:18.301   Training iter 350, batch loss 0.0189, batch acc 0.9958
20:41:18.499   Training iter 400, batch loss 0.0173, batch acc 0.9968
20:41:18.699   Training iter 450, batch loss 0.0201, batch acc 0.9964
20:41:18.908   Training iter 500, batch loss 0.0214, batch acc 0.9952
20:41:19.117   Training iter 550, batch loss 0.0191, batch acc 0.9968
20:41:19.352   Training iter 600, batch loss 0.0185, batch acc 0.9966
20:41:19.354 Training @ 63 epoch...
20:41:19.593   Training iter 50, batch loss 0.0169, batch acc 0.9980
20:41:19.852   Training iter 100, batch loss 0.0174, batch acc 0.9964
20:41:20.098   Training iter 150, batch loss 0.0193, batch acc 0.9956
20:41:20.328   Training iter 200, batch loss 0.0187, batch acc 0.9964
20:41:20.544   Training iter 250, batch loss 0.0180, batch acc 0.9964
20:41:20.797   Training iter 300, batch loss 0.0195, batch acc 0.9970
20:41:21.044   Training iter 350, batch loss 0.0165, batch acc 0.9984
20:41:21.266   Training iter 400, batch loss 0.0179, batch acc 0.9980
20:41:21.516   Training iter 450, batch loss 0.0181, batch acc 0.9972
20:41:21.873   Training iter 500, batch loss 0.0186, batch acc 0.9972
20:41:22.193   Training iter 550, batch loss 0.0194, batch acc 0.9966
20:41:22.468   Training iter 600, batch loss 0.0217, batch acc 0.9944
20:41:22.470 Training @ 64 epoch...
20:41:22.858   Training iter 50, batch loss 0.0167, batch acc 0.9964
20:41:23.154   Training iter 100, batch loss 0.0179, batch acc 0.9966
20:41:23.389   Training iter 150, batch loss 0.0166, batch acc 0.9970
20:41:23.675   Training iter 200, batch loss 0.0174, batch acc 0.9970
20:41:23.969   Training iter 250, batch loss 0.0185, batch acc 0.9976
20:41:24.204   Training iter 300, batch loss 0.0194, batch acc 0.9968
20:41:24.436   Training iter 350, batch loss 0.0180, batch acc 0.9970
20:41:24.656   Training iter 400, batch loss 0.0192, batch acc 0.9968
20:41:24.900   Training iter 450, batch loss 0.0179, batch acc 0.9968
20:41:25.180   Training iter 500, batch loss 0.0181, batch acc 0.9984
20:41:25.429   Training iter 550, batch loss 0.0179, batch acc 0.9972
20:41:25.685   Training iter 600, batch loss 0.0218, batch acc 0.9946
20:41:25.686 Training @ 65 epoch...
20:41:25.931   Training iter 50, batch loss 0.0201, batch acc 0.9954
20:41:26.172   Training iter 100, batch loss 0.0168, batch acc 0.9974
20:41:26.387   Training iter 150, batch loss 0.0172, batch acc 0.9978
20:41:26.653   Training iter 200, batch loss 0.0170, batch acc 0.9978
20:41:26.906   Training iter 250, batch loss 0.0178, batch acc 0.9972
20:41:27.132   Training iter 300, batch loss 0.0164, batch acc 0.9980
20:41:27.349   Training iter 350, batch loss 0.0176, batch acc 0.9966
20:41:27.593   Training iter 400, batch loss 0.0189, batch acc 0.9972
20:41:27.825   Training iter 450, batch loss 0.0210, batch acc 0.9948
20:41:28.101   Training iter 500, batch loss 0.0205, batch acc 0.9960
20:41:28.463   Training iter 550, batch loss 0.0188, batch acc 0.9968
20:41:28.704   Training iter 600, batch loss 0.0183, batch acc 0.9968
20:41:28.705 Testing @ 65 epoch...
20:41:28.797     Testing, total mean loss 0.03740, total acc 0.98560
20:41:28.798 Training @ 66 epoch...
20:41:29.033   Training iter 50, batch loss 0.0166, batch acc 0.9980
20:41:29.265   Training iter 100, batch loss 0.0175, batch acc 0.9976
20:41:29.555   Training iter 150, batch loss 0.0205, batch acc 0.9948
20:41:29.754   Training iter 200, batch loss 0.0191, batch acc 0.9966
20:41:29.996   Training iter 250, batch loss 0.0182, batch acc 0.9964
20:41:30.219   Training iter 300, batch loss 0.0179, batch acc 0.9972
20:41:30.428   Training iter 350, batch loss 0.0176, batch acc 0.9972
20:41:30.626   Training iter 400, batch loss 0.0178, batch acc 0.9970
20:41:30.907   Training iter 450, batch loss 0.0169, batch acc 0.9986
20:41:31.152   Training iter 500, batch loss 0.0196, batch acc 0.9962
20:41:31.409   Training iter 550, batch loss 0.0191, batch acc 0.9964
20:41:31.643   Training iter 600, batch loss 0.0175, batch acc 0.9972
20:41:31.643 Training @ 67 epoch...
20:41:31.841   Training iter 50, batch loss 0.0174, batch acc 0.9972
20:41:32.079   Training iter 100, batch loss 0.0155, batch acc 0.9978
20:41:32.303   Training iter 150, batch loss 0.0174, batch acc 0.9968
20:41:32.585   Training iter 200, batch loss 0.0180, batch acc 0.9968
20:41:32.809   Training iter 250, batch loss 0.0183, batch acc 0.9962
20:41:33.061   Training iter 300, batch loss 0.0182, batch acc 0.9968
20:41:33.265   Training iter 350, batch loss 0.0183, batch acc 0.9978
20:41:33.463   Training iter 400, batch loss 0.0170, batch acc 0.9970
20:41:33.762   Training iter 450, batch loss 0.0167, batch acc 0.9982
20:41:34.033   Training iter 500, batch loss 0.0191, batch acc 0.9976
20:41:34.329   Training iter 550, batch loss 0.0186, batch acc 0.9972
20:41:34.564   Training iter 600, batch loss 0.0192, batch acc 0.9966
20:41:34.564 Training @ 68 epoch...
20:41:34.844   Training iter 50, batch loss 0.0176, batch acc 0.9960
20:41:35.107   Training iter 100, batch loss 0.0185, batch acc 0.9978
20:41:35.389   Training iter 150, batch loss 0.0173, batch acc 0.9980
20:41:35.667   Training iter 200, batch loss 0.0171, batch acc 0.9978
20:41:35.895   Training iter 250, batch loss 0.0171, batch acc 0.9970
20:41:36.178   Training iter 300, batch loss 0.0170, batch acc 0.9978
20:41:36.497   Training iter 350, batch loss 0.0175, batch acc 0.9974
20:41:36.848   Training iter 400, batch loss 0.0178, batch acc 0.9974
20:41:37.162   Training iter 450, batch loss 0.0186, batch acc 0.9966
20:41:37.574   Training iter 500, batch loss 0.0190, batch acc 0.9972
20:41:37.873   Training iter 550, batch loss 0.0202, batch acc 0.9962
20:41:38.200   Training iter 600, batch loss 0.0179, batch acc 0.9960
20:41:38.202 Training @ 69 epoch...
20:41:38.411   Training iter 50, batch loss 0.0166, batch acc 0.9972
20:41:38.687   Training iter 100, batch loss 0.0177, batch acc 0.9972
20:41:38.883   Training iter 150, batch loss 0.0168, batch acc 0.9984
20:41:39.448   Training iter 200, batch loss 0.0180, batch acc 0.9974
20:41:39.735   Training iter 250, batch loss 0.0167, batch acc 0.9974
20:41:40.065   Training iter 300, batch loss 0.0172, batch acc 0.9976
20:41:40.337   Training iter 350, batch loss 0.0181, batch acc 0.9964
20:41:40.737   Training iter 400, batch loss 0.0185, batch acc 0.9958
20:41:41.008   Training iter 450, batch loss 0.0199, batch acc 0.9950
20:41:41.229   Training iter 500, batch loss 0.0172, batch acc 0.9974
20:41:41.505   Training iter 550, batch loss 0.0193, batch acc 0.9964
20:41:41.746   Training iter 600, batch loss 0.0180, batch acc 0.9968
20:41:41.746 Training @ 70 epoch...
20:41:41.979   Training iter 50, batch loss 0.0177, batch acc 0.9972
20:41:42.271   Training iter 100, batch loss 0.0182, batch acc 0.9964
20:41:42.568   Training iter 150, batch loss 0.0164, batch acc 0.9978
20:41:42.836   Training iter 200, batch loss 0.0190, batch acc 0.9970
20:41:43.106   Training iter 250, batch loss 0.0163, batch acc 0.9968
20:41:43.314   Training iter 300, batch loss 0.0175, batch acc 0.9974
20:41:43.532   Training iter 350, batch loss 0.0182, batch acc 0.9968
20:41:43.721   Training iter 400, batch loss 0.0181, batch acc 0.9970
20:41:43.932   Training iter 450, batch loss 0.0186, batch acc 0.9972
20:41:44.136   Training iter 500, batch loss 0.0201, batch acc 0.9954
20:41:44.345   Training iter 550, batch loss 0.0170, batch acc 0.9976
20:41:44.532   Training iter 600, batch loss 0.0172, batch acc 0.9974
20:41:44.533 Testing @ 70 epoch...
20:41:44.641     Testing, total mean loss 0.03650, total acc 0.98630
20:41:44.641 Training @ 71 epoch...
20:41:44.847   Training iter 50, batch loss 0.0160, batch acc 0.9976
20:41:45.087   Training iter 100, batch loss 0.0179, batch acc 0.9960
20:41:45.436   Training iter 150, batch loss 0.0168, batch acc 0.9972
20:41:45.723   Training iter 200, batch loss 0.0181, batch acc 0.9960
20:41:46.068   Training iter 250, batch loss 0.0174, batch acc 0.9974
20:41:46.388   Training iter 300, batch loss 0.0182, batch acc 0.9964
20:41:46.639   Training iter 350, batch loss 0.0187, batch acc 0.9972
20:41:46.966   Training iter 400, batch loss 0.0180, batch acc 0.9970
20:41:47.247   Training iter 450, batch loss 0.0186, batch acc 0.9970
20:41:47.529   Training iter 500, batch loss 0.0176, batch acc 0.9974
20:41:47.848   Training iter 550, batch loss 0.0153, batch acc 0.9988
20:41:48.130   Training iter 600, batch loss 0.0187, batch acc 0.9960
20:41:48.131 Training @ 72 epoch...
20:41:48.464   Training iter 50, batch loss 0.0153, batch acc 0.9980
20:41:48.913   Training iter 100, batch loss 0.0165, batch acc 0.9974
20:41:49.202   Training iter 150, batch loss 0.0181, batch acc 0.9968
20:41:49.593   Training iter 200, batch loss 0.0170, batch acc 0.9970
20:41:50.007   Training iter 250, batch loss 0.0179, batch acc 0.9972
20:41:50.354   Training iter 300, batch loss 0.0180, batch acc 0.9976
20:41:50.571   Training iter 350, batch loss 0.0175, batch acc 0.9978
20:41:50.829   Training iter 400, batch loss 0.0187, batch acc 0.9962
20:41:51.186   Training iter 450, batch loss 0.0170, batch acc 0.9978
20:41:51.537   Training iter 500, batch loss 0.0169, batch acc 0.9972
20:41:51.809   Training iter 550, batch loss 0.0166, batch acc 0.9982
20:41:52.012   Training iter 600, batch loss 0.0201, batch acc 0.9970
20:41:52.012 Training @ 73 epoch...
20:41:52.232   Training iter 50, batch loss 0.0172, batch acc 0.9966
20:41:52.435   Training iter 100, batch loss 0.0165, batch acc 0.9968
20:41:52.639   Training iter 150, batch loss 0.0165, batch acc 0.9978
20:41:52.823   Training iter 200, batch loss 0.0176, batch acc 0.9966
20:41:53.082   Training iter 250, batch loss 0.0153, batch acc 0.9982
20:41:53.408   Training iter 300, batch loss 0.0167, batch acc 0.9970
20:41:53.647   Training iter 350, batch loss 0.0179, batch acc 0.9962
20:41:53.955   Training iter 400, batch loss 0.0188, batch acc 0.9962
20:41:54.296   Training iter 450, batch loss 0.0190, batch acc 0.9964
20:41:54.614   Training iter 500, batch loss 0.0188, batch acc 0.9976
20:41:55.078   Training iter 550, batch loss 0.0186, batch acc 0.9982
20:41:55.414   Training iter 600, batch loss 0.0179, batch acc 0.9980
20:41:55.416 Training @ 74 epoch...
20:41:55.654   Training iter 50, batch loss 0.0161, batch acc 0.9976
20:41:55.869   Training iter 100, batch loss 0.0166, batch acc 0.9970
20:41:56.143   Training iter 150, batch loss 0.0176, batch acc 0.9972
20:41:56.418   Training iter 200, batch loss 0.0174, batch acc 0.9976
20:41:56.660   Training iter 250, batch loss 0.0160, batch acc 0.9980
20:41:56.972   Training iter 300, batch loss 0.0159, batch acc 0.9980
20:41:57.216   Training iter 350, batch loss 0.0164, batch acc 0.9976
20:41:57.443   Training iter 400, batch loss 0.0192, batch acc 0.9960
20:41:57.706   Training iter 450, batch loss 0.0180, batch acc 0.9980
20:41:57.895   Training iter 500, batch loss 0.0185, batch acc 0.9970
20:41:58.161   Training iter 550, batch loss 0.0170, batch acc 0.9974
20:41:58.384   Training iter 600, batch loss 0.0189, batch acc 0.9962
20:41:58.385 Training @ 75 epoch...
20:41:58.748   Training iter 50, batch loss 0.0167, batch acc 0.9970
20:41:59.067   Training iter 100, batch loss 0.0174, batch acc 0.9978
20:41:59.519   Training iter 150, batch loss 0.0160, batch acc 0.9974
20:41:59.829   Training iter 200, batch loss 0.0171, batch acc 0.9980
20:42:00.216   Training iter 250, batch loss 0.0175, batch acc 0.9972
20:42:00.563   Training iter 300, batch loss 0.0163, batch acc 0.9978
20:42:01.066   Training iter 350, batch loss 0.0164, batch acc 0.9974
20:42:01.337   Training iter 400, batch loss 0.0184, batch acc 0.9970
20:42:01.665   Training iter 450, batch loss 0.0175, batch acc 0.9964
20:42:01.933   Training iter 500, batch loss 0.0186, batch acc 0.9970
20:42:02.224   Training iter 550, batch loss 0.0188, batch acc 0.9968
20:42:02.477   Training iter 600, batch loss 0.0155, batch acc 0.9990
20:42:02.479 Testing @ 75 epoch...
20:42:02.609     Testing, total mean loss 0.03761, total acc 0.98550
20:42:02.609 Training @ 76 epoch...
20:42:02.793   Training iter 50, batch loss 0.0151, batch acc 0.9982
20:42:03.122   Training iter 100, batch loss 0.0155, batch acc 0.9984
20:42:03.522   Training iter 150, batch loss 0.0168, batch acc 0.9976
20:42:03.858   Training iter 200, batch loss 0.0192, batch acc 0.9958
20:42:04.200   Training iter 250, batch loss 0.0163, batch acc 0.9972
20:42:04.473   Training iter 300, batch loss 0.0169, batch acc 0.9984
20:42:04.724   Training iter 350, batch loss 0.0167, batch acc 0.9978
20:42:04.931   Training iter 400, batch loss 0.0192, batch acc 0.9960
20:42:05.137   Training iter 450, batch loss 0.0182, batch acc 0.9964
20:42:05.329   Training iter 500, batch loss 0.0168, batch acc 0.9980
20:42:05.549   Training iter 550, batch loss 0.0166, batch acc 0.9966
20:42:05.772   Training iter 600, batch loss 0.0195, batch acc 0.9972
20:42:05.775 Training @ 77 epoch...
20:42:06.043   Training iter 50, batch loss 0.0164, batch acc 0.9972
20:42:06.280   Training iter 100, batch loss 0.0158, batch acc 0.9982
20:42:06.530   Training iter 150, batch loss 0.0174, batch acc 0.9968
20:42:06.746   Training iter 200, batch loss 0.0160, batch acc 0.9978
20:42:06.940   Training iter 250, batch loss 0.0183, batch acc 0.9956
20:42:07.146   Training iter 300, batch loss 0.0182, batch acc 0.9974
20:42:08.024   Training iter 350, batch loss 0.0175, batch acc 0.9974
20:42:08.256   Training iter 400, batch loss 0.0159, batch acc 0.9982
20:42:08.474   Training iter 450, batch loss 0.0190, batch acc 0.9962
20:42:08.742   Training iter 500, batch loss 0.0170, batch acc 0.9974
20:42:09.103   Training iter 550, batch loss 0.0166, batch acc 0.9978
20:42:09.466   Training iter 600, batch loss 0.0177, batch acc 0.9978
20:42:09.468 Training @ 78 epoch...
20:42:09.950   Training iter 50, batch loss 0.0151, batch acc 0.9984
20:42:10.328   Training iter 100, batch loss 0.0141, batch acc 0.9984
20:42:10.657   Training iter 150, batch loss 0.0164, batch acc 0.9970
20:42:11.151   Training iter 200, batch loss 0.0163, batch acc 0.9974
20:42:11.557   Training iter 250, batch loss 0.0160, batch acc 0.9982
20:42:12.118   Training iter 300, batch loss 0.0194, batch acc 0.9958
20:42:12.432   Training iter 350, batch loss 0.0178, batch acc 0.9974
20:42:12.731   Training iter 400, batch loss 0.0186, batch acc 0.9962
20:42:12.942   Training iter 450, batch loss 0.0179, batch acc 0.9972
20:42:13.191   Training iter 500, batch loss 0.0172, batch acc 0.9972
20:42:13.458   Training iter 550, batch loss 0.0178, batch acc 0.9972
20:42:13.688   Training iter 600, batch loss 0.0193, batch acc 0.9964
20:42:13.688 Training @ 79 epoch...
20:42:14.031   Training iter 50, batch loss 0.0147, batch acc 0.9986
20:42:14.222   Training iter 100, batch loss 0.0173, batch acc 0.9964
20:42:14.429   Training iter 150, batch loss 0.0167, batch acc 0.9988
20:42:14.714   Training iter 200, batch loss 0.0171, batch acc 0.9972
20:42:15.033   Training iter 250, batch loss 0.0153, batch acc 0.9980
20:42:15.392   Training iter 300, batch loss 0.0175, batch acc 0.9974
20:42:15.660   Training iter 350, batch loss 0.0182, batch acc 0.9972
20:42:16.032   Training iter 400, batch loss 0.0168, batch acc 0.9976
20:42:16.275   Training iter 450, batch loss 0.0190, batch acc 0.9964
20:42:16.561   Training iter 500, batch loss 0.0160, batch acc 0.9980
20:42:16.754   Training iter 550, batch loss 0.0176, batch acc 0.9962
20:42:16.990   Training iter 600, batch loss 0.0193, batch acc 0.9964
20:42:16.991 Training @ 80 epoch...
20:42:17.253   Training iter 50, batch loss 0.0159, batch acc 0.9972
20:42:17.506   Training iter 100, batch loss 0.0172, batch acc 0.9980
20:42:17.732   Training iter 150, batch loss 0.0170, batch acc 0.9972
20:42:18.066   Training iter 200, batch loss 0.0165, batch acc 0.9978
20:42:18.375   Training iter 250, batch loss 0.0169, batch acc 0.9968
20:42:18.724   Training iter 300, batch loss 0.0163, batch acc 0.9978
20:42:18.958   Training iter 350, batch loss 0.0172, batch acc 0.9980
20:42:19.203   Training iter 400, batch loss 0.0168, batch acc 0.9976
20:42:19.474   Training iter 450, batch loss 0.0154, batch acc 0.9980
20:42:19.732   Training iter 500, batch loss 0.0165, batch acc 0.9976
20:42:19.981   Training iter 550, batch loss 0.0195, batch acc 0.9968
20:42:20.201   Training iter 600, batch loss 0.0184, batch acc 0.9972
20:42:20.204 Testing @ 80 epoch...
20:42:20.346     Testing, total mean loss 0.03695, total acc 0.98550
20:42:20.346 Training @ 81 epoch...
20:42:20.648   Training iter 50, batch loss 0.0154, batch acc 0.9978
20:42:20.988   Training iter 100, batch loss 0.0164, batch acc 0.9972
20:42:21.668   Training iter 150, batch loss 0.0138, batch acc 0.9988
20:42:22.505   Training iter 200, batch loss 0.0145, batch acc 0.9980
20:42:22.863   Training iter 250, batch loss 0.0185, batch acc 0.9970
20:42:23.112   Training iter 300, batch loss 0.0181, batch acc 0.9976
20:42:23.342   Training iter 350, batch loss 0.0189, batch acc 0.9970
20:42:23.546   Training iter 400, batch loss 0.0180, batch acc 0.9964
20:42:23.913   Training iter 450, batch loss 0.0162, batch acc 0.9970
20:42:24.202   Training iter 500, batch loss 0.0188, batch acc 0.9962
20:42:24.547   Training iter 550, batch loss 0.0168, batch acc 0.9976
20:42:24.782   Training iter 600, batch loss 0.0173, batch acc 0.9974
20:42:24.783 Training @ 82 epoch...
20:42:24.994   Training iter 50, batch loss 0.0153, batch acc 0.9976
20:42:25.188   Training iter 100, batch loss 0.0162, batch acc 0.9974
20:42:25.430   Training iter 150, batch loss 0.0172, batch acc 0.9978
20:42:25.712   Training iter 200, batch loss 0.0190, batch acc 0.9966
20:42:25.896   Training iter 250, batch loss 0.0169, batch acc 0.9976
20:42:26.146   Training iter 300, batch loss 0.0180, batch acc 0.9966
20:42:26.375   Training iter 350, batch loss 0.0196, batch acc 0.9966
20:42:26.618   Training iter 400, batch loss 0.0153, batch acc 0.9990
20:42:27.144   Training iter 450, batch loss 0.0163, batch acc 0.9984
20:42:27.483   Training iter 500, batch loss 0.0172, batch acc 0.9980
20:42:27.867   Training iter 550, batch loss 0.0203, batch acc 0.9962
20:42:28.111   Training iter 600, batch loss 0.0168, batch acc 0.9976
20:42:28.121 Training @ 83 epoch...
20:42:28.410   Training iter 50, batch loss 0.0161, batch acc 0.9970
20:42:28.647   Training iter 100, batch loss 0.0145, batch acc 0.9980
20:42:28.904   Training iter 150, batch loss 0.0177, batch acc 0.9962
20:42:29.166   Training iter 200, batch loss 0.0181, batch acc 0.9972
20:42:29.610   Training iter 250, batch loss 0.0163, batch acc 0.9982
20:42:29.895   Training iter 300, batch loss 0.0159, batch acc 0.9970
20:42:30.447   Training iter 350, batch loss 0.0184, batch acc 0.9968
20:42:30.744   Training iter 400, batch loss 0.0170, batch acc 0.9970
20:42:30.943   Training iter 450, batch loss 0.0160, batch acc 0.9980
20:42:31.217   Training iter 500, batch loss 0.0186, batch acc 0.9964
20:42:31.598   Training iter 550, batch loss 0.0169, batch acc 0.9978
20:42:31.869   Training iter 600, batch loss 0.0166, batch acc 0.9980
20:42:31.869 Training @ 84 epoch...
20:42:32.365   Training iter 50, batch loss 0.0162, batch acc 0.9984
20:42:32.592   Training iter 100, batch loss 0.0156, batch acc 0.9982
20:42:32.910   Training iter 150, batch loss 0.0170, batch acc 0.9976
20:42:33.303   Training iter 200, batch loss 0.0163, batch acc 0.9976
20:42:33.638   Training iter 250, batch loss 0.0148, batch acc 0.9984
20:42:33.979   Training iter 300, batch loss 0.0162, batch acc 0.9974
20:42:34.208   Training iter 350, batch loss 0.0170, batch acc 0.9972
20:42:34.435   Training iter 400, batch loss 0.0171, batch acc 0.9960
20:42:34.659   Training iter 450, batch loss 0.0191, batch acc 0.9962
20:42:34.875   Training iter 500, batch loss 0.0175, batch acc 0.9976
20:42:35.138   Training iter 550, batch loss 0.0180, batch acc 0.9964
20:42:35.401   Training iter 600, batch loss 0.0176, batch acc 0.9968
20:42:35.402 Training @ 85 epoch...
20:42:35.629   Training iter 50, batch loss 0.0151, batch acc 0.9984
20:42:35.910   Training iter 100, batch loss 0.0148, batch acc 0.9978
20:42:36.190   Training iter 150, batch loss 0.0162, batch acc 0.9978
20:42:36.620   Training iter 200, batch loss 0.0174, batch acc 0.9980
20:42:36.993   Training iter 250, batch loss 0.0190, batch acc 0.9952
20:42:37.203   Training iter 300, batch loss 0.0192, batch acc 0.9962
20:42:37.616   Training iter 350, batch loss 0.0184, batch acc 0.9972
20:42:37.984   Training iter 400, batch loss 0.0160, batch acc 0.9974
20:42:38.270   Training iter 450, batch loss 0.0186, batch acc 0.9954
20:42:38.531   Training iter 500, batch loss 0.0174, batch acc 0.9968
20:42:38.781   Training iter 550, batch loss 0.0159, batch acc 0.9978
20:42:39.137   Training iter 600, batch loss 0.0156, batch acc 0.9988
20:42:39.138 Testing @ 85 epoch...
20:42:39.597     Testing, total mean loss 0.03904, total acc 0.98590
20:42:39.597 Training @ 86 epoch...
20:42:40.026   Training iter 50, batch loss 0.0165, batch acc 0.9968
20:42:40.421   Training iter 100, batch loss 0.0152, batch acc 0.9982
20:42:40.770   Training iter 150, batch loss 0.0178, batch acc 0.9968
20:42:41.032   Training iter 200, batch loss 0.0155, batch acc 0.9982
20:42:41.326   Training iter 250, batch loss 0.0183, batch acc 0.9962
20:42:41.611   Training iter 300, batch loss 0.0168, batch acc 0.9982
20:42:41.862   Training iter 350, batch loss 0.0156, batch acc 0.9980
20:42:42.128   Training iter 400, batch loss 0.0162, batch acc 0.9976
20:42:42.567   Training iter 450, batch loss 0.0171, batch acc 0.9970
20:42:42.966   Training iter 500, batch loss 0.0169, batch acc 0.9974
20:42:43.297   Training iter 550, batch loss 0.0180, batch acc 0.9980
20:42:43.602   Training iter 600, batch loss 0.0173, batch acc 0.9972
20:42:43.604 Training @ 87 epoch...
20:42:43.833   Training iter 50, batch loss 0.0152, batch acc 0.9978
20:42:44.218   Training iter 100, batch loss 0.0158, batch acc 0.9978
20:42:44.565   Training iter 150, batch loss 0.0178, batch acc 0.9956
20:42:44.989   Training iter 200, batch loss 0.0149, batch acc 0.9986
20:42:45.325   Training iter 250, batch loss 0.0155, batch acc 0.9982
20:42:45.539   Training iter 300, batch loss 0.0166, batch acc 0.9974
20:42:45.742   Training iter 350, batch loss 0.0162, batch acc 0.9974
20:42:45.982   Training iter 400, batch loss 0.0146, batch acc 0.9984
20:42:46.197   Training iter 450, batch loss 0.0192, batch acc 0.9954
20:42:46.438   Training iter 500, batch loss 0.0167, batch acc 0.9978
20:42:47.074   Training iter 550, batch loss 0.0168, batch acc 0.9974
20:42:47.434   Training iter 600, batch loss 0.0175, batch acc 0.9986
20:42:47.435 Training @ 88 epoch...
20:42:47.695   Training iter 50, batch loss 0.0161, batch acc 0.9980
20:42:47.953   Training iter 100, batch loss 0.0154, batch acc 0.9976
20:42:48.348   Training iter 150, batch loss 0.0171, batch acc 0.9972
20:42:48.698   Training iter 200, batch loss 0.0156, batch acc 0.9982
20:42:49.116   Training iter 250, batch loss 0.0165, batch acc 0.9978
20:42:49.475   Training iter 300, batch loss 0.0160, batch acc 0.9982
20:42:49.882   Training iter 350, batch loss 0.0157, batch acc 0.9980
20:42:50.296   Training iter 400, batch loss 0.0171, batch acc 0.9970
20:42:50.608   Training iter 450, batch loss 0.0169, batch acc 0.9968
20:42:50.897   Training iter 500, batch loss 0.0186, batch acc 0.9976
20:42:51.140   Training iter 550, batch loss 0.0185, batch acc 0.9960
20:42:51.438   Training iter 600, batch loss 0.0165, batch acc 0.9972
20:42:51.438 Training @ 89 epoch...
20:42:51.636   Training iter 50, batch loss 0.0141, batch acc 0.9988
20:42:51.916   Training iter 100, batch loss 0.0174, batch acc 0.9960
20:42:52.175   Training iter 150, batch loss 0.0163, batch acc 0.9968
20:42:52.424   Training iter 200, batch loss 0.0177, batch acc 0.9972
20:42:52.660   Training iter 250, batch loss 0.0172, batch acc 0.9976
20:42:53.310   Training iter 300, batch loss 0.0161, batch acc 0.9980
20:42:54.283   Training iter 350, batch loss 0.0161, batch acc 0.9986
20:42:54.645   Training iter 400, batch loss 0.0190, batch acc 0.9972
20:42:54.967   Training iter 450, batch loss 0.0162, batch acc 0.9972
20:42:55.555   Training iter 500, batch loss 0.0172, batch acc 0.9978
20:42:55.899   Training iter 550, batch loss 0.0166, batch acc 0.9980
20:42:56.147   Training iter 600, batch loss 0.0183, batch acc 0.9976
20:42:56.147 Training @ 90 epoch...
20:42:56.416   Training iter 50, batch loss 0.0168, batch acc 0.9976
20:42:56.760   Training iter 100, batch loss 0.0163, batch acc 0.9970
20:42:57.122   Training iter 150, batch loss 0.0162, batch acc 0.9976
20:42:57.461   Training iter 200, batch loss 0.0149, batch acc 0.9986
20:42:57.695   Training iter 250, batch loss 0.0166, batch acc 0.9980
20:42:58.016   Training iter 300, batch loss 0.0155, batch acc 0.9982
20:42:58.311   Training iter 350, batch loss 0.0181, batch acc 0.9970
20:42:58.599   Training iter 400, batch loss 0.0151, batch acc 0.9986
20:42:58.875   Training iter 450, batch loss 0.0171, batch acc 0.9976
20:42:59.093   Training iter 500, batch loss 0.0175, batch acc 0.9978
20:42:59.364   Training iter 550, batch loss 0.0162, batch acc 0.9976
20:42:59.697   Training iter 600, batch loss 0.0187, batch acc 0.9968
20:42:59.698 Testing @ 90 epoch...
20:42:59.848     Testing, total mean loss 0.03896, total acc 0.98520
20:42:59.848 Training @ 91 epoch...
20:43:00.336   Training iter 50, batch loss 0.0144, batch acc 0.9984
20:43:00.622   Training iter 100, batch loss 0.0147, batch acc 0.9978
20:43:00.948   Training iter 150, batch loss 0.0189, batch acc 0.9966
20:43:01.214   Training iter 200, batch loss 0.0153, batch acc 0.9976
20:43:01.410   Training iter 250, batch loss 0.0164, batch acc 0.9970
20:43:01.600   Training iter 300, batch loss 0.0170, batch acc 0.9968
20:43:01.797   Training iter 350, batch loss 0.0154, batch acc 0.9980
20:43:02.017   Training iter 400, batch loss 0.0167, batch acc 0.9974
20:43:02.245   Training iter 450, batch loss 0.0186, batch acc 0.9968
20:43:02.517   Training iter 500, batch loss 0.0159, batch acc 0.9986
20:43:02.816   Training iter 550, batch loss 0.0178, batch acc 0.9972
20:43:03.138   Training iter 600, batch loss 0.0187, batch acc 0.9976
20:43:03.139 Training @ 92 epoch...
20:43:03.397   Training iter 50, batch loss 0.0158, batch acc 0.9980
20:43:03.618   Training iter 100, batch loss 0.0148, batch acc 0.9976
20:43:03.872   Training iter 150, batch loss 0.0147, batch acc 0.9980
20:43:04.125   Training iter 200, batch loss 0.0157, batch acc 0.9974
20:43:04.329   Training iter 250, batch loss 0.0159, batch acc 0.9980
20:43:04.693   Training iter 300, batch loss 0.0152, batch acc 0.9988
20:43:04.918   Training iter 350, batch loss 0.0173, batch acc 0.9978
20:43:05.167   Training iter 400, batch loss 0.0151, batch acc 0.9986
20:43:05.414   Training iter 450, batch loss 0.0176, batch acc 0.9970
20:43:05.754   Training iter 500, batch loss 0.0206, batch acc 0.9952
20:43:05.987   Training iter 550, batch loss 0.0180, batch acc 0.9978
20:43:06.351   Training iter 600, batch loss 0.0177, batch acc 0.9968
20:43:06.353 Training @ 93 epoch...
20:43:06.635   Training iter 50, batch loss 0.0151, batch acc 0.9976
20:43:07.126   Training iter 100, batch loss 0.0139, batch acc 0.9984
20:43:07.606   Training iter 150, batch loss 0.0145, batch acc 0.9980
20:43:07.965   Training iter 200, batch loss 0.0171, batch acc 0.9968
20:43:08.254   Training iter 250, batch loss 0.0166, batch acc 0.9968
20:43:08.588   Training iter 300, batch loss 0.0157, batch acc 0.9978
20:43:08.891   Training iter 350, batch loss 0.0164, batch acc 0.9974
20:43:09.163   Training iter 400, batch loss 0.0164, batch acc 0.9978
20:43:09.381   Training iter 450, batch loss 0.0158, batch acc 0.9984
20:43:09.638   Training iter 500, batch loss 0.0184, batch acc 0.9966
20:43:09.841   Training iter 550, batch loss 0.0163, batch acc 0.9968
20:43:10.025   Training iter 600, batch loss 0.0197, batch acc 0.9962
20:43:10.027 Training @ 94 epoch...
20:43:10.235   Training iter 50, batch loss 0.0150, batch acc 0.9980
20:43:10.430   Training iter 100, batch loss 0.0147, batch acc 0.9978
20:43:10.643   Training iter 150, batch loss 0.0166, batch acc 0.9974
20:43:10.848   Training iter 200, batch loss 0.0177, batch acc 0.9976
20:43:11.034   Training iter 250, batch loss 0.0155, batch acc 0.9980
20:43:11.287   Training iter 300, batch loss 0.0167, batch acc 0.9966
20:43:11.508   Training iter 350, batch loss 0.0157, batch acc 0.9988
20:43:11.744   Training iter 400, batch loss 0.0199, batch acc 0.9964
20:43:12.015   Training iter 450, batch loss 0.0186, batch acc 0.9966
20:43:12.207   Training iter 500, batch loss 0.0166, batch acc 0.9986
20:43:12.397   Training iter 550, batch loss 0.0179, batch acc 0.9968
20:43:12.600   Training iter 600, batch loss 0.0160, batch acc 0.9980
20:43:12.602 Training @ 95 epoch...
20:43:12.787   Training iter 50, batch loss 0.0157, batch acc 0.9978
20:43:13.080   Training iter 100, batch loss 0.0159, batch acc 0.9970
20:43:13.312   Training iter 150, batch loss 0.0152, batch acc 0.9976
20:43:13.530   Training iter 200, batch loss 0.0151, batch acc 0.9982
20:43:13.720   Training iter 250, batch loss 0.0151, batch acc 0.9982
20:43:13.928   Training iter 300, batch loss 0.0159, batch acc 0.9980
20:43:14.184   Training iter 350, batch loss 0.0152, batch acc 0.9982
20:43:14.511   Training iter 400, batch loss 0.0189, batch acc 0.9964
20:43:14.806   Training iter 450, batch loss 0.0176, batch acc 0.9974
20:43:15.056   Training iter 500, batch loss 0.0170, batch acc 0.9982
20:43:15.343   Training iter 550, batch loss 0.0167, batch acc 0.9976
20:43:15.545   Training iter 600, batch loss 0.0179, batch acc 0.9970
20:43:15.546 Testing @ 95 epoch...
20:43:15.829     Testing, total mean loss 0.03647, total acc 0.98530
20:43:15.829 Training @ 96 epoch...
20:43:16.049   Training iter 50, batch loss 0.0147, batch acc 0.9992
20:43:16.346   Training iter 100, batch loss 0.0153, batch acc 0.9976
20:43:17.113   Training iter 150, batch loss 0.0160, batch acc 0.9984
20:43:17.354   Training iter 200, batch loss 0.0166, batch acc 0.9976
20:43:17.739   Training iter 250, batch loss 0.0165, batch acc 0.9978
20:43:18.018   Training iter 300, batch loss 0.0153, batch acc 0.9974
20:43:18.317   Training iter 350, batch loss 0.0165, batch acc 0.9968
20:43:18.554   Training iter 400, batch loss 0.0164, batch acc 0.9974
20:43:18.745   Training iter 450, batch loss 0.0167, batch acc 0.9976
20:43:19.051   Training iter 500, batch loss 0.0173, batch acc 0.9970
20:43:19.337   Training iter 550, batch loss 0.0193, batch acc 0.9960
20:43:19.532   Training iter 600, batch loss 0.0158, batch acc 0.9974
20:43:19.532 Training @ 97 epoch...
20:43:19.803   Training iter 50, batch loss 0.0138, batch acc 0.9986
20:43:20.100   Training iter 100, batch loss 0.0151, batch acc 0.9984
20:43:20.363   Training iter 150, batch loss 0.0162, batch acc 0.9976
20:43:20.644   Training iter 200, batch loss 0.0167, batch acc 0.9964
20:43:21.225   Training iter 250, batch loss 0.0163, batch acc 0.9980
20:43:21.642   Training iter 300, batch loss 0.0164, batch acc 0.9972
20:43:21.947   Training iter 350, batch loss 0.0163, batch acc 0.9982
20:43:22.227   Training iter 400, batch loss 0.0158, batch acc 0.9986
20:43:22.487   Training iter 450, batch loss 0.0157, batch acc 0.9982
20:43:22.826   Training iter 500, batch loss 0.0180, batch acc 0.9972
20:43:23.426   Training iter 550, batch loss 0.0180, batch acc 0.9962
20:43:23.887   Training iter 600, batch loss 0.0168, batch acc 0.9974
20:43:23.888 Training @ 98 epoch...
20:43:24.169   Training iter 50, batch loss 0.0162, batch acc 0.9970
20:43:24.459   Training iter 100, batch loss 0.0137, batch acc 0.9988
20:43:24.703   Training iter 150, batch loss 0.0144, batch acc 0.9986
20:43:25.111   Training iter 200, batch loss 0.0163, batch acc 0.9976
20:43:25.356   Training iter 250, batch loss 0.0164, batch acc 0.9976
20:43:25.930   Training iter 300, batch loss 0.0153, batch acc 0.9976
20:43:26.232   Training iter 350, batch loss 0.0157, batch acc 0.9972
20:43:26.511   Training iter 400, batch loss 0.0160, batch acc 0.9968
20:43:26.774   Training iter 450, batch loss 0.0156, batch acc 0.9978
20:43:27.078   Training iter 500, batch loss 0.0185, batch acc 0.9972
20:43:27.423   Training iter 550, batch loss 0.0181, batch acc 0.9968
20:43:27.635   Training iter 600, batch loss 0.0173, batch acc 0.9964
20:43:27.636 Training @ 99 epoch...
20:43:27.854   Training iter 50, batch loss 0.0146, batch acc 0.9976
20:43:28.290   Training iter 100, batch loss 0.0146, batch acc 0.9984
20:43:28.588   Training iter 150, batch loss 0.0166, batch acc 0.9974
20:43:28.894   Training iter 200, batch loss 0.0163, batch acc 0.9982
20:43:29.467   Training iter 250, batch loss 0.0170, batch acc 0.9978
20:43:29.783   Training iter 300, batch loss 0.0144, batch acc 0.9990
20:43:30.070   Training iter 350, batch loss 0.0158, batch acc 0.9970
20:43:30.367   Training iter 400, batch loss 0.0164, batch acc 0.9974
20:43:30.604   Training iter 450, batch loss 0.0160, batch acc 0.9980
20:43:31.513   Training iter 500, batch loss 0.0157, batch acc 0.9978
20:43:31.916   Training iter 550, batch loss 0.0179, batch acc 0.9966
20:43:32.226   Training iter 600, batch loss 0.0177, batch acc 0.9974
20:43:32.228 Testing @ 99 epoch...
20:43:32.396     Testing, total mean loss 0.03659, total acc 0.98610