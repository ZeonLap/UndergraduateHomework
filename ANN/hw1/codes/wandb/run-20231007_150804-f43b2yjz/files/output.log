15:08:09.221 Training @ 0 epoch...
15:08:09.374   Training iter 50, batch loss 2.1147, batch acc 0.4158
15:08:09.568   Training iter 100, batch loss 1.0670, batch acc 0.7214
15:08:09.738   Training iter 150, batch loss 0.5964, batch acc 0.8386
15:08:09.923   Training iter 200, batch loss 0.4748, batch acc 0.8690
15:08:10.142   Training iter 250, batch loss 0.4230, batch acc 0.8784
15:08:10.417   Training iter 300, batch loss 0.3788, batch acc 0.8884
15:08:10.643   Training iter 350, batch loss 0.3632, batch acc 0.9000
15:08:10.834   Training iter 400, batch loss 0.3438, batch acc 0.9006
15:08:11.029   Training iter 450, batch loss 0.3651, batch acc 0.8978
15:08:11.201   Training iter 500, batch loss 0.3369, batch acc 0.9084
15:08:11.395   Training iter 550, batch loss 0.3536, batch acc 0.8948
15:08:11.526   Training iter 600, batch loss 0.3540, batch acc 0.9008
15:08:11.529 Testing @ 0 epoch...
15:08:11.632     Testing, total mean loss 0.32149, total acc 0.90540
15:08:11.632 Training @ 1 epoch...
15:08:11.722   Training iter 50, batch loss 0.3352, batch acc 0.8982
15:08:11.817   Training iter 100, batch loss 0.3075, batch acc 0.9124
15:08:11.914   Training iter 150, batch loss 0.3213, batch acc 0.9048
15:08:12.011   Training iter 200, batch loss 0.2918, batch acc 0.9100
15:08:12.106   Training iter 250, batch loss 0.3083, batch acc 0.9128
15:08:12.204   Training iter 300, batch loss 0.2995, batch acc 0.9096
15:08:12.519   Training iter 350, batch loss 0.2993, batch acc 0.9098
15:08:12.708   Training iter 400, batch loss 0.3003, batch acc 0.9118
15:08:12.862   Training iter 450, batch loss 0.2957, batch acc 0.9132
15:08:13.096   Training iter 500, batch loss 0.3016, batch acc 0.9110
15:08:13.251   Training iter 550, batch loss 0.2987, batch acc 0.9148
15:08:13.460   Training iter 600, batch loss 0.2882, batch acc 0.9180
15:08:13.460 Training @ 2 epoch...
15:08:13.593   Training iter 50, batch loss 0.2727, batch acc 0.9244
15:08:13.695   Training iter 100, batch loss 0.2697, batch acc 0.9218
15:08:13.806   Training iter 150, batch loss 0.3044, batch acc 0.9130
15:08:13.983   Training iter 200, batch loss 0.2634, batch acc 0.9246
15:08:14.170   Training iter 250, batch loss 0.2815, batch acc 0.9202
15:08:14.328   Training iter 300, batch loss 0.2702, batch acc 0.9212
15:08:14.503   Training iter 350, batch loss 0.2658, batch acc 0.9254
15:08:14.673   Training iter 400, batch loss 0.2709, batch acc 0.9204
15:08:14.839   Training iter 450, batch loss 0.2693, batch acc 0.9206
15:08:14.976   Training iter 500, batch loss 0.2637, batch acc 0.9266
15:08:15.118   Training iter 550, batch loss 0.2764, batch acc 0.9144
15:08:15.260   Training iter 600, batch loss 0.2438, batch acc 0.9290
15:08:15.262 Training @ 3 epoch...
15:08:15.438   Training iter 50, batch loss 0.2389, batch acc 0.9328
15:08:15.593   Training iter 100, batch loss 0.2552, batch acc 0.9272
15:08:15.732   Training iter 150, batch loss 0.2245, batch acc 0.9366
15:08:15.913   Training iter 200, batch loss 0.2348, batch acc 0.9326
15:08:16.111   Training iter 250, batch loss 0.2560, batch acc 0.9250
15:08:16.214   Training iter 300, batch loss 0.2503, batch acc 0.9268
15:08:16.323   Training iter 350, batch loss 0.2259, batch acc 0.9332
15:08:16.450   Training iter 400, batch loss 0.2377, batch acc 0.9322
15:08:16.576   Training iter 450, batch loss 0.2475, batch acc 0.9290
15:08:16.787   Training iter 500, batch loss 0.2464, batch acc 0.9308
15:08:16.971   Training iter 550, batch loss 0.2291, batch acc 0.9342
15:08:17.146   Training iter 600, batch loss 0.2388, batch acc 0.9366
15:08:17.147 Training @ 4 epoch...
15:08:17.308   Training iter 50, batch loss 0.2402, batch acc 0.9322
15:08:17.491   Training iter 100, batch loss 0.2248, batch acc 0.9372
15:08:17.673   Training iter 150, batch loss 0.2127, batch acc 0.9390
15:08:17.805   Training iter 200, batch loss 0.1993, batch acc 0.9466
15:08:17.976   Training iter 250, batch loss 0.2219, batch acc 0.9396
15:08:18.130   Training iter 300, batch loss 0.2145, batch acc 0.9390
15:08:18.312   Training iter 350, batch loss 0.2050, batch acc 0.9396
15:08:18.429   Training iter 400, batch loss 0.2162, batch acc 0.9366
15:08:18.546   Training iter 450, batch loss 0.2104, batch acc 0.9390
15:08:18.735   Training iter 500, batch loss 0.2017, batch acc 0.9414
15:08:18.925   Training iter 550, batch loss 0.2062, batch acc 0.9384
15:08:19.083   Training iter 600, batch loss 0.1915, batch acc 0.9434
15:08:19.083 Training @ 5 epoch...
15:08:19.192   Training iter 50, batch loss 0.1973, batch acc 0.9410
15:08:19.367   Training iter 100, batch loss 0.1983, batch acc 0.9412
15:08:19.641   Training iter 150, batch loss 0.1925, batch acc 0.9432
15:08:19.758   Training iter 200, batch loss 0.1997, batch acc 0.9474
15:08:19.896   Training iter 250, batch loss 0.2073, batch acc 0.9382
15:08:20.001   Training iter 300, batch loss 0.1872, batch acc 0.9506
15:08:20.123   Training iter 350, batch loss 0.1905, batch acc 0.9498
15:08:20.230   Training iter 400, batch loss 0.2039, batch acc 0.9442
15:08:20.343   Training iter 450, batch loss 0.1768, batch acc 0.9476
15:08:20.453   Training iter 500, batch loss 0.1709, batch acc 0.9540
15:08:20.551   Training iter 550, batch loss 0.1849, batch acc 0.9462
15:08:20.727   Training iter 600, batch loss 0.1805, batch acc 0.9486
15:08:20.727 Testing @ 5 epoch...
15:08:20.806     Testing, total mean loss 0.18276, total acc 0.94620
15:08:20.806 Training @ 6 epoch...
15:08:20.917   Training iter 50, batch loss 0.1869, batch acc 0.9480
15:08:21.019   Training iter 100, batch loss 0.1711, batch acc 0.9500
15:08:21.136   Training iter 150, batch loss 0.1732, batch acc 0.9484
15:08:21.246   Training iter 200, batch loss 0.1739, batch acc 0.9520
15:08:21.360   Training iter 250, batch loss 0.1690, batch acc 0.9518
15:08:21.466   Training iter 300, batch loss 0.1696, batch acc 0.9520
15:08:21.562   Training iter 350, batch loss 0.1737, batch acc 0.9474
15:08:21.686   Training iter 400, batch loss 0.1656, batch acc 0.9510
15:08:21.813   Training iter 450, batch loss 0.1727, batch acc 0.9498
15:08:21.927   Training iter 500, batch loss 0.1715, batch acc 0.9530
15:08:22.014   Training iter 550, batch loss 0.1785, batch acc 0.9504
15:08:22.105   Training iter 600, batch loss 0.1667, batch acc 0.9520
15:08:22.105 Training @ 7 epoch...
15:08:22.272   Training iter 50, batch loss 0.1617, batch acc 0.9536
15:08:22.372   Training iter 100, batch loss 0.1596, batch acc 0.9526
15:08:22.499   Training iter 150, batch loss 0.1581, batch acc 0.9560
15:08:22.584   Training iter 200, batch loss 0.1570, batch acc 0.9528
15:08:22.672   Training iter 250, batch loss 0.1527, batch acc 0.9576
15:08:22.777   Training iter 300, batch loss 0.1709, batch acc 0.9516
15:08:22.870   Training iter 350, batch loss 0.1532, batch acc 0.9606
15:08:22.965   Training iter 400, batch loss 0.1548, batch acc 0.9566
15:08:23.057   Training iter 450, batch loss 0.1521, batch acc 0.9566
15:08:23.151   Training iter 500, batch loss 0.1593, batch acc 0.9562
15:08:23.233   Training iter 550, batch loss 0.1519, batch acc 0.9568
15:08:23.319   Training iter 600, batch loss 0.1500, batch acc 0.9544
15:08:23.321 Training @ 8 epoch...
15:08:23.416   Training iter 50, batch loss 0.1496, batch acc 0.9582
15:08:23.499   Training iter 100, batch loss 0.1385, batch acc 0.9616
15:08:23.584   Training iter 150, batch loss 0.1472, batch acc 0.9554
15:08:23.678   Training iter 200, batch loss 0.1564, batch acc 0.9550
15:08:23.770   Training iter 250, batch loss 0.1575, batch acc 0.9540
15:08:23.860   Training iter 300, batch loss 0.1417, batch acc 0.9602
15:08:23.958   Training iter 350, batch loss 0.1500, batch acc 0.9580
15:08:24.053   Training iter 400, batch loss 0.1477, batch acc 0.9574
15:08:24.149   Training iter 450, batch loss 0.1424, batch acc 0.9574
15:08:24.235   Training iter 500, batch loss 0.1572, batch acc 0.9564
15:08:24.341   Training iter 550, batch loss 0.1377, batch acc 0.9620
15:08:24.446   Training iter 600, batch loss 0.1376, batch acc 0.9590
15:08:24.448 Training @ 9 epoch...
15:08:24.570   Training iter 50, batch loss 0.1245, batch acc 0.9666
15:08:24.692   Training iter 100, batch loss 0.1395, batch acc 0.9624
15:08:24.823   Training iter 150, batch loss 0.1393, batch acc 0.9594
15:08:24.943   Training iter 200, batch loss 0.1295, batch acc 0.9670
15:08:25.059   Training iter 250, batch loss 0.1367, batch acc 0.9632
15:08:25.137   Training iter 300, batch loss 0.1433, batch acc 0.9570
15:08:25.221   Training iter 350, batch loss 0.1382, batch acc 0.9626
15:08:25.315   Training iter 400, batch loss 0.1292, batch acc 0.9608
15:08:25.442   Training iter 450, batch loss 0.1387, batch acc 0.9594
15:08:25.537   Training iter 500, batch loss 0.1358, batch acc 0.9622
15:08:25.619   Training iter 550, batch loss 0.1521, batch acc 0.9554
15:08:25.705   Training iter 600, batch loss 0.1110, batch acc 0.9674
15:08:25.706 Training @ 10 epoch...
15:08:25.798   Training iter 50, batch loss 0.1308, batch acc 0.9638
15:08:25.882   Training iter 100, batch loss 0.1247, batch acc 0.9622
15:08:25.983   Training iter 150, batch loss 0.1171, batch acc 0.9654
15:08:26.069   Training iter 200, batch loss 0.1236, batch acc 0.9608
15:08:26.180   Training iter 250, batch loss 0.1246, batch acc 0.9658
15:08:26.281   Training iter 300, batch loss 0.1212, batch acc 0.9650
15:08:26.384   Training iter 350, batch loss 0.1249, batch acc 0.9660
15:08:26.466   Training iter 400, batch loss 0.1410, batch acc 0.9608
15:08:26.624   Training iter 450, batch loss 0.1200, batch acc 0.9680
15:08:26.715   Training iter 500, batch loss 0.1204, batch acc 0.9648
15:08:26.835   Training iter 550, batch loss 0.1379, batch acc 0.9616
15:08:26.924   Training iter 600, batch loss 0.1247, batch acc 0.9638
15:08:26.925 Testing @ 10 epoch...
15:08:27.013     Testing, total mean loss 0.14010, total acc 0.95840
15:08:27.013 Training @ 11 epoch...
15:08:27.137   Training iter 50, batch loss 0.1070, batch acc 0.9692
15:08:27.247   Training iter 100, batch loss 0.1232, batch acc 0.9638
15:08:27.390   Training iter 150, batch loss 0.1115, batch acc 0.9688
15:08:27.496   Training iter 200, batch loss 0.1215, batch acc 0.9660
15:08:27.603   Training iter 250, batch loss 0.1300, batch acc 0.9614
15:08:27.697   Training iter 300, batch loss 0.1188, batch acc 0.9694
15:08:27.833   Training iter 350, batch loss 0.1210, batch acc 0.9620
15:08:27.922   Training iter 400, batch loss 0.1132, batch acc 0.9674
15:08:28.023   Training iter 450, batch loss 0.1251, batch acc 0.9656
15:08:28.140   Training iter 500, batch loss 0.1203, batch acc 0.9636
15:08:28.262   Training iter 550, batch loss 0.1202, batch acc 0.9654
15:08:28.365   Training iter 600, batch loss 0.1342, batch acc 0.9586
15:08:28.367 Training @ 12 epoch...
15:08:28.465   Training iter 50, batch loss 0.1102, batch acc 0.9676
15:08:28.549   Training iter 100, batch loss 0.1091, batch acc 0.9670
15:08:28.636   Training iter 150, batch loss 0.1049, batch acc 0.9702
15:08:28.731   Training iter 200, batch loss 0.1293, batch acc 0.9624
15:08:28.825   Training iter 250, batch loss 0.1167, batch acc 0.9674
15:08:28.934   Training iter 300, batch loss 0.1266, batch acc 0.9658
15:08:29.024   Training iter 350, batch loss 0.1173, batch acc 0.9668
15:08:29.124   Training iter 400, batch loss 0.1069, batch acc 0.9690
15:08:29.216   Training iter 450, batch loss 0.1141, batch acc 0.9670
15:08:29.306   Training iter 500, batch loss 0.0978, batch acc 0.9710
15:08:29.522   Training iter 550, batch loss 0.1106, batch acc 0.9700
15:08:29.615   Training iter 600, batch loss 0.1062, batch acc 0.9710
15:08:29.616 Training @ 13 epoch...
15:08:29.724   Training iter 50, batch loss 0.1042, batch acc 0.9718
15:08:29.840   Training iter 100, batch loss 0.1079, batch acc 0.9670
15:08:29.963   Training iter 150, batch loss 0.1058, batch acc 0.9686
15:08:30.077   Training iter 200, batch loss 0.0997, batch acc 0.9714
15:08:30.199   Training iter 250, batch loss 0.1084, batch acc 0.9686
15:08:30.309   Training iter 300, batch loss 0.1029, batch acc 0.9682
15:08:30.505   Training iter 350, batch loss 0.1045, batch acc 0.9674
15:08:30.638   Training iter 400, batch loss 0.1162, batch acc 0.9688
15:08:30.746   Training iter 450, batch loss 0.1132, batch acc 0.9684
15:08:30.850   Training iter 500, batch loss 0.1096, batch acc 0.9672
15:08:30.974   Training iter 550, batch loss 0.1061, batch acc 0.9708
15:08:31.096   Training iter 600, batch loss 0.1205, batch acc 0.9676
15:08:31.096 Training @ 14 epoch...
15:08:31.338   Training iter 50, batch loss 0.1097, batch acc 0.9642
15:08:31.470   Training iter 100, batch loss 0.0995, batch acc 0.9706
15:08:31.650   Training iter 150, batch loss 0.0951, batch acc 0.9744
15:08:31.787   Training iter 200, batch loss 0.1018, batch acc 0.9688
15:08:31.949   Training iter 250, batch loss 0.0992, batch acc 0.9700
15:08:32.054   Training iter 300, batch loss 0.1028, batch acc 0.9700
15:08:32.157   Training iter 350, batch loss 0.0893, batch acc 0.9742
15:08:32.279   Training iter 400, batch loss 0.1072, batch acc 0.9716
15:08:32.473   Training iter 450, batch loss 0.1084, batch acc 0.9694
15:08:32.660   Training iter 500, batch loss 0.1074, batch acc 0.9706
15:08:32.787   Training iter 550, batch loss 0.1042, batch acc 0.9688
15:08:32.907   Training iter 600, batch loss 0.1056, batch acc 0.9686
15:08:32.907 Training @ 15 epoch...
15:08:33.027   Training iter 50, batch loss 0.0989, batch acc 0.9726
15:08:33.205   Training iter 100, batch loss 0.1069, batch acc 0.9702
15:08:33.319   Training iter 150, batch loss 0.1034, batch acc 0.9706
15:08:33.493   Training iter 200, batch loss 0.0951, batch acc 0.9732
15:08:33.630   Training iter 250, batch loss 0.1026, batch acc 0.9716
15:08:33.809   Training iter 300, batch loss 0.0871, batch acc 0.9742
15:08:33.943   Training iter 350, batch loss 0.0977, batch acc 0.9710
15:08:34.065   Training iter 400, batch loss 0.0988, batch acc 0.9726
15:08:34.176   Training iter 450, batch loss 0.0915, batch acc 0.9742
15:08:34.310   Training iter 500, batch loss 0.0855, batch acc 0.9742
15:08:34.470   Training iter 550, batch loss 0.1084, batch acc 0.9688
15:08:34.625   Training iter 600, batch loss 0.1037, batch acc 0.9688
15:08:34.625 Testing @ 15 epoch...
15:08:34.724     Testing, total mean loss 0.11130, total acc 0.96770
15:08:34.724 Training @ 16 epoch...
15:08:34.865   Training iter 50, batch loss 0.0933, batch acc 0.9750
15:08:35.018   Training iter 100, batch loss 0.0832, batch acc 0.9754
15:08:35.181   Training iter 150, batch loss 0.1130, batch acc 0.9678
15:08:35.328   Training iter 200, batch loss 0.0924, batch acc 0.9720
15:08:35.456   Training iter 250, batch loss 0.1022, batch acc 0.9688
15:08:35.598   Training iter 300, batch loss 0.0991, batch acc 0.9742
15:08:35.719   Training iter 350, batch loss 0.0956, batch acc 0.9738
15:08:35.832   Training iter 400, batch loss 0.0958, batch acc 0.9724
15:08:35.971   Training iter 450, batch loss 0.0887, batch acc 0.9744
15:08:36.097   Training iter 500, batch loss 0.0922, batch acc 0.9716
15:08:36.193   Training iter 550, batch loss 0.0934, batch acc 0.9714
15:08:36.295   Training iter 600, batch loss 0.0920, batch acc 0.9740
15:08:36.296 Training @ 17 epoch...
15:08:36.394   Training iter 50, batch loss 0.0956, batch acc 0.9750
15:08:36.483   Training iter 100, batch loss 0.0918, batch acc 0.9766
15:08:36.603   Training iter 150, batch loss 0.0903, batch acc 0.9728
15:08:36.753   Training iter 200, batch loss 0.0890, batch acc 0.9756
15:08:36.905   Training iter 250, batch loss 0.0892, batch acc 0.9744
15:08:37.032   Training iter 300, batch loss 0.0909, batch acc 0.9754
15:08:37.219   Training iter 350, batch loss 0.0986, batch acc 0.9730
15:08:37.337   Training iter 400, batch loss 0.0946, batch acc 0.9714
15:08:37.474   Training iter 450, batch loss 0.0826, batch acc 0.9784
15:08:37.644   Training iter 500, batch loss 0.0892, batch acc 0.9726
15:08:37.754   Training iter 550, batch loss 0.0909, batch acc 0.9752
15:08:37.902   Training iter 600, batch loss 0.0796, batch acc 0.9770
15:08:37.904 Training @ 18 epoch...
15:08:38.003   Training iter 50, batch loss 0.0948, batch acc 0.9726
15:08:38.131   Training iter 100, batch loss 0.0869, batch acc 0.9734
15:08:38.261   Training iter 150, batch loss 0.0841, batch acc 0.9764
15:08:38.406   Training iter 200, batch loss 0.0888, batch acc 0.9744
15:08:38.527   Training iter 250, batch loss 0.0882, batch acc 0.9724
15:08:38.654   Training iter 300, batch loss 0.0806, batch acc 0.9780
15:08:38.801   Training iter 350, batch loss 0.0848, batch acc 0.9770
15:08:38.955   Training iter 400, batch loss 0.0831, batch acc 0.9754
15:08:39.189   Training iter 450, batch loss 0.0845, batch acc 0.9748
15:08:39.342   Training iter 500, batch loss 0.0923, batch acc 0.9744
15:08:39.492   Training iter 550, batch loss 0.0897, batch acc 0.9738
15:08:39.603   Training iter 600, batch loss 0.0935, batch acc 0.9712
15:08:39.604 Training @ 19 epoch...
15:08:39.765   Training iter 50, batch loss 0.0821, batch acc 0.9738
15:08:39.890   Training iter 100, batch loss 0.0805, batch acc 0.9778
15:08:39.983   Training iter 150, batch loss 0.0887, batch acc 0.9758
15:08:40.092   Training iter 200, batch loss 0.0818, batch acc 0.9788
15:08:40.206   Training iter 250, batch loss 0.0865, batch acc 0.9746
15:08:40.366   Training iter 300, batch loss 0.0780, batch acc 0.9798
15:08:40.496   Training iter 350, batch loss 0.0769, batch acc 0.9804
15:08:40.647   Training iter 400, batch loss 0.0866, batch acc 0.9736
15:08:40.802   Training iter 450, batch loss 0.0840, batch acc 0.9750
15:08:40.938   Training iter 500, batch loss 0.0857, batch acc 0.9766
15:08:41.065   Training iter 550, batch loss 0.0924, batch acc 0.9746
15:08:41.171   Training iter 600, batch loss 0.0922, batch acc 0.9738
15:08:41.172 Training @ 20 epoch...
15:08:41.289   Training iter 50, batch loss 0.0733, batch acc 0.9792
15:08:41.421   Training iter 100, batch loss 0.0880, batch acc 0.9754
15:08:41.564   Training iter 150, batch loss 0.0869, batch acc 0.9752
15:08:41.737   Training iter 200, batch loss 0.0827, batch acc 0.9760
15:08:41.872   Training iter 250, batch loss 0.0788, batch acc 0.9778
15:08:42.058   Training iter 300, batch loss 0.0771, batch acc 0.9766
15:08:42.176   Training iter 350, batch loss 0.0756, batch acc 0.9762
15:08:42.296   Training iter 400, batch loss 0.0806, batch acc 0.9780
15:08:42.401   Training iter 450, batch loss 0.0908, batch acc 0.9734
15:08:42.496   Training iter 500, batch loss 0.0758, batch acc 0.9762
15:08:42.602   Training iter 550, batch loss 0.0826, batch acc 0.9780
15:08:42.702   Training iter 600, batch loss 0.0854, batch acc 0.9770
15:08:42.702 Testing @ 20 epoch...
15:08:42.789     Testing, total mean loss 0.09887, total acc 0.96890
15:08:42.789 Training @ 21 epoch...
15:08:42.919   Training iter 50, batch loss 0.0775, batch acc 0.9768
15:08:43.020   Training iter 100, batch loss 0.0829, batch acc 0.9764
15:08:43.123   Training iter 150, batch loss 0.0753, batch acc 0.9788
15:08:43.225   Training iter 200, batch loss 0.0837, batch acc 0.9766
15:08:43.337   Training iter 250, batch loss 0.0796, batch acc 0.9792
15:08:43.435   Training iter 300, batch loss 0.0740, batch acc 0.9762
15:08:43.533   Training iter 350, batch loss 0.0766, batch acc 0.9776
15:08:43.656   Training iter 400, batch loss 0.0844, batch acc 0.9764
15:08:43.836   Training iter 450, batch loss 0.0796, batch acc 0.9788
15:08:43.953   Training iter 500, batch loss 0.0841, batch acc 0.9768
15:08:44.055   Training iter 550, batch loss 0.0735, batch acc 0.9818
15:08:44.179   Training iter 600, batch loss 0.0881, batch acc 0.9746
15:08:44.179 Training @ 22 epoch...
15:08:44.286   Training iter 50, batch loss 0.0628, batch acc 0.9850
15:08:44.413   Training iter 100, batch loss 0.0752, batch acc 0.9820
15:08:44.543   Training iter 150, batch loss 0.0786, batch acc 0.9784
15:08:44.641   Training iter 200, batch loss 0.0728, batch acc 0.9792
15:08:44.740   Training iter 250, batch loss 0.0786, batch acc 0.9782
15:08:44.852   Training iter 300, batch loss 0.0846, batch acc 0.9754
15:08:44.960   Training iter 350, batch loss 0.0759, batch acc 0.9810
15:08:45.065   Training iter 400, batch loss 0.0684, batch acc 0.9808
15:08:45.153   Training iter 450, batch loss 0.0859, batch acc 0.9758
15:08:45.250   Training iter 500, batch loss 0.0786, batch acc 0.9762
15:08:45.333   Training iter 550, batch loss 0.0807, batch acc 0.9798
15:08:45.432   Training iter 600, batch loss 0.0747, batch acc 0.9774
15:08:45.433 Training @ 23 epoch...
15:08:45.538   Training iter 50, batch loss 0.0614, batch acc 0.9838
15:08:45.635   Training iter 100, batch loss 0.0903, batch acc 0.9746
15:08:45.735   Training iter 150, batch loss 0.0681, batch acc 0.9816
15:08:45.826   Training iter 200, batch loss 0.0821, batch acc 0.9758
15:08:45.919   Training iter 250, batch loss 0.0760, batch acc 0.9792
15:08:46.015   Training iter 300, batch loss 0.0812, batch acc 0.9738
15:08:46.104   Training iter 350, batch loss 0.0793, batch acc 0.9776
15:08:46.207   Training iter 400, batch loss 0.0744, batch acc 0.9814
15:08:46.298   Training iter 450, batch loss 0.0832, batch acc 0.9742
15:08:46.400   Training iter 500, batch loss 0.0731, batch acc 0.9790
15:08:46.493   Training iter 550, batch loss 0.0728, batch acc 0.9812
15:08:46.609   Training iter 600, batch loss 0.0839, batch acc 0.9772
15:08:46.610 Training @ 24 epoch...
15:08:46.715   Training iter 50, batch loss 0.0646, batch acc 0.9838
15:08:46.826   Training iter 100, batch loss 0.0735, batch acc 0.9798
15:08:46.930   Training iter 150, batch loss 0.0735, batch acc 0.9810
15:08:47.034   Training iter 200, batch loss 0.0717, batch acc 0.9824
15:08:47.139   Training iter 250, batch loss 0.0798, batch acc 0.9776
15:08:47.280   Training iter 300, batch loss 0.0775, batch acc 0.9770
15:08:47.398   Training iter 350, batch loss 0.0707, batch acc 0.9806
15:08:47.505   Training iter 400, batch loss 0.0744, batch acc 0.9778
15:08:47.620   Training iter 450, batch loss 0.0718, batch acc 0.9800
15:08:47.782   Training iter 500, batch loss 0.0785, batch acc 0.9780
15:08:47.891   Training iter 550, batch loss 0.0737, batch acc 0.9794
15:08:48.113   Training iter 600, batch loss 0.0722, batch acc 0.9786
15:08:48.114 Training @ 25 epoch...
15:08:48.225   Training iter 50, batch loss 0.0718, batch acc 0.9800
15:08:48.329   Training iter 100, batch loss 0.0737, batch acc 0.9794
15:08:48.479   Training iter 150, batch loss 0.0739, batch acc 0.9774
15:08:48.581   Training iter 200, batch loss 0.0796, batch acc 0.9784
15:08:48.685   Training iter 250, batch loss 0.0676, batch acc 0.9814
15:08:48.781   Training iter 300, batch loss 0.0878, batch acc 0.9728
15:08:48.873   Training iter 350, batch loss 0.0763, batch acc 0.9758
15:08:48.981   Training iter 400, batch loss 0.0679, batch acc 0.9802
15:08:49.075   Training iter 450, batch loss 0.0758, batch acc 0.9780
15:08:49.167   Training iter 500, batch loss 0.0645, batch acc 0.9816
15:08:49.359   Training iter 550, batch loss 0.0712, batch acc 0.9790
15:08:49.480   Training iter 600, batch loss 0.0682, batch acc 0.9822
15:08:49.481 Testing @ 25 epoch...
15:08:49.568     Testing, total mean loss 0.09571, total acc 0.97040
15:08:49.568 Training @ 26 epoch...
15:08:49.691   Training iter 50, batch loss 0.0709, batch acc 0.9814
15:08:50.003   Training iter 100, batch loss 0.0667, batch acc 0.9830
15:08:50.197   Training iter 150, batch loss 0.0700, batch acc 0.9822
15:08:50.441   Training iter 200, batch loss 0.0787, batch acc 0.9788
15:08:50.622   Training iter 250, batch loss 0.0635, batch acc 0.9824
15:08:50.762   Training iter 300, batch loss 0.0689, batch acc 0.9806
15:08:50.875   Training iter 350, batch loss 0.0762, batch acc 0.9796
15:08:50.976   Training iter 400, batch loss 0.0761, batch acc 0.9780
15:08:51.080   Training iter 450, batch loss 0.0765, batch acc 0.9786
15:08:51.186   Training iter 500, batch loss 0.0673, batch acc 0.9808
15:08:51.276   Training iter 550, batch loss 0.0784, batch acc 0.9770
15:08:51.486   Training iter 600, batch loss 0.0636, batch acc 0.9820
15:08:51.486 Training @ 27 epoch...
15:08:51.676   Training iter 50, batch loss 0.0678, batch acc 0.9816
15:08:51.823   Training iter 100, batch loss 0.0593, batch acc 0.9842
15:08:52.022   Training iter 150, batch loss 0.0815, batch acc 0.9780
15:08:52.226   Training iter 200, batch loss 0.0755, batch acc 0.9782
15:08:52.485   Training iter 250, batch loss 0.0601, batch acc 0.9850
15:08:52.602   Training iter 300, batch loss 0.0660, batch acc 0.9818
15:08:52.793   Training iter 350, batch loss 0.0760, batch acc 0.9790
15:08:52.936   Training iter 400, batch loss 0.0653, batch acc 0.9816
15:08:53.155   Training iter 450, batch loss 0.0725, batch acc 0.9782
15:08:53.330   Training iter 500, batch loss 0.0779, batch acc 0.9758
15:08:53.593   Training iter 550, batch loss 0.0661, batch acc 0.9808
15:08:53.804   Training iter 600, batch loss 0.0693, batch acc 0.9826
15:08:53.805 Training @ 28 epoch...
15:08:53.954   Training iter 50, batch loss 0.0671, batch acc 0.9830
15:08:54.077   Training iter 100, batch loss 0.0700, batch acc 0.9822
15:08:54.201   Training iter 150, batch loss 0.0664, batch acc 0.9828
15:08:54.325   Training iter 200, batch loss 0.0607, batch acc 0.9834
15:08:54.468   Training iter 250, batch loss 0.0605, batch acc 0.9830
15:08:54.569   Training iter 300, batch loss 0.0693, batch acc 0.9818
15:08:54.667   Training iter 350, batch loss 0.0815, batch acc 0.9780
15:08:54.796   Training iter 400, batch loss 0.0666, batch acc 0.9806
15:08:54.925   Training iter 450, batch loss 0.0641, batch acc 0.9824
15:08:55.053   Training iter 500, batch loss 0.0685, batch acc 0.9796
15:08:55.203   Training iter 550, batch loss 0.0782, batch acc 0.9766
15:08:55.342   Training iter 600, batch loss 0.0674, batch acc 0.9812
15:08:55.343 Training @ 29 epoch...
15:08:55.451   Training iter 50, batch loss 0.0697, batch acc 0.9814
15:08:55.549   Training iter 100, batch loss 0.0630, batch acc 0.9842
15:08:55.624   Training iter 150, batch loss 0.0638, batch acc 0.9820
15:08:55.827   Training iter 200, batch loss 0.0699, batch acc 0.9800
15:08:55.965   Training iter 250, batch loss 0.0685, batch acc 0.9810
15:08:56.091   Training iter 300, batch loss 0.0741, batch acc 0.9784
15:08:56.189   Training iter 350, batch loss 0.0729, batch acc 0.9786
15:08:56.284   Training iter 400, batch loss 0.0646, batch acc 0.9808
15:08:56.407   Training iter 450, batch loss 0.0690, batch acc 0.9810
15:08:56.502   Training iter 500, batch loss 0.0705, batch acc 0.9810
15:08:56.602   Training iter 550, batch loss 0.0678, batch acc 0.9820
15:08:56.697   Training iter 600, batch loss 0.0653, batch acc 0.9808
15:08:56.697 Training @ 30 epoch...
15:08:56.802   Training iter 50, batch loss 0.0594, batch acc 0.9826
15:08:56.908   Training iter 100, batch loss 0.0592, batch acc 0.9848
15:08:57.005   Training iter 150, batch loss 0.0625, batch acc 0.9816
15:08:57.109   Training iter 200, batch loss 0.0648, batch acc 0.9834
15:08:57.208   Training iter 250, batch loss 0.0686, batch acc 0.9812
15:08:57.300   Training iter 300, batch loss 0.0669, batch acc 0.9826
15:08:57.414   Training iter 350, batch loss 0.0652, batch acc 0.9812
15:08:57.625   Training iter 400, batch loss 0.0618, batch acc 0.9840
15:08:57.745   Training iter 450, batch loss 0.0693, batch acc 0.9814
15:08:57.872   Training iter 500, batch loss 0.0699, batch acc 0.9804
15:08:58.022   Training iter 550, batch loss 0.0645, batch acc 0.9830
15:08:58.150   Training iter 600, batch loss 0.0665, batch acc 0.9826
15:08:58.153 Testing @ 30 epoch...
15:08:58.255     Testing, total mean loss 0.08460, total acc 0.97410
15:08:58.255 Training @ 31 epoch...
15:08:58.407   Training iter 50, batch loss 0.0637, batch acc 0.9824
15:08:58.531   Training iter 100, batch loss 0.0640, batch acc 0.9804
15:08:58.654   Training iter 150, batch loss 0.0659, batch acc 0.9822
15:08:58.808   Training iter 200, batch loss 0.0628, batch acc 0.9836
15:08:58.988   Training iter 250, batch loss 0.0659, batch acc 0.9800
15:08:59.088   Training iter 300, batch loss 0.0673, batch acc 0.9826
15:08:59.165   Training iter 350, batch loss 0.0584, batch acc 0.9842
15:08:59.271   Training iter 400, batch loss 0.0667, batch acc 0.9806
15:08:59.371   Training iter 450, batch loss 0.0566, batch acc 0.9846
15:08:59.481   Training iter 500, batch loss 0.0651, batch acc 0.9818
15:08:59.586   Training iter 550, batch loss 0.0698, batch acc 0.9802
15:08:59.674   Training iter 600, batch loss 0.0684, batch acc 0.9822
15:08:59.674 Training @ 32 epoch...
15:08:59.774   Training iter 50, batch loss 0.0518, batch acc 0.9870
15:08:59.928   Training iter 100, batch loss 0.0619, batch acc 0.9836
15:09:00.110   Training iter 150, batch loss 0.0607, batch acc 0.9838
15:09:00.452   Training iter 200, batch loss 0.0568, batch acc 0.9842
15:09:00.704   Training iter 250, batch loss 0.0632, batch acc 0.9840
15:09:01.348   Training iter 300, batch loss 0.0603, batch acc 0.9840
15:09:01.474   Training iter 350, batch loss 0.0597, batch acc 0.9848
15:09:01.599   Training iter 400, batch loss 0.0638, batch acc 0.9824
15:09:01.756   Training iter 450, batch loss 0.0660, batch acc 0.9824
15:09:01.858   Training iter 500, batch loss 0.0646, batch acc 0.9810
15:09:01.976   Training iter 550, batch loss 0.0714, batch acc 0.9788
15:09:02.319   Training iter 600, batch loss 0.0708, batch acc 0.9798
15:09:02.319 Training @ 33 epoch...
15:09:02.465   Training iter 50, batch loss 0.0576, batch acc 0.9858
15:09:02.606   Training iter 100, batch loss 0.0580, batch acc 0.9832
15:09:02.692   Training iter 150, batch loss 0.0622, batch acc 0.9814
15:09:02.891   Training iter 200, batch loss 0.0667, batch acc 0.9820
15:09:03.019   Training iter 250, batch loss 0.0607, batch acc 0.9842
15:09:03.124   Training iter 300, batch loss 0.0551, batch acc 0.9870
15:09:03.317   Training iter 350, batch loss 0.0569, batch acc 0.9846
15:09:03.508   Training iter 400, batch loss 0.0682, batch acc 0.9808
15:09:03.671   Training iter 450, batch loss 0.0713, batch acc 0.9792
15:09:03.817   Training iter 500, batch loss 0.0634, batch acc 0.9822
15:09:03.985   Training iter 550, batch loss 0.0643, batch acc 0.9824
15:09:04.109   Training iter 600, batch loss 0.0700, batch acc 0.9800
15:09:04.110 Training @ 34 epoch...
15:09:04.225   Training iter 50, batch loss 0.0574, batch acc 0.9834
15:09:04.487   Training iter 100, batch loss 0.0596, batch acc 0.9856
15:09:04.619   Training iter 150, batch loss 0.0648, batch acc 0.9816
15:09:04.902   Training iter 200, batch loss 0.0669, batch acc 0.9810
15:09:05.036   Training iter 250, batch loss 0.0696, batch acc 0.9798
15:09:05.257   Training iter 300, batch loss 0.0569, batch acc 0.9856
15:09:05.402   Training iter 350, batch loss 0.0595, batch acc 0.9832
15:09:05.570   Training iter 400, batch loss 0.0606, batch acc 0.9834
15:09:05.719   Training iter 450, batch loss 0.0569, batch acc 0.9854
15:09:06.007   Training iter 500, batch loss 0.0676, batch acc 0.9808
15:09:06.180   Training iter 550, batch loss 0.0617, batch acc 0.9842
15:09:06.450   Training iter 600, batch loss 0.0626, batch acc 0.9830
15:09:06.451 Training @ 35 epoch...
15:09:06.588   Training iter 50, batch loss 0.0606, batch acc 0.9836
15:09:06.780   Training iter 100, batch loss 0.0675, batch acc 0.9820
15:09:06.958   Training iter 150, batch loss 0.0653, batch acc 0.9824
15:09:07.164   Training iter 200, batch loss 0.0619, batch acc 0.9846
15:09:07.318   Training iter 250, batch loss 0.0562, batch acc 0.9854
15:09:07.514   Training iter 300, batch loss 0.0599, batch acc 0.9834
15:09:07.704   Training iter 350, batch loss 0.0561, batch acc 0.9850
15:09:07.823   Training iter 400, batch loss 0.0650, batch acc 0.9822
15:09:07.939   Training iter 450, batch loss 0.0504, batch acc 0.9862
15:09:08.134   Training iter 500, batch loss 0.0676, batch acc 0.9786
15:09:08.257   Training iter 550, batch loss 0.0602, batch acc 0.9826
15:09:08.346   Training iter 600, batch loss 0.0607, batch acc 0.9848
15:09:08.347 Testing @ 35 epoch...
15:09:08.497     Testing, total mean loss 0.08229, total acc 0.97590
15:09:08.497 Training @ 36 epoch...
15:09:08.670   Training iter 50, batch loss 0.0509, batch acc 0.9880
15:09:08.818   Training iter 100, batch loss 0.0604, batch acc 0.9848
15:09:08.926   Training iter 150, batch loss 0.0669, batch acc 0.9824
15:09:09.161   Training iter 200, batch loss 0.0551, batch acc 0.9876
15:09:09.466   Training iter 250, batch loss 0.0651, batch acc 0.9826
15:09:09.600   Training iter 300, batch loss 0.0557, batch acc 0.9854
15:09:09.739   Training iter 350, batch loss 0.0559, batch acc 0.9862
15:09:09.917   Training iter 400, batch loss 0.0610, batch acc 0.9808
15:09:10.056   Training iter 450, batch loss 0.0557, batch acc 0.9846
15:09:10.186   Training iter 500, batch loss 0.0597, batch acc 0.9822
15:09:10.341   Training iter 550, batch loss 0.0643, batch acc 0.9810
15:09:10.492   Training iter 600, batch loss 0.0649, batch acc 0.9806
15:09:10.493 Training @ 37 epoch...
15:09:10.616   Training iter 50, batch loss 0.0600, batch acc 0.9834
15:09:10.753   Training iter 100, batch loss 0.0563, batch acc 0.9848
15:09:10.880   Training iter 150, batch loss 0.0638, batch acc 0.9814
15:09:11.098   Training iter 200, batch loss 0.0552, batch acc 0.9830
15:09:11.230   Training iter 250, batch loss 0.0556, batch acc 0.9856
15:09:11.374   Training iter 300, batch loss 0.0535, batch acc 0.9872
15:09:11.571   Training iter 350, batch loss 0.0599, batch acc 0.9850
15:09:11.679   Training iter 400, batch loss 0.0657, batch acc 0.9840
15:09:11.906   Training iter 450, batch loss 0.0614, batch acc 0.9852
15:09:12.044   Training iter 500, batch loss 0.0596, batch acc 0.9850
15:09:12.142   Training iter 550, batch loss 0.0641, batch acc 0.9820
15:09:12.257   Training iter 600, batch loss 0.0641, batch acc 0.9826
15:09:12.258 Training @ 38 epoch...
15:09:12.357   Training iter 50, batch loss 0.0553, batch acc 0.9862
15:09:12.478   Training iter 100, batch loss 0.0516, batch acc 0.9878
15:09:12.586   Training iter 150, batch loss 0.0631, batch acc 0.9830
15:09:12.700   Training iter 200, batch loss 0.0519, batch acc 0.9856
15:09:12.834   Training iter 250, batch loss 0.0645, batch acc 0.9808
15:09:12.936   Training iter 300, batch loss 0.0532, batch acc 0.9874
15:09:13.052   Training iter 350, batch loss 0.0582, batch acc 0.9838
15:09:13.166   Training iter 400, batch loss 0.0507, batch acc 0.9868
15:09:13.280   Training iter 450, batch loss 0.0624, batch acc 0.9830
15:09:13.379   Training iter 500, batch loss 0.0667, batch acc 0.9804
15:09:13.471   Training iter 550, batch loss 0.0602, batch acc 0.9832
15:09:13.566   Training iter 600, batch loss 0.0643, batch acc 0.9830
15:09:13.567 Training @ 39 epoch...
15:09:13.659   Training iter 50, batch loss 0.0599, batch acc 0.9842
15:09:13.769   Training iter 100, batch loss 0.0578, batch acc 0.9844
15:09:13.875   Training iter 150, batch loss 0.0601, batch acc 0.9826
15:09:13.970   Training iter 200, batch loss 0.0513, batch acc 0.9884
15:09:14.105   Training iter 250, batch loss 0.0615, batch acc 0.9842
15:09:14.189   Training iter 300, batch loss 0.0604, batch acc 0.9836
15:09:14.285   Training iter 350, batch loss 0.0590, batch acc 0.9836
15:09:14.417   Training iter 400, batch loss 0.0558, batch acc 0.9868
15:09:14.547   Training iter 450, batch loss 0.0561, batch acc 0.9854
15:09:14.665   Training iter 500, batch loss 0.0574, batch acc 0.9838
15:09:14.784   Training iter 550, batch loss 0.0613, batch acc 0.9832
15:09:14.943   Training iter 600, batch loss 0.0545, batch acc 0.9868
15:09:14.946 Training @ 40 epoch...
15:09:15.101   Training iter 50, batch loss 0.0545, batch acc 0.9858
15:09:15.239   Training iter 100, batch loss 0.0577, batch acc 0.9850
15:09:15.354   Training iter 150, batch loss 0.0529, batch acc 0.9868
15:09:15.484   Training iter 200, batch loss 0.0597, batch acc 0.9842
15:09:15.584   Training iter 250, batch loss 0.0497, batch acc 0.9876
15:09:15.702   Training iter 300, batch loss 0.0620, batch acc 0.9842
15:09:15.812   Training iter 350, batch loss 0.0582, batch acc 0.9814
15:09:15.958   Training iter 400, batch loss 0.0564, batch acc 0.9834
15:09:16.073   Training iter 450, batch loss 0.0640, batch acc 0.9834
15:09:16.222   Training iter 500, batch loss 0.0577, batch acc 0.9848
15:09:16.392   Training iter 550, batch loss 0.0512, batch acc 0.9882
15:09:16.518   Training iter 600, batch loss 0.0539, batch acc 0.9850
15:09:16.518 Testing @ 40 epoch...
15:09:16.617     Testing, total mean loss 0.07988, total acc 0.97600
15:09:16.617 Training @ 41 epoch...
15:09:16.745   Training iter 50, batch loss 0.0532, batch acc 0.9866
15:09:16.863   Training iter 100, batch loss 0.0519, batch acc 0.9872
15:09:16.974   Training iter 150, batch loss 0.0568, batch acc 0.9850
15:09:17.095   Training iter 200, batch loss 0.0498, batch acc 0.9886
15:09:17.210   Training iter 250, batch loss 0.0535, batch acc 0.9876
15:09:17.322   Training iter 300, batch loss 0.0571, batch acc 0.9854
15:09:17.410   Training iter 350, batch loss 0.0542, batch acc 0.9864
15:09:17.607   Training iter 400, batch loss 0.0620, batch acc 0.9822
15:09:17.724   Training iter 450, batch loss 0.0601, batch acc 0.9838
15:09:17.842   Training iter 500, batch loss 0.0597, batch acc 0.9842
15:09:17.960   Training iter 550, batch loss 0.0636, batch acc 0.9816
15:09:18.075   Training iter 600, batch loss 0.0579, batch acc 0.9836
15:09:18.075 Training @ 42 epoch...
15:09:18.183   Training iter 50, batch loss 0.0533, batch acc 0.9864
15:09:18.279   Training iter 100, batch loss 0.0613, batch acc 0.9828
15:09:18.402   Training iter 150, batch loss 0.0561, batch acc 0.9866
15:09:18.511   Training iter 200, batch loss 0.0587, batch acc 0.9854
15:09:18.617   Training iter 250, batch loss 0.0588, batch acc 0.9856
15:09:18.719   Training iter 300, batch loss 0.0539, batch acc 0.9864
15:09:18.834   Training iter 350, batch loss 0.0497, batch acc 0.9852
15:09:18.956   Training iter 400, batch loss 0.0578, batch acc 0.9842
15:09:19.051   Training iter 450, batch loss 0.0609, batch acc 0.9840
15:09:19.173   Training iter 500, batch loss 0.0528, batch acc 0.9878
15:09:19.257   Training iter 550, batch loss 0.0493, batch acc 0.9856
15:09:19.342   Training iter 600, batch loss 0.0581, batch acc 0.9828
15:09:19.343 Training @ 43 epoch...
15:09:19.468   Training iter 50, batch loss 0.0569, batch acc 0.9854
15:09:19.600   Training iter 100, batch loss 0.0502, batch acc 0.9884
15:09:19.692   Training iter 150, batch loss 0.0518, batch acc 0.9840
15:09:19.771   Training iter 200, batch loss 0.0580, batch acc 0.9842
15:09:19.858   Training iter 250, batch loss 0.0509, batch acc 0.9882
15:09:19.948   Training iter 300, batch loss 0.0565, batch acc 0.9856
15:09:20.033   Training iter 350, batch loss 0.0524, batch acc 0.9856
15:09:20.111   Training iter 400, batch loss 0.0553, batch acc 0.9852
15:09:20.203   Training iter 450, batch loss 0.0606, batch acc 0.9840
15:09:20.283   Training iter 500, batch loss 0.0584, batch acc 0.9850
15:09:20.372   Training iter 550, batch loss 0.0601, batch acc 0.9832
15:09:20.506   Training iter 600, batch loss 0.0621, batch acc 0.9860
15:09:20.507 Training @ 44 epoch...
15:09:20.619   Training iter 50, batch loss 0.0483, batch acc 0.9870
15:09:20.731   Training iter 100, batch loss 0.0510, batch acc 0.9866
15:09:20.872   Training iter 150, batch loss 0.0555, batch acc 0.9856
15:09:20.998   Training iter 200, batch loss 0.0612, batch acc 0.9832
15:09:21.130   Training iter 250, batch loss 0.0550, batch acc 0.9842
15:09:21.222   Training iter 300, batch loss 0.0600, batch acc 0.9866
15:09:21.306   Training iter 350, batch loss 0.0590, batch acc 0.9832
15:09:21.520   Training iter 400, batch loss 0.0521, batch acc 0.9858
15:09:21.683   Training iter 450, batch loss 0.0557, batch acc 0.9858
15:09:21.793   Training iter 500, batch loss 0.0495, batch acc 0.9866
15:09:21.923   Training iter 550, batch loss 0.0576, batch acc 0.9834
15:09:22.019   Training iter 600, batch loss 0.0559, batch acc 0.9850
15:09:22.020 Training @ 45 epoch...
15:09:22.123   Training iter 50, batch loss 0.0496, batch acc 0.9892
15:09:22.228   Training iter 100, batch loss 0.0486, batch acc 0.9892
15:09:22.337   Training iter 150, batch loss 0.0493, batch acc 0.9868
15:09:22.418   Training iter 200, batch loss 0.0574, batch acc 0.9838
15:09:22.504   Training iter 250, batch loss 0.0494, batch acc 0.9884
15:09:22.590   Training iter 300, batch loss 0.0530, batch acc 0.9870
15:09:22.670   Training iter 350, batch loss 0.0534, batch acc 0.9842
15:09:22.760   Training iter 400, batch loss 0.0600, batch acc 0.9836
15:09:22.858   Training iter 450, batch loss 0.0566, batch acc 0.9860
15:09:22.983   Training iter 500, batch loss 0.0633, batch acc 0.9826
15:09:23.118   Training iter 550, batch loss 0.0557, batch acc 0.9846
15:09:23.267   Training iter 600, batch loss 0.0543, batch acc 0.9870
15:09:23.267 Testing @ 45 epoch...
15:09:23.350     Testing, total mean loss 0.07847, total acc 0.97640
15:09:23.350 Training @ 46 epoch...
15:09:23.471   Training iter 50, batch loss 0.0530, batch acc 0.9848
15:09:23.566   Training iter 100, batch loss 0.0517, batch acc 0.9882
15:09:23.685   Training iter 150, batch loss 0.0521, batch acc 0.9862
15:09:23.802   Training iter 200, batch loss 0.0522, batch acc 0.9876
15:09:23.917   Training iter 250, batch loss 0.0518, batch acc 0.9870
15:09:24.024   Training iter 300, batch loss 0.0538, batch acc 0.9878
15:09:24.118   Training iter 350, batch loss 0.0543, batch acc 0.9862
15:09:24.233   Training iter 400, batch loss 0.0596, batch acc 0.9844
15:09:24.345   Training iter 450, batch loss 0.0490, batch acc 0.9862
15:09:24.797   Training iter 500, batch loss 0.0553, batch acc 0.9870
15:09:24.958   Training iter 550, batch loss 0.0580, batch acc 0.9848
15:09:25.124   Training iter 600, batch loss 0.0573, batch acc 0.9836
15:09:25.125 Training @ 47 epoch...
15:09:25.222   Training iter 50, batch loss 0.0514, batch acc 0.9876
15:09:25.358   Training iter 100, batch loss 0.0500, batch acc 0.9874
15:09:25.573   Training iter 150, batch loss 0.0589, batch acc 0.9836
15:09:25.725   Training iter 200, batch loss 0.0528, batch acc 0.9860
15:09:25.874   Training iter 250, batch loss 0.0548, batch acc 0.9856
15:09:26.033   Training iter 300, batch loss 0.0554, batch acc 0.9870
15:09:26.163   Training iter 350, batch loss 0.0535, batch acc 0.9862
15:09:26.290   Training iter 400, batch loss 0.0531, batch acc 0.9884
15:09:26.408   Training iter 450, batch loss 0.0573, batch acc 0.9846
15:09:26.534   Training iter 500, batch loss 0.0451, batch acc 0.9884
15:09:26.662   Training iter 550, batch loss 0.0559, batch acc 0.9862
15:09:26.835   Training iter 600, batch loss 0.0606, batch acc 0.9828
15:09:26.836 Training @ 48 epoch...
15:09:26.938   Training iter 50, batch loss 0.0462, batch acc 0.9896
15:09:27.063   Training iter 100, batch loss 0.0500, batch acc 0.9882
15:09:27.155   Training iter 150, batch loss 0.0566, batch acc 0.9856
15:09:27.256   Training iter 200, batch loss 0.0521, batch acc 0.9862
15:09:27.490   Training iter 250, batch loss 0.0489, batch acc 0.9866
15:09:27.663   Training iter 300, batch loss 0.0545, batch acc 0.9842
15:09:27.772   Training iter 350, batch loss 0.0551, batch acc 0.9852
15:09:27.907   Training iter 400, batch loss 0.0573, batch acc 0.9848
15:09:28.129   Training iter 450, batch loss 0.0514, batch acc 0.9876
15:09:28.300   Training iter 500, batch loss 0.0607, batch acc 0.9836
15:09:28.471   Training iter 550, batch loss 0.0559, batch acc 0.9836
15:09:28.603   Training iter 600, batch loss 0.0497, batch acc 0.9878
15:09:28.603 Training @ 49 epoch...
15:09:28.741   Training iter 50, batch loss 0.0463, batch acc 0.9896
15:09:28.907   Training iter 100, batch loss 0.0478, batch acc 0.9894
15:09:29.023   Training iter 150, batch loss 0.0422, batch acc 0.9884
15:09:29.215   Training iter 200, batch loss 0.0527, batch acc 0.9856
15:09:29.338   Training iter 250, batch loss 0.0510, batch acc 0.9870
15:09:29.525   Training iter 300, batch loss 0.0489, batch acc 0.9876
15:09:29.676   Training iter 350, batch loss 0.0550, batch acc 0.9848
15:09:29.782   Training iter 400, batch loss 0.0543, batch acc 0.9844
15:09:29.878   Training iter 450, batch loss 0.0599, batch acc 0.9846
15:09:29.981   Training iter 500, batch loss 0.0623, batch acc 0.9828
15:09:30.093   Training iter 550, batch loss 0.0503, batch acc 0.9866
15:09:30.222   Training iter 600, batch loss 0.0583, batch acc 0.9848
15:09:30.223 Training @ 50 epoch...
15:09:30.358   Training iter 50, batch loss 0.0495, batch acc 0.9866
15:09:30.493   Training iter 100, batch loss 0.0445, batch acc 0.9888
15:09:30.620   Training iter 150, batch loss 0.0470, batch acc 0.9880
15:09:30.736   Training iter 200, batch loss 0.0531, batch acc 0.9874
15:09:30.841   Training iter 250, batch loss 0.0498, batch acc 0.9878
15:09:30.977   Training iter 300, batch loss 0.0525, batch acc 0.9880
15:09:31.084   Training iter 350, batch loss 0.0588, batch acc 0.9822
15:09:31.200   Training iter 400, batch loss 0.0570, batch acc 0.9852
15:09:31.291   Training iter 450, batch loss 0.0505, batch acc 0.9876
15:09:31.393   Training iter 500, batch loss 0.0585, batch acc 0.9862
15:09:31.504   Training iter 550, batch loss 0.0514, batch acc 0.9864
15:09:31.621   Training iter 600, batch loss 0.0572, batch acc 0.9844
15:09:31.623 Testing @ 50 epoch...
15:09:31.696     Testing, total mean loss 0.07858, total acc 0.97440
15:09:31.696 Training @ 51 epoch...
15:09:32.030   Training iter 50, batch loss 0.0526, batch acc 0.9868
15:09:32.244   Training iter 100, batch loss 0.0511, batch acc 0.9870
15:09:32.474   Training iter 150, batch loss 0.0519, batch acc 0.9874
15:09:32.596   Training iter 200, batch loss 0.0523, batch acc 0.9862
15:09:32.739   Training iter 250, batch loss 0.0482, batch acc 0.9880
15:09:32.972   Training iter 300, batch loss 0.0549, batch acc 0.9862
15:09:33.134   Training iter 350, batch loss 0.0493, batch acc 0.9868
15:09:33.254   Training iter 400, batch loss 0.0543, batch acc 0.9862
15:09:33.353   Training iter 450, batch loss 0.0530, batch acc 0.9852
15:09:33.430   Training iter 500, batch loss 0.0544, batch acc 0.9868
15:09:33.524   Training iter 550, batch loss 0.0479, batch acc 0.9880
15:09:33.637   Training iter 600, batch loss 0.0546, batch acc 0.9852
15:09:33.638 Training @ 52 epoch...
15:09:33.775   Training iter 50, batch loss 0.0546, batch acc 0.9864
15:09:33.989   Training iter 100, batch loss 0.0527, batch acc 0.9872
15:09:34.147   Training iter 150, batch loss 0.0477, batch acc 0.9878
15:09:34.334   Training iter 200, batch loss 0.0516, batch acc 0.9878
15:09:34.507   Training iter 250, batch loss 0.0550, batch acc 0.9862
15:09:34.627   Training iter 300, batch loss 0.0501, batch acc 0.9868
15:09:34.753   Training iter 350, batch loss 0.0482, batch acc 0.9880
15:09:34.872   Training iter 400, batch loss 0.0452, batch acc 0.9890
15:09:35.202   Training iter 450, batch loss 0.0538, batch acc 0.9854
15:09:35.300   Training iter 500, batch loss 0.0543, batch acc 0.9860
15:09:35.438   Training iter 550, batch loss 0.0551, batch acc 0.9854
15:09:35.548   Training iter 600, batch loss 0.0483, batch acc 0.9864
15:09:35.548 Training @ 53 epoch...
15:09:35.700   Training iter 50, batch loss 0.0420, batch acc 0.9906
15:09:35.802   Training iter 100, batch loss 0.0443, batch acc 0.9900
15:09:35.916   Training iter 150, batch loss 0.0552, batch acc 0.9868
15:09:36.047   Training iter 200, batch loss 0.0492, batch acc 0.9888
15:09:36.158   Training iter 250, batch loss 0.0513, batch acc 0.9876
15:09:36.491   Training iter 300, batch loss 0.0552, batch acc 0.9852
15:09:36.804   Training iter 350, batch loss 0.0578, batch acc 0.9850
15:09:37.001   Training iter 400, batch loss 0.0503, batch acc 0.9884
15:09:37.129   Training iter 450, batch loss 0.0557, batch acc 0.9854
15:09:37.305   Training iter 500, batch loss 0.0544, batch acc 0.9856
15:09:37.442   Training iter 550, batch loss 0.0512, batch acc 0.9868
15:09:37.592   Training iter 600, batch loss 0.0549, batch acc 0.9836
15:09:37.593 Training @ 54 epoch...
15:09:37.788   Training iter 50, batch loss 0.0429, batch acc 0.9912
15:09:37.950   Training iter 100, batch loss 0.0466, batch acc 0.9898
15:09:38.053   Training iter 150, batch loss 0.0496, batch acc 0.9860
15:09:38.218   Training iter 200, batch loss 0.0479, batch acc 0.9868
15:09:38.336   Training iter 250, batch loss 0.0440, batch acc 0.9892
15:09:38.506   Training iter 300, batch loss 0.0601, batch acc 0.9832
15:09:38.759   Training iter 350, batch loss 0.0459, batch acc 0.9888
15:09:38.942   Training iter 400, batch loss 0.0519, batch acc 0.9866
15:09:39.135   Training iter 450, batch loss 0.0579, batch acc 0.9818
15:09:39.406   Training iter 500, batch loss 0.0534, batch acc 0.9860
15:09:39.561   Training iter 550, batch loss 0.0566, batch acc 0.9824
15:09:39.703   Training iter 600, batch loss 0.0477, batch acc 0.9888
15:09:39.704 Training @ 55 epoch...
15:09:39.861   Training iter 50, batch loss 0.0433, batch acc 0.9894
15:09:40.073   Training iter 100, batch loss 0.0440, batch acc 0.9892
15:09:40.233   Training iter 150, batch loss 0.0563, batch acc 0.9846
15:09:40.400   Training iter 200, batch loss 0.0479, batch acc 0.9870
15:09:40.588   Training iter 250, batch loss 0.0568, batch acc 0.9852
15:09:40.743   Training iter 300, batch loss 0.0534, batch acc 0.9868
15:09:40.870   Training iter 350, batch loss 0.0493, batch acc 0.9866
15:09:41.020   Training iter 400, batch loss 0.0481, batch acc 0.9882
15:09:41.166   Training iter 450, batch loss 0.0477, batch acc 0.9870
15:09:41.500   Training iter 500, batch loss 0.0478, batch acc 0.9864
15:09:41.626   Training iter 550, batch loss 0.0519, batch acc 0.9862
15:09:41.890   Training iter 600, batch loss 0.0521, batch acc 0.9878
15:09:41.891 Testing @ 55 epoch...
15:09:41.986     Testing, total mean loss 0.07856, total acc 0.97540
15:09:41.986 Training @ 56 epoch...
15:09:42.153   Training iter 50, batch loss 0.0475, batch acc 0.9892
15:09:42.349   Training iter 100, batch loss 0.0505, batch acc 0.9842
15:09:42.470   Training iter 150, batch loss 0.0464, batch acc 0.9874
15:09:42.602   Training iter 200, batch loss 0.0490, batch acc 0.9876
15:09:42.791   Training iter 250, batch loss 0.0528, batch acc 0.9856
15:09:42.969   Training iter 300, batch loss 0.0489, batch acc 0.9870
15:09:43.143   Training iter 350, batch loss 0.0541, batch acc 0.9870
15:09:43.309   Training iter 400, batch loss 0.0521, batch acc 0.9862
15:09:43.474   Training iter 450, batch loss 0.0545, batch acc 0.9866
15:09:43.580   Training iter 500, batch loss 0.0473, batch acc 0.9882
15:09:43.697   Training iter 550, batch loss 0.0519, batch acc 0.9870
15:09:43.807   Training iter 600, batch loss 0.0485, batch acc 0.9858
15:09:43.807 Training @ 57 epoch...
15:09:43.929   Training iter 50, batch loss 0.0514, batch acc 0.9868
15:09:44.104   Training iter 100, batch loss 0.0495, batch acc 0.9864
15:09:44.250   Training iter 150, batch loss 0.0470, batch acc 0.9890
15:09:44.402   Training iter 200, batch loss 0.0542, batch acc 0.9862
15:09:44.511   Training iter 250, batch loss 0.0451, batch acc 0.9890
15:09:44.645   Training iter 300, batch loss 0.0475, batch acc 0.9880
15:09:44.787   Training iter 350, batch loss 0.0472, batch acc 0.9868
15:09:44.950   Training iter 400, batch loss 0.0536, batch acc 0.9858
15:09:45.118   Training iter 450, batch loss 0.0521, batch acc 0.9868
15:09:45.272   Training iter 500, batch loss 0.0554, batch acc 0.9856
15:09:45.706   Training iter 550, batch loss 0.0456, batch acc 0.9896
15:09:45.844   Training iter 600, batch loss 0.0504, batch acc 0.9868
15:09:45.846 Training @ 58 epoch...
15:09:46.092   Training iter 50, batch loss 0.0472, batch acc 0.9874
15:09:46.313   Training iter 100, batch loss 0.0426, batch acc 0.9892
15:09:46.495   Training iter 150, batch loss 0.0489, batch acc 0.9882
15:09:46.650   Training iter 200, batch loss 0.0524, batch acc 0.9860
15:09:46.790   Training iter 250, batch loss 0.0486, batch acc 0.9898
15:09:46.918   Training iter 300, batch loss 0.0518, batch acc 0.9850
15:09:47.063   Training iter 350, batch loss 0.0438, batch acc 0.9898
15:09:47.210   Training iter 400, batch loss 0.0476, batch acc 0.9892
15:09:47.378   Training iter 450, batch loss 0.0538, batch acc 0.9874
15:09:47.541   Training iter 500, batch loss 0.0555, batch acc 0.9850
15:09:47.671   Training iter 550, batch loss 0.0529, batch acc 0.9870
15:09:47.823   Training iter 600, batch loss 0.0501, batch acc 0.9862
15:09:47.825 Training @ 59 epoch...
15:09:48.021   Training iter 50, batch loss 0.0379, batch acc 0.9936
15:09:48.166   Training iter 100, batch loss 0.0474, batch acc 0.9882
15:09:48.352   Training iter 150, batch loss 0.0488, batch acc 0.9876
15:09:48.524   Training iter 200, batch loss 0.0460, batch acc 0.9888
15:09:48.710   Training iter 250, batch loss 0.0534, batch acc 0.9848
15:09:48.855   Training iter 300, batch loss 0.0474, batch acc 0.9886
15:09:49.014   Training iter 350, batch loss 0.0475, batch acc 0.9868
15:09:49.190   Training iter 400, batch loss 0.0505, batch acc 0.9860
15:09:49.329   Training iter 450, batch loss 0.0560, batch acc 0.9850
15:09:49.462   Training iter 500, batch loss 0.0484, batch acc 0.9866
15:09:49.607   Training iter 550, batch loss 0.0550, batch acc 0.9850
15:09:49.774   Training iter 600, batch loss 0.0513, batch acc 0.9860
15:09:49.774 Training @ 60 epoch...
15:09:49.943   Training iter 50, batch loss 0.0503, batch acc 0.9864
15:09:50.111   Training iter 100, batch loss 0.0510, batch acc 0.9878
15:09:50.225   Training iter 150, batch loss 0.0482, batch acc 0.9882
15:09:50.352   Training iter 200, batch loss 0.0452, batch acc 0.9884
15:09:50.456   Training iter 250, batch loss 0.0458, batch acc 0.9888
15:09:50.613   Training iter 300, batch loss 0.0442, batch acc 0.9896
15:09:50.950   Training iter 350, batch loss 0.0495, batch acc 0.9864
15:09:51.123   Training iter 400, batch loss 0.0510, batch acc 0.9856
15:09:51.411   Training iter 450, batch loss 0.0522, batch acc 0.9866
15:09:51.577   Training iter 500, batch loss 0.0462, batch acc 0.9882
15:09:51.734   Training iter 550, batch loss 0.0629, batch acc 0.9842
15:09:51.888   Training iter 600, batch loss 0.0523, batch acc 0.9860
15:09:51.888 Testing @ 60 epoch...
15:09:52.030     Testing, total mean loss 0.07514, total acc 0.97710
15:09:52.030 Training @ 61 epoch...
15:09:52.136   Training iter 50, batch loss 0.0506, batch acc 0.9866
15:09:52.237   Training iter 100, batch loss 0.0495, batch acc 0.9886
15:09:52.414   Training iter 150, batch loss 0.0462, batch acc 0.9872
15:09:52.610   Training iter 200, batch loss 0.0501, batch acc 0.9876
15:09:52.796   Training iter 250, batch loss 0.0488, batch acc 0.9884
15:09:53.058   Training iter 300, batch loss 0.0495, batch acc 0.9872
15:09:53.200   Training iter 350, batch loss 0.0466, batch acc 0.9872
15:09:53.308   Training iter 400, batch loss 0.0458, batch acc 0.9892
15:09:53.491   Training iter 450, batch loss 0.0510, batch acc 0.9872
15:09:53.643   Training iter 500, batch loss 0.0479, batch acc 0.9880
15:09:53.767   Training iter 550, batch loss 0.0463, batch acc 0.9874
15:09:53.890   Training iter 600, batch loss 0.0564, batch acc 0.9844
15:09:53.890 Training @ 62 epoch...
15:09:54.031   Training iter 50, batch loss 0.0461, batch acc 0.9900
15:09:54.193   Training iter 100, batch loss 0.0533, batch acc 0.9862
15:09:54.318   Training iter 150, batch loss 0.0519, batch acc 0.9878
15:09:54.437   Training iter 200, batch loss 0.0462, batch acc 0.9872
15:09:54.576   Training iter 250, batch loss 0.0463, batch acc 0.9898
15:09:54.713   Training iter 300, batch loss 0.0471, batch acc 0.9888
15:09:54.847   Training iter 350, batch loss 0.0434, batch acc 0.9894
15:09:54.963   Training iter 400, batch loss 0.0501, batch acc 0.9866
15:09:55.204   Training iter 450, batch loss 0.0524, batch acc 0.9876
15:09:55.317   Training iter 500, batch loss 0.0536, batch acc 0.9848
15:09:55.466   Training iter 550, batch loss 0.0442, batch acc 0.9904
15:09:55.632   Training iter 600, batch loss 0.0485, batch acc 0.9876
15:09:55.633 Training @ 63 epoch...
15:09:55.802   Training iter 50, batch loss 0.0494, batch acc 0.9888
15:09:55.958   Training iter 100, batch loss 0.0473, batch acc 0.9872
15:09:56.073   Training iter 150, batch loss 0.0467, batch acc 0.9882
15:09:56.206   Training iter 200, batch loss 0.0457, batch acc 0.9892
15:09:56.332   Training iter 250, batch loss 0.0545, batch acc 0.9850
15:09:56.463   Training iter 300, batch loss 0.0443, batch acc 0.9894
15:09:56.608   Training iter 350, batch loss 0.0527, batch acc 0.9868
15:09:56.806   Training iter 400, batch loss 0.0459, batch acc 0.9884
15:09:56.972   Training iter 450, batch loss 0.0447, batch acc 0.9916
15:09:57.208   Training iter 500, batch loss 0.0543, batch acc 0.9850
15:09:57.392   Training iter 550, batch loss 0.0484, batch acc 0.9870
15:09:57.617   Training iter 600, batch loss 0.0474, batch acc 0.9876
15:09:57.619 Training @ 64 epoch...
15:09:57.773   Training iter 50, batch loss 0.0455, batch acc 0.9910
15:09:57.901   Training iter 100, batch loss 0.0457, batch acc 0.9878
15:09:58.050   Training iter 150, batch loss 0.0509, batch acc 0.9882
15:09:58.197   Training iter 200, batch loss 0.0488, batch acc 0.9878
15:09:58.357   Training iter 250, batch loss 0.0462, batch acc 0.9882
15:09:58.488   Training iter 300, batch loss 0.0453, batch acc 0.9898
15:09:58.628   Training iter 350, batch loss 0.0419, batch acc 0.9878
15:09:58.772   Training iter 400, batch loss 0.0485, batch acc 0.9872
15:09:58.936   Training iter 450, batch loss 0.0490, batch acc 0.9876
15:09:59.072   Training iter 500, batch loss 0.0510, batch acc 0.9874
15:09:59.291   Training iter 550, batch loss 0.0458, batch acc 0.9880
15:09:59.469   Training iter 600, batch loss 0.0561, batch acc 0.9854
15:09:59.470 Training @ 65 epoch...
15:09:59.635   Training iter 50, batch loss 0.0475, batch acc 0.9878
15:09:59.789   Training iter 100, batch loss 0.0472, batch acc 0.9878
15:09:59.937   Training iter 150, batch loss 0.0501, batch acc 0.9872
15:10:00.319   Training iter 200, batch loss 0.0402, batch acc 0.9900
15:10:00.524   Training iter 250, batch loss 0.0449, batch acc 0.9878
15:10:00.647   Training iter 300, batch loss 0.0495, batch acc 0.9872
15:10:00.852   Training iter 350, batch loss 0.0479, batch acc 0.9884
15:10:01.029   Training iter 400, batch loss 0.0480, batch acc 0.9876
15:10:01.296   Training iter 450, batch loss 0.0445, batch acc 0.9892
15:10:01.531   Training iter 500, batch loss 0.0491, batch acc 0.9874
15:10:01.757   Training iter 550, batch loss 0.0496, batch acc 0.9892
15:10:02.054   Training iter 600, batch loss 0.0501, batch acc 0.9864
15:10:02.054 Testing @ 65 epoch...
15:10:02.148     Testing, total mean loss 0.07489, total acc 0.97640
15:10:02.148 Training @ 66 epoch...
15:10:02.263   Training iter 50, batch loss 0.0494, batch acc 0.9884
15:10:02.491   Training iter 100, batch loss 0.0427, batch acc 0.9918
15:10:02.668   Training iter 150, batch loss 0.0481, batch acc 0.9862
15:10:02.959   Training iter 200, batch loss 0.0443, batch acc 0.9904
15:10:03.223   Training iter 250, batch loss 0.0451, batch acc 0.9900
15:10:03.471   Training iter 300, batch loss 0.0452, batch acc 0.9902
15:10:03.721   Training iter 350, batch loss 0.0460, batch acc 0.9866
15:10:04.009   Training iter 400, batch loss 0.0534, batch acc 0.9866
15:10:04.209   Training iter 450, batch loss 0.0531, batch acc 0.9864
15:10:04.386   Training iter 500, batch loss 0.0489, batch acc 0.9866
15:10:04.530   Training iter 550, batch loss 0.0503, batch acc 0.9886
15:10:04.671   Training iter 600, batch loss 0.0516, batch acc 0.9860
15:10:04.671 Training @ 67 epoch...
15:10:04.820   Training iter 50, batch loss 0.0496, batch acc 0.9898
15:10:04.953   Training iter 100, batch loss 0.0462, batch acc 0.9896
15:10:05.091   Training iter 150, batch loss 0.0459, batch acc 0.9894
15:10:05.233   Training iter 200, batch loss 0.0481, batch acc 0.9876
15:10:05.397   Training iter 250, batch loss 0.0454, batch acc 0.9902
15:10:05.537   Training iter 300, batch loss 0.0508, batch acc 0.9864
15:10:05.763   Training iter 350, batch loss 0.0480, batch acc 0.9882
15:10:05.973   Training iter 400, batch loss 0.0502, batch acc 0.9878
15:10:06.149   Training iter 450, batch loss 0.0515, batch acc 0.9850
15:10:06.322   Training iter 500, batch loss 0.0451, batch acc 0.9874
15:10:06.465   Training iter 550, batch loss 0.0522, batch acc 0.9866
15:10:06.605   Training iter 600, batch loss 0.0400, batch acc 0.9916
15:10:06.606 Training @ 68 epoch...
15:10:06.750   Training iter 50, batch loss 0.0380, batch acc 0.9906
15:10:06.887   Training iter 100, batch loss 0.0529, batch acc 0.9866
15:10:07.022   Training iter 150, batch loss 0.0528, batch acc 0.9840
15:10:07.234   Training iter 200, batch loss 0.0498, batch acc 0.9870
15:10:07.370   Training iter 250, batch loss 0.0483, batch acc 0.9898
15:10:07.521   Training iter 300, batch loss 0.0503, batch acc 0.9882
15:10:07.717   Training iter 350, batch loss 0.0425, batch acc 0.9902
15:10:07.866   Training iter 400, batch loss 0.0447, batch acc 0.9904
15:10:08.011   Training iter 450, batch loss 0.0459, batch acc 0.9892
15:10:08.161   Training iter 500, batch loss 0.0468, batch acc 0.9878
15:10:08.284   Training iter 550, batch loss 0.0503, batch acc 0.9854
15:10:08.406   Training iter 600, batch loss 0.0474, batch acc 0.9882
15:10:08.407 Training @ 69 epoch...
15:10:08.544   Training iter 50, batch loss 0.0404, batch acc 0.9918
15:10:08.696   Training iter 100, batch loss 0.0500, batch acc 0.9864
15:10:08.884   Training iter 150, batch loss 0.0505, batch acc 0.9880
15:10:09.005   Training iter 200, batch loss 0.0464, batch acc 0.9890
15:10:09.133   Training iter 250, batch loss 0.0500, batch acc 0.9864
15:10:09.284   Training iter 300, batch loss 0.0456, batch acc 0.9894
15:10:09.412   Training iter 350, batch loss 0.0494, batch acc 0.9878
15:10:09.534   Training iter 400, batch loss 0.0428, batch acc 0.9912
15:10:09.681   Training iter 450, batch loss 0.0451, batch acc 0.9884
15:10:09.850   Training iter 500, batch loss 0.0507, batch acc 0.9874
15:10:09.967   Training iter 550, batch loss 0.0456, batch acc 0.9894
15:10:10.121   Training iter 600, batch loss 0.0473, batch acc 0.9892
15:10:10.124 Training @ 70 epoch...
15:10:10.259   Training iter 50, batch loss 0.0419, batch acc 0.9896
15:10:10.379   Training iter 100, batch loss 0.0483, batch acc 0.9860
15:10:10.502   Training iter 150, batch loss 0.0465, batch acc 0.9888
15:10:10.608   Training iter 200, batch loss 0.0434, batch acc 0.9900
15:10:10.756   Training iter 250, batch loss 0.0437, batch acc 0.9888
15:10:10.916   Training iter 300, batch loss 0.0481, batch acc 0.9882
15:10:11.068   Training iter 350, batch loss 0.0441, batch acc 0.9888
15:10:11.203   Training iter 400, batch loss 0.0463, batch acc 0.9882
15:10:11.337   Training iter 450, batch loss 0.0503, batch acc 0.9862
15:10:11.502   Training iter 500, batch loss 0.0525, batch acc 0.9866
15:10:11.625   Training iter 550, batch loss 0.0494, batch acc 0.9870
15:10:11.747   Training iter 600, batch loss 0.0586, batch acc 0.9850
15:10:11.748 Testing @ 70 epoch...
15:10:11.829     Testing, total mean loss 0.08109, total acc 0.97490
15:10:11.829 Training @ 71 epoch...
15:10:11.958   Training iter 50, batch loss 0.0453, batch acc 0.9888
15:10:12.075   Training iter 100, batch loss 0.0507, batch acc 0.9874
15:10:12.204   Training iter 150, batch loss 0.0448, batch acc 0.9886
15:10:12.337   Training iter 200, batch loss 0.0469, batch acc 0.9886
15:10:12.466   Training iter 250, batch loss 0.0473, batch acc 0.9888
15:10:12.579   Training iter 300, batch loss 0.0442, batch acc 0.9878
15:10:12.702   Training iter 350, batch loss 0.0408, batch acc 0.9908
15:10:12.822   Training iter 400, batch loss 0.0423, batch acc 0.9896
15:10:12.983   Training iter 450, batch loss 0.0501, batch acc 0.9866
15:10:13.109   Training iter 500, batch loss 0.0456, batch acc 0.9890
15:10:13.242   Training iter 550, batch loss 0.0554, batch acc 0.9844
15:10:13.376   Training iter 600, batch loss 0.0510, batch acc 0.9880
15:10:13.378 Training @ 72 epoch...
15:10:13.558   Training iter 50, batch loss 0.0448, batch acc 0.9894
15:10:13.902   Training iter 100, batch loss 0.0500, batch acc 0.9868
15:10:14.088   Training iter 150, batch loss 0.0517, batch acc 0.9852
15:10:14.259   Training iter 200, batch loss 0.0448, batch acc 0.9886
15:10:14.437   Training iter 250, batch loss 0.0432, batch acc 0.9918
15:10:14.693   Training iter 300, batch loss 0.0446, batch acc 0.9900
15:10:14.971   Training iter 350, batch loss 0.0431, batch acc 0.9894
15:10:15.197   Training iter 400, batch loss 0.0545, batch acc 0.9848
15:10:15.420   Training iter 450, batch loss 0.0472, batch acc 0.9884
15:10:15.626   Training iter 500, batch loss 0.0478, batch acc 0.9880
15:10:15.765   Training iter 550, batch loss 0.0426, batch acc 0.9894
15:10:16.008   Training iter 600, batch loss 0.0474, batch acc 0.9882
15:10:16.009 Training @ 73 epoch...
15:10:16.143   Training iter 50, batch loss 0.0457, batch acc 0.9894
15:10:16.298   Training iter 100, batch loss 0.0476, batch acc 0.9878
15:10:16.541   Training iter 150, batch loss 0.0443, batch acc 0.9892
15:10:16.788   Training iter 200, batch loss 0.0456, batch acc 0.9894
15:10:17.054   Training iter 250, batch loss 0.0448, batch acc 0.9888
15:10:17.274   Training iter 300, batch loss 0.0409, batch acc 0.9906
15:10:17.492   Training iter 350, batch loss 0.0432, batch acc 0.9910
15:10:17.607   Training iter 400, batch loss 0.0491, batch acc 0.9886
15:10:17.716   Training iter 450, batch loss 0.0467, batch acc 0.9876
15:10:17.841   Training iter 500, batch loss 0.0432, batch acc 0.9900
15:10:17.974   Training iter 550, batch loss 0.0493, batch acc 0.9886
15:10:18.092   Training iter 600, batch loss 0.0499, batch acc 0.9878
15:10:18.092 Training @ 74 epoch...
15:10:18.216   Training iter 50, batch loss 0.0441, batch acc 0.9910
15:10:18.328   Training iter 100, batch loss 0.0437, batch acc 0.9900
15:10:18.457   Training iter 150, batch loss 0.0495, batch acc 0.9882
15:10:18.567   Training iter 200, batch loss 0.0490, batch acc 0.9874
15:10:18.697   Training iter 250, batch loss 0.0425, batch acc 0.9894
15:10:18.819   Training iter 300, batch loss 0.0466, batch acc 0.9884
15:10:18.940   Training iter 350, batch loss 0.0441, batch acc 0.9878
15:10:19.066   Training iter 400, batch loss 0.0469, batch acc 0.9870
15:10:19.179   Training iter 450, batch loss 0.0490, batch acc 0.9874
15:10:19.297   Training iter 500, batch loss 0.0484, batch acc 0.9878
15:10:19.449   Training iter 550, batch loss 0.0490, batch acc 0.9856
15:10:19.599   Training iter 600, batch loss 0.0466, batch acc 0.9880
15:10:19.600 Training @ 75 epoch...
15:10:19.731   Training iter 50, batch loss 0.0489, batch acc 0.9848
15:10:19.888   Training iter 100, batch loss 0.0440, batch acc 0.9892
15:10:20.035   Training iter 150, batch loss 0.0467, batch acc 0.9886
15:10:20.287   Training iter 200, batch loss 0.0502, batch acc 0.9874
15:10:20.442   Training iter 250, batch loss 0.0447, batch acc 0.9898
15:10:20.568   Training iter 300, batch loss 0.0505, batch acc 0.9874
15:10:20.688   Training iter 350, batch loss 0.0467, batch acc 0.9892
15:10:20.823   Training iter 400, batch loss 0.0412, batch acc 0.9912
15:10:20.940   Training iter 450, batch loss 0.0412, batch acc 0.9900
15:10:21.072   Training iter 500, batch loss 0.0447, batch acc 0.9900
15:10:21.207   Training iter 550, batch loss 0.0434, batch acc 0.9880
15:10:21.336   Training iter 600, batch loss 0.0442, batch acc 0.9886
15:10:21.336 Testing @ 75 epoch...
15:10:21.422     Testing, total mean loss 0.07575, total acc 0.97510
15:10:21.422 Training @ 76 epoch...
15:10:21.556   Training iter 50, batch loss 0.0440, batch acc 0.9894
15:10:21.673   Training iter 100, batch loss 0.0430, batch acc 0.9906
15:10:21.800   Training iter 150, batch loss 0.0455, batch acc 0.9892
15:10:21.934   Training iter 200, batch loss 0.0514, batch acc 0.9858
15:10:22.045   Training iter 250, batch loss 0.0456, batch acc 0.9876
15:10:22.224   Training iter 300, batch loss 0.0451, batch acc 0.9892
15:10:22.369   Training iter 350, batch loss 0.0447, batch acc 0.9892
15:10:22.524   Training iter 400, batch loss 0.0478, batch acc 0.9878
15:10:22.726   Training iter 450, batch loss 0.0443, batch acc 0.9872
15:10:22.918   Training iter 500, batch loss 0.0437, batch acc 0.9882
15:10:23.096   Training iter 550, batch loss 0.0431, batch acc 0.9904
15:10:23.248   Training iter 600, batch loss 0.0529, batch acc 0.9850
15:10:23.248 Training @ 77 epoch...
15:10:23.418   Training iter 50, batch loss 0.0383, batch acc 0.9922
15:10:23.547   Training iter 100, batch loss 0.0423, batch acc 0.9892
15:10:23.736   Training iter 150, batch loss 0.0426, batch acc 0.9898
15:10:23.953   Training iter 200, batch loss 0.0482, batch acc 0.9878
15:10:24.150   Training iter 250, batch loss 0.0433, batch acc 0.9912
15:10:24.465   Training iter 300, batch loss 0.0494, batch acc 0.9876
15:10:24.642   Training iter 350, batch loss 0.0441, batch acc 0.9894
15:10:24.803   Training iter 400, batch loss 0.0482, batch acc 0.9876
15:10:24.963   Training iter 450, batch loss 0.0484, batch acc 0.9876
15:10:25.259   Training iter 500, batch loss 0.0429, batch acc 0.9896
15:10:25.464   Training iter 550, batch loss 0.0518, batch acc 0.9886
15:10:25.639   Training iter 600, batch loss 0.0478, batch acc 0.9874
15:10:25.641 Training @ 78 epoch...
15:10:25.840   Training iter 50, batch loss 0.0429, batch acc 0.9888
15:10:26.083   Training iter 100, batch loss 0.0443, batch acc 0.9916
15:10:26.229   Training iter 150, batch loss 0.0465, batch acc 0.9882
15:10:26.393   Training iter 200, batch loss 0.0430, batch acc 0.9892
15:10:26.565   Training iter 250, batch loss 0.0434, batch acc 0.9886
15:10:26.755   Training iter 300, batch loss 0.0481, batch acc 0.9874
15:10:26.930   Training iter 350, batch loss 0.0434, batch acc 0.9898
15:10:27.073   Training iter 400, batch loss 0.0457, batch acc 0.9894
15:10:27.222   Training iter 450, batch loss 0.0471, batch acc 0.9880
15:10:27.371   Training iter 500, batch loss 0.0503, batch acc 0.9876
15:10:27.521   Training iter 550, batch loss 0.0558, batch acc 0.9850
15:10:27.646   Training iter 600, batch loss 0.0465, batch acc 0.9890
15:10:27.647 Training @ 79 epoch...
15:10:27.825   Training iter 50, batch loss 0.0452, batch acc 0.9892
15:10:27.968   Training iter 100, batch loss 0.0456, batch acc 0.9898
15:10:28.131   Training iter 150, batch loss 0.0418, batch acc 0.9900
15:10:28.309   Training iter 200, batch loss 0.0432, batch acc 0.9902
15:10:28.488   Training iter 250, batch loss 0.0444, batch acc 0.9894
15:10:28.643   Training iter 300, batch loss 0.0390, batch acc 0.9922
15:10:28.820   Training iter 350, batch loss 0.0401, batch acc 0.9894
15:10:28.988   Training iter 400, batch loss 0.0465, batch acc 0.9864
15:10:29.115   Training iter 450, batch loss 0.0487, batch acc 0.9880
15:10:29.262   Training iter 500, batch loss 0.0557, batch acc 0.9858
15:10:29.458   Training iter 550, batch loss 0.0441, batch acc 0.9898
15:10:29.592   Training iter 600, batch loss 0.0498, batch acc 0.9870
15:10:29.592 Training @ 80 epoch...
15:10:29.770   Training iter 50, batch loss 0.0474, batch acc 0.9892
15:10:29.908   Training iter 100, batch loss 0.0456, batch acc 0.9890
15:10:30.052   Training iter 150, batch loss 0.0418, batch acc 0.9910
15:10:30.180   Training iter 200, batch loss 0.0437, batch acc 0.9920
15:10:30.359   Training iter 250, batch loss 0.0455, batch acc 0.9880
15:10:30.490   Training iter 300, batch loss 0.0519, batch acc 0.9872
15:10:30.656   Training iter 350, batch loss 0.0430, batch acc 0.9902
15:10:30.837   Training iter 400, batch loss 0.0484, batch acc 0.9876
15:10:31.007   Training iter 450, batch loss 0.0487, batch acc 0.9866
15:10:31.185   Training iter 500, batch loss 0.0418, batch acc 0.9900
15:10:31.322   Training iter 550, batch loss 0.0435, batch acc 0.9884
15:10:31.496   Training iter 600, batch loss 0.0459, batch acc 0.9880
15:10:31.498 Testing @ 80 epoch...
15:10:31.623     Testing, total mean loss 0.07255, total acc 0.97680
15:10:31.623 Training @ 81 epoch...
15:10:31.813   Training iter 50, batch loss 0.0372, batch acc 0.9928
15:10:31.940   Training iter 100, batch loss 0.0420, batch acc 0.9910
15:10:32.094   Training iter 150, batch loss 0.0470, batch acc 0.9874
15:10:32.256   Training iter 200, batch loss 0.0428, batch acc 0.9880
15:10:32.469   Training iter 250, batch loss 0.0430, batch acc 0.9888
15:10:32.603   Training iter 300, batch loss 0.0494, batch acc 0.9880
15:10:32.742   Training iter 350, batch loss 0.0441, batch acc 0.9896
15:10:32.946   Training iter 400, batch loss 0.0513, batch acc 0.9886
15:10:33.110   Training iter 450, batch loss 0.0455, batch acc 0.9892
15:10:33.247   Training iter 500, batch loss 0.0454, batch acc 0.9894
15:10:33.414   Training iter 550, batch loss 0.0488, batch acc 0.9864
15:10:33.560   Training iter 600, batch loss 0.0482, batch acc 0.9874
15:10:33.561 Training @ 82 epoch...
15:10:33.710   Training iter 50, batch loss 0.0424, batch acc 0.9904
15:10:33.986   Training iter 100, batch loss 0.0467, batch acc 0.9896
15:10:34.217   Training iter 150, batch loss 0.0406, batch acc 0.9896
15:10:34.526   Training iter 200, batch loss 0.0441, batch acc 0.9908
15:10:34.826   Training iter 250, batch loss 0.0443, batch acc 0.9900
15:10:35.065   Training iter 300, batch loss 0.0403, batch acc 0.9906
15:10:35.287   Training iter 350, batch loss 0.0461, batch acc 0.9896
15:10:35.457   Training iter 400, batch loss 0.0479, batch acc 0.9886
15:10:35.683   Training iter 450, batch loss 0.0535, batch acc 0.9856
15:10:35.907   Training iter 500, batch loss 0.0487, batch acc 0.9860
15:10:36.044   Training iter 550, batch loss 0.0489, batch acc 0.9866
15:10:36.223   Training iter 600, batch loss 0.0452, batch acc 0.9890
15:10:36.223 Training @ 83 epoch...
15:10:36.417   Training iter 50, batch loss 0.0418, batch acc 0.9898
15:10:36.624   Training iter 100, batch loss 0.0452, batch acc 0.9896
15:10:36.811   Training iter 150, batch loss 0.0444, batch acc 0.9870
15:10:37.016   Training iter 200, batch loss 0.0417, batch acc 0.9884
15:10:37.302   Training iter 250, batch loss 0.0484, batch acc 0.9884
15:10:37.542   Training iter 300, batch loss 0.0446, batch acc 0.9898
15:10:37.788   Training iter 350, batch loss 0.0403, batch acc 0.9906
15:10:37.931   Training iter 400, batch loss 0.0515, batch acc 0.9862
15:10:38.107   Training iter 450, batch loss 0.0452, batch acc 0.9884
15:10:38.346   Training iter 500, batch loss 0.0485, batch acc 0.9884
15:10:38.476   Training iter 550, batch loss 0.0457, batch acc 0.9880
15:10:38.653   Training iter 600, batch loss 0.0429, batch acc 0.9906
15:10:38.653 Training @ 84 epoch...
15:10:38.866   Training iter 50, batch loss 0.0413, batch acc 0.9908
15:10:39.019   Training iter 100, batch loss 0.0403, batch acc 0.9914
15:10:39.206   Training iter 150, batch loss 0.0447, batch acc 0.9894
15:10:39.413   Training iter 200, batch loss 0.0481, batch acc 0.9872
15:10:39.603   Training iter 250, batch loss 0.0488, batch acc 0.9868
15:10:39.841   Training iter 300, batch loss 0.0426, batch acc 0.9898
15:10:40.071   Training iter 350, batch loss 0.0453, batch acc 0.9878
15:10:40.267   Training iter 400, batch loss 0.0469, batch acc 0.9880
15:10:40.437   Training iter 450, batch loss 0.0427, batch acc 0.9902
15:10:40.589   Training iter 500, batch loss 0.0440, batch acc 0.9878
15:10:40.739   Training iter 550, batch loss 0.0488, batch acc 0.9886
15:10:40.884   Training iter 600, batch loss 0.0487, batch acc 0.9886
15:10:40.886 Training @ 85 epoch...
15:10:41.024   Training iter 50, batch loss 0.0429, batch acc 0.9896
15:10:41.203   Training iter 100, batch loss 0.0415, batch acc 0.9898
15:10:41.313   Training iter 150, batch loss 0.0415, batch acc 0.9894
15:10:41.439   Training iter 200, batch loss 0.0463, batch acc 0.9884
15:10:41.589   Training iter 250, batch loss 0.0432, batch acc 0.9898
15:10:41.719   Training iter 300, batch loss 0.0437, batch acc 0.9904
15:10:41.933   Training iter 350, batch loss 0.0446, batch acc 0.9902
15:10:42.121   Training iter 400, batch loss 0.0408, batch acc 0.9910
15:10:42.294   Training iter 450, batch loss 0.0516, batch acc 0.9856
15:10:42.491   Training iter 500, batch loss 0.0444, batch acc 0.9896
15:10:42.696   Training iter 550, batch loss 0.0465, batch acc 0.9896
15:10:42.892   Training iter 600, batch loss 0.0436, batch acc 0.9896
15:10:42.892 Testing @ 85 epoch...
15:10:43.030     Testing, total mean loss 0.07107, total acc 0.97810
15:10:43.030 Training @ 86 epoch...
15:10:43.175   Training iter 50, batch loss 0.0429, batch acc 0.9896
15:10:43.316   Training iter 100, batch loss 0.0428, batch acc 0.9900
15:10:43.448   Training iter 150, batch loss 0.0397, batch acc 0.9914
15:10:43.570   Training iter 200, batch loss 0.0435, batch acc 0.9888
15:10:43.714   Training iter 250, batch loss 0.0475, batch acc 0.9866
15:10:43.896   Training iter 300, batch loss 0.0447, batch acc 0.9902
15:10:44.044   Training iter 350, batch loss 0.0476, batch acc 0.9880
15:10:44.183   Training iter 400, batch loss 0.0470, batch acc 0.9872
15:10:44.324   Training iter 450, batch loss 0.0423, batch acc 0.9902
15:10:44.455   Training iter 500, batch loss 0.0404, batch acc 0.9904
15:10:44.617   Training iter 550, batch loss 0.0446, batch acc 0.9900
15:10:44.746   Training iter 600, batch loss 0.0511, batch acc 0.9862
15:10:44.747 Training @ 87 epoch...
15:10:44.955   Training iter 50, batch loss 0.0406, batch acc 0.9914
15:10:45.147   Training iter 100, batch loss 0.0464, batch acc 0.9886
15:10:45.289   Training iter 150, batch loss 0.0454, batch acc 0.9882
15:10:45.439   Training iter 200, batch loss 0.0450, batch acc 0.9906
15:10:45.619   Training iter 250, batch loss 0.0449, batch acc 0.9894
15:10:45.800   Training iter 300, batch loss 0.0422, batch acc 0.9890
15:10:45.947   Training iter 350, batch loss 0.0476, batch acc 0.9874
15:10:46.068   Training iter 400, batch loss 0.0454, batch acc 0.9890
15:10:46.185   Training iter 450, batch loss 0.0437, batch acc 0.9894
15:10:46.327   Training iter 500, batch loss 0.0483, batch acc 0.9880
15:10:46.425   Training iter 550, batch loss 0.0436, batch acc 0.9904
15:10:46.573   Training iter 600, batch loss 0.0436, batch acc 0.9904
15:10:46.577 Training @ 88 epoch...
15:10:46.699   Training iter 50, batch loss 0.0426, batch acc 0.9904
15:10:46.830   Training iter 100, batch loss 0.0395, batch acc 0.9914
15:10:46.960   Training iter 150, batch loss 0.0432, batch acc 0.9894
15:10:47.077   Training iter 200, batch loss 0.0491, batch acc 0.9876
15:10:47.181   Training iter 250, batch loss 0.0453, batch acc 0.9880
15:10:47.375   Training iter 300, batch loss 0.0435, batch acc 0.9892
15:10:47.550   Training iter 350, batch loss 0.0446, batch acc 0.9896
15:10:47.680   Training iter 400, batch loss 0.0403, batch acc 0.9904
15:10:47.839   Training iter 450, batch loss 0.0502, batch acc 0.9864
15:10:48.049   Training iter 500, batch loss 0.0397, batch acc 0.9918
15:10:48.301   Training iter 550, batch loss 0.0517, batch acc 0.9858
15:10:48.482   Training iter 600, batch loss 0.0518, batch acc 0.9868
15:10:48.482 Training @ 89 epoch...
15:10:48.688   Training iter 50, batch loss 0.0456, batch acc 0.9896
15:10:48.819   Training iter 100, batch loss 0.0453, batch acc 0.9872
15:10:48.974   Training iter 150, batch loss 0.0463, batch acc 0.9894
15:10:49.113   Training iter 200, batch loss 0.0406, batch acc 0.9898
15:10:49.252   Training iter 250, batch loss 0.0421, batch acc 0.9902
15:10:49.404   Training iter 300, batch loss 0.0406, batch acc 0.9906
15:10:49.542   Training iter 350, batch loss 0.0460, batch acc 0.9878
15:10:49.692   Training iter 400, batch loss 0.0427, batch acc 0.9900
15:10:49.847   Training iter 450, batch loss 0.0473, batch acc 0.9876
15:10:49.994   Training iter 500, batch loss 0.0438, batch acc 0.9916
15:10:50.118   Training iter 550, batch loss 0.0457, batch acc 0.9884
15:10:50.258   Training iter 600, batch loss 0.0457, batch acc 0.9882
15:10:50.263 Training @ 90 epoch...
15:10:50.397   Training iter 50, batch loss 0.0434, batch acc 0.9912
15:10:50.506   Training iter 100, batch loss 0.0420, batch acc 0.9894
15:10:50.630   Training iter 150, batch loss 0.0443, batch acc 0.9898
15:10:50.788   Training iter 200, batch loss 0.0426, batch acc 0.9912
15:10:50.947   Training iter 250, batch loss 0.0445, batch acc 0.9886
15:10:51.092   Training iter 300, batch loss 0.0430, batch acc 0.9886
15:10:51.263   Training iter 350, batch loss 0.0399, batch acc 0.9912
15:10:51.430   Training iter 400, batch loss 0.0446, batch acc 0.9902
15:10:51.608   Training iter 450, batch loss 0.0433, batch acc 0.9886
15:10:51.722   Training iter 500, batch loss 0.0437, batch acc 0.9896
15:10:51.883   Training iter 550, batch loss 0.0500, batch acc 0.9876
15:10:52.019   Training iter 600, batch loss 0.0514, batch acc 0.9862
15:10:52.019 Testing @ 90 epoch...
15:10:52.102     Testing, total mean loss 0.07194, total acc 0.97760
15:10:52.102 Training @ 91 epoch...
15:10:52.255   Training iter 50, batch loss 0.0407, batch acc 0.9906
15:10:52.380   Training iter 100, batch loss 0.0442, batch acc 0.9892
15:10:52.488   Training iter 150, batch loss 0.0459, batch acc 0.9880
15:10:52.618   Training iter 200, batch loss 0.0400, batch acc 0.9912
15:10:52.776   Training iter 250, batch loss 0.0435, batch acc 0.9892
15:10:52.917   Training iter 300, batch loss 0.0410, batch acc 0.9918
15:10:53.046   Training iter 350, batch loss 0.0435, batch acc 0.9890
15:10:53.168   Training iter 400, batch loss 0.0504, batch acc 0.9872
15:10:53.286   Training iter 450, batch loss 0.0440, batch acc 0.9876
15:10:53.425   Training iter 500, batch loss 0.0479, batch acc 0.9878
15:10:53.556   Training iter 550, batch loss 0.0448, batch acc 0.9890
15:10:53.763   Training iter 600, batch loss 0.0496, batch acc 0.9898
15:10:53.764 Training @ 92 epoch...
15:10:53.908   Training iter 50, batch loss 0.0415, batch acc 0.9908
15:10:54.043   Training iter 100, batch loss 0.0440, batch acc 0.9886
15:10:54.204   Training iter 150, batch loss 0.0418, batch acc 0.9892
15:10:54.359   Training iter 200, batch loss 0.0478, batch acc 0.9900
15:10:54.484   Training iter 250, batch loss 0.0382, batch acc 0.9926
15:10:54.631   Training iter 300, batch loss 0.0473, batch acc 0.9870
15:10:54.748   Training iter 350, batch loss 0.0417, batch acc 0.9896
15:10:54.908   Training iter 400, batch loss 0.0454, batch acc 0.9902
15:10:55.034   Training iter 450, batch loss 0.0484, batch acc 0.9886
15:10:55.160   Training iter 500, batch loss 0.0455, batch acc 0.9888
15:10:55.288   Training iter 550, batch loss 0.0463, batch acc 0.9870
15:10:55.410   Training iter 600, batch loss 0.0427, batch acc 0.9894
15:10:55.410 Training @ 93 epoch...
15:10:55.527   Training iter 50, batch loss 0.0485, batch acc 0.9866
15:10:55.668   Training iter 100, batch loss 0.0414, batch acc 0.9902
15:10:55.808   Training iter 150, batch loss 0.0429, batch acc 0.9922
15:10:55.946   Training iter 200, batch loss 0.0401, batch acc 0.9902
15:10:56.114   Training iter 250, batch loss 0.0411, batch acc 0.9904
15:10:56.234   Training iter 300, batch loss 0.0501, batch acc 0.9856
15:10:56.413   Training iter 350, batch loss 0.0446, batch acc 0.9898
15:10:56.556   Training iter 400, batch loss 0.0459, batch acc 0.9880
15:10:56.705   Training iter 450, batch loss 0.0448, batch acc 0.9886
15:10:56.874   Training iter 500, batch loss 0.0429, batch acc 0.9892
15:10:57.080   Training iter 550, batch loss 0.0421, batch acc 0.9898
15:10:57.226   Training iter 600, batch loss 0.0417, batch acc 0.9904
15:10:57.227 Training @ 94 epoch...
15:10:57.380   Training iter 50, batch loss 0.0388, batch acc 0.9924
15:10:57.499   Training iter 100, batch loss 0.0457, batch acc 0.9894
15:10:57.634   Training iter 150, batch loss 0.0455, batch acc 0.9886
15:10:57.749   Training iter 200, batch loss 0.0426, batch acc 0.9904
15:10:57.913   Training iter 250, batch loss 0.0423, batch acc 0.9900
15:10:58.046   Training iter 300, batch loss 0.0470, batch acc 0.9896
15:10:58.274   Training iter 350, batch loss 0.0470, batch acc 0.9874
15:10:58.501   Training iter 400, batch loss 0.0475, batch acc 0.9890
15:10:58.667   Training iter 450, batch loss 0.0448, batch acc 0.9890
15:10:58.968   Training iter 500, batch loss 0.0434, batch acc 0.9900
15:10:59.110   Training iter 550, batch loss 0.0507, batch acc 0.9856
15:10:59.250   Training iter 600, batch loss 0.0440, batch acc 0.9900
15:10:59.251 Training @ 95 epoch...
15:10:59.466   Training iter 50, batch loss 0.0386, batch acc 0.9914
15:10:59.760   Training iter 100, batch loss 0.0361, batch acc 0.9938
15:11:00.039   Training iter 150, batch loss 0.0437, batch acc 0.9900
15:11:00.326   Training iter 200, batch loss 0.0459, batch acc 0.9882
15:11:00.506   Training iter 250, batch loss 0.0449, batch acc 0.9888
15:11:00.703   Training iter 300, batch loss 0.0431, batch acc 0.9888
15:11:00.864   Training iter 350, batch loss 0.0477, batch acc 0.9878
15:11:01.024   Training iter 400, batch loss 0.0497, batch acc 0.9860
15:11:01.182   Training iter 450, batch loss 0.0466, batch acc 0.9886
15:11:01.350   Training iter 500, batch loss 0.0438, batch acc 0.9886
15:11:01.498   Training iter 550, batch loss 0.0425, batch acc 0.9908
15:11:01.650   Training iter 600, batch loss 0.0418, batch acc 0.9892
15:11:01.652 Testing @ 95 epoch...
15:11:01.848     Testing, total mean loss 0.07109, total acc 0.97860
15:11:01.848 Training @ 96 epoch...
15:11:02.020   Training iter 50, batch loss 0.0382, batch acc 0.9924
15:11:02.187   Training iter 100, batch loss 0.0482, batch acc 0.9874
15:11:02.423   Training iter 150, batch loss 0.0457, batch acc 0.9898
15:11:02.597   Training iter 200, batch loss 0.0440, batch acc 0.9908
15:11:02.832   Training iter 250, batch loss 0.0429, batch acc 0.9896
15:11:02.954   Training iter 300, batch loss 0.0443, batch acc 0.9894
15:11:03.132   Training iter 350, batch loss 0.0462, batch acc 0.9898
15:11:03.274   Training iter 400, batch loss 0.0405, batch acc 0.9900
15:11:03.448   Training iter 450, batch loss 0.0384, batch acc 0.9920
15:11:03.626   Training iter 500, batch loss 0.0477, batch acc 0.9886
15:11:03.784   Training iter 550, batch loss 0.0411, batch acc 0.9904
15:11:04.007   Training iter 600, batch loss 0.0464, batch acc 0.9878
15:11:04.008 Training @ 97 epoch...
15:11:04.207   Training iter 50, batch loss 0.0392, batch acc 0.9904
15:11:04.386   Training iter 100, batch loss 0.0417, batch acc 0.9908
15:11:04.550   Training iter 150, batch loss 0.0403, batch acc 0.9900
15:11:04.704   Training iter 200, batch loss 0.0458, batch acc 0.9892
15:11:04.924   Training iter 250, batch loss 0.0473, batch acc 0.9892
15:11:05.169   Training iter 300, batch loss 0.0424, batch acc 0.9896
15:11:05.317   Training iter 350, batch loss 0.0449, batch acc 0.9884
15:11:05.610   Training iter 400, batch loss 0.0447, batch acc 0.9902
15:11:05.796   Training iter 450, batch loss 0.0422, batch acc 0.9904
15:11:05.990   Training iter 500, batch loss 0.0522, batch acc 0.9854
15:11:06.230   Training iter 550, batch loss 0.0442, batch acc 0.9888
15:11:06.417   Training iter 600, batch loss 0.0424, batch acc 0.9910
15:11:06.418 Training @ 98 epoch...
15:11:06.626   Training iter 50, batch loss 0.0429, batch acc 0.9910
15:11:06.810   Training iter 100, batch loss 0.0515, batch acc 0.9854
15:11:07.076   Training iter 150, batch loss 0.0430, batch acc 0.9884
15:11:07.209   Training iter 200, batch loss 0.0471, batch acc 0.9888
15:11:07.466   Training iter 250, batch loss 0.0338, batch acc 0.9926
15:11:07.660   Training iter 300, batch loss 0.0421, batch acc 0.9882
15:11:07.931   Training iter 350, batch loss 0.0453, batch acc 0.9906
15:11:08.161   Training iter 400, batch loss 0.0446, batch acc 0.9890
15:11:08.391   Training iter 450, batch loss 0.0409, batch acc 0.9910
15:11:08.632   Training iter 500, batch loss 0.0467, batch acc 0.9896
15:11:08.806   Training iter 550, batch loss 0.0474, batch acc 0.9876
15:11:08.973   Training iter 600, batch loss 0.0447, batch acc 0.9890
15:11:08.975 Training @ 99 epoch...
15:11:09.120   Training iter 50, batch loss 0.0388, batch acc 0.9918
15:11:09.255   Training iter 100, batch loss 0.0447, batch acc 0.9884
15:11:09.419   Training iter 150, batch loss 0.0465, batch acc 0.9884
15:11:09.655   Training iter 200, batch loss 0.0456, batch acc 0.9884
15:11:09.839   Training iter 250, batch loss 0.0443, batch acc 0.9880
15:11:09.973   Training iter 300, batch loss 0.0437, batch acc 0.9894
15:11:10.131   Training iter 350, batch loss 0.0405, batch acc 0.9902
15:11:10.353   Training iter 400, batch loss 0.0364, batch acc 0.9918
15:11:10.506   Training iter 450, batch loss 0.0429, batch acc 0.9900
15:11:10.677   Training iter 500, batch loss 0.0420, batch acc 0.9916
15:11:10.855   Training iter 550, batch loss 0.0442, batch acc 0.9878
15:11:11.023   Training iter 600, batch loss 0.0491, batch acc 0.9874