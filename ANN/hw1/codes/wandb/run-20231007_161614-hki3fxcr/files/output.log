16:16:19.398 Training @ 0 epoch...
16:16:19.611   Training iter 50, batch loss 0.6849, batch acc 0.5842
16:16:19.752   Training iter 100, batch loss 0.4547, batch acc 0.8218
16:16:19.884   Training iter 150, batch loss 0.4199, batch acc 0.8398
16:16:20.032   Training iter 200, batch loss 0.4076, batch acc 0.8480
16:16:20.150   Training iter 250, batch loss 0.4035, batch acc 0.8460
16:16:20.266   Training iter 300, batch loss 0.3933, batch acc 0.8558
16:16:20.392   Training iter 350, batch loss 0.3856, batch acc 0.8598
16:16:20.532   Training iter 400, batch loss 0.3670, batch acc 0.8600
16:16:20.651   Training iter 450, batch loss 0.3457, batch acc 0.8750
16:16:20.777   Training iter 500, batch loss 0.3475, batch acc 0.8722
16:16:20.902   Training iter 550, batch loss 0.3352, batch acc 0.8766
16:16:21.019   Training iter 600, batch loss 0.3402, batch acc 0.8702
16:16:21.019 Testing @ 0 epoch...
16:16:21.128     Testing, total mean loss 0.32572, total acc 0.86850
16:16:21.128 Training @ 1 epoch...
16:16:21.275   Training iter 50, batch loss 0.3204, batch acc 0.8794
16:16:21.484   Training iter 100, batch loss 0.3103, batch acc 0.8836
16:16:21.594   Training iter 150, batch loss 0.3011, batch acc 0.8804
16:16:21.693   Training iter 200, batch loss 0.3059, batch acc 0.8836
16:16:21.804   Training iter 250, batch loss 0.3059, batch acc 0.8770
16:16:21.898   Training iter 300, batch loss 0.2912, batch acc 0.8892
16:16:22.016   Training iter 350, batch loss 0.2823, batch acc 0.8948
16:16:22.102   Training iter 400, batch loss 0.2856, batch acc 0.8930
16:16:22.212   Training iter 450, batch loss 0.2718, batch acc 0.8934
16:16:22.320   Training iter 500, batch loss 0.2805, batch acc 0.8814
16:16:22.444   Training iter 550, batch loss 0.2658, batch acc 0.8992
16:16:22.625   Training iter 600, batch loss 0.2596, batch acc 0.8952
16:16:22.626 Training @ 2 epoch...
16:16:22.719   Training iter 50, batch loss 0.2589, batch acc 0.8934
16:16:22.845   Training iter 100, batch loss 0.2622, batch acc 0.8924
16:16:22.941   Training iter 150, batch loss 0.2570, batch acc 0.9026
16:16:23.085   Training iter 200, batch loss 0.2423, batch acc 0.8990
16:16:23.206   Training iter 250, batch loss 0.2290, batch acc 0.9086
16:16:23.299   Training iter 300, batch loss 0.2349, batch acc 0.9098
16:16:23.403   Training iter 350, batch loss 0.2352, batch acc 0.9016
16:16:23.530   Training iter 400, batch loss 0.2448, batch acc 0.9056
16:16:23.658   Training iter 450, batch loss 0.2328, batch acc 0.9098
16:16:23.779   Training iter 500, batch loss 0.2346, batch acc 0.9032
16:16:23.902   Training iter 550, batch loss 0.2313, batch acc 0.9026
16:16:24.040   Training iter 600, batch loss 0.2226, batch acc 0.9120
16:16:24.041 Training @ 3 epoch...
16:16:24.183   Training iter 50, batch loss 0.2215, batch acc 0.9158
16:16:24.390   Training iter 100, batch loss 0.2315, batch acc 0.9120
16:16:24.523   Training iter 150, batch loss 0.2203, batch acc 0.9138
16:16:24.645   Training iter 200, batch loss 0.2191, batch acc 0.9098
16:16:24.759   Training iter 250, batch loss 0.2233, batch acc 0.9074
16:16:24.896   Training iter 300, batch loss 0.2260, batch acc 0.9122
16:16:25.092   Training iter 350, batch loss 0.2241, batch acc 0.9080
16:16:25.217   Training iter 400, batch loss 0.2266, batch acc 0.9072
16:16:25.343   Training iter 450, batch loss 0.2214, batch acc 0.9132
16:16:25.465   Training iter 500, batch loss 0.2134, batch acc 0.9180
16:16:25.763   Training iter 550, batch loss 0.2096, batch acc 0.9094
16:16:25.959   Training iter 600, batch loss 0.2089, batch acc 0.9160
16:16:25.960 Training @ 4 epoch...
16:16:26.133   Training iter 50, batch loss 0.2160, batch acc 0.9112
16:16:26.298   Training iter 100, batch loss 0.2084, batch acc 0.9134
16:16:26.437   Training iter 150, batch loss 0.2089, batch acc 0.9188
16:16:26.586   Training iter 200, batch loss 0.2106, batch acc 0.9134
16:16:26.714   Training iter 250, batch loss 0.2041, batch acc 0.9178
16:16:26.848   Training iter 300, batch loss 0.2059, batch acc 0.9142
16:16:26.989   Training iter 350, batch loss 0.2051, batch acc 0.9138
16:16:27.136   Training iter 400, batch loss 0.2099, batch acc 0.9096
16:16:27.285   Training iter 450, batch loss 0.2040, batch acc 0.9172
16:16:27.409   Training iter 500, batch loss 0.1926, batch acc 0.9218
16:16:27.550   Training iter 550, batch loss 0.2010, batch acc 0.9190
16:16:27.727   Training iter 600, batch loss 0.1966, batch acc 0.9238
16:16:27.727 Training @ 5 epoch...
16:16:27.900   Training iter 50, batch loss 0.1931, batch acc 0.9238
16:16:28.052   Training iter 100, batch loss 0.1998, batch acc 0.9180
16:16:28.179   Training iter 150, batch loss 0.1981, batch acc 0.9180
16:16:28.298   Training iter 200, batch loss 0.1961, batch acc 0.9192
16:16:28.452   Training iter 250, batch loss 0.2033, batch acc 0.9166
16:16:28.735   Training iter 300, batch loss 0.1953, batch acc 0.9200
16:16:28.881   Training iter 350, batch loss 0.1933, batch acc 0.9244
16:16:29.068   Training iter 400, batch loss 0.2027, batch acc 0.9190
16:16:29.215   Training iter 450, batch loss 0.1972, batch acc 0.9150
16:16:29.345   Training iter 500, batch loss 0.1926, batch acc 0.9190
16:16:29.462   Training iter 550, batch loss 0.1895, batch acc 0.9294
16:16:29.602   Training iter 600, batch loss 0.2025, batch acc 0.9188
16:16:29.603 Testing @ 5 epoch...
16:16:29.702     Testing, total mean loss 0.20776, total acc 0.92150
16:16:29.702 Training @ 6 epoch...
16:16:29.828   Training iter 50, batch loss 0.1844, batch acc 0.9342
16:16:29.961   Training iter 100, batch loss 0.1894, batch acc 0.9244
16:16:30.145   Training iter 150, batch loss 0.1943, batch acc 0.9196
16:16:30.260   Training iter 200, batch loss 0.1977, batch acc 0.9206
16:16:30.447   Training iter 250, batch loss 0.2043, batch acc 0.9180
16:16:30.596   Training iter 300, batch loss 0.1904, batch acc 0.9210
16:16:30.719   Training iter 350, batch loss 0.1871, batch acc 0.9202
16:16:30.876   Training iter 400, batch loss 0.1833, batch acc 0.9268
16:16:31.017   Training iter 450, batch loss 0.1875, batch acc 0.9268
16:16:31.127   Training iter 500, batch loss 0.1876, batch acc 0.9188
16:16:31.229   Training iter 550, batch loss 0.1888, batch acc 0.9224
16:16:31.333   Training iter 600, batch loss 0.1935, batch acc 0.9236
16:16:31.334 Training @ 7 epoch...
16:16:31.434   Training iter 50, batch loss 0.1860, batch acc 0.9244
16:16:31.579   Training iter 100, batch loss 0.1819, batch acc 0.9292
16:16:31.702   Training iter 150, batch loss 0.1848, batch acc 0.9246
16:16:31.865   Training iter 200, batch loss 0.1876, batch acc 0.9274
16:16:32.043   Training iter 250, batch loss 0.1848, batch acc 0.9290
16:16:32.172   Training iter 300, batch loss 0.1843, batch acc 0.9262
16:16:32.290   Training iter 350, batch loss 0.1778, batch acc 0.9312
16:16:32.432   Training iter 400, batch loss 0.1903, batch acc 0.9218
16:16:32.562   Training iter 450, batch loss 0.1895, batch acc 0.9240
16:16:32.681   Training iter 500, batch loss 0.1890, batch acc 0.9266
16:16:32.858   Training iter 550, batch loss 0.1851, batch acc 0.9300
16:16:32.981   Training iter 600, batch loss 0.1888, batch acc 0.9292
16:16:32.982 Training @ 8 epoch...
16:16:33.229   Training iter 50, batch loss 0.1816, batch acc 0.9300
16:16:33.384   Training iter 100, batch loss 0.1804, batch acc 0.9310
16:16:33.525   Training iter 150, batch loss 0.1818, batch acc 0.9332
16:16:33.665   Training iter 200, batch loss 0.1750, batch acc 0.9354
16:16:33.782   Training iter 250, batch loss 0.1791, batch acc 0.9286
16:16:33.915   Training iter 300, batch loss 0.1871, batch acc 0.9238
16:16:34.085   Training iter 350, batch loss 0.1896, batch acc 0.9258
16:16:34.361   Training iter 400, batch loss 0.1944, batch acc 0.9240
16:16:34.494   Training iter 450, batch loss 0.1809, batch acc 0.9268
16:16:34.631   Training iter 500, batch loss 0.1843, batch acc 0.9272
16:16:34.775   Training iter 550, batch loss 0.1802, batch acc 0.9258
16:16:34.908   Training iter 600, batch loss 0.1851, batch acc 0.9220
16:16:34.910 Training @ 9 epoch...
16:16:35.102   Training iter 50, batch loss 0.1749, batch acc 0.9334
16:16:35.328   Training iter 100, batch loss 0.1752, batch acc 0.9306
16:16:35.462   Training iter 150, batch loss 0.1814, batch acc 0.9350
16:16:35.603   Training iter 200, batch loss 0.1705, batch acc 0.9304
16:16:35.720   Training iter 250, batch loss 0.1843, batch acc 0.9276
16:16:35.880   Training iter 300, batch loss 0.1871, batch acc 0.9246
16:16:36.041   Training iter 350, batch loss 0.1740, batch acc 0.9346
16:16:36.217   Training iter 400, batch loss 0.1806, batch acc 0.9302
16:16:36.361   Training iter 450, batch loss 0.1722, batch acc 0.9336
16:16:36.547   Training iter 500, batch loss 0.1728, batch acc 0.9350
16:16:36.712   Training iter 550, batch loss 0.1845, batch acc 0.9270
16:16:36.873   Training iter 600, batch loss 0.1878, batch acc 0.9252
16:16:36.873 Training @ 10 epoch...
16:16:37.049   Training iter 50, batch loss 0.1716, batch acc 0.9338
16:16:37.292   Training iter 100, batch loss 0.1722, batch acc 0.9304
16:16:37.492   Training iter 150, batch loss 0.1746, batch acc 0.9354
16:16:37.616   Training iter 200, batch loss 0.1743, batch acc 0.9306
16:16:37.864   Training iter 250, batch loss 0.1774, batch acc 0.9336
16:16:38.146   Training iter 300, batch loss 0.1761, batch acc 0.9302
16:16:38.337   Training iter 350, batch loss 0.1805, batch acc 0.9328
16:16:38.512   Training iter 400, batch loss 0.1814, batch acc 0.9252
16:16:38.729   Training iter 450, batch loss 0.1762, batch acc 0.9306
16:16:38.866   Training iter 500, batch loss 0.1757, batch acc 0.9326
16:16:38.985   Training iter 550, batch loss 0.1820, batch acc 0.9276
16:16:39.146   Training iter 600, batch loss 0.1791, batch acc 0.9322
16:16:39.147 Testing @ 10 epoch...
16:16:39.248     Testing, total mean loss 0.16519, total acc 0.93290
16:16:39.248 Training @ 11 epoch...
16:16:39.375   Training iter 50, batch loss 0.1745, batch acc 0.9322
16:16:39.479   Training iter 100, batch loss 0.1764, batch acc 0.9330
16:16:39.608   Training iter 150, batch loss 0.1699, batch acc 0.9380
16:16:39.728   Training iter 200, batch loss 0.1687, batch acc 0.9358
16:16:39.853   Training iter 250, batch loss 0.1791, batch acc 0.9270
16:16:39.960   Training iter 300, batch loss 0.1713, batch acc 0.9294
16:16:40.162   Training iter 350, batch loss 0.1676, batch acc 0.9374
16:16:40.352   Training iter 400, batch loss 0.1798, batch acc 0.9316
16:16:40.487   Training iter 450, batch loss 0.1790, batch acc 0.9304
16:16:40.676   Training iter 500, batch loss 0.1779, batch acc 0.9350
16:16:40.798   Training iter 550, batch loss 0.1685, batch acc 0.9390
16:16:40.930   Training iter 600, batch loss 0.1852, batch acc 0.9244
16:16:40.931 Training @ 12 epoch...
16:16:41.118   Training iter 50, batch loss 0.1653, batch acc 0.9404
16:16:41.301   Training iter 100, batch loss 0.1772, batch acc 0.9310
16:16:41.460   Training iter 150, batch loss 0.1697, batch acc 0.9346
16:16:41.735   Training iter 200, batch loss 0.1682, batch acc 0.9322
16:16:41.914   Training iter 250, batch loss 0.1643, batch acc 0.9356
16:16:42.458   Training iter 300, batch loss 0.1766, batch acc 0.9316
16:16:42.647   Training iter 350, batch loss 0.1706, batch acc 0.9380
16:16:42.912   Training iter 400, batch loss 0.1628, batch acc 0.9342
16:16:43.110   Training iter 450, batch loss 0.1660, batch acc 0.9396
16:16:43.245   Training iter 500, batch loss 0.1747, batch acc 0.9316
16:16:43.383   Training iter 550, batch loss 0.1850, batch acc 0.9266
16:16:43.494   Training iter 600, batch loss 0.1746, batch acc 0.9352
16:16:43.495 Training @ 13 epoch...
16:16:43.620   Training iter 50, batch loss 0.1701, batch acc 0.9342
16:16:43.733   Training iter 100, batch loss 0.1695, batch acc 0.9378
16:16:43.858   Training iter 150, batch loss 0.1596, batch acc 0.9438
16:16:43.985   Training iter 200, batch loss 0.1772, batch acc 0.9312
16:16:44.197   Training iter 250, batch loss 0.1800, batch acc 0.9304
16:16:44.301   Training iter 300, batch loss 0.1696, batch acc 0.9376
16:16:44.398   Training iter 350, batch loss 0.1699, batch acc 0.9366
16:16:44.512   Training iter 400, batch loss 0.1625, batch acc 0.9368
16:16:44.618   Training iter 450, batch loss 0.1775, batch acc 0.9300
16:16:44.714   Training iter 500, batch loss 0.1831, batch acc 0.9294
16:16:44.815   Training iter 550, batch loss 0.1705, batch acc 0.9330
16:16:44.912   Training iter 600, batch loss 0.1663, batch acc 0.9352
16:16:44.912 Training @ 14 epoch...
16:16:45.024   Training iter 50, batch loss 0.1597, batch acc 0.9426
16:16:46.054   Training iter 100, batch loss 0.1695, batch acc 0.9370
16:16:46.247   Training iter 150, batch loss 0.1660, batch acc 0.9390
16:16:46.356   Training iter 200, batch loss 0.1754, batch acc 0.9322
16:16:46.456   Training iter 250, batch loss 0.1616, batch acc 0.9426
16:16:46.586   Training iter 300, batch loss 0.1684, batch acc 0.9324
16:16:46.739   Training iter 350, batch loss 0.1747, batch acc 0.9374
16:16:46.915   Training iter 400, batch loss 0.1692, batch acc 0.9344
16:16:47.102   Training iter 450, batch loss 0.1701, batch acc 0.9376
16:16:47.373   Training iter 500, batch loss 0.1791, batch acc 0.9350
16:16:47.583   Training iter 550, batch loss 0.1688, batch acc 0.9392
16:16:47.823   Training iter 600, batch loss 0.1674, batch acc 0.9374
16:16:47.825 Training @ 15 epoch...
16:16:47.970   Training iter 50, batch loss 0.1687, batch acc 0.9362
16:16:48.078   Training iter 100, batch loss 0.1735, batch acc 0.9362
16:16:48.174   Training iter 150, batch loss 0.1690, batch acc 0.9368
16:16:48.339   Training iter 200, batch loss 0.1671, batch acc 0.9400
16:16:48.510   Training iter 250, batch loss 0.1672, batch acc 0.9400
16:16:48.634   Training iter 300, batch loss 0.1712, batch acc 0.9352
16:16:48.789   Training iter 350, batch loss 0.1657, batch acc 0.9386
16:16:48.967   Training iter 400, batch loss 0.1612, batch acc 0.9420
16:16:49.174   Training iter 450, batch loss 0.1628, batch acc 0.9390
16:16:49.298   Training iter 500, batch loss 0.1704, batch acc 0.9362
16:16:49.401   Training iter 550, batch loss 0.1667, batch acc 0.9346
16:16:49.514   Training iter 600, batch loss 0.1623, batch acc 0.9384
16:16:49.515 Testing @ 15 epoch...
16:16:49.605     Testing, total mean loss 0.17317, total acc 0.93630
16:16:49.605 Training @ 16 epoch...
16:16:49.716   Training iter 50, batch loss 0.1689, batch acc 0.9416
16:16:49.829   Training iter 100, batch loss 0.1743, batch acc 0.9312
16:16:49.960   Training iter 150, batch loss 0.1650, batch acc 0.9384
16:16:50.077   Training iter 200, batch loss 0.1583, batch acc 0.9442
16:16:50.315   Training iter 250, batch loss 0.1624, batch acc 0.9392
16:16:50.438   Training iter 300, batch loss 0.1735, batch acc 0.9364
16:16:50.561   Training iter 350, batch loss 0.1614, batch acc 0.9396
16:16:50.735   Training iter 400, batch loss 0.1639, batch acc 0.9374
16:16:50.930   Training iter 450, batch loss 0.1688, batch acc 0.9428
16:16:51.103   Training iter 500, batch loss 0.1637, batch acc 0.9434
16:16:51.246   Training iter 550, batch loss 0.1580, batch acc 0.9430
16:16:51.372   Training iter 600, batch loss 0.1642, batch acc 0.9356
16:16:51.372 Training @ 17 epoch...
16:16:51.556   Training iter 50, batch loss 0.1624, batch acc 0.9428
16:16:51.709   Training iter 100, batch loss 0.1734, batch acc 0.9358
16:16:51.844   Training iter 150, batch loss 0.1509, batch acc 0.9446
16:16:51.988   Training iter 200, batch loss 0.1582, batch acc 0.9402
16:16:52.105   Training iter 250, batch loss 0.1559, batch acc 0.9438
16:16:52.232   Training iter 300, batch loss 0.1707, batch acc 0.9338
16:16:52.416   Training iter 350, batch loss 0.1613, batch acc 0.9380
16:16:52.534   Training iter 400, batch loss 0.1696, batch acc 0.9376
16:16:52.686   Training iter 450, batch loss 0.1655, batch acc 0.9426
16:16:52.789   Training iter 500, batch loss 0.1596, batch acc 0.9412
16:16:52.946   Training iter 550, batch loss 0.1580, batch acc 0.9456
16:16:53.036   Training iter 600, batch loss 0.1668, batch acc 0.9424
16:16:53.036 Training @ 18 epoch...
16:16:53.128   Training iter 50, batch loss 0.1628, batch acc 0.9416
16:16:53.225   Training iter 100, batch loss 0.1630, batch acc 0.9416
16:16:53.312   Training iter 150, batch loss 0.1578, batch acc 0.9436
16:16:53.401   Training iter 200, batch loss 0.1568, batch acc 0.9416
16:16:53.496   Training iter 250, batch loss 0.1547, batch acc 0.9398
16:16:53.581   Training iter 300, batch loss 0.1629, batch acc 0.9426
16:16:53.673   Training iter 350, batch loss 0.1697, batch acc 0.9404
16:16:53.764   Training iter 400, batch loss 0.1590, batch acc 0.9400
16:16:53.863   Training iter 450, batch loss 0.1640, batch acc 0.9388
16:16:53.963   Training iter 500, batch loss 0.1614, batch acc 0.9424
16:16:54.055   Training iter 550, batch loss 0.1626, batch acc 0.9418
16:16:54.225   Training iter 600, batch loss 0.1635, batch acc 0.9416
16:16:54.226 Training @ 19 epoch...
16:16:54.343   Training iter 50, batch loss 0.1611, batch acc 0.9392
16:16:54.453   Training iter 100, batch loss 0.1568, batch acc 0.9444
16:16:54.558   Training iter 150, batch loss 0.1588, batch acc 0.9440
16:16:54.674   Training iter 200, batch loss 0.1589, batch acc 0.9454
16:16:54.765   Training iter 250, batch loss 0.1556, batch acc 0.9430
16:16:54.868   Training iter 300, batch loss 0.1553, batch acc 0.9466
16:16:54.960   Training iter 350, batch loss 0.1552, batch acc 0.9468
16:16:55.070   Training iter 400, batch loss 0.1589, batch acc 0.9414
16:16:55.225   Training iter 450, batch loss 0.1622, batch acc 0.9426
16:16:55.366   Training iter 500, batch loss 0.1673, batch acc 0.9374
16:16:55.476   Training iter 550, batch loss 0.1579, batch acc 0.9408
16:16:55.595   Training iter 600, batch loss 0.1556, batch acc 0.9478
16:16:55.597 Training @ 20 epoch...
16:16:55.714   Training iter 50, batch loss 0.1689, batch acc 0.9352
16:16:55.895   Training iter 100, batch loss 0.1582, batch acc 0.9450
16:16:55.997   Training iter 150, batch loss 0.1585, batch acc 0.9450
16:16:56.120   Training iter 200, batch loss 0.1613, batch acc 0.9388
16:16:56.229   Training iter 250, batch loss 0.1552, batch acc 0.9452
16:16:56.376   Training iter 300, batch loss 0.1533, batch acc 0.9466
16:16:56.533   Training iter 350, batch loss 0.1673, batch acc 0.9446
16:16:56.711   Training iter 400, batch loss 0.1591, batch acc 0.9412
16:16:56.878   Training iter 450, batch loss 0.1565, batch acc 0.9466
16:16:57.007   Training iter 500, batch loss 0.1624, batch acc 0.9434
16:16:57.142   Training iter 550, batch loss 0.1578, batch acc 0.9454
16:16:57.310   Training iter 600, batch loss 0.1637, batch acc 0.9416
16:16:57.311 Testing @ 20 epoch...
16:16:57.427     Testing, total mean loss 0.15888, total acc 0.94110
16:16:57.427 Training @ 21 epoch...
16:16:57.583   Training iter 50, batch loss 0.1624, batch acc 0.9416
16:16:57.767   Training iter 100, batch loss 0.1546, batch acc 0.9508
16:16:57.899   Training iter 150, batch loss 0.1596, batch acc 0.9432
16:16:58.012   Training iter 200, batch loss 0.1522, batch acc 0.9474
16:16:58.134   Training iter 250, batch loss 0.1547, batch acc 0.9460
16:16:58.230   Training iter 300, batch loss 0.1546, batch acc 0.9450
16:16:58.339   Training iter 350, batch loss 0.1607, batch acc 0.9434
16:16:58.463   Training iter 400, batch loss 0.1574, batch acc 0.9454
16:16:58.649   Training iter 450, batch loss 0.1594, batch acc 0.9382
16:16:58.769   Training iter 500, batch loss 0.1682, batch acc 0.9406
16:16:58.937   Training iter 550, batch loss 0.1504, batch acc 0.9472
16:16:59.075   Training iter 600, batch loss 0.1658, batch acc 0.9418
16:16:59.077 Training @ 22 epoch...
16:16:59.277   Training iter 50, batch loss 0.1471, batch acc 0.9524
16:16:59.466   Training iter 100, batch loss 0.1493, batch acc 0.9496
16:16:59.639   Training iter 150, batch loss 0.1552, batch acc 0.9410
16:16:59.754   Training iter 200, batch loss 0.1590, batch acc 0.9456
16:16:59.930   Training iter 250, batch loss 0.1512, batch acc 0.9452
16:17:00.042   Training iter 300, batch loss 0.1624, batch acc 0.9444
16:17:00.154   Training iter 350, batch loss 0.1588, batch acc 0.9430
16:17:00.278   Training iter 400, batch loss 0.1595, batch acc 0.9402
16:17:00.392   Training iter 450, batch loss 0.1523, batch acc 0.9444
16:17:00.510   Training iter 500, batch loss 0.1617, batch acc 0.9446
16:17:00.627   Training iter 550, batch loss 0.1537, batch acc 0.9448
16:17:00.745   Training iter 600, batch loss 0.1649, batch acc 0.9392
16:17:00.746 Training @ 23 epoch...
16:17:00.854   Training iter 50, batch loss 0.1510, batch acc 0.9472
16:17:01.010   Training iter 100, batch loss 0.1535, batch acc 0.9448
16:17:01.124   Training iter 150, batch loss 0.1631, batch acc 0.9444
16:17:01.425   Training iter 200, batch loss 0.1567, batch acc 0.9478
16:17:02.940   Training iter 250, batch loss 0.1562, batch acc 0.9444
16:17:03.085   Training iter 300, batch loss 0.1504, batch acc 0.9482
16:17:03.248   Training iter 350, batch loss 0.1518, batch acc 0.9452
16:17:03.388   Training iter 400, batch loss 0.1556, batch acc 0.9440
16:17:03.499   Training iter 450, batch loss 0.1592, batch acc 0.9438
16:17:03.596   Training iter 500, batch loss 0.1492, batch acc 0.9496
16:17:03.712   Training iter 550, batch loss 0.1623, batch acc 0.9432
16:17:03.830   Training iter 600, batch loss 0.1596, batch acc 0.9388
16:17:03.830 Training @ 24 epoch...
16:17:03.948   Training iter 50, batch loss 0.1538, batch acc 0.9448
16:17:04.079   Training iter 100, batch loss 0.1503, batch acc 0.9502
16:17:04.212   Training iter 150, batch loss 0.1590, batch acc 0.9440
16:17:04.335   Training iter 200, batch loss 0.1590, batch acc 0.9430
16:17:04.459   Training iter 250, batch loss 0.1587, batch acc 0.9502
16:17:04.573   Training iter 300, batch loss 0.1505, batch acc 0.9470
16:17:04.680   Training iter 350, batch loss 0.1566, batch acc 0.9474
16:17:04.799   Training iter 400, batch loss 0.1585, batch acc 0.9452
16:17:04.937   Training iter 450, batch loss 0.1524, batch acc 0.9506
16:17:05.090   Training iter 500, batch loss 0.1534, batch acc 0.9490
16:17:05.206   Training iter 550, batch loss 0.1529, batch acc 0.9432
16:17:05.373   Training iter 600, batch loss 0.1625, batch acc 0.9386
16:17:05.373 Training @ 25 epoch...
16:17:05.524   Training iter 50, batch loss 0.1463, batch acc 0.9494
16:17:05.688   Training iter 100, batch loss 0.1495, batch acc 0.9464
16:17:05.816   Training iter 150, batch loss 0.1546, batch acc 0.9462
16:17:05.930   Training iter 200, batch loss 0.1524, batch acc 0.9476
16:17:06.031   Training iter 250, batch loss 0.1490, batch acc 0.9472
16:17:06.141   Training iter 300, batch loss 0.1593, batch acc 0.9462
16:17:06.248   Training iter 350, batch loss 0.1617, batch acc 0.9430
16:17:06.353   Training iter 400, batch loss 0.1540, batch acc 0.9434
16:17:06.465   Training iter 450, batch loss 0.1502, batch acc 0.9494
16:17:06.581   Training iter 500, batch loss 0.1542, batch acc 0.9488
16:17:06.689   Training iter 550, batch loss 0.1528, batch acc 0.9456
16:17:06.797   Training iter 600, batch loss 0.1581, batch acc 0.9442
16:17:06.797 Testing @ 25 epoch...
16:17:06.893     Testing, total mean loss 0.14853, total acc 0.94360
16:17:06.893 Training @ 26 epoch...
16:17:06.993   Training iter 50, batch loss 0.1535, batch acc 0.9478
16:17:07.089   Training iter 100, batch loss 0.1599, batch acc 0.9452
16:17:07.277   Training iter 150, batch loss 0.1555, batch acc 0.9448
16:17:07.463   Training iter 200, batch loss 0.1503, batch acc 0.9456
16:17:07.601   Training iter 250, batch loss 0.1443, batch acc 0.9522
16:17:07.813   Training iter 300, batch loss 0.1510, batch acc 0.9464
16:17:07.946   Training iter 350, batch loss 0.1517, batch acc 0.9488
16:17:08.036   Training iter 400, batch loss 0.1637, batch acc 0.9440
16:17:08.124   Training iter 450, batch loss 0.1600, batch acc 0.9466
16:17:08.215   Training iter 500, batch loss 0.1485, batch acc 0.9490
16:17:08.294   Training iter 550, batch loss 0.1484, batch acc 0.9464
16:17:08.378   Training iter 600, batch loss 0.1588, batch acc 0.9408
16:17:08.380 Training @ 27 epoch...
16:17:08.566   Training iter 50, batch loss 0.1519, batch acc 0.9488
16:17:08.670   Training iter 100, batch loss 0.1453, batch acc 0.9536
16:17:08.769   Training iter 150, batch loss 0.1539, batch acc 0.9444
16:17:08.865   Training iter 200, batch loss 0.1473, batch acc 0.9478
16:17:08.973   Training iter 250, batch loss 0.1450, batch acc 0.9506
16:17:09.105   Training iter 300, batch loss 0.1516, batch acc 0.9468
16:17:09.214   Training iter 350, batch loss 0.1624, batch acc 0.9416
16:17:09.318   Training iter 400, batch loss 0.1491, batch acc 0.9498
16:17:09.418   Training iter 450, batch loss 0.1478, batch acc 0.9490
16:17:09.533   Training iter 500, batch loss 0.1570, batch acc 0.9422
16:17:09.657   Training iter 550, batch loss 0.1484, batch acc 0.9502
16:17:09.788   Training iter 600, batch loss 0.1503, batch acc 0.9462
16:17:09.789 Training @ 28 epoch...
16:17:09.965   Training iter 50, batch loss 0.1517, batch acc 0.9498
16:17:10.101   Training iter 100, batch loss 0.1485, batch acc 0.9484
16:17:10.205   Training iter 150, batch loss 0.1421, batch acc 0.9510
16:17:10.293   Training iter 200, batch loss 0.1500, batch acc 0.9506
16:17:10.387   Training iter 250, batch loss 0.1589, batch acc 0.9468
16:17:10.485   Training iter 300, batch loss 0.1551, batch acc 0.9462
16:17:10.580   Training iter 350, batch loss 0.1511, batch acc 0.9454
16:17:10.677   Training iter 400, batch loss 0.1500, batch acc 0.9490
16:17:10.767   Training iter 450, batch loss 0.1513, batch acc 0.9462
16:17:10.858   Training iter 500, batch loss 0.1525, batch acc 0.9444
16:17:10.939   Training iter 550, batch loss 0.1538, batch acc 0.9430
16:17:11.047   Training iter 600, batch loss 0.1538, batch acc 0.9470
16:17:11.048 Training @ 29 epoch...
16:17:11.137   Training iter 50, batch loss 0.1597, batch acc 0.9456
16:17:11.346   Training iter 100, batch loss 0.1421, batch acc 0.9528
16:17:11.447   Training iter 150, batch loss 0.1541, batch acc 0.9462
16:17:11.560   Training iter 200, batch loss 0.1466, batch acc 0.9464
16:17:11.703   Training iter 250, batch loss 0.1562, batch acc 0.9464
16:17:11.809   Training iter 300, batch loss 0.1579, batch acc 0.9448
16:17:11.957   Training iter 350, batch loss 0.1546, batch acc 0.9442
16:17:12.079   Training iter 400, batch loss 0.1433, batch acc 0.9514
16:17:12.193   Training iter 450, batch loss 0.1566, batch acc 0.9524
16:17:12.305   Training iter 500, batch loss 0.1565, batch acc 0.9488
16:17:12.403   Training iter 550, batch loss 0.1447, batch acc 0.9504
16:17:12.532   Training iter 600, batch loss 0.1492, batch acc 0.9484
16:17:12.534 Training @ 30 epoch...
16:17:12.644   Training iter 50, batch loss 0.1489, batch acc 0.9444
16:17:12.736   Training iter 100, batch loss 0.1493, batch acc 0.9532
16:17:12.833   Training iter 150, batch loss 0.1491, batch acc 0.9496
16:17:12.938   Training iter 200, batch loss 0.1461, batch acc 0.9518
16:17:13.039   Training iter 250, batch loss 0.1485, batch acc 0.9518
16:17:13.144   Training iter 300, batch loss 0.1479, batch acc 0.9494
16:17:13.235   Training iter 350, batch loss 0.1542, batch acc 0.9492
16:17:13.324   Training iter 400, batch loss 0.1521, batch acc 0.9476
16:17:13.425   Training iter 450, batch loss 0.1534, batch acc 0.9472
16:17:13.521   Training iter 500, batch loss 0.1432, batch acc 0.9524
16:17:13.625   Training iter 550, batch loss 0.1631, batch acc 0.9412
16:17:13.717   Training iter 600, batch loss 0.1549, batch acc 0.9482
16:17:13.717 Testing @ 30 epoch...
16:17:13.781     Testing, total mean loss 0.17531, total acc 0.94150
16:17:13.781 Training @ 31 epoch...
16:17:13.874   Training iter 50, batch loss 0.1492, batch acc 0.9512
16:17:14.035   Training iter 100, batch loss 0.1523, batch acc 0.9468
16:17:14.132   Training iter 150, batch loss 0.1515, batch acc 0.9446
16:17:14.239   Training iter 200, batch loss 0.1499, batch acc 0.9514
16:17:14.326   Training iter 250, batch loss 0.1490, batch acc 0.9518
16:17:14.414   Training iter 300, batch loss 0.1542, batch acc 0.9458
16:17:14.515   Training iter 350, batch loss 0.1542, batch acc 0.9464
16:17:14.614   Training iter 400, batch loss 0.1540, batch acc 0.9448
16:17:14.697   Training iter 450, batch loss 0.1475, batch acc 0.9504
16:17:14.806   Training iter 500, batch loss 0.1423, batch acc 0.9520
16:17:14.906   Training iter 550, batch loss 0.1475, batch acc 0.9496
16:17:15.050   Training iter 600, batch loss 0.1520, batch acc 0.9448
16:17:15.051 Training @ 32 epoch...
16:17:15.158   Training iter 50, batch loss 0.1503, batch acc 0.9478
16:17:15.269   Training iter 100, batch loss 0.1486, batch acc 0.9500
16:17:15.375   Training iter 150, batch loss 0.1460, batch acc 0.9496
16:17:15.507   Training iter 200, batch loss 0.1363, batch acc 0.9566
16:17:15.593   Training iter 250, batch loss 0.1513, batch acc 0.9462
16:17:15.680   Training iter 300, batch loss 0.1474, batch acc 0.9508
16:17:15.779   Training iter 350, batch loss 0.1414, batch acc 0.9526
16:17:15.881   Training iter 400, batch loss 0.1490, batch acc 0.9510
16:17:15.990   Training iter 450, batch loss 0.1448, batch acc 0.9506
16:17:16.090   Training iter 500, batch loss 0.1481, batch acc 0.9500
16:17:16.205   Training iter 550, batch loss 0.1541, batch acc 0.9464
16:17:16.325   Training iter 600, batch loss 0.1540, batch acc 0.9450
16:17:16.325 Training @ 33 epoch...
16:17:16.422   Training iter 50, batch loss 0.1454, batch acc 0.9498
16:17:16.517   Training iter 100, batch loss 0.1491, batch acc 0.9512
16:17:16.617   Training iter 150, batch loss 0.1465, batch acc 0.9522
16:17:16.725   Training iter 200, batch loss 0.1483, batch acc 0.9496
16:17:16.834   Training iter 250, batch loss 0.1514, batch acc 0.9470
16:17:17.139   Training iter 300, batch loss 0.1514, batch acc 0.9482
16:17:17.323   Training iter 350, batch loss 0.1502, batch acc 0.9516
16:17:17.498   Training iter 400, batch loss 0.1484, batch acc 0.9520
16:17:17.620   Training iter 450, batch loss 0.1513, batch acc 0.9468
16:17:17.735   Training iter 500, batch loss 0.1483, batch acc 0.9476
16:17:17.870   Training iter 550, batch loss 0.1545, batch acc 0.9472
16:17:18.003   Training iter 600, batch loss 0.1529, batch acc 0.9486
16:17:18.004 Training @ 34 epoch...
16:17:18.157   Training iter 50, batch loss 0.1457, batch acc 0.9534
16:17:18.365   Training iter 100, batch loss 0.1453, batch acc 0.9518
16:17:18.492   Training iter 150, batch loss 0.1453, batch acc 0.9486
16:17:18.644   Training iter 200, batch loss 0.1513, batch acc 0.9450
16:17:18.740   Training iter 250, batch loss 0.1444, batch acc 0.9512
16:17:18.824   Training iter 300, batch loss 0.1526, batch acc 0.9474
16:17:18.918   Training iter 350, batch loss 0.1432, batch acc 0.9526
16:17:19.033   Training iter 400, batch loss 0.1588, batch acc 0.9464
16:17:19.118   Training iter 450, batch loss 0.1514, batch acc 0.9480
16:17:19.193   Training iter 500, batch loss 0.1450, batch acc 0.9540
16:17:19.283   Training iter 550, batch loss 0.1549, batch acc 0.9474
16:17:19.376   Training iter 600, batch loss 0.1515, batch acc 0.9510
16:17:19.378 Training @ 35 epoch...
16:17:19.478   Training iter 50, batch loss 0.1500, batch acc 0.9488
16:17:19.578   Training iter 100, batch loss 0.1435, batch acc 0.9484
16:17:19.665   Training iter 150, batch loss 0.1509, batch acc 0.9502
16:17:19.757   Training iter 200, batch loss 0.1486, batch acc 0.9494
16:17:19.847   Training iter 250, batch loss 0.1500, batch acc 0.9492
16:17:19.951   Training iter 300, batch loss 0.1424, batch acc 0.9468
16:17:20.054   Training iter 350, batch loss 0.1413, batch acc 0.9554
16:17:20.178   Training iter 400, batch loss 0.1556, batch acc 0.9480
16:17:20.308   Training iter 450, batch loss 0.1441, batch acc 0.9514
16:17:20.420   Training iter 500, batch loss 0.1447, batch acc 0.9510
16:17:20.536   Training iter 550, batch loss 0.1474, batch acc 0.9492
16:17:20.667   Training iter 600, batch loss 0.1434, batch acc 0.9524
16:17:20.668 Testing @ 35 epoch...
16:17:20.753     Testing, total mean loss 0.15547, total acc 0.94660
16:17:20.753 Training @ 36 epoch...
16:17:20.909   Training iter 50, batch loss 0.1432, batch acc 0.9514
16:17:21.066   Training iter 100, batch loss 0.1444, batch acc 0.9556
16:17:21.222   Training iter 150, batch loss 0.1466, batch acc 0.9512
16:17:21.496   Training iter 200, batch loss 0.1405, batch acc 0.9540
16:17:21.598   Training iter 250, batch loss 0.1506, batch acc 0.9498
16:17:21.689   Training iter 300, batch loss 0.1408, batch acc 0.9542
16:17:21.784   Training iter 350, batch loss 0.1584, batch acc 0.9446
16:17:21.884   Training iter 400, batch loss 0.1688, batch acc 0.9492
16:17:21.981   Training iter 450, batch loss 0.1517, batch acc 0.9492
16:17:22.084   Training iter 500, batch loss 0.1417, batch acc 0.9516
16:17:22.194   Training iter 550, batch loss 0.1575, batch acc 0.9484
16:17:22.293   Training iter 600, batch loss 0.1463, batch acc 0.9512
16:17:22.293 Training @ 37 epoch...
16:17:22.398   Training iter 50, batch loss 0.1535, batch acc 0.9474
16:17:22.489   Training iter 100, batch loss 0.1409, batch acc 0.9510
16:17:22.590   Training iter 150, batch loss 0.1389, batch acc 0.9502
16:17:22.727   Training iter 200, batch loss 0.1491, batch acc 0.9512
16:17:22.842   Training iter 250, batch loss 0.1514, batch acc 0.9514
16:17:22.961   Training iter 300, batch loss 0.1452, batch acc 0.9500
16:17:23.094   Training iter 350, batch loss 0.1436, batch acc 0.9552
16:17:23.267   Training iter 400, batch loss 0.1463, batch acc 0.9494
16:17:23.381   Training iter 450, batch loss 0.1421, batch acc 0.9538
16:17:23.489   Training iter 500, batch loss 0.1465, batch acc 0.9526
16:17:23.600   Training iter 550, batch loss 0.1497, batch acc 0.9482
16:17:23.714   Training iter 600, batch loss 0.1481, batch acc 0.9486
16:17:23.716 Training @ 38 epoch...
16:17:23.838   Training iter 50, batch loss 0.1415, batch acc 0.9532
16:17:23.916   Training iter 100, batch loss 0.1500, batch acc 0.9582
16:17:24.023   Training iter 150, batch loss 0.1501, batch acc 0.9462
16:17:24.115   Training iter 200, batch loss 0.1426, batch acc 0.9502
16:17:24.192   Training iter 250, batch loss 0.1538, batch acc 0.9480
16:17:24.282   Training iter 300, batch loss 0.1550, batch acc 0.9480
16:17:24.359   Training iter 350, batch loss 0.1466, batch acc 0.9540
16:17:24.450   Training iter 400, batch loss 0.1452, batch acc 0.9524
16:17:24.543   Training iter 450, batch loss 0.1398, batch acc 0.9504
16:17:24.648   Training iter 500, batch loss 0.1427, batch acc 0.9530
16:17:24.738   Training iter 550, batch loss 0.1583, batch acc 0.9448
16:17:24.840   Training iter 600, batch loss 0.1451, batch acc 0.9502
16:17:24.840 Training @ 39 epoch...
16:17:24.933   Training iter 50, batch loss 0.1451, batch acc 0.9512
16:17:25.022   Training iter 100, batch loss 0.1468, batch acc 0.9510
16:17:25.104   Training iter 150, batch loss 0.1479, batch acc 0.9506
16:17:25.203   Training iter 200, batch loss 0.1458, batch acc 0.9496
16:17:25.328   Training iter 250, batch loss 0.1458, batch acc 0.9488
16:17:25.460   Training iter 300, batch loss 0.1420, batch acc 0.9532
16:17:25.576   Training iter 350, batch loss 0.1419, batch acc 0.9524
16:17:25.684   Training iter 400, batch loss 0.1475, batch acc 0.9494
16:17:25.777   Training iter 450, batch loss 0.1479, batch acc 0.9490
16:17:25.879   Training iter 500, batch loss 0.1423, batch acc 0.9544
16:17:25.989   Training iter 550, batch loss 0.1434, batch acc 0.9562
16:17:26.107   Training iter 600, batch loss 0.1389, batch acc 0.9542
16:17:26.109 Training @ 40 epoch...
16:17:26.329   Training iter 50, batch loss 0.1486, batch acc 0.9468
16:17:26.660   Training iter 100, batch loss 0.1483, batch acc 0.9490
16:17:26.830   Training iter 150, batch loss 0.1400, batch acc 0.9552
16:17:27.049   Training iter 200, batch loss 0.1407, batch acc 0.9518
16:17:27.204   Training iter 250, batch loss 0.1469, batch acc 0.9496
16:17:27.398   Training iter 300, batch loss 0.1429, batch acc 0.9540
16:17:27.547   Training iter 350, batch loss 0.1496, batch acc 0.9508
16:17:27.682   Training iter 400, batch loss 0.1509, batch acc 0.9466
16:17:27.875   Training iter 450, batch loss 0.1424, batch acc 0.9500
16:17:28.073   Training iter 500, batch loss 0.1404, batch acc 0.9552
16:17:28.225   Training iter 550, batch loss 0.1406, batch acc 0.9544
16:17:28.361   Training iter 600, batch loss 0.1465, batch acc 0.9494
16:17:28.362 Testing @ 40 epoch...
16:17:28.437     Testing, total mean loss 0.14774, total acc 0.94990
16:17:28.437 Training @ 41 epoch...
16:17:28.584   Training iter 50, batch loss 0.1520, batch acc 0.9496
16:17:28.715   Training iter 100, batch loss 0.1514, batch acc 0.9466
16:17:28.855   Training iter 150, batch loss 0.1461, batch acc 0.9502
16:17:28.977   Training iter 200, batch loss 0.1449, batch acc 0.9512
16:17:29.085   Training iter 250, batch loss 0.1395, batch acc 0.9528
16:17:29.236   Training iter 300, batch loss 0.1468, batch acc 0.9512
16:17:29.368   Training iter 350, batch loss 0.1455, batch acc 0.9512
16:17:29.542   Training iter 400, batch loss 0.1462, batch acc 0.9534
16:17:29.694   Training iter 450, batch loss 0.1406, batch acc 0.9544
16:17:29.807   Training iter 500, batch loss 0.1442, batch acc 0.9520
16:17:29.902   Training iter 550, batch loss 0.1391, batch acc 0.9518
16:17:29.997   Training iter 600, batch loss 0.1380, batch acc 0.9562
16:17:29.998 Training @ 42 epoch...
16:17:30.107   Training iter 50, batch loss 0.1381, batch acc 0.9542
16:17:30.325   Training iter 100, batch loss 0.1415, batch acc 0.9510
16:17:30.446   Training iter 150, batch loss 0.1387, batch acc 0.9550
16:17:30.549   Training iter 200, batch loss 0.1403, batch acc 0.9560
16:17:30.636   Training iter 250, batch loss 0.1442, batch acc 0.9550
16:17:30.736   Training iter 300, batch loss 0.1495, batch acc 0.9544
16:17:30.835   Training iter 350, batch loss 0.1474, batch acc 0.9498
16:17:30.922   Training iter 400, batch loss 0.1451, batch acc 0.9496
16:17:31.005   Training iter 450, batch loss 0.1444, batch acc 0.9496
16:17:31.099   Training iter 500, batch loss 0.1471, batch acc 0.9514
16:17:31.192   Training iter 550, batch loss 0.1513, batch acc 0.9508
16:17:31.292   Training iter 600, batch loss 0.1424, batch acc 0.9494
16:17:31.294 Training @ 43 epoch...
16:17:31.381   Training iter 50, batch loss 0.1461, batch acc 0.9504
16:17:31.485   Training iter 100, batch loss 0.1425, batch acc 0.9544
16:17:31.590   Training iter 150, batch loss 0.1402, batch acc 0.9568
16:17:31.699   Training iter 200, batch loss 0.1518, batch acc 0.9494
16:17:31.805   Training iter 250, batch loss 0.1460, batch acc 0.9514
16:17:31.917   Training iter 300, batch loss 0.1496, batch acc 0.9534
16:17:32.039   Training iter 350, batch loss 0.1408, batch acc 0.9536
16:17:32.201   Training iter 400, batch loss 0.1427, batch acc 0.9514
16:17:32.303   Training iter 450, batch loss 0.1392, batch acc 0.9536
16:17:32.401   Training iter 500, batch loss 0.1361, batch acc 0.9538
16:17:32.568   Training iter 550, batch loss 0.1454, batch acc 0.9534
16:17:32.786   Training iter 600, batch loss 0.1483, batch acc 0.9468
16:17:32.788 Training @ 44 epoch...
16:17:32.899   Training iter 50, batch loss 0.1440, batch acc 0.9544
16:17:33.004   Training iter 100, batch loss 0.1554, batch acc 0.9522
16:17:33.148   Training iter 150, batch loss 0.1406, batch acc 0.9534
16:17:33.273   Training iter 200, batch loss 0.1478, batch acc 0.9506
16:17:33.399   Training iter 250, batch loss 0.1429, batch acc 0.9532
16:17:33.515   Training iter 300, batch loss 0.1384, batch acc 0.9538
16:17:33.627   Training iter 350, batch loss 0.1500, batch acc 0.9500
16:17:33.718   Training iter 400, batch loss 0.1456, batch acc 0.9498
16:17:33.835   Training iter 450, batch loss 0.1454, batch acc 0.9496
16:17:33.934   Training iter 500, batch loss 0.1389, batch acc 0.9568
16:17:34.055   Training iter 550, batch loss 0.1440, batch acc 0.9520
16:17:34.159   Training iter 600, batch loss 0.1490, batch acc 0.9482
16:17:34.160 Training @ 45 epoch...
16:17:34.277   Training iter 50, batch loss 0.1460, batch acc 0.9526
16:17:34.387   Training iter 100, batch loss 0.1441, batch acc 0.9524
16:17:34.491   Training iter 150, batch loss 0.1404, batch acc 0.9536
16:17:34.607   Training iter 200, batch loss 0.1385, batch acc 0.9526
16:17:34.721   Training iter 250, batch loss 0.1419, batch acc 0.9550
16:17:34.840   Training iter 300, batch loss 0.1472, batch acc 0.9536
16:17:34.979   Training iter 350, batch loss 0.1493, batch acc 0.9466
16:17:35.101   Training iter 400, batch loss 0.1479, batch acc 0.9530
16:17:35.223   Training iter 450, batch loss 0.1411, batch acc 0.9556
16:17:35.381   Training iter 500, batch loss 0.1457, batch acc 0.9538
16:17:35.477   Training iter 550, batch loss 0.1474, batch acc 0.9524
16:17:35.577   Training iter 600, batch loss 0.1434, batch acc 0.9538
16:17:35.578 Testing @ 45 epoch...
16:17:35.656     Testing, total mean loss 0.17530, total acc 0.94710
16:17:35.656 Training @ 46 epoch...
16:17:35.747   Training iter 50, batch loss 0.1491, batch acc 0.9506
16:17:35.889   Training iter 100, batch loss 0.1447, batch acc 0.9516
16:17:35.981   Training iter 150, batch loss 0.1404, batch acc 0.9538
16:17:36.076   Training iter 200, batch loss 0.1442, batch acc 0.9536
16:17:36.174   Training iter 250, batch loss 0.1422, batch acc 0.9546
16:17:36.333   Training iter 300, batch loss 0.1420, batch acc 0.9498
16:17:36.438   Training iter 350, batch loss 0.1483, batch acc 0.9546
16:17:36.585   Training iter 400, batch loss 0.1516, batch acc 0.9536
16:17:36.686   Training iter 450, batch loss 0.1492, batch acc 0.9484
16:17:36.876   Training iter 500, batch loss 0.1459, batch acc 0.9520
16:17:37.003   Training iter 550, batch loss 0.1437, batch acc 0.9518
16:17:37.117   Training iter 600, batch loss 0.1491, batch acc 0.9552
16:17:37.119 Training @ 47 epoch...
16:17:37.228   Training iter 50, batch loss 0.1405, batch acc 0.9558
16:17:37.357   Training iter 100, batch loss 0.1443, batch acc 0.9508
16:17:37.463   Training iter 150, batch loss 0.1467, batch acc 0.9528
16:17:37.577   Training iter 200, batch loss 0.1477, batch acc 0.9462
16:17:37.734   Training iter 250, batch loss 0.1510, batch acc 0.9532
16:17:37.897   Training iter 300, batch loss 0.1487, batch acc 0.9522
16:17:37.991   Training iter 350, batch loss 0.1480, batch acc 0.9528
16:17:38.137   Training iter 400, batch loss 0.1402, batch acc 0.9538
16:17:38.264   Training iter 450, batch loss 0.1363, batch acc 0.9604
16:17:38.378   Training iter 500, batch loss 0.1353, batch acc 0.9578
16:17:38.509   Training iter 550, batch loss 0.1389, batch acc 0.9538
16:17:38.614   Training iter 600, batch loss 0.1452, batch acc 0.9560
16:17:38.614 Training @ 48 epoch...
16:17:38.753   Training iter 50, batch loss 0.1349, batch acc 0.9584
16:17:38.876   Training iter 100, batch loss 0.1434, batch acc 0.9526
16:17:39.035   Training iter 150, batch loss 0.1385, batch acc 0.9536
16:17:39.149   Training iter 200, batch loss 0.1410, batch acc 0.9522
16:17:39.304   Training iter 250, batch loss 0.1432, batch acc 0.9566
16:17:39.414   Training iter 300, batch loss 0.1464, batch acc 0.9516
16:17:39.526   Training iter 350, batch loss 0.1495, batch acc 0.9482
16:17:39.675   Training iter 400, batch loss 0.1440, batch acc 0.9524
16:17:39.806   Training iter 450, batch loss 0.1480, batch acc 0.9482
16:17:39.920   Training iter 500, batch loss 0.1437, batch acc 0.9542
16:17:40.033   Training iter 550, batch loss 0.1490, batch acc 0.9520
16:17:40.148   Training iter 600, batch loss 0.1496, batch acc 0.9544
16:17:40.150 Training @ 49 epoch...
16:17:40.271   Training iter 50, batch loss 0.1399, batch acc 0.9546
16:17:40.393   Training iter 100, batch loss 0.1450, batch acc 0.9522
16:17:40.528   Training iter 150, batch loss 0.1332, batch acc 0.9594
16:17:40.640   Training iter 200, batch loss 0.1486, batch acc 0.9484
16:17:40.753   Training iter 250, batch loss 0.1371, batch acc 0.9554
16:17:40.858   Training iter 300, batch loss 0.1359, batch acc 0.9564
16:17:40.949   Training iter 350, batch loss 0.1447, batch acc 0.9526
16:17:41.133   Training iter 400, batch loss 0.1499, batch acc 0.9550
16:17:41.279   Training iter 450, batch loss 0.1427, batch acc 0.9566
16:17:41.418   Training iter 500, batch loss 0.1551, batch acc 0.9488
16:17:41.525   Training iter 550, batch loss 0.1482, batch acc 0.9512
16:17:41.685   Training iter 600, batch loss 0.1485, batch acc 0.9530
16:17:41.687 Training @ 50 epoch...
16:17:41.800   Training iter 50, batch loss 0.1440, batch acc 0.9496
16:17:41.922   Training iter 100, batch loss 0.1481, batch acc 0.9520
16:17:42.022   Training iter 150, batch loss 0.1438, batch acc 0.9532
16:17:42.133   Training iter 200, batch loss 0.1457, batch acc 0.9552
16:17:42.241   Training iter 250, batch loss 0.1575, batch acc 0.9500
16:17:42.494   Training iter 300, batch loss 0.1388, batch acc 0.9532
16:17:42.601   Training iter 350, batch loss 0.1367, batch acc 0.9518
16:17:42.745   Training iter 400, batch loss 0.1424, batch acc 0.9530
16:17:42.853   Training iter 450, batch loss 0.1380, batch acc 0.9532
16:17:42.976   Training iter 500, batch loss 0.1444, batch acc 0.9528
16:17:43.100   Training iter 550, batch loss 0.1449, batch acc 0.9544
16:17:43.217   Training iter 600, batch loss 0.1444, batch acc 0.9528
16:17:43.217 Testing @ 50 epoch...
16:17:43.311     Testing, total mean loss 0.13838, total acc 0.95110
16:17:43.311 Training @ 51 epoch...
16:17:43.465   Training iter 50, batch loss 0.1534, batch acc 0.9508
16:17:43.556   Training iter 100, batch loss 0.1514, batch acc 0.9508
16:17:43.700   Training iter 150, batch loss 0.1408, batch acc 0.9554
16:17:43.793   Training iter 200, batch loss 0.1357, batch acc 0.9582
16:17:43.930   Training iter 250, batch loss 0.1384, batch acc 0.9556
16:17:44.032   Training iter 300, batch loss 0.1493, batch acc 0.9542
16:17:44.201   Training iter 350, batch loss 0.1422, batch acc 0.9544
16:17:44.315   Training iter 400, batch loss 0.1450, batch acc 0.9510
16:17:44.442   Training iter 450, batch loss 0.1469, batch acc 0.9502
16:17:44.613   Training iter 500, batch loss 0.1498, batch acc 0.9510
16:17:44.741   Training iter 550, batch loss 0.1449, batch acc 0.9504
16:17:44.879   Training iter 600, batch loss 0.1485, batch acc 0.9486
16:17:44.881 Training @ 52 epoch...
16:17:44.983   Training iter 50, batch loss 0.1514, batch acc 0.9498
16:17:45.094   Training iter 100, batch loss 0.1445, batch acc 0.9534
16:17:45.187   Training iter 150, batch loss 0.1407, batch acc 0.9518
16:17:45.319   Training iter 200, batch loss 0.1381, batch acc 0.9586
16:17:45.469   Training iter 250, batch loss 0.1408, batch acc 0.9544
16:17:45.584   Training iter 300, batch loss 0.1481, batch acc 0.9512
16:17:45.679   Training iter 350, batch loss 0.1371, batch acc 0.9522
16:17:45.782   Training iter 400, batch loss 0.1382, batch acc 0.9556
16:17:45.895   Training iter 450, batch loss 0.1395, batch acc 0.9560
16:17:46.008   Training iter 500, batch loss 0.1448, batch acc 0.9502
16:17:46.131   Training iter 550, batch loss 0.1395, batch acc 0.9568
16:17:46.256   Training iter 600, batch loss 0.1439, batch acc 0.9510
16:17:46.257 Training @ 53 epoch...
16:17:46.414   Training iter 50, batch loss 0.1469, batch acc 0.9518
16:17:46.579   Training iter 100, batch loss 0.1421, batch acc 0.9536
16:17:46.669   Training iter 150, batch loss 0.1420, batch acc 0.9536
16:17:46.824   Training iter 200, batch loss 0.1336, batch acc 0.9568
16:17:46.933   Training iter 250, batch loss 0.1404, batch acc 0.9546
16:17:47.025   Training iter 300, batch loss 0.1442, batch acc 0.9498
16:17:47.130   Training iter 350, batch loss 0.1468, batch acc 0.9524
16:17:47.236   Training iter 400, batch loss 0.1352, batch acc 0.9550
16:17:47.377   Training iter 450, batch loss 0.1445, batch acc 0.9514
16:17:47.469   Training iter 500, batch loss 0.1362, batch acc 0.9590
16:17:47.613   Training iter 550, batch loss 0.1366, batch acc 0.9558
16:17:47.707   Training iter 600, batch loss 0.1453, batch acc 0.9550
16:17:47.707 Training @ 54 epoch...
16:17:47.817   Training iter 50, batch loss 0.1344, batch acc 0.9570
16:17:47.977   Training iter 100, batch loss 0.1455, batch acc 0.9552
16:17:48.067   Training iter 150, batch loss 0.1551, batch acc 0.9536
16:17:48.183   Training iter 200, batch loss 0.1447, batch acc 0.9554
16:17:48.284   Training iter 250, batch loss 0.1406, batch acc 0.9522
16:17:48.402   Training iter 300, batch loss 0.1436, batch acc 0.9512
16:17:48.517   Training iter 350, batch loss 0.1476, batch acc 0.9502
16:17:48.623   Training iter 400, batch loss 0.1416, batch acc 0.9572
16:17:48.740   Training iter 450, batch loss 0.1451, batch acc 0.9518
16:17:48.840   Training iter 500, batch loss 0.1387, batch acc 0.9584
16:17:48.940   Training iter 550, batch loss 0.1432, batch acc 0.9504
16:17:49.054   Training iter 600, batch loss 0.1446, batch acc 0.9570
16:17:49.055 Training @ 55 epoch...
16:17:49.209   Training iter 50, batch loss 0.1429, batch acc 0.9516
16:17:49.301   Training iter 100, batch loss 0.1417, batch acc 0.9506
16:17:49.458   Training iter 150, batch loss 0.1375, batch acc 0.9556
16:17:49.568   Training iter 200, batch loss 0.1381, batch acc 0.9528
16:17:49.672   Training iter 250, batch loss 0.1370, batch acc 0.9566
16:17:49.779   Training iter 300, batch loss 0.1430, batch acc 0.9548
16:17:49.902   Training iter 350, batch loss 0.1455, batch acc 0.9546
16:17:50.017   Training iter 400, batch loss 0.1433, batch acc 0.9548
16:17:50.155   Training iter 450, batch loss 0.1437, batch acc 0.9536
16:17:50.278   Training iter 500, batch loss 0.1484, batch acc 0.9484
16:17:50.369   Training iter 550, batch loss 0.1369, batch acc 0.9528
16:17:50.488   Training iter 600, batch loss 0.1403, batch acc 0.9562
16:17:50.489 Testing @ 55 epoch...
16:17:50.573     Testing, total mean loss 0.14783, total acc 0.94940
16:17:50.573 Training @ 56 epoch...
16:17:50.662   Training iter 50, batch loss 0.1448, batch acc 0.9550
16:17:50.753   Training iter 100, batch loss 0.1308, batch acc 0.9604
16:17:50.846   Training iter 150, batch loss 0.1422, batch acc 0.9522
16:17:50.933   Training iter 200, batch loss 0.1490, batch acc 0.9474
16:17:51.056   Training iter 250, batch loss 0.1419, batch acc 0.9528
16:17:51.153   Training iter 300, batch loss 0.1340, batch acc 0.9548
16:17:51.269   Training iter 350, batch loss 0.1435, batch acc 0.9538
16:17:51.417   Training iter 400, batch loss 0.1416, batch acc 0.9554
16:17:51.517   Training iter 450, batch loss 0.1446, batch acc 0.9546
16:17:51.647   Training iter 500, batch loss 0.1383, batch acc 0.9526
16:17:51.754   Training iter 550, batch loss 0.1445, batch acc 0.9522
16:17:51.887   Training iter 600, batch loss 0.1503, batch acc 0.9522
16:17:51.889 Training @ 57 epoch...
16:17:52.017   Training iter 50, batch loss 0.1439, batch acc 0.9534
16:17:52.136   Training iter 100, batch loss 0.1435, batch acc 0.9510
16:17:52.228   Training iter 150, batch loss 0.1431, batch acc 0.9560
16:17:52.348   Training iter 200, batch loss 0.1372, batch acc 0.9562
16:17:52.504   Training iter 250, batch loss 0.1462, batch acc 0.9522
16:17:52.648   Training iter 300, batch loss 0.1436, batch acc 0.9532
16:17:52.797   Training iter 350, batch loss 0.1478, batch acc 0.9526
16:17:52.918   Training iter 400, batch loss 0.1434, batch acc 0.9522
16:17:53.010   Training iter 450, batch loss 0.1407, batch acc 0.9580
16:17:53.099   Training iter 500, batch loss 0.1327, batch acc 0.9588
16:17:53.210   Training iter 550, batch loss 0.1433, batch acc 0.9536
16:17:53.305   Training iter 600, batch loss 0.1412, batch acc 0.9552
16:17:53.305 Training @ 58 epoch...
16:17:53.409   Training iter 50, batch loss 0.1458, batch acc 0.9496
16:17:53.520   Training iter 100, batch loss 0.1366, batch acc 0.9554
16:17:53.636   Training iter 150, batch loss 0.1430, batch acc 0.9536
16:17:53.733   Training iter 200, batch loss 0.1451, batch acc 0.9560
16:17:53.877   Training iter 250, batch loss 0.1424, batch acc 0.9574
16:17:54.078   Training iter 300, batch loss 0.1441, batch acc 0.9552
16:17:54.225   Training iter 350, batch loss 0.1426, batch acc 0.9504
16:17:54.399   Training iter 400, batch loss 0.1376, batch acc 0.9592
16:17:54.554   Training iter 450, batch loss 0.1416, batch acc 0.9526
16:17:54.670   Training iter 500, batch loss 0.1417, batch acc 0.9558
16:17:54.835   Training iter 550, batch loss 0.1404, batch acc 0.9558
16:17:55.101   Training iter 600, batch loss 0.1414, batch acc 0.9558
16:17:55.103 Training @ 59 epoch...
16:17:55.300   Training iter 50, batch loss 0.1338, batch acc 0.9588
16:17:55.479   Training iter 100, batch loss 0.1495, batch acc 0.9518
16:17:55.669   Training iter 150, batch loss 0.1262, batch acc 0.9618
16:17:55.855   Training iter 200, batch loss 0.1473, batch acc 0.9528
16:17:55.976   Training iter 250, batch loss 0.1439, batch acc 0.9562
16:17:56.167   Training iter 300, batch loss 0.1415, batch acc 0.9530
16:17:56.417   Training iter 350, batch loss 0.1395, batch acc 0.9564
16:17:56.547   Training iter 400, batch loss 0.1479, batch acc 0.9470
16:17:56.681   Training iter 450, batch loss 0.1538, batch acc 0.9502
16:17:56.819   Training iter 500, batch loss 0.1393, batch acc 0.9552
16:17:56.969   Training iter 550, batch loss 0.1344, batch acc 0.9558
16:17:57.113   Training iter 600, batch loss 0.1374, batch acc 0.9556
16:17:57.114 Training @ 60 epoch...
16:17:57.237   Training iter 50, batch loss 0.1371, batch acc 0.9564
16:17:57.366   Training iter 100, batch loss 0.1393, batch acc 0.9530
16:17:57.510   Training iter 150, batch loss 0.1384, batch acc 0.9548
16:17:57.648   Training iter 200, batch loss 0.1454, batch acc 0.9534
16:17:57.802   Training iter 250, batch loss 0.1409, batch acc 0.9564
16:17:58.001   Training iter 300, batch loss 0.1374, batch acc 0.9586
16:17:58.177   Training iter 350, batch loss 0.1442, batch acc 0.9560
16:17:58.385   Training iter 400, batch loss 0.1420, batch acc 0.9520
16:17:58.548   Training iter 450, batch loss 0.1438, batch acc 0.9558
16:17:58.720   Training iter 500, batch loss 0.1383, batch acc 0.9582
16:17:58.879   Training iter 550, batch loss 0.1475, batch acc 0.9542
16:17:59.010   Training iter 600, batch loss 0.1326, batch acc 0.9594
16:17:59.013 Testing @ 60 epoch...
16:17:59.120     Testing, total mean loss 0.14726, total acc 0.95150
16:17:59.120 Training @ 61 epoch...
16:17:59.281   Training iter 50, batch loss 0.1409, batch acc 0.9562
16:17:59.413   Training iter 100, batch loss 0.1460, batch acc 0.9528
16:17:59.554   Training iter 150, batch loss 0.1365, batch acc 0.9544
16:17:59.689   Training iter 200, batch loss 0.1450, batch acc 0.9546
16:17:59.831   Training iter 250, batch loss 0.1365, batch acc 0.9568
16:17:59.978   Training iter 300, batch loss 0.1348, batch acc 0.9588
16:18:00.146   Training iter 350, batch loss 0.1414, batch acc 0.9562
16:18:00.279   Training iter 400, batch loss 0.1405, batch acc 0.9546
16:18:00.428   Training iter 450, batch loss 0.1488, batch acc 0.9498
16:18:00.541   Training iter 500, batch loss 0.1502, batch acc 0.9516
16:18:00.664   Training iter 550, batch loss 0.1372, batch acc 0.9580
16:18:00.781   Training iter 600, batch loss 0.1374, batch acc 0.9542
16:18:00.782 Training @ 62 epoch...
16:18:00.897   Training iter 50, batch loss 0.1380, batch acc 0.9596
16:18:01.020   Training iter 100, batch loss 0.1345, batch acc 0.9554
16:18:01.149   Training iter 150, batch loss 0.1448, batch acc 0.9540
16:18:01.267   Training iter 200, batch loss 0.1467, batch acc 0.9496
16:18:01.382   Training iter 250, batch loss 0.1473, batch acc 0.9530
16:18:01.500   Training iter 300, batch loss 0.1328, batch acc 0.9588
16:18:01.603   Training iter 350, batch loss 0.1432, batch acc 0.9546
16:18:01.729   Training iter 400, batch loss 0.1380, batch acc 0.9574
16:18:01.850   Training iter 450, batch loss 0.1348, batch acc 0.9582
16:18:01.978   Training iter 500, batch loss 0.1470, batch acc 0.9534
16:18:02.105   Training iter 550, batch loss 0.1417, batch acc 0.9568
16:18:02.231   Training iter 600, batch loss 0.1450, batch acc 0.9514
16:18:02.231 Training @ 63 epoch...
16:18:02.378   Training iter 50, batch loss 0.1445, batch acc 0.9492
16:18:02.542   Training iter 100, batch loss 0.1413, batch acc 0.9592
16:18:02.693   Training iter 150, batch loss 0.1471, batch acc 0.9522
16:18:02.855   Training iter 200, batch loss 0.1469, batch acc 0.9516
16:18:03.010   Training iter 250, batch loss 0.1392, batch acc 0.9554
16:18:03.185   Training iter 300, batch loss 0.1391, batch acc 0.9578
16:18:03.311   Training iter 350, batch loss 0.1321, batch acc 0.9616
16:18:03.425   Training iter 400, batch loss 0.1407, batch acc 0.9548
16:18:03.592   Training iter 450, batch loss 0.1357, batch acc 0.9552
16:18:03.713   Training iter 500, batch loss 0.1390, batch acc 0.9570
16:18:03.841   Training iter 550, batch loss 0.1357, batch acc 0.9592
16:18:03.963   Training iter 600, batch loss 0.1365, batch acc 0.9596
16:18:03.963 Training @ 64 epoch...
16:18:04.087   Training iter 50, batch loss 0.1365, batch acc 0.9604
16:18:04.215   Training iter 100, batch loss 0.1340, batch acc 0.9574
16:18:04.334   Training iter 150, batch loss 0.1369, batch acc 0.9530
16:18:04.449   Training iter 200, batch loss 0.1441, batch acc 0.9504
16:18:04.575   Training iter 250, batch loss 0.1399, batch acc 0.9522
16:18:04.701   Training iter 300, batch loss 0.1383, batch acc 0.9554
16:18:04.811   Training iter 350, batch loss 0.1371, batch acc 0.9628
16:18:04.934   Training iter 400, batch loss 0.1437, batch acc 0.9544
16:18:05.061   Training iter 450, batch loss 0.1403, batch acc 0.9560
16:18:05.194   Training iter 500, batch loss 0.1478, batch acc 0.9520
16:18:05.352   Training iter 550, batch loss 0.1388, batch acc 0.9550
16:18:05.478   Training iter 600, batch loss 0.1431, batch acc 0.9580
16:18:05.479 Training @ 65 epoch...
16:18:05.610   Training iter 50, batch loss 0.1289, batch acc 0.9580
16:18:05.742   Training iter 100, batch loss 0.1453, batch acc 0.9530
16:18:05.882   Training iter 150, batch loss 0.1409, batch acc 0.9570
16:18:06.015   Training iter 200, batch loss 0.1401, batch acc 0.9544
16:18:06.161   Training iter 250, batch loss 0.1400, batch acc 0.9574
16:18:06.309   Training iter 300, batch loss 0.1422, batch acc 0.9566
16:18:06.425   Training iter 350, batch loss 0.1399, batch acc 0.9546
16:18:06.546   Training iter 400, batch loss 0.1383, batch acc 0.9558
16:18:06.663   Training iter 450, batch loss 0.1393, batch acc 0.9576
16:18:06.786   Training iter 500, batch loss 0.1487, batch acc 0.9512
16:18:06.918   Training iter 550, batch loss 0.1474, batch acc 0.9528
16:18:07.040   Training iter 600, batch loss 0.1435, batch acc 0.9528
16:18:07.042 Testing @ 65 epoch...
16:18:07.119     Testing, total mean loss 0.16136, total acc 0.95300
16:18:07.120 Training @ 66 epoch...
16:18:07.276   Training iter 50, batch loss 0.1509, batch acc 0.9516
16:18:07.429   Training iter 100, batch loss 0.1388, batch acc 0.9524
16:18:07.595   Training iter 150, batch loss 0.1443, batch acc 0.9546
16:18:07.802   Training iter 200, batch loss 0.1411, batch acc 0.9568
16:18:07.985   Training iter 250, batch loss 0.1433, batch acc 0.9538
16:18:08.115   Training iter 300, batch loss 0.1401, batch acc 0.9548
16:18:08.246   Training iter 350, batch loss 0.1393, batch acc 0.9550
16:18:08.391   Training iter 400, batch loss 0.1421, batch acc 0.9548
16:18:08.553   Training iter 450, batch loss 0.1415, batch acc 0.9534
16:18:08.687   Training iter 500, batch loss 0.1354, batch acc 0.9576
16:18:08.830   Training iter 550, batch loss 0.1390, batch acc 0.9576
16:18:08.999   Training iter 600, batch loss 0.1375, batch acc 0.9576
16:18:09.001 Training @ 67 epoch...
16:18:09.152   Training iter 50, batch loss 0.1394, batch acc 0.9544
16:18:09.276   Training iter 100, batch loss 0.1403, batch acc 0.9524
16:18:09.378   Training iter 150, batch loss 0.1437, batch acc 0.9554
16:18:09.493   Training iter 200, batch loss 0.1384, batch acc 0.9578
16:18:09.609   Training iter 250, batch loss 0.1302, batch acc 0.9644
16:18:09.730   Training iter 300, batch loss 0.1364, batch acc 0.9582
16:18:09.843   Training iter 350, batch loss 0.1411, batch acc 0.9568
16:18:09.963   Training iter 400, batch loss 0.1454, batch acc 0.9526
16:18:10.082   Training iter 450, batch loss 0.1343, batch acc 0.9592
16:18:10.210   Training iter 500, batch loss 0.1373, batch acc 0.9554
16:18:10.497   Training iter 550, batch loss 0.1395, batch acc 0.9534
16:18:10.874   Training iter 600, batch loss 0.1395, batch acc 0.9580
16:18:10.874 Training @ 68 epoch...
16:18:11.035   Training iter 50, batch loss 0.1400, batch acc 0.9584
16:18:11.209   Training iter 100, batch loss 0.1339, batch acc 0.9582
16:18:11.353   Training iter 150, batch loss 0.1472, batch acc 0.9568
16:18:11.483   Training iter 200, batch loss 0.1452, batch acc 0.9530
16:18:11.618   Training iter 250, batch loss 0.1378, batch acc 0.9580
16:18:11.730   Training iter 300, batch loss 0.1453, batch acc 0.9580
16:18:11.898   Training iter 350, batch loss 0.1427, batch acc 0.9556
16:18:12.478   Training iter 400, batch loss 0.1443, batch acc 0.9510
16:18:12.658   Training iter 450, batch loss 0.1345, batch acc 0.9622
16:18:12.822   Training iter 500, batch loss 0.1391, batch acc 0.9606
16:18:13.000   Training iter 550, batch loss 0.1402, batch acc 0.9506
16:18:13.195   Training iter 600, batch loss 0.1366, batch acc 0.9558
16:18:13.196 Training @ 69 epoch...
16:18:13.318   Training iter 50, batch loss 0.1326, batch acc 0.9556
16:18:13.520   Training iter 100, batch loss 0.1355, batch acc 0.9586
16:18:13.638   Training iter 150, batch loss 0.1358, batch acc 0.9596
16:18:13.772   Training iter 200, batch loss 0.1509, batch acc 0.9532
16:18:13.945   Training iter 250, batch loss 0.1379, batch acc 0.9588
16:18:14.165   Training iter 300, batch loss 0.1369, batch acc 0.9598
16:18:14.349   Training iter 350, batch loss 0.1482, batch acc 0.9534
16:18:14.495   Training iter 400, batch loss 0.1421, batch acc 0.9530
16:18:14.655   Training iter 450, batch loss 0.1392, batch acc 0.9566
16:18:14.863   Training iter 500, batch loss 0.1407, batch acc 0.9568
16:18:15.083   Training iter 550, batch loss 0.1372, batch acc 0.9558
16:18:15.209   Training iter 600, batch loss 0.1332, batch acc 0.9552
16:18:15.210 Training @ 70 epoch...
16:18:15.382   Training iter 50, batch loss 0.1385, batch acc 0.9566
16:18:15.553   Training iter 100, batch loss 0.1310, batch acc 0.9638
16:18:15.679   Training iter 150, batch loss 0.1364, batch acc 0.9600
16:18:15.845   Training iter 200, batch loss 0.1346, batch acc 0.9530
16:18:16.009   Training iter 250, batch loss 0.1374, batch acc 0.9588
16:18:16.169   Training iter 300, batch loss 0.1418, batch acc 0.9546
16:18:16.427   Training iter 350, batch loss 0.1325, batch acc 0.9582
16:18:16.605   Training iter 400, batch loss 0.1413, batch acc 0.9566
16:18:16.797   Training iter 450, batch loss 0.1319, batch acc 0.9604
16:18:16.928   Training iter 500, batch loss 0.1362, batch acc 0.9548
16:18:17.059   Training iter 550, batch loss 0.1393, batch acc 0.9532
16:18:17.203   Training iter 600, batch loss 0.1568, batch acc 0.9558
16:18:17.204 Testing @ 70 epoch...
16:18:17.326     Testing, total mean loss 0.15270, total acc 0.95020
16:18:17.326 Training @ 71 epoch...
16:18:17.444   Training iter 50, batch loss 0.1447, batch acc 0.9548
16:18:17.617   Training iter 100, batch loss 0.1349, batch acc 0.9596
16:18:17.775   Training iter 150, batch loss 0.1410, batch acc 0.9552
16:18:17.967   Training iter 200, batch loss 0.1440, batch acc 0.9566
16:18:18.142   Training iter 250, batch loss 0.1400, batch acc 0.9526
16:18:18.285   Training iter 300, batch loss 0.1388, batch acc 0.9600
16:18:18.420   Training iter 350, batch loss 0.1433, batch acc 0.9546
16:18:18.536   Training iter 400, batch loss 0.1377, batch acc 0.9564
16:18:18.655   Training iter 450, batch loss 0.1365, batch acc 0.9580
16:18:18.778   Training iter 500, batch loss 0.1489, batch acc 0.9542
16:18:18.903   Training iter 550, batch loss 0.1432, batch acc 0.9544
16:18:19.031   Training iter 600, batch loss 0.1419, batch acc 0.9578
16:18:19.031 Training @ 72 epoch...
16:18:19.168   Training iter 50, batch loss 0.1454, batch acc 0.9572
16:18:19.288   Training iter 100, batch loss 0.1344, batch acc 0.9584
16:18:19.404   Training iter 150, batch loss 0.1377, batch acc 0.9610
16:18:19.552   Training iter 200, batch loss 0.1417, batch acc 0.9574
16:18:19.663   Training iter 250, batch loss 0.1331, batch acc 0.9614
16:18:19.815   Training iter 300, batch loss 0.1446, batch acc 0.9512
16:18:19.951   Training iter 350, batch loss 0.1333, batch acc 0.9586
16:18:20.094   Training iter 400, batch loss 0.1458, batch acc 0.9548
16:18:20.237   Training iter 450, batch loss 0.1353, batch acc 0.9586
16:18:20.381   Training iter 500, batch loss 0.1409, batch acc 0.9554
16:18:20.501   Training iter 550, batch loss 0.1404, batch acc 0.9506
16:18:20.619   Training iter 600, batch loss 0.1446, batch acc 0.9534
16:18:20.619 Training @ 73 epoch...
16:18:20.748   Training iter 50, batch loss 0.1292, batch acc 0.9622
16:18:20.967   Training iter 100, batch loss 0.1390, batch acc 0.9572
16:18:21.072   Training iter 150, batch loss 0.1373, batch acc 0.9570
16:18:21.202   Training iter 200, batch loss 0.1440, batch acc 0.9572
16:18:21.314   Training iter 250, batch loss 0.1462, batch acc 0.9542
16:18:21.449   Training iter 300, batch loss 0.1386, batch acc 0.9560
16:18:21.574   Training iter 350, batch loss 0.1360, batch acc 0.9574
16:18:21.695   Training iter 400, batch loss 0.1333, batch acc 0.9582
16:18:21.825   Training iter 450, batch loss 0.1336, batch acc 0.9568
16:18:21.940   Training iter 500, batch loss 0.1474, batch acc 0.9524
16:18:22.055   Training iter 550, batch loss 0.1377, batch acc 0.9542
16:18:22.178   Training iter 600, batch loss 0.1344, batch acc 0.9614
16:18:22.178 Training @ 74 epoch...
16:18:22.314   Training iter 50, batch loss 0.1361, batch acc 0.9570
16:18:22.464   Training iter 100, batch loss 0.1420, batch acc 0.9574
16:18:22.615   Training iter 150, batch loss 0.1418, batch acc 0.9528
16:18:22.739   Training iter 200, batch loss 0.1387, batch acc 0.9550
16:18:22.876   Training iter 250, batch loss 0.1319, batch acc 0.9616
16:18:23.034   Training iter 300, batch loss 0.1372, batch acc 0.9586
16:18:23.183   Training iter 350, batch loss 0.1434, batch acc 0.9588
16:18:23.324   Training iter 400, batch loss 0.1372, batch acc 0.9578
16:18:23.437   Training iter 450, batch loss 0.1426, batch acc 0.9560
16:18:23.554   Training iter 500, batch loss 0.1342, batch acc 0.9610
16:18:23.666   Training iter 550, batch loss 0.1313, batch acc 0.9578
16:18:23.792   Training iter 600, batch loss 0.1390, batch acc 0.9568
16:18:23.794 Training @ 75 epoch...
16:18:23.919   Training iter 50, batch loss 0.1438, batch acc 0.9548
16:18:24.050   Training iter 100, batch loss 0.1407, batch acc 0.9558
16:18:24.177   Training iter 150, batch loss 0.1423, batch acc 0.9568
16:18:24.287   Training iter 200, batch loss 0.1406, batch acc 0.9592
16:18:24.424   Training iter 250, batch loss 0.1372, batch acc 0.9568
16:18:24.559   Training iter 300, batch loss 0.1365, batch acc 0.9540
16:18:24.680   Training iter 350, batch loss 0.1375, batch acc 0.9592
16:18:24.792   Training iter 400, batch loss 0.1367, batch acc 0.9524
16:18:24.976   Training iter 450, batch loss 0.1429, batch acc 0.9540
16:18:25.097   Training iter 500, batch loss 0.1437, batch acc 0.9582
16:18:25.230   Training iter 550, batch loss 0.1425, batch acc 0.9580
16:18:25.364   Training iter 600, batch loss 0.1374, batch acc 0.9574
16:18:25.365 Testing @ 75 epoch...
16:18:25.495     Testing, total mean loss 0.13747, total acc 0.95330
16:18:25.495 Training @ 76 epoch...
16:18:25.642   Training iter 50, batch loss 0.1411, batch acc 0.9528
16:18:25.789   Training iter 100, batch loss 0.1373, batch acc 0.9556
16:18:25.932   Training iter 150, batch loss 0.1363, batch acc 0.9548
16:18:26.099   Training iter 200, batch loss 0.1378, batch acc 0.9596
16:18:26.215   Training iter 250, batch loss 0.1311, batch acc 0.9592
16:18:26.337   Training iter 300, batch loss 0.1350, batch acc 0.9596
16:18:26.440   Training iter 350, batch loss 0.1337, batch acc 0.9566
16:18:26.555   Training iter 400, batch loss 0.1377, batch acc 0.9584
16:18:26.678   Training iter 450, batch loss 0.1407, batch acc 0.9586
16:18:26.800   Training iter 500, batch loss 0.1384, batch acc 0.9572
16:18:26.936   Training iter 550, batch loss 0.1395, batch acc 0.9554
16:18:27.062   Training iter 600, batch loss 0.1459, batch acc 0.9588
16:18:27.063 Training @ 77 epoch...
16:18:27.226   Training iter 50, batch loss 0.1398, batch acc 0.9610
16:18:27.313   Training iter 100, batch loss 0.1327, batch acc 0.9600
16:18:27.423   Training iter 150, batch loss 0.1480, batch acc 0.9516
16:18:27.550   Training iter 200, batch loss 0.1388, batch acc 0.9568
16:18:27.670   Training iter 250, batch loss 0.1395, batch acc 0.9566
16:18:27.781   Training iter 300, batch loss 0.1413, batch acc 0.9556
16:18:27.915   Training iter 350, batch loss 0.1366, batch acc 0.9580
16:18:28.030   Training iter 400, batch loss 0.1451, batch acc 0.9566
16:18:28.157   Training iter 450, batch loss 0.1385, batch acc 0.9584
16:18:28.276   Training iter 500, batch loss 0.1410, batch acc 0.9576
16:18:28.403   Training iter 550, batch loss 0.1406, batch acc 0.9578
16:18:28.543   Training iter 600, batch loss 0.1370, batch acc 0.9542
16:18:28.544 Training @ 78 epoch...
16:18:28.684   Training iter 50, batch loss 0.1397, batch acc 0.9566
16:18:28.802   Training iter 100, batch loss 0.1324, batch acc 0.9590
16:18:28.953   Training iter 150, batch loss 0.1368, batch acc 0.9536
16:18:29.097   Training iter 200, batch loss 0.1360, batch acc 0.9574
16:18:29.210   Training iter 250, batch loss 0.1460, batch acc 0.9568
16:18:29.344   Training iter 300, batch loss 0.1375, batch acc 0.9596
16:18:29.461   Training iter 350, batch loss 0.1392, batch acc 0.9564
16:18:29.576   Training iter 400, batch loss 0.1370, batch acc 0.9546
16:18:29.699   Training iter 450, batch loss 0.1322, batch acc 0.9626
16:18:29.832   Training iter 500, batch loss 0.1329, batch acc 0.9602
16:18:29.958   Training iter 550, batch loss 0.1387, batch acc 0.9564
16:18:30.098   Training iter 600, batch loss 0.1454, batch acc 0.9520
16:18:30.098 Training @ 79 epoch...
16:18:30.216   Training iter 50, batch loss 0.1344, batch acc 0.9578
16:18:30.360   Training iter 100, batch loss 0.1273, batch acc 0.9662
16:18:30.470   Training iter 150, batch loss 0.1377, batch acc 0.9538
16:18:30.593   Training iter 200, batch loss 0.1374, batch acc 0.9588
16:18:30.709   Training iter 250, batch loss 0.1358, batch acc 0.9612
16:18:30.837   Training iter 300, batch loss 0.1415, batch acc 0.9548
16:18:30.970   Training iter 350, batch loss 0.1304, batch acc 0.9618
16:18:31.097   Training iter 400, batch loss 0.1332, batch acc 0.9590
16:18:31.230   Training iter 450, batch loss 0.1460, batch acc 0.9558
16:18:31.389   Training iter 500, batch loss 0.1366, batch acc 0.9586
16:18:31.672   Training iter 550, batch loss 0.1462, batch acc 0.9552
16:18:31.834   Training iter 600, batch loss 0.1416, batch acc 0.9564
16:18:31.834 Training @ 80 epoch...
16:18:31.986   Training iter 50, batch loss 0.1430, batch acc 0.9574
16:18:32.142   Training iter 100, batch loss 0.1372, batch acc 0.9600
16:18:32.280   Training iter 150, batch loss 0.1379, batch acc 0.9562
16:18:32.408   Training iter 200, batch loss 0.1361, batch acc 0.9590
16:18:32.525   Training iter 250, batch loss 0.1300, batch acc 0.9648
16:18:32.687   Training iter 300, batch loss 0.1364, batch acc 0.9532
16:18:32.811   Training iter 350, batch loss 0.1376, batch acc 0.9588
16:18:32.949   Training iter 400, batch loss 0.1387, batch acc 0.9574
16:18:33.114   Training iter 450, batch loss 0.1415, batch acc 0.9554
16:18:33.240   Training iter 500, batch loss 0.1363, batch acc 0.9586
16:18:33.358   Training iter 550, batch loss 0.1362, batch acc 0.9562
16:18:33.468   Training iter 600, batch loss 0.1424, batch acc 0.9534
16:18:33.468 Testing @ 80 epoch...
16:18:33.553     Testing, total mean loss 0.14130, total acc 0.95360
16:18:33.553 Training @ 81 epoch...
16:18:33.682   Training iter 50, batch loss 0.1339, batch acc 0.9554
16:18:33.817   Training iter 100, batch loss 0.1424, batch acc 0.9548
16:18:33.985   Training iter 150, batch loss 0.1300, batch acc 0.9582
16:18:34.131   Training iter 200, batch loss 0.1379, batch acc 0.9606
16:18:34.280   Training iter 250, batch loss 0.1306, batch acc 0.9596
16:18:34.403   Training iter 300, batch loss 0.1326, batch acc 0.9660
16:18:34.537   Training iter 350, batch loss 0.1452, batch acc 0.9576
16:18:34.690   Training iter 400, batch loss 0.1368, batch acc 0.9560
16:18:34.851   Training iter 450, batch loss 0.1396, batch acc 0.9542
16:18:34.979   Training iter 500, batch loss 0.1442, batch acc 0.9556
16:18:35.087   Training iter 550, batch loss 0.1465, batch acc 0.9552
16:18:35.243   Training iter 600, batch loss 0.1415, batch acc 0.9602
16:18:35.244 Training @ 82 epoch...
16:18:35.380   Training iter 50, batch loss 0.1408, batch acc 0.9554
16:18:35.538   Training iter 100, batch loss 0.1401, batch acc 0.9612
16:18:35.664   Training iter 150, batch loss 0.1298, batch acc 0.9664
16:18:35.819   Training iter 200, batch loss 0.1396, batch acc 0.9546
16:18:35.960   Training iter 250, batch loss 0.1372, batch acc 0.9578
16:18:36.083   Training iter 300, batch loss 0.1459, batch acc 0.9548
16:18:36.204   Training iter 350, batch loss 0.1440, batch acc 0.9546
16:18:36.336   Training iter 400, batch loss 0.1407, batch acc 0.9552
16:18:36.453   Training iter 450, batch loss 0.1428, batch acc 0.9596
16:18:36.573   Training iter 500, batch loss 0.1338, batch acc 0.9574
16:18:36.789   Training iter 550, batch loss 0.1368, batch acc 0.9590
16:18:36.950   Training iter 600, batch loss 0.1542, batch acc 0.9504
16:18:36.951 Training @ 83 epoch...
16:18:37.101   Training iter 50, batch loss 0.1425, batch acc 0.9572
16:18:37.254   Training iter 100, batch loss 0.1394, batch acc 0.9576
16:18:37.420   Training iter 150, batch loss 0.1384, batch acc 0.9550
16:18:37.598   Training iter 200, batch loss 0.1362, batch acc 0.9574
16:18:37.806   Training iter 250, batch loss 0.1341, batch acc 0.9574
16:18:37.960   Training iter 300, batch loss 0.1359, batch acc 0.9592
16:18:38.102   Training iter 350, batch loss 0.1465, batch acc 0.9550
16:18:38.287   Training iter 400, batch loss 0.1462, batch acc 0.9562
16:18:38.547   Training iter 450, batch loss 0.1317, batch acc 0.9574
16:18:38.669   Training iter 500, batch loss 0.1375, batch acc 0.9618
16:18:38.789   Training iter 550, batch loss 0.1349, batch acc 0.9554
16:18:38.905   Training iter 600, batch loss 0.1359, batch acc 0.9596
16:18:38.905 Training @ 84 epoch...
16:18:39.045   Training iter 50, batch loss 0.1351, batch acc 0.9570
16:18:39.170   Training iter 100, batch loss 0.1412, batch acc 0.9588
16:18:39.306   Training iter 150, batch loss 0.1305, batch acc 0.9634
16:18:39.420   Training iter 200, batch loss 0.1352, batch acc 0.9618
16:18:39.549   Training iter 250, batch loss 0.1378, batch acc 0.9566
16:18:39.664   Training iter 300, batch loss 0.1345, batch acc 0.9614
16:18:39.818   Training iter 350, batch loss 0.1345, batch acc 0.9584
16:18:39.953   Training iter 400, batch loss 0.1338, batch acc 0.9624
16:18:40.094   Training iter 450, batch loss 0.1362, batch acc 0.9550
16:18:40.234   Training iter 500, batch loss 0.1320, batch acc 0.9610
16:18:40.367   Training iter 550, batch loss 0.1395, batch acc 0.9568
16:18:40.499   Training iter 600, batch loss 0.1374, batch acc 0.9560
16:18:40.501 Training @ 85 epoch...
16:18:40.661   Training iter 50, batch loss 0.1309, batch acc 0.9592
16:18:40.797   Training iter 100, batch loss 0.1342, batch acc 0.9588
16:18:40.913   Training iter 150, batch loss 0.1369, batch acc 0.9634
16:18:41.030   Training iter 200, batch loss 0.1337, batch acc 0.9598
16:18:41.157   Training iter 250, batch loss 0.1344, batch acc 0.9586
16:18:41.278   Training iter 300, batch loss 0.1365, batch acc 0.9584
16:18:41.413   Training iter 350, batch loss 0.1411, batch acc 0.9560
16:18:41.530   Training iter 400, batch loss 0.1382, batch acc 0.9564
16:18:41.635   Training iter 450, batch loss 0.1401, batch acc 0.9568
16:18:41.752   Training iter 500, batch loss 0.1338, batch acc 0.9566
16:18:41.928   Training iter 550, batch loss 0.1393, batch acc 0.9560
16:18:42.063   Training iter 600, batch loss 0.1372, batch acc 0.9588
16:18:42.064 Testing @ 85 epoch...
16:18:42.146     Testing, total mean loss 0.13922, total acc 0.95390
16:18:42.146 Training @ 86 epoch...
16:18:42.267   Training iter 50, batch loss 0.1427, batch acc 0.9568
16:18:42.360   Training iter 100, batch loss 0.1353, batch acc 0.9592
16:18:42.496   Training iter 150, batch loss 0.1353, batch acc 0.9596
16:18:42.626   Training iter 200, batch loss 0.1332, batch acc 0.9566
16:18:42.779   Training iter 250, batch loss 0.1419, batch acc 0.9552
16:18:42.901   Training iter 300, batch loss 0.1405, batch acc 0.9580
16:18:43.069   Training iter 350, batch loss 0.1360, batch acc 0.9596
16:18:43.186   Training iter 400, batch loss 0.1353, batch acc 0.9608
16:18:43.367   Training iter 450, batch loss 0.1355, batch acc 0.9546
16:18:43.536   Training iter 500, batch loss 0.1357, batch acc 0.9528
16:18:43.643   Training iter 550, batch loss 0.1281, batch acc 0.9598
16:18:43.749   Training iter 600, batch loss 0.1311, batch acc 0.9590
16:18:43.750 Training @ 87 epoch...
16:18:43.863   Training iter 50, batch loss 0.1410, batch acc 0.9538
16:18:43.980   Training iter 100, batch loss 0.1378, batch acc 0.9602
16:18:44.096   Training iter 150, batch loss 0.1367, batch acc 0.9570
16:18:44.215   Training iter 200, batch loss 0.1267, batch acc 0.9616
16:18:44.323   Training iter 250, batch loss 0.1409, batch acc 0.9566
16:18:44.452   Training iter 300, batch loss 0.1417, batch acc 0.9568
16:18:44.582   Training iter 350, batch loss 0.1415, batch acc 0.9566
16:18:44.707   Training iter 400, batch loss 0.1400, batch acc 0.9540
16:18:44.817   Training iter 450, batch loss 0.1368, batch acc 0.9582
16:18:44.943   Training iter 500, batch loss 0.1325, batch acc 0.9618
16:18:45.069   Training iter 550, batch loss 0.1389, batch acc 0.9590
16:18:45.200   Training iter 600, batch loss 0.1388, batch acc 0.9564
16:18:45.201 Training @ 88 epoch...
16:18:45.329   Training iter 50, batch loss 0.1470, batch acc 0.9574
16:18:45.470   Training iter 100, batch loss 0.1415, batch acc 0.9566
16:18:45.593   Training iter 150, batch loss 0.1335, batch acc 0.9602
16:18:45.731   Training iter 200, batch loss 0.1353, batch acc 0.9554
16:18:45.866   Training iter 250, batch loss 0.1360, batch acc 0.9544
16:18:46.009   Training iter 300, batch loss 0.1355, batch acc 0.9610
16:18:46.153   Training iter 350, batch loss 0.1346, batch acc 0.9600
16:18:46.313   Training iter 400, batch loss 0.1343, batch acc 0.9590
16:18:46.460   Training iter 450, batch loss 0.1357, batch acc 0.9590
16:18:46.585   Training iter 500, batch loss 0.1340, batch acc 0.9588
16:18:46.700   Training iter 550, batch loss 0.1359, batch acc 0.9584
16:18:46.829   Training iter 600, batch loss 0.1341, batch acc 0.9606
16:18:46.830 Training @ 89 epoch...
16:18:46.958   Training iter 50, batch loss 0.1362, batch acc 0.9560
16:18:47.077   Training iter 100, batch loss 0.1336, batch acc 0.9576
16:18:47.193   Training iter 150, batch loss 0.1318, batch acc 0.9540
16:18:47.340   Training iter 200, batch loss 0.1441, batch acc 0.9572
16:18:47.464   Training iter 250, batch loss 0.1443, batch acc 0.9580
16:18:47.578   Training iter 300, batch loss 0.1398, batch acc 0.9596
16:18:47.755   Training iter 350, batch loss 0.1377, batch acc 0.9580
16:18:47.904   Training iter 400, batch loss 0.1336, batch acc 0.9558
16:18:48.006   Training iter 450, batch loss 0.1321, batch acc 0.9568
16:18:48.145   Training iter 500, batch loss 0.1320, batch acc 0.9636
16:18:48.267   Training iter 550, batch loss 0.1340, batch acc 0.9650
16:18:48.393   Training iter 600, batch loss 0.1349, batch acc 0.9588
16:18:48.394 Training @ 90 epoch...
16:18:48.531   Training iter 50, batch loss 0.1321, batch acc 0.9596
16:18:48.678   Training iter 100, batch loss 0.1290, batch acc 0.9604
16:18:48.818   Training iter 150, batch loss 0.1324, batch acc 0.9610
16:18:48.968   Training iter 200, batch loss 0.1399, batch acc 0.9610
16:18:49.090   Training iter 250, batch loss 0.1361, batch acc 0.9598
16:18:49.248   Training iter 300, batch loss 0.1434, batch acc 0.9578
16:18:49.355   Training iter 350, batch loss 0.1380, batch acc 0.9580
16:18:49.473   Training iter 400, batch loss 0.1338, batch acc 0.9610
16:18:49.582   Training iter 450, batch loss 0.1515, batch acc 0.9520
16:18:49.714   Training iter 500, batch loss 0.1411, batch acc 0.9588
16:18:49.835   Training iter 550, batch loss 0.1363, batch acc 0.9566
16:18:49.963   Training iter 600, batch loss 0.1314, batch acc 0.9612
16:18:49.963 Testing @ 90 epoch...
16:18:50.049     Testing, total mean loss 0.12847, total acc 0.95680
16:18:50.049 Training @ 91 epoch...
16:18:50.176   Training iter 50, batch loss 0.1291, batch acc 0.9624
16:18:50.301   Training iter 100, batch loss 0.1313, batch acc 0.9582
16:18:50.428   Training iter 150, batch loss 0.1373, batch acc 0.9604
16:18:50.563   Training iter 200, batch loss 0.1356, batch acc 0.9620
16:18:50.709   Training iter 250, batch loss 0.1404, batch acc 0.9580
16:18:50.847   Training iter 300, batch loss 0.1326, batch acc 0.9588
16:18:50.981   Training iter 350, batch loss 0.1502, batch acc 0.9520
16:18:51.102   Training iter 400, batch loss 0.1380, batch acc 0.9586
16:18:51.233   Training iter 450, batch loss 0.1308, batch acc 0.9588
16:18:51.376   Training iter 500, batch loss 0.1315, batch acc 0.9568
16:18:51.534   Training iter 550, batch loss 0.1368, batch acc 0.9562
16:18:51.686   Training iter 600, batch loss 0.1378, batch acc 0.9602
16:18:51.689 Training @ 92 epoch...
16:18:51.846   Training iter 50, batch loss 0.1414, batch acc 0.9536
16:18:52.009   Training iter 100, batch loss 0.1330, batch acc 0.9634
16:18:52.155   Training iter 150, batch loss 0.1259, batch acc 0.9620
16:18:52.284   Training iter 200, batch loss 0.1449, batch acc 0.9598
16:18:52.418   Training iter 250, batch loss 0.1391, batch acc 0.9580
16:18:52.547   Training iter 300, batch loss 0.1406, batch acc 0.9546
16:18:52.678   Training iter 350, batch loss 0.1264, batch acc 0.9608
16:18:52.801   Training iter 400, batch loss 0.1317, batch acc 0.9578
16:18:52.919   Training iter 450, batch loss 0.1379, batch acc 0.9626
16:18:53.047   Training iter 500, batch loss 0.1352, batch acc 0.9602
16:18:53.162   Training iter 550, batch loss 0.1298, batch acc 0.9570
16:18:53.283   Training iter 600, batch loss 0.1371, batch acc 0.9600
16:18:53.284 Training @ 93 epoch...
16:18:53.423   Training iter 50, batch loss 0.1313, batch acc 0.9632
16:18:53.543   Training iter 100, batch loss 0.1328, batch acc 0.9544
16:18:53.682   Training iter 150, batch loss 0.1392, batch acc 0.9554
16:18:53.804   Training iter 200, batch loss 0.1379, batch acc 0.9594
16:18:53.931   Training iter 250, batch loss 0.1375, batch acc 0.9578
16:18:54.074   Training iter 300, batch loss 0.1351, batch acc 0.9598
16:18:54.224   Training iter 350, batch loss 0.1389, batch acc 0.9608
16:18:54.358   Training iter 400, batch loss 0.1342, batch acc 0.9624
16:18:54.498   Training iter 450, batch loss 0.1369, batch acc 0.9548
16:18:54.627   Training iter 500, batch loss 0.1405, batch acc 0.9562
16:18:54.764   Training iter 550, batch loss 0.1347, batch acc 0.9608
16:18:54.963   Training iter 600, batch loss 0.1361, batch acc 0.9578
16:18:54.964 Training @ 94 epoch...
16:18:55.117   Training iter 50, batch loss 0.1312, batch acc 0.9594
16:18:55.241   Training iter 100, batch loss 0.1366, batch acc 0.9640
16:18:55.369   Training iter 150, batch loss 0.1363, batch acc 0.9582
16:18:55.491   Training iter 200, batch loss 0.1363, batch acc 0.9588
16:18:55.604   Training iter 250, batch loss 0.1312, batch acc 0.9626
16:18:55.787   Training iter 300, batch loss 0.1406, batch acc 0.9592
16:18:55.918   Training iter 350, batch loss 0.1339, batch acc 0.9558
16:18:56.028   Training iter 400, batch loss 0.1360, batch acc 0.9578
16:18:56.163   Training iter 450, batch loss 0.1368, batch acc 0.9620
16:18:56.288   Training iter 500, batch loss 0.1388, batch acc 0.9544
16:18:56.414   Training iter 550, batch loss 0.1308, batch acc 0.9598
16:18:56.529   Training iter 600, batch loss 0.1385, batch acc 0.9530
16:18:56.530 Training @ 95 epoch...
16:18:56.656   Training iter 50, batch loss 0.1348, batch acc 0.9596
16:18:56.779   Training iter 100, batch loss 0.1398, batch acc 0.9622
16:18:56.947   Training iter 150, batch loss 0.1374, batch acc 0.9596
16:18:57.076   Training iter 200, batch loss 0.1338, batch acc 0.9610
16:18:57.294   Training iter 250, batch loss 0.1431, batch acc 0.9584
16:18:57.430   Training iter 300, batch loss 0.1341, batch acc 0.9580
16:18:57.594   Training iter 350, batch loss 0.1376, batch acc 0.9586
16:18:57.719   Training iter 400, batch loss 0.1393, batch acc 0.9604
16:18:57.889   Training iter 450, batch loss 0.1361, batch acc 0.9564
16:18:58.012   Training iter 500, batch loss 0.1327, batch acc 0.9568
16:18:58.133   Training iter 550, batch loss 0.1361, batch acc 0.9610
16:18:58.246   Training iter 600, batch loss 0.1443, batch acc 0.9582
16:18:58.247 Testing @ 95 epoch...
16:18:58.336     Testing, total mean loss 0.13084, total acc 0.95640
16:18:58.336 Training @ 96 epoch...
16:18:58.458   Training iter 50, batch loss 0.1356, batch acc 0.9624
16:18:58.586   Training iter 100, batch loss 0.1390, batch acc 0.9536
16:18:58.702   Training iter 150, batch loss 0.1338, batch acc 0.9570
16:18:58.859   Training iter 200, batch loss 0.1378, batch acc 0.9594
16:18:58.969   Training iter 250, batch loss 0.1313, batch acc 0.9624
16:18:59.075   Training iter 300, batch loss 0.1335, batch acc 0.9584
16:18:59.188   Training iter 350, batch loss 0.1356, batch acc 0.9574
16:18:59.309   Training iter 400, batch loss 0.1383, batch acc 0.9616
16:18:59.447   Training iter 450, batch loss 0.1394, batch acc 0.9604
16:18:59.569   Training iter 500, batch loss 0.1392, batch acc 0.9562
16:18:59.688   Training iter 550, batch loss 0.1367, batch acc 0.9594
16:18:59.808   Training iter 600, batch loss 0.1385, batch acc 0.9588
16:18:59.809 Training @ 97 epoch...
16:18:59.968   Training iter 50, batch loss 0.1381, batch acc 0.9556
16:19:00.138   Training iter 100, batch loss 0.1305, batch acc 0.9622
16:19:00.262   Training iter 150, batch loss 0.1313, batch acc 0.9622
16:19:00.401   Training iter 200, batch loss 0.1296, batch acc 0.9600
16:19:00.531   Training iter 250, batch loss 0.1318, batch acc 0.9608
16:19:00.663   Training iter 300, batch loss 0.1391, batch acc 0.9566
16:19:00.787   Training iter 350, batch loss 0.1402, batch acc 0.9594
16:19:00.900   Training iter 400, batch loss 0.1390, batch acc 0.9596
16:19:01.022   Training iter 450, batch loss 0.1362, batch acc 0.9586
16:19:01.148   Training iter 500, batch loss 0.1336, batch acc 0.9578
16:19:01.359   Training iter 550, batch loss 0.1358, batch acc 0.9604
16:19:01.486   Training iter 600, batch loss 0.1320, batch acc 0.9614
16:19:01.487 Training @ 98 epoch...
16:19:01.601   Training iter 50, batch loss 0.1319, batch acc 0.9618
16:19:01.728   Training iter 100, batch loss 0.1295, batch acc 0.9594
16:19:01.856   Training iter 150, batch loss 0.1330, batch acc 0.9620
16:19:01.976   Training iter 200, batch loss 0.1346, batch acc 0.9602
16:19:02.099   Training iter 250, batch loss 0.1363, batch acc 0.9630
16:19:02.214   Training iter 300, batch loss 0.1434, batch acc 0.9536
16:19:02.339   Training iter 350, batch loss 0.1297, batch acc 0.9620
16:19:02.457   Training iter 400, batch loss 0.1433, batch acc 0.9592
16:19:02.591   Training iter 450, batch loss 0.1288, batch acc 0.9616
16:19:02.729   Training iter 500, batch loss 0.1398, batch acc 0.9544
16:19:02.869   Training iter 550, batch loss 0.1406, batch acc 0.9556
16:19:03.007   Training iter 600, batch loss 0.1340, batch acc 0.9618
16:19:03.008 Training @ 99 epoch...
16:19:03.159   Training iter 50, batch loss 0.1295, batch acc 0.9572
16:19:03.300   Training iter 100, batch loss 0.1363, batch acc 0.9582
16:19:03.431   Training iter 150, batch loss 0.1347, batch acc 0.9560
16:19:03.563   Training iter 200, batch loss 0.1416, batch acc 0.9636
16:19:03.714   Training iter 250, batch loss 0.1365, batch acc 0.9604
16:19:03.842   Training iter 300, batch loss 0.1461, batch acc 0.9580
16:19:03.961   Training iter 350, batch loss 0.1349, batch acc 0.9582
16:19:04.078   Training iter 400, batch loss 0.1405, batch acc 0.9572
16:19:04.192   Training iter 450, batch loss 0.1311, batch acc 0.9630
16:19:04.333   Training iter 500, batch loss 0.1297, batch acc 0.9628
16:19:04.453   Training iter 550, batch loss 0.1305, batch acc 0.9614
16:19:04.558   Training iter 600, batch loss 0.1432, batch acc 0.9556
16:19:04.559 Testing @ 99 epoch...
16:19:04.624     Testing, total mean loss 0.14070, total acc 0.95500