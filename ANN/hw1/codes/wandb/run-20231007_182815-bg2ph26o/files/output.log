18:28:19.484 Training @ 0 epoch...
18:28:19.748   Training iter 50, batch loss 2.2870, batch acc 0.1712
18:28:20.031   Training iter 100, batch loss 2.1156, batch acc 0.3420
18:28:20.168   Training iter 150, batch loss 1.2637, batch acc 0.6512
18:28:20.279   Training iter 200, batch loss 0.7259, batch acc 0.7956
18:28:20.379   Training iter 250, batch loss 0.5539, batch acc 0.8386
18:28:20.561   Training iter 300, batch loss 0.4394, batch acc 0.8732
18:28:20.694   Training iter 350, batch loss 0.4055, batch acc 0.8800
18:28:20.798   Training iter 400, batch loss 0.3925, batch acc 0.8870
18:28:20.922   Training iter 450, batch loss 0.4013, batch acc 0.8894
18:28:21.064   Training iter 500, batch loss 0.3905, batch acc 0.8862
18:28:21.180   Training iter 550, batch loss 0.3710, batch acc 0.8902
18:28:21.293   Training iter 600, batch loss 0.3835, batch acc 0.8912
18:28:21.294 Testing @ 0 epoch...
18:28:21.395     Testing, total mean loss 0.35749, total acc 0.89140
18:28:21.395 Training @ 1 epoch...
18:28:21.533   Training iter 50, batch loss 0.3414, batch acc 0.9024
18:28:21.672   Training iter 100, batch loss 0.3610, batch acc 0.8994
18:28:21.772   Training iter 150, batch loss 0.3460, batch acc 0.9024
18:28:21.869   Training iter 200, batch loss 0.3385, batch acc 0.9006
18:28:22.025   Training iter 250, batch loss 0.3418, batch acc 0.9036
18:28:22.182   Training iter 300, batch loss 0.3248, batch acc 0.9046
18:28:22.300   Training iter 350, batch loss 0.3125, batch acc 0.9076
18:28:22.399   Training iter 400, batch loss 0.2859, batch acc 0.9170
18:28:22.501   Training iter 450, batch loss 0.3196, batch acc 0.9088
18:28:22.624   Training iter 500, batch loss 0.3152, batch acc 0.9038
18:28:22.738   Training iter 550, batch loss 0.3139, batch acc 0.9080
18:28:22.838   Training iter 600, batch loss 0.3078, batch acc 0.9106
18:28:22.840 Training @ 2 epoch...
18:28:23.067   Training iter 50, batch loss 0.2893, batch acc 0.9162
18:28:23.258   Training iter 100, batch loss 0.2858, batch acc 0.9126
18:28:23.451   Training iter 150, batch loss 0.2717, batch acc 0.9252
18:28:23.567   Training iter 200, batch loss 0.2978, batch acc 0.9178
18:28:23.725   Training iter 250, batch loss 0.2636, batch acc 0.9266
18:28:23.947   Training iter 300, batch loss 0.2718, batch acc 0.9146
18:28:24.180   Training iter 350, batch loss 0.2931, batch acc 0.9164
18:28:24.393   Training iter 400, batch loss 0.2819, batch acc 0.9200
18:28:24.717   Training iter 450, batch loss 0.2924, batch acc 0.9162
18:28:24.877   Training iter 500, batch loss 0.2660, batch acc 0.9204
18:28:25.089   Training iter 550, batch loss 0.2473, batch acc 0.9300
18:28:25.323   Training iter 600, batch loss 0.2730, batch acc 0.9220
18:28:25.324 Training @ 3 epoch...
18:28:25.857   Training iter 50, batch loss 0.2649, batch acc 0.9212
18:28:26.357   Training iter 100, batch loss 0.2343, batch acc 0.9318
18:28:30.030   Training iter 150, batch loss 0.2448, batch acc 0.9292
18:28:31.950   Training iter 200, batch loss 0.2389, batch acc 0.9310
18:28:33.896   Training iter 250, batch loss 0.2558, batch acc 0.9264
18:28:35.813   Training iter 300, batch loss 0.2316, batch acc 0.9336
18:28:38.207   Training iter 350, batch loss 0.2253, batch acc 0.9344
18:28:40.179   Training iter 400, batch loss 0.2264, batch acc 0.9324
18:28:42.627   Training iter 450, batch loss 0.2412, batch acc 0.9270
18:28:45.153   Training iter 500, batch loss 0.2449, batch acc 0.9280
18:28:47.186   Training iter 550, batch loss 0.2357, batch acc 0.9348
18:28:49.482   Training iter 600, batch loss 0.2377, batch acc 0.9308
18:28:49.486 Training @ 4 epoch...
18:28:51.672   Training iter 50, batch loss 0.2250, batch acc 0.9334
18:28:53.801   Training iter 100, batch loss 0.2113, batch acc 0.9420
18:28:55.873   Training iter 150, batch loss 0.2236, batch acc 0.9332
18:28:56.738   Training iter 200, batch loss 0.2208, batch acc 0.9340
18:28:56.914   Training iter 250, batch loss 0.2043, batch acc 0.9380
18:28:57.083   Training iter 300, batch loss 0.2052, batch acc 0.9392
18:28:57.190   Training iter 350, batch loss 0.2234, batch acc 0.9362
18:28:57.298   Training iter 400, batch loss 0.2137, batch acc 0.9400
18:28:57.407   Training iter 450, batch loss 0.1940, batch acc 0.9470
18:28:57.504   Training iter 500, batch loss 0.1911, batch acc 0.9468
18:28:57.598   Training iter 550, batch loss 0.2072, batch acc 0.9410
18:28:57.695   Training iter 600, batch loss 0.2021, batch acc 0.9412
18:28:57.696 Training @ 5 epoch...
18:28:57.812   Training iter 50, batch loss 0.1760, batch acc 0.9506
18:28:57.900   Training iter 100, batch loss 0.1959, batch acc 0.9438
18:28:58.012   Training iter 150, batch loss 0.1982, batch acc 0.9424
18:28:58.107   Training iter 200, batch loss 0.1903, batch acc 0.9448
18:28:58.198   Training iter 250, batch loss 0.1968, batch acc 0.9386
18:28:58.294   Training iter 300, batch loss 0.2006, batch acc 0.9466
18:28:58.398   Training iter 350, batch loss 0.1801, batch acc 0.9468
18:28:58.494   Training iter 400, batch loss 0.1813, batch acc 0.9482
18:28:58.581   Training iter 450, batch loss 0.1993, batch acc 0.9414
18:28:58.682   Training iter 500, batch loss 0.1976, batch acc 0.9444
18:28:58.804   Training iter 550, batch loss 0.1801, batch acc 0.9480
18:28:58.899   Training iter 600, batch loss 0.1628, batch acc 0.9538
18:28:58.900 Testing @ 5 epoch...
18:28:58.991     Testing, total mean loss 0.17051, total acc 0.94970
18:28:58.991 Training @ 6 epoch...
18:28:59.112   Training iter 50, batch loss 0.1783, batch acc 0.9488
18:28:59.229   Training iter 100, batch loss 0.1765, batch acc 0.9482
18:28:59.349   Training iter 150, batch loss 0.1810, batch acc 0.9448
18:28:59.476   Training iter 200, batch loss 0.1690, batch acc 0.9520
18:28:59.605   Training iter 250, batch loss 0.1636, batch acc 0.9556
18:28:59.729   Training iter 300, batch loss 0.1773, batch acc 0.9528
18:28:59.884   Training iter 350, batch loss 0.1689, batch acc 0.9520
18:28:59.975   Training iter 400, batch loss 0.1812, batch acc 0.9492
18:29:00.094   Training iter 450, batch loss 0.1624, batch acc 0.9564
18:29:00.194   Training iter 500, batch loss 0.1635, batch acc 0.9512
18:29:00.290   Training iter 550, batch loss 0.1699, batch acc 0.9518
18:29:00.383   Training iter 600, batch loss 0.1698, batch acc 0.9510
18:29:00.384 Training @ 7 epoch...
18:29:00.492   Training iter 50, batch loss 0.1551, batch acc 0.9556
18:29:00.588   Training iter 100, batch loss 0.1604, batch acc 0.9520
18:29:00.690   Training iter 150, batch loss 0.1699, batch acc 0.9522
18:29:00.800   Training iter 200, batch loss 0.1644, batch acc 0.9514
18:29:00.907   Training iter 250, batch loss 0.1575, batch acc 0.9532
18:29:01.008   Training iter 300, batch loss 0.1535, batch acc 0.9560
18:29:01.141   Training iter 350, batch loss 0.1539, batch acc 0.9530
18:29:01.262   Training iter 400, batch loss 0.1610, batch acc 0.9566
18:29:01.355   Training iter 450, batch loss 0.1432, batch acc 0.9598
18:29:01.467   Training iter 500, batch loss 0.1480, batch acc 0.9578
18:29:01.563   Training iter 550, batch loss 0.1711, batch acc 0.9514
18:29:01.664   Training iter 600, batch loss 0.1464, batch acc 0.9572
18:29:01.666 Training @ 8 epoch...
18:29:01.779   Training iter 50, batch loss 0.1484, batch acc 0.9566
18:29:01.898   Training iter 100, batch loss 0.1536, batch acc 0.9554
18:29:01.999   Training iter 150, batch loss 0.1571, batch acc 0.9552
18:29:02.128   Training iter 200, batch loss 0.1321, batch acc 0.9622
18:29:02.232   Training iter 250, batch loss 0.1348, batch acc 0.9614
18:29:02.373   Training iter 300, batch loss 0.1523, batch acc 0.9604
18:29:02.502   Training iter 350, batch loss 0.1301, batch acc 0.9644
18:29:02.626   Training iter 400, batch loss 0.1422, batch acc 0.9586
18:29:02.833   Training iter 450, batch loss 0.1550, batch acc 0.9556
18:29:02.957   Training iter 500, batch loss 0.1498, batch acc 0.9580
18:29:03.048   Training iter 550, batch loss 0.1352, batch acc 0.9606
18:29:03.150   Training iter 600, batch loss 0.1372, batch acc 0.9620
18:29:03.151 Training @ 9 epoch...
18:29:03.316   Training iter 50, batch loss 0.1383, batch acc 0.9608
18:29:03.479   Training iter 100, batch loss 0.1381, batch acc 0.9598
18:29:03.585   Training iter 150, batch loss 0.1419, batch acc 0.9580
18:29:03.671   Training iter 200, batch loss 0.1426, batch acc 0.9596
18:29:03.876   Training iter 250, batch loss 0.1377, batch acc 0.9646
18:29:03.975   Training iter 300, batch loss 0.1223, batch acc 0.9658
18:29:04.062   Training iter 350, batch loss 0.1219, batch acc 0.9650
18:29:04.267   Training iter 400, batch loss 0.1303, batch acc 0.9584
18:29:04.367   Training iter 450, batch loss 0.1329, batch acc 0.9620
18:29:04.481   Training iter 500, batch loss 0.1363, batch acc 0.9612
18:29:04.609   Training iter 550, batch loss 0.1351, batch acc 0.9594
18:29:04.716   Training iter 600, batch loss 0.1338, batch acc 0.9606
18:29:04.717 Training @ 10 epoch...
18:29:04.843   Training iter 50, batch loss 0.1281, batch acc 0.9638
18:29:05.003   Training iter 100, batch loss 0.1284, batch acc 0.9636
18:29:05.133   Training iter 150, batch loss 0.1212, batch acc 0.9650
18:29:05.250   Training iter 200, batch loss 0.1345, batch acc 0.9622
18:29:05.357   Training iter 250, batch loss 0.1309, batch acc 0.9632
18:29:05.471   Training iter 300, batch loss 0.1240, batch acc 0.9616
18:29:05.617   Training iter 350, batch loss 0.1157, batch acc 0.9654
18:29:05.709   Training iter 400, batch loss 0.1264, batch acc 0.9666
18:29:05.832   Training iter 450, batch loss 0.1129, batch acc 0.9656
18:29:05.941   Training iter 500, batch loss 0.1325, batch acc 0.9614
18:29:06.036   Training iter 550, batch loss 0.1269, batch acc 0.9636
18:29:06.132   Training iter 600, batch loss 0.1321, batch acc 0.9626
18:29:06.134 Testing @ 10 epoch...
18:29:06.212     Testing, total mean loss 0.12436, total acc 0.96220
18:29:06.212 Training @ 11 epoch...
18:29:06.314   Training iter 50, batch loss 0.1204, batch acc 0.9658
18:29:06.398   Training iter 100, batch loss 0.1244, batch acc 0.9630
18:29:06.509   Training iter 150, batch loss 0.1072, batch acc 0.9714
18:29:06.625   Training iter 200, batch loss 0.1193, batch acc 0.9662
18:29:06.787   Training iter 250, batch loss 0.1177, batch acc 0.9642
18:29:06.937   Training iter 300, batch loss 0.1298, batch acc 0.9634
18:29:07.046   Training iter 350, batch loss 0.1214, batch acc 0.9678
18:29:07.158   Training iter 400, batch loss 0.1128, batch acc 0.9672
18:29:07.298   Training iter 450, batch loss 0.1208, batch acc 0.9646
18:29:07.388   Training iter 500, batch loss 0.1172, batch acc 0.9670
18:29:07.565   Training iter 550, batch loss 0.1175, batch acc 0.9680
18:29:07.757   Training iter 600, batch loss 0.1231, batch acc 0.9644
18:29:07.759 Training @ 12 epoch...
18:29:07.866   Training iter 50, batch loss 0.1097, batch acc 0.9706
18:29:08.015   Training iter 100, batch loss 0.1128, batch acc 0.9648
18:29:08.173   Training iter 150, batch loss 0.1230, batch acc 0.9646
18:29:08.329   Training iter 200, batch loss 0.1162, batch acc 0.9684
18:29:08.474   Training iter 250, batch loss 0.1100, batch acc 0.9716
18:29:08.668   Training iter 300, batch loss 0.1238, batch acc 0.9646
18:29:08.810   Training iter 350, batch loss 0.1051, batch acc 0.9708
18:29:08.915   Training iter 400, batch loss 0.1114, batch acc 0.9702
18:29:09.059   Training iter 450, batch loss 0.1153, batch acc 0.9694
18:29:09.189   Training iter 500, batch loss 0.1128, batch acc 0.9676
18:29:09.283   Training iter 550, batch loss 0.1115, batch acc 0.9672
18:29:09.398   Training iter 600, batch loss 0.1101, batch acc 0.9696
18:29:09.399 Training @ 13 epoch...
18:29:09.482   Training iter 50, batch loss 0.1038, batch acc 0.9702
18:29:09.615   Training iter 100, batch loss 0.1058, batch acc 0.9720
18:29:09.778   Training iter 150, batch loss 0.1160, batch acc 0.9682
18:29:09.887   Training iter 200, batch loss 0.1150, batch acc 0.9662
18:29:10.031   Training iter 250, batch loss 0.1120, batch acc 0.9670
18:29:10.181   Training iter 300, batch loss 0.1122, batch acc 0.9688
18:29:10.327   Training iter 350, batch loss 0.1040, batch acc 0.9708
18:29:10.469   Training iter 400, batch loss 0.0968, batch acc 0.9726
18:29:10.599   Training iter 450, batch loss 0.1047, batch acc 0.9708
18:29:10.892   Training iter 500, batch loss 0.0990, batch acc 0.9746
18:29:11.025   Training iter 550, batch loss 0.1109, batch acc 0.9662
18:29:11.284   Training iter 600, batch loss 0.1095, batch acc 0.9664
18:29:11.285 Training @ 14 epoch...
18:29:11.447   Training iter 50, batch loss 0.0982, batch acc 0.9716
18:29:11.647   Training iter 100, batch loss 0.0945, batch acc 0.9722
18:29:11.815   Training iter 150, batch loss 0.1051, batch acc 0.9716
18:29:11.915   Training iter 200, batch loss 0.1099, batch acc 0.9686
18:29:12.015   Training iter 250, batch loss 0.1046, batch acc 0.9702
18:29:12.143   Training iter 300, batch loss 0.1016, batch acc 0.9692
18:29:12.274   Training iter 350, batch loss 0.1045, batch acc 0.9698
18:29:12.400   Training iter 400, batch loss 0.1031, batch acc 0.9698
18:29:12.493   Training iter 450, batch loss 0.1134, batch acc 0.9668
18:29:12.593   Training iter 500, batch loss 0.0986, batch acc 0.9722
18:29:12.686   Training iter 550, batch loss 0.0975, batch acc 0.9718
18:29:12.827   Training iter 600, batch loss 0.0987, batch acc 0.9732
18:29:12.831 Training @ 15 epoch...
18:29:12.990   Training iter 50, batch loss 0.0980, batch acc 0.9690
18:29:13.132   Training iter 100, batch loss 0.0939, batch acc 0.9710
18:29:13.268   Training iter 150, batch loss 0.0944, batch acc 0.9714
18:29:13.407   Training iter 200, batch loss 0.1029, batch acc 0.9712
18:29:13.554   Training iter 250, batch loss 0.1020, batch acc 0.9710
18:29:13.700   Training iter 300, batch loss 0.1024, batch acc 0.9724
18:29:13.843   Training iter 350, batch loss 0.0868, batch acc 0.9760
18:29:13.997   Training iter 400, batch loss 0.0890, batch acc 0.9736
18:29:14.145   Training iter 450, batch loss 0.1034, batch acc 0.9696
18:29:14.271   Training iter 500, batch loss 0.0992, batch acc 0.9734
18:29:14.405   Training iter 550, batch loss 0.1160, batch acc 0.9682
18:29:14.527   Training iter 600, batch loss 0.0918, batch acc 0.9748
18:29:14.527 Testing @ 15 epoch...
18:29:14.615     Testing, total mean loss 0.10363, total acc 0.96950
18:29:14.615 Training @ 16 epoch...
18:29:14.728   Training iter 50, batch loss 0.1005, batch acc 0.9700
18:29:14.829   Training iter 100, batch loss 0.0943, batch acc 0.9704
18:29:14.920   Training iter 150, batch loss 0.0906, batch acc 0.9762
18:29:15.059   Training iter 200, batch loss 0.1003, batch acc 0.9714
18:29:15.306   Training iter 250, batch loss 0.0974, batch acc 0.9738
18:29:15.447   Training iter 300, batch loss 0.0947, batch acc 0.9730
18:29:15.549   Training iter 350, batch loss 0.0917, batch acc 0.9714
18:29:15.634   Training iter 400, batch loss 0.0853, batch acc 0.9768
18:29:15.793   Training iter 450, batch loss 0.0965, batch acc 0.9752
18:29:16.151   Training iter 500, batch loss 0.1007, batch acc 0.9716
18:29:16.497   Training iter 550, batch loss 0.1010, batch acc 0.9714
18:29:16.797   Training iter 600, batch loss 0.0916, batch acc 0.9758
18:29:16.797 Training @ 17 epoch...
18:29:17.044   Training iter 50, batch loss 0.0958, batch acc 0.9710
18:29:17.466   Training iter 100, batch loss 0.0885, batch acc 0.9748
18:29:17.645   Training iter 150, batch loss 0.0899, batch acc 0.9764
18:29:17.852   Training iter 200, batch loss 0.0866, batch acc 0.9756
18:29:18.126   Training iter 250, batch loss 0.0939, batch acc 0.9726
18:29:18.328   Training iter 300, batch loss 0.0935, batch acc 0.9726
18:29:18.515   Training iter 350, batch loss 0.0964, batch acc 0.9722
18:29:18.664   Training iter 400, batch loss 0.0936, batch acc 0.9734
18:29:18.815   Training iter 450, batch loss 0.0909, batch acc 0.9732
18:29:18.947   Training iter 500, batch loss 0.0958, batch acc 0.9736
18:29:19.077   Training iter 550, batch loss 0.0934, batch acc 0.9738
18:29:19.232   Training iter 600, batch loss 0.0904, batch acc 0.9744
18:29:19.233 Training @ 18 epoch...
18:29:19.381   Training iter 50, batch loss 0.0789, batch acc 0.9782
18:29:19.546   Training iter 100, batch loss 0.0776, batch acc 0.9784
18:29:19.728   Training iter 150, batch loss 0.0876, batch acc 0.9748
18:29:19.865   Training iter 200, batch loss 0.0803, batch acc 0.9778
18:29:20.044   Training iter 250, batch loss 0.0883, batch acc 0.9734
18:29:20.160   Training iter 300, batch loss 0.0912, batch acc 0.9714
18:29:20.293   Training iter 350, batch loss 0.0940, batch acc 0.9736
18:29:20.409   Training iter 400, batch loss 0.0980, batch acc 0.9712
18:29:20.526   Training iter 450, batch loss 0.0892, batch acc 0.9772
18:29:20.652   Training iter 500, batch loss 0.0922, batch acc 0.9734
18:29:20.797   Training iter 550, batch loss 0.0991, batch acc 0.9716
18:29:20.942   Training iter 600, batch loss 0.0847, batch acc 0.9780
18:29:20.943 Training @ 19 epoch...
18:29:21.068   Training iter 50, batch loss 0.0895, batch acc 0.9764
18:29:21.252   Training iter 100, batch loss 0.0814, batch acc 0.9782
18:29:21.391   Training iter 150, batch loss 0.0884, batch acc 0.9742
18:29:21.529   Training iter 200, batch loss 0.0814, batch acc 0.9780
18:29:21.658   Training iter 250, batch loss 0.0818, batch acc 0.9772
18:29:21.794   Training iter 300, batch loss 0.0929, batch acc 0.9736
18:29:21.941   Training iter 350, batch loss 0.0868, batch acc 0.9740
18:29:22.084   Training iter 400, batch loss 0.0815, batch acc 0.9768
18:29:22.223   Training iter 450, batch loss 0.0854, batch acc 0.9752
18:29:22.368   Training iter 500, batch loss 0.0888, batch acc 0.9726
18:29:22.531   Training iter 550, batch loss 0.0867, batch acc 0.9766
18:29:22.682   Training iter 600, batch loss 0.0866, batch acc 0.9762
18:29:22.682 Training @ 20 epoch...
18:29:22.863   Training iter 50, batch loss 0.0809, batch acc 0.9764
18:29:22.996   Training iter 100, batch loss 0.0886, batch acc 0.9736
18:29:23.147   Training iter 150, batch loss 0.0843, batch acc 0.9768
18:29:23.379   Training iter 200, batch loss 0.0870, batch acc 0.9768
18:29:23.562   Training iter 250, batch loss 0.0831, batch acc 0.9760
18:29:23.779   Training iter 300, batch loss 0.0779, batch acc 0.9780
18:29:24.023   Training iter 350, batch loss 0.0762, batch acc 0.9774
18:29:24.198   Training iter 400, batch loss 0.0811, batch acc 0.9772
18:29:24.385   Training iter 450, batch loss 0.0865, batch acc 0.9744
18:29:24.580   Training iter 500, batch loss 0.0891, batch acc 0.9740
18:29:24.771   Training iter 550, batch loss 0.0820, batch acc 0.9772
18:29:24.969   Training iter 600, batch loss 0.0879, batch acc 0.9740
18:29:24.970 Testing @ 20 epoch...
18:29:25.085     Testing, total mean loss 0.09582, total acc 0.97150
18:29:25.085 Training @ 21 epoch...
18:29:25.261   Training iter 50, batch loss 0.0860, batch acc 0.9756
18:29:25.417   Training iter 100, batch loss 0.0703, batch acc 0.9804
18:29:25.725   Training iter 150, batch loss 0.0822, batch acc 0.9764
18:29:25.927   Training iter 200, batch loss 0.0829, batch acc 0.9784
18:29:26.095   Training iter 250, batch loss 0.0844, batch acc 0.9774
18:29:26.264   Training iter 300, batch loss 0.0724, batch acc 0.9786
18:29:26.464   Training iter 350, batch loss 0.0800, batch acc 0.9786
18:29:26.575   Training iter 400, batch loss 0.0797, batch acc 0.9792
18:29:26.737   Training iter 450, batch loss 0.0804, batch acc 0.9770
18:29:26.932   Training iter 500, batch loss 0.0888, batch acc 0.9750
18:29:27.115   Training iter 550, batch loss 0.0787, batch acc 0.9782
18:29:27.296   Training iter 600, batch loss 0.0837, batch acc 0.9764
18:29:27.298 Training @ 22 epoch...
18:29:27.631   Training iter 50, batch loss 0.0834, batch acc 0.9768
18:29:27.833   Training iter 100, batch loss 0.0900, batch acc 0.9752
18:29:28.011   Training iter 150, batch loss 0.0806, batch acc 0.9764
18:29:28.235   Training iter 200, batch loss 0.0826, batch acc 0.9778
18:29:28.461   Training iter 250, batch loss 0.0679, batch acc 0.9816
18:29:28.659   Training iter 300, batch loss 0.0700, batch acc 0.9812
18:29:28.785   Training iter 350, batch loss 0.0802, batch acc 0.9768
18:29:28.930   Training iter 400, batch loss 0.0812, batch acc 0.9782
18:29:29.098   Training iter 450, batch loss 0.0823, batch acc 0.9762
18:29:29.385   Training iter 500, batch loss 0.0778, batch acc 0.9762
18:29:29.655   Training iter 550, batch loss 0.0809, batch acc 0.9782
18:29:29.849   Training iter 600, batch loss 0.0815, batch acc 0.9770
18:29:29.850 Training @ 23 epoch...
18:29:29.979   Training iter 50, batch loss 0.0818, batch acc 0.9778
18:29:30.112   Training iter 100, batch loss 0.0788, batch acc 0.9780
18:29:30.252   Training iter 150, batch loss 0.0792, batch acc 0.9770
18:29:30.379   Training iter 200, batch loss 0.0777, batch acc 0.9770
18:29:30.490   Training iter 250, batch loss 0.0642, batch acc 0.9832
18:29:30.645   Training iter 300, batch loss 0.0757, batch acc 0.9802
18:29:30.794   Training iter 350, batch loss 0.0811, batch acc 0.9774
18:29:31.043   Training iter 400, batch loss 0.0748, batch acc 0.9776
18:29:31.249   Training iter 450, batch loss 0.0766, batch acc 0.9766
18:29:31.445   Training iter 500, batch loss 0.0767, batch acc 0.9772
18:29:31.699   Training iter 550, batch loss 0.0794, batch acc 0.9766
18:29:31.877   Training iter 600, batch loss 0.0809, batch acc 0.9766
18:29:31.877 Training @ 24 epoch...
18:29:32.047   Training iter 50, batch loss 0.0713, batch acc 0.9784
18:29:32.308   Training iter 100, batch loss 0.0806, batch acc 0.9792
18:29:32.533   Training iter 150, batch loss 0.0783, batch acc 0.9784
18:29:32.717   Training iter 200, batch loss 0.0769, batch acc 0.9768
18:29:32.885   Training iter 250, batch loss 0.0797, batch acc 0.9798
18:29:33.060   Training iter 300, batch loss 0.0802, batch acc 0.9780
18:29:33.231   Training iter 350, batch loss 0.0771, batch acc 0.9802
18:29:33.385   Training iter 400, batch loss 0.0726, batch acc 0.9790
18:29:33.678   Training iter 450, batch loss 0.0629, batch acc 0.9834
18:29:33.941   Training iter 500, batch loss 0.0830, batch acc 0.9748
18:29:34.144   Training iter 550, batch loss 0.0763, batch acc 0.9756
18:29:34.331   Training iter 600, batch loss 0.0647, batch acc 0.9818
18:29:34.333 Training @ 25 epoch...
18:29:34.509   Training iter 50, batch loss 0.0812, batch acc 0.9774
18:29:34.644   Training iter 100, batch loss 0.0760, batch acc 0.9804
18:29:34.779   Training iter 150, batch loss 0.0720, batch acc 0.9816
18:29:34.964   Training iter 200, batch loss 0.0688, batch acc 0.9798
18:29:35.085   Training iter 250, batch loss 0.0746, batch acc 0.9798
18:29:35.172   Training iter 300, batch loss 0.0727, batch acc 0.9818
18:29:35.268   Training iter 350, batch loss 0.0732, batch acc 0.9796
18:29:35.385   Training iter 400, batch loss 0.0655, batch acc 0.9798
18:29:35.494   Training iter 450, batch loss 0.0805, batch acc 0.9770
18:29:35.605   Training iter 500, batch loss 0.0690, batch acc 0.9798
18:29:35.691   Training iter 550, batch loss 0.0754, batch acc 0.9784
18:29:35.803   Training iter 600, batch loss 0.0753, batch acc 0.9796
18:29:35.804 Testing @ 25 epoch...
18:29:35.903     Testing, total mean loss 0.09077, total acc 0.97400
18:29:35.903 Training @ 26 epoch...
18:29:36.000   Training iter 50, batch loss 0.0630, batch acc 0.9812
18:29:36.116   Training iter 100, batch loss 0.0674, batch acc 0.9820
18:29:36.208   Training iter 150, batch loss 0.0767, batch acc 0.9784
18:29:36.313   Training iter 200, batch loss 0.0666, batch acc 0.9808
18:29:36.407   Training iter 250, batch loss 0.0730, batch acc 0.9804
18:29:36.519   Training iter 300, batch loss 0.0671, batch acc 0.9820
18:29:36.637   Training iter 350, batch loss 0.0786, batch acc 0.9788
18:29:36.765   Training iter 400, batch loss 0.0743, batch acc 0.9808
18:29:36.874   Training iter 450, batch loss 0.0720, batch acc 0.9796
18:29:37.015   Training iter 500, batch loss 0.0755, batch acc 0.9768
18:29:37.172   Training iter 550, batch loss 0.0781, batch acc 0.9776
18:29:37.433   Training iter 600, batch loss 0.0738, batch acc 0.9788
18:29:37.435 Training @ 27 epoch...
18:29:37.631   Training iter 50, batch loss 0.0633, batch acc 0.9814
18:29:37.873   Training iter 100, batch loss 0.0698, batch acc 0.9806
18:29:38.082   Training iter 150, batch loss 0.0803, batch acc 0.9796
18:29:38.262   Training iter 200, batch loss 0.0708, batch acc 0.9812
18:29:38.428   Training iter 250, batch loss 0.0767, batch acc 0.9776
18:29:38.560   Training iter 300, batch loss 0.0678, batch acc 0.9800
18:29:38.693   Training iter 350, batch loss 0.0628, batch acc 0.9832
18:29:38.832   Training iter 400, batch loss 0.0716, batch acc 0.9794
18:29:38.968   Training iter 450, batch loss 0.0671, batch acc 0.9816
18:29:39.104   Training iter 500, batch loss 0.0688, batch acc 0.9818
18:29:39.282   Training iter 550, batch loss 0.0736, batch acc 0.9774
18:29:39.474   Training iter 600, batch loss 0.0784, batch acc 0.9776
18:29:39.476 Training @ 28 epoch...
18:29:39.664   Training iter 50, batch loss 0.0565, batch acc 0.9876
18:29:39.853   Training iter 100, batch loss 0.0676, batch acc 0.9790
18:29:40.009   Training iter 150, batch loss 0.0711, batch acc 0.9804
18:29:40.180   Training iter 200, batch loss 0.0747, batch acc 0.9786
18:29:40.318   Training iter 250, batch loss 0.0652, batch acc 0.9834
18:29:40.485   Training iter 300, batch loss 0.0711, batch acc 0.9790
18:29:40.629   Training iter 350, batch loss 0.0779, batch acc 0.9796
18:29:40.817   Training iter 400, batch loss 0.0702, batch acc 0.9798
18:29:41.000   Training iter 450, batch loss 0.0713, batch acc 0.9818
18:29:41.144   Training iter 500, batch loss 0.0679, batch acc 0.9812
18:29:41.282   Training iter 550, batch loss 0.0663, batch acc 0.9820
18:29:41.424   Training iter 600, batch loss 0.0721, batch acc 0.9782
18:29:41.425 Training @ 29 epoch...
18:29:41.552   Training iter 50, batch loss 0.0680, batch acc 0.9814
18:29:41.800   Training iter 100, batch loss 0.0683, batch acc 0.9832
18:29:42.012   Training iter 150, batch loss 0.0657, batch acc 0.9832
18:29:42.147   Training iter 200, batch loss 0.0730, batch acc 0.9798
18:29:42.327   Training iter 250, batch loss 0.0670, batch acc 0.9816
18:29:42.493   Training iter 300, batch loss 0.0692, batch acc 0.9792
18:29:42.649   Training iter 350, batch loss 0.0700, batch acc 0.9818
18:29:42.825   Training iter 400, batch loss 0.0683, batch acc 0.9804
18:29:42.997   Training iter 450, batch loss 0.0647, batch acc 0.9844
18:29:43.181   Training iter 500, batch loss 0.0673, batch acc 0.9804
18:29:43.325   Training iter 550, batch loss 0.0619, batch acc 0.9822
18:29:43.446   Training iter 600, batch loss 0.0756, batch acc 0.9810
18:29:43.447 Training @ 30 epoch...
18:29:43.917   Training iter 50, batch loss 0.0734, batch acc 0.9818
18:29:44.135   Training iter 100, batch loss 0.0717, batch acc 0.9816
18:29:44.285   Training iter 150, batch loss 0.0581, batch acc 0.9844
18:29:44.429   Training iter 200, batch loss 0.0677, batch acc 0.9846
18:29:44.563   Training iter 250, batch loss 0.0641, batch acc 0.9824
18:29:44.766   Training iter 300, batch loss 0.0658, batch acc 0.9808
18:29:44.967   Training iter 350, batch loss 0.0733, batch acc 0.9792
18:29:45.178   Training iter 400, batch loss 0.0667, batch acc 0.9816
18:29:45.416   Training iter 450, batch loss 0.0676, batch acc 0.9822
18:29:45.814   Training iter 500, batch loss 0.0792, batch acc 0.9772
18:29:46.226   Training iter 550, batch loss 0.0643, batch acc 0.9808
18:29:46.495   Training iter 600, batch loss 0.0675, batch acc 0.9820
18:29:46.498 Testing @ 30 epoch...
18:29:46.700     Testing, total mean loss 0.08934, total acc 0.97250
18:29:46.700 Training @ 31 epoch...
18:29:46.978   Training iter 50, batch loss 0.0636, batch acc 0.9818
18:29:47.184   Training iter 100, batch loss 0.0638, batch acc 0.9824
18:29:47.342   Training iter 150, batch loss 0.0717, batch acc 0.9792
18:29:47.462   Training iter 200, batch loss 0.0659, batch acc 0.9828
18:29:47.606   Training iter 250, batch loss 0.0585, batch acc 0.9858
18:29:47.757   Training iter 300, batch loss 0.0682, batch acc 0.9812
18:29:47.925   Training iter 350, batch loss 0.0564, batch acc 0.9848
18:29:48.081   Training iter 400, batch loss 0.0677, batch acc 0.9824
18:29:48.229   Training iter 450, batch loss 0.0617, batch acc 0.9832
18:29:48.380   Training iter 500, batch loss 0.0740, batch acc 0.9792
18:29:48.525   Training iter 550, batch loss 0.0730, batch acc 0.9788
18:29:48.741   Training iter 600, batch loss 0.0727, batch acc 0.9802
18:29:48.741 Training @ 32 epoch...
18:29:48.962   Training iter 50, batch loss 0.0582, batch acc 0.9866
18:29:49.117   Training iter 100, batch loss 0.0776, batch acc 0.9778
18:29:49.274   Training iter 150, batch loss 0.0687, batch acc 0.9806
18:29:49.428   Training iter 200, batch loss 0.0596, batch acc 0.9852
18:29:49.747   Training iter 250, batch loss 0.0646, batch acc 0.9840
18:29:49.902   Training iter 300, batch loss 0.0634, batch acc 0.9816
18:29:50.029   Training iter 350, batch loss 0.0636, batch acc 0.9818
18:29:50.183   Training iter 400, batch loss 0.0629, batch acc 0.9826
18:29:50.464   Training iter 450, batch loss 0.0642, batch acc 0.9834
18:29:50.601   Training iter 500, batch loss 0.0621, batch acc 0.9826
18:29:50.750   Training iter 550, batch loss 0.0720, batch acc 0.9784
18:29:50.913   Training iter 600, batch loss 0.0703, batch acc 0.9820
18:29:50.915 Training @ 33 epoch...
18:29:51.066   Training iter 50, batch loss 0.0624, batch acc 0.9846
18:29:51.215   Training iter 100, batch loss 0.0706, batch acc 0.9786
18:29:51.349   Training iter 150, batch loss 0.0660, batch acc 0.9810
18:29:51.514   Training iter 200, batch loss 0.0660, batch acc 0.9810
18:29:51.818   Training iter 250, batch loss 0.0669, batch acc 0.9826
18:29:52.001   Training iter 300, batch loss 0.0693, batch acc 0.9812
18:29:52.132   Training iter 350, batch loss 0.0648, batch acc 0.9812
18:29:52.301   Training iter 400, batch loss 0.0672, batch acc 0.9802
18:29:52.515   Training iter 450, batch loss 0.0657, batch acc 0.9812
18:29:52.697   Training iter 500, batch loss 0.0544, batch acc 0.9872
18:29:52.888   Training iter 550, batch loss 0.0653, batch acc 0.9806
18:29:53.271   Training iter 600, batch loss 0.0612, batch acc 0.9838
18:29:53.274 Training @ 34 epoch...
18:29:53.962   Training iter 50, batch loss 0.0590, batch acc 0.9862
18:29:54.766   Training iter 100, batch loss 0.0581, batch acc 0.9842
18:29:55.645   Training iter 150, batch loss 0.0609, batch acc 0.9830
18:29:56.399   Training iter 200, batch loss 0.0721, batch acc 0.9804
18:29:57.349   Training iter 250, batch loss 0.0719, batch acc 0.9778
18:29:58.710   Training iter 300, batch loss 0.0623, batch acc 0.9814
18:29:59.308   Training iter 350, batch loss 0.0616, batch acc 0.9820
18:30:00.421   Training iter 400, batch loss 0.0597, batch acc 0.9830
18:30:01.524   Training iter 450, batch loss 0.0616, batch acc 0.9838
18:30:02.072   Training iter 500, batch loss 0.0729, batch acc 0.9800
18:30:02.635   Training iter 550, batch loss 0.0635, batch acc 0.9842
18:30:02.961   Training iter 600, batch loss 0.0647, batch acc 0.9826
18:30:02.961 Training @ 35 epoch...
18:30:03.125   Training iter 50, batch loss 0.0539, batch acc 0.9860
18:30:03.349   Training iter 100, batch loss 0.0616, batch acc 0.9834
18:30:03.681   Training iter 150, batch loss 0.0643, batch acc 0.9836
18:30:03.911   Training iter 200, batch loss 0.0550, batch acc 0.9852
18:30:04.092   Training iter 250, batch loss 0.0603, batch acc 0.9844
18:30:04.298   Training iter 300, batch loss 0.0589, batch acc 0.9848
18:30:04.455   Training iter 350, batch loss 0.0635, batch acc 0.9850
18:30:04.628   Training iter 400, batch loss 0.0654, batch acc 0.9812
18:30:04.761   Training iter 450, batch loss 0.0605, batch acc 0.9838
18:30:04.965   Training iter 500, batch loss 0.0738, batch acc 0.9794
18:30:05.131   Training iter 550, batch loss 0.0708, batch acc 0.9816
18:30:05.548   Training iter 600, batch loss 0.0594, batch acc 0.9864
18:30:05.549 Testing @ 35 epoch...
18:30:05.722     Testing, total mean loss 0.08326, total acc 0.97530
18:30:05.722 Training @ 36 epoch...
18:30:05.980   Training iter 50, batch loss 0.0656, batch acc 0.9810
18:30:06.163   Training iter 100, batch loss 0.0531, batch acc 0.9872
18:30:06.329   Training iter 150, batch loss 0.0597, batch acc 0.9818
18:30:06.515   Training iter 200, batch loss 0.0582, batch acc 0.9858
18:30:06.867   Training iter 250, batch loss 0.0663, batch acc 0.9832
18:30:07.078   Training iter 300, batch loss 0.0635, batch acc 0.9824
18:30:07.250   Training iter 350, batch loss 0.0614, batch acc 0.9826
18:30:07.445   Training iter 400, batch loss 0.0586, batch acc 0.9858
18:30:07.626   Training iter 450, batch loss 0.0600, batch acc 0.9840
18:30:07.824   Training iter 500, batch loss 0.0630, batch acc 0.9836
18:30:07.947   Training iter 550, batch loss 0.0699, batch acc 0.9788
18:30:08.115   Training iter 600, batch loss 0.0635, batch acc 0.9826
18:30:08.115 Training @ 37 epoch...
18:30:08.299   Training iter 50, batch loss 0.0551, batch acc 0.9852
18:30:08.629   Training iter 100, batch loss 0.0629, batch acc 0.9808
18:30:08.843   Training iter 150, batch loss 0.0641, batch acc 0.9816
18:30:09.014   Training iter 200, batch loss 0.0520, batch acc 0.9870
18:30:09.217   Training iter 250, batch loss 0.0593, batch acc 0.9808
18:30:09.407   Training iter 300, batch loss 0.0615, batch acc 0.9832
18:30:09.607   Training iter 350, batch loss 0.0670, batch acc 0.9820
18:30:09.776   Training iter 400, batch loss 0.0596, batch acc 0.9830
18:30:09.899   Training iter 450, batch loss 0.0707, batch acc 0.9820
18:30:10.249   Training iter 500, batch loss 0.0622, batch acc 0.9846
18:30:10.498   Training iter 550, batch loss 0.0625, batch acc 0.9838
18:30:10.679   Training iter 600, batch loss 0.0547, batch acc 0.9860
18:30:10.679 Training @ 38 epoch...
18:30:10.897   Training iter 50, batch loss 0.0550, batch acc 0.9840
18:30:11.068   Training iter 100, batch loss 0.0580, batch acc 0.9852
18:30:11.333   Training iter 150, batch loss 0.0542, batch acc 0.9862
18:30:11.597   Training iter 200, batch loss 0.0704, batch acc 0.9806
18:30:11.783   Training iter 250, batch loss 0.0544, batch acc 0.9864
18:30:11.942   Training iter 300, batch loss 0.0675, batch acc 0.9810
18:30:12.092   Training iter 350, batch loss 0.0568, batch acc 0.9854
18:30:12.265   Training iter 400, batch loss 0.0639, batch acc 0.9828
18:30:12.692   Training iter 450, batch loss 0.0608, batch acc 0.9832
18:30:13.080   Training iter 500, batch loss 0.0607, batch acc 0.9842
18:30:13.366   Training iter 550, batch loss 0.0661, batch acc 0.9814
18:30:13.548   Training iter 600, batch loss 0.0596, batch acc 0.9836
18:30:13.549 Training @ 39 epoch...
18:30:13.818   Training iter 50, batch loss 0.0588, batch acc 0.9836
18:30:14.115   Training iter 100, batch loss 0.0556, batch acc 0.9856
18:30:14.300   Training iter 150, batch loss 0.0619, batch acc 0.9848
18:30:14.445   Training iter 200, batch loss 0.0617, batch acc 0.9830
18:30:14.614   Training iter 250, batch loss 0.0661, batch acc 0.9828
18:30:14.761   Training iter 300, batch loss 0.0569, batch acc 0.9850
18:30:14.898   Training iter 350, batch loss 0.0537, batch acc 0.9872
18:30:15.036   Training iter 400, batch loss 0.0654, batch acc 0.9806
18:30:15.198   Training iter 450, batch loss 0.0592, batch acc 0.9840
18:30:15.376   Training iter 500, batch loss 0.0613, batch acc 0.9844
18:30:15.514   Training iter 550, batch loss 0.0553, batch acc 0.9838
18:30:15.650   Training iter 600, batch loss 0.0620, batch acc 0.9832
18:30:15.650 Training @ 40 epoch...
18:30:15.792   Training iter 50, batch loss 0.0660, batch acc 0.9810
18:30:15.934   Training iter 100, batch loss 0.0567, batch acc 0.9862
18:30:16.160   Training iter 150, batch loss 0.0567, batch acc 0.9852
18:30:16.351   Training iter 200, batch loss 0.0663, batch acc 0.9830
18:30:16.546   Training iter 250, batch loss 0.0529, batch acc 0.9872
18:30:16.700   Training iter 300, batch loss 0.0584, batch acc 0.9838
18:30:16.851   Training iter 350, batch loss 0.0609, batch acc 0.9832
18:30:17.001   Training iter 400, batch loss 0.0592, batch acc 0.9852
18:30:17.158   Training iter 450, batch loss 0.0575, batch acc 0.9834
18:30:17.344   Training iter 500, batch loss 0.0625, batch acc 0.9844
18:30:17.534   Training iter 550, batch loss 0.0566, batch acc 0.9858
18:30:17.677   Training iter 600, batch loss 0.0536, batch acc 0.9858
18:30:17.678 Testing @ 40 epoch...
18:30:17.817     Testing, total mean loss 0.08119, total acc 0.97510
18:30:17.818 Training @ 41 epoch...
18:30:17.963   Training iter 50, batch loss 0.0563, batch acc 0.9856
18:30:18.122   Training iter 100, batch loss 0.0556, batch acc 0.9854
18:30:18.313   Training iter 150, batch loss 0.0552, batch acc 0.9864
18:30:18.451   Training iter 200, batch loss 0.0616, batch acc 0.9836
18:30:18.597   Training iter 250, batch loss 0.0562, batch acc 0.9858
18:30:18.741   Training iter 300, batch loss 0.0625, batch acc 0.9850
18:30:18.877   Training iter 350, batch loss 0.0706, batch acc 0.9830
18:30:19.133   Training iter 400, batch loss 0.0658, batch acc 0.9834
18:30:19.290   Training iter 450, batch loss 0.0528, batch acc 0.9856
18:30:19.413   Training iter 500, batch loss 0.0545, batch acc 0.9858
18:30:19.646   Training iter 550, batch loss 0.0574, batch acc 0.9840
18:30:19.791   Training iter 600, batch loss 0.0539, batch acc 0.9858
18:30:19.792 Training @ 42 epoch...
18:30:19.946   Training iter 50, batch loss 0.0597, batch acc 0.9846
18:30:20.080   Training iter 100, batch loss 0.0583, batch acc 0.9844
18:30:20.298   Training iter 150, batch loss 0.0589, batch acc 0.9844
18:30:20.530   Training iter 200, batch loss 0.0559, batch acc 0.9844
18:30:20.685   Training iter 250, batch loss 0.0599, batch acc 0.9842
18:30:20.862   Training iter 300, batch loss 0.0563, batch acc 0.9850
18:30:21.066   Training iter 350, batch loss 0.0563, batch acc 0.9854
18:30:21.230   Training iter 400, batch loss 0.0741, batch acc 0.9800
18:30:21.385   Training iter 450, batch loss 0.0543, batch acc 0.9864
18:30:21.541   Training iter 500, batch loss 0.0495, batch acc 0.9876
18:30:21.676   Training iter 550, batch loss 0.0586, batch acc 0.9848
18:30:21.910   Training iter 600, batch loss 0.0583, batch acc 0.9830
18:30:21.912 Training @ 43 epoch...
18:30:22.049   Training iter 50, batch loss 0.0566, batch acc 0.9850
18:30:22.203   Training iter 100, batch loss 0.0525, batch acc 0.9872
18:30:22.330   Training iter 150, batch loss 0.0577, batch acc 0.9840
18:30:22.466   Training iter 200, batch loss 0.0573, batch acc 0.9850
18:30:22.602   Training iter 250, batch loss 0.0474, batch acc 0.9888
18:30:22.762   Training iter 300, batch loss 0.0606, batch acc 0.9846
18:30:22.896   Training iter 350, batch loss 0.0585, batch acc 0.9840
18:30:23.131   Training iter 400, batch loss 0.0605, batch acc 0.9826
18:30:23.317   Training iter 450, batch loss 0.0644, batch acc 0.9802
18:30:23.512   Training iter 500, batch loss 0.0605, batch acc 0.9844
18:30:23.683   Training iter 550, batch loss 0.0562, batch acc 0.9868
18:30:23.849   Training iter 600, batch loss 0.0615, batch acc 0.9830
18:30:23.850 Training @ 44 epoch...
18:30:24.043   Training iter 50, batch loss 0.0581, batch acc 0.9848
18:30:24.183   Training iter 100, batch loss 0.0569, batch acc 0.9848
18:30:24.330   Training iter 150, batch loss 0.0605, batch acc 0.9852
18:30:24.477   Training iter 200, batch loss 0.0608, batch acc 0.9830
18:30:24.598   Training iter 250, batch loss 0.0537, batch acc 0.9860
18:30:24.731   Training iter 300, batch loss 0.0579, batch acc 0.9836
18:30:24.880   Training iter 350, batch loss 0.0511, batch acc 0.9870
18:30:25.010   Training iter 400, batch loss 0.0468, batch acc 0.9890
18:30:25.131   Training iter 450, batch loss 0.0674, batch acc 0.9814
18:30:25.267   Training iter 500, batch loss 0.0580, batch acc 0.9852
18:30:25.429   Training iter 550, batch loss 0.0603, batch acc 0.9830
18:30:25.566   Training iter 600, batch loss 0.0532, batch acc 0.9876
18:30:25.567 Training @ 45 epoch...
18:30:25.762   Training iter 50, batch loss 0.0573, batch acc 0.9846
18:30:25.935   Training iter 100, batch loss 0.0636, batch acc 0.9822
18:30:26.099   Training iter 150, batch loss 0.0489, batch acc 0.9882
18:30:26.273   Training iter 200, batch loss 0.0580, batch acc 0.9846
18:30:26.417   Training iter 250, batch loss 0.0537, batch acc 0.9866
18:30:26.562   Training iter 300, batch loss 0.0524, batch acc 0.9860
18:30:26.714   Training iter 350, batch loss 0.0497, batch acc 0.9876
18:30:26.924   Training iter 400, batch loss 0.0619, batch acc 0.9854
18:30:27.064   Training iter 450, batch loss 0.0559, batch acc 0.9842
18:30:27.196   Training iter 500, batch loss 0.0633, batch acc 0.9850
18:30:27.328   Training iter 550, batch loss 0.0580, batch acc 0.9850
18:30:27.450   Training iter 600, batch loss 0.0550, batch acc 0.9862
18:30:27.450 Testing @ 45 epoch...
18:30:27.564     Testing, total mean loss 0.08431, total acc 0.97520
18:30:27.565 Training @ 46 epoch...
18:30:27.869   Training iter 50, batch loss 0.0522, batch acc 0.9880
18:30:28.000   Training iter 100, batch loss 0.0573, batch acc 0.9834
18:30:28.129   Training iter 150, batch loss 0.0584, batch acc 0.9824
18:30:28.269   Training iter 200, batch loss 0.0529, batch acc 0.9860
18:30:28.427   Training iter 250, batch loss 0.0608, batch acc 0.9824
18:30:28.610   Training iter 300, batch loss 0.0565, batch acc 0.9840
18:30:28.775   Training iter 350, batch loss 0.0574, batch acc 0.9848
18:30:28.951   Training iter 400, batch loss 0.0532, batch acc 0.9862
18:30:29.097   Training iter 450, batch loss 0.0599, batch acc 0.9854
18:30:29.445   Training iter 500, batch loss 0.0605, batch acc 0.9836
18:30:29.615   Training iter 550, batch loss 0.0570, batch acc 0.9844
18:30:29.868   Training iter 600, batch loss 0.0507, batch acc 0.9850
18:30:29.868 Training @ 47 epoch...
18:30:30.101   Training iter 50, batch loss 0.0596, batch acc 0.9842
18:30:30.317   Training iter 100, batch loss 0.0511, batch acc 0.9856
18:30:30.514   Training iter 150, batch loss 0.0532, batch acc 0.9854
18:30:30.669   Training iter 200, batch loss 0.0589, batch acc 0.9866
18:30:30.826   Training iter 250, batch loss 0.0566, batch acc 0.9852
18:30:30.960   Training iter 300, batch loss 0.0512, batch acc 0.9860
18:30:31.130   Training iter 350, batch loss 0.0555, batch acc 0.9852
18:30:31.318   Training iter 400, batch loss 0.0576, batch acc 0.9870
18:30:31.509   Training iter 450, batch loss 0.0607, batch acc 0.9838
18:30:31.649   Training iter 500, batch loss 0.0548, batch acc 0.9848
18:30:31.802   Training iter 550, batch loss 0.0591, batch acc 0.9834
18:30:31.975   Training iter 600, batch loss 0.0548, batch acc 0.9852
18:30:31.976 Training @ 48 epoch...
18:30:32.143   Training iter 50, batch loss 0.0566, batch acc 0.9846
18:30:32.308   Training iter 100, batch loss 0.0490, batch acc 0.9886
18:30:32.501   Training iter 150, batch loss 0.0615, batch acc 0.9824
18:30:32.697   Training iter 200, batch loss 0.0547, batch acc 0.9856
18:30:32.960   Training iter 250, batch loss 0.0478, batch acc 0.9896
18:30:33.117   Training iter 300, batch loss 0.0558, batch acc 0.9852
18:30:33.259   Training iter 350, batch loss 0.0530, batch acc 0.9876
18:30:33.376   Training iter 400, batch loss 0.0511, batch acc 0.9876
18:30:33.498   Training iter 450, batch loss 0.0589, batch acc 0.9852
18:30:33.635   Training iter 500, batch loss 0.0623, batch acc 0.9834
18:30:33.781   Training iter 550, batch loss 0.0561, batch acc 0.9848
18:30:33.915   Training iter 600, batch loss 0.0570, batch acc 0.9836
18:30:33.916 Training @ 49 epoch...
18:30:34.149   Training iter 50, batch loss 0.0532, batch acc 0.9882
18:30:34.366   Training iter 100, batch loss 0.0535, batch acc 0.9862
18:30:34.552   Training iter 150, batch loss 0.0569, batch acc 0.9856
18:30:34.669   Training iter 200, batch loss 0.0570, batch acc 0.9860
18:30:34.816   Training iter 250, batch loss 0.0523, batch acc 0.9864
18:30:35.001   Training iter 300, batch loss 0.0561, batch acc 0.9824
18:30:35.162   Training iter 350, batch loss 0.0511, batch acc 0.9870
18:30:35.326   Training iter 400, batch loss 0.0593, batch acc 0.9850
18:30:35.481   Training iter 450, batch loss 0.0567, batch acc 0.9858
18:30:35.609   Training iter 500, batch loss 0.0527, batch acc 0.9870
18:30:35.763   Training iter 550, batch loss 0.0532, batch acc 0.9874
18:30:35.895   Training iter 600, batch loss 0.0527, batch acc 0.9874
18:30:35.897 Training @ 50 epoch...
18:30:36.026   Training iter 50, batch loss 0.0534, batch acc 0.9864
18:30:36.147   Training iter 100, batch loss 0.0480, batch acc 0.9868
18:30:36.301   Training iter 150, batch loss 0.0523, batch acc 0.9856
18:30:36.427   Training iter 200, batch loss 0.0562, batch acc 0.9820
18:30:36.549   Training iter 250, batch loss 0.0530, batch acc 0.9862
18:30:36.682   Training iter 300, batch loss 0.0561, batch acc 0.9848
18:30:36.906   Training iter 350, batch loss 0.0525, batch acc 0.9860
18:30:37.025   Training iter 400, batch loss 0.0558, batch acc 0.9856
18:30:37.158   Training iter 450, batch loss 0.0556, batch acc 0.9864
18:30:37.285   Training iter 500, batch loss 0.0592, batch acc 0.9836
18:30:37.476   Training iter 550, batch loss 0.0570, batch acc 0.9850
18:30:37.615   Training iter 600, batch loss 0.0536, batch acc 0.9876
18:30:37.616 Testing @ 50 epoch...
18:30:37.811     Testing, total mean loss 0.07837, total acc 0.97740
18:30:37.811 Training @ 51 epoch...
18:30:37.964   Training iter 50, batch loss 0.0530, batch acc 0.9864
18:30:38.116   Training iter 100, batch loss 0.0527, batch acc 0.9864
18:30:38.264   Training iter 150, batch loss 0.0560, batch acc 0.9842
18:30:38.481   Training iter 200, batch loss 0.0583, batch acc 0.9834
18:30:38.735   Training iter 250, batch loss 0.0509, batch acc 0.9882
18:30:38.895   Training iter 300, batch loss 0.0562, batch acc 0.9856
18:30:39.029   Training iter 350, batch loss 0.0526, batch acc 0.9856
18:30:39.250   Training iter 400, batch loss 0.0502, batch acc 0.9866
18:30:39.368   Training iter 450, batch loss 0.0558, batch acc 0.9844
18:30:39.528   Training iter 500, batch loss 0.0542, batch acc 0.9868
18:30:39.701   Training iter 550, batch loss 0.0555, batch acc 0.9844
18:30:39.861   Training iter 600, batch loss 0.0563, batch acc 0.9864
18:30:39.863 Training @ 52 epoch...
18:30:40.008   Training iter 50, batch loss 0.0517, batch acc 0.9886
18:30:40.140   Training iter 100, batch loss 0.0481, batch acc 0.9870
18:30:40.343   Training iter 150, batch loss 0.0551, batch acc 0.9846
18:30:40.514   Training iter 200, batch loss 0.0554, batch acc 0.9854
18:30:40.669   Training iter 250, batch loss 0.0512, batch acc 0.9882
18:30:40.859   Training iter 300, batch loss 0.0528, batch acc 0.9868
18:30:41.025   Training iter 350, batch loss 0.0500, batch acc 0.9876
18:30:41.217   Training iter 400, batch loss 0.0572, batch acc 0.9842
18:30:41.353   Training iter 450, batch loss 0.0621, batch acc 0.9820
18:30:41.493   Training iter 500, batch loss 0.0525, batch acc 0.9854
18:30:41.669   Training iter 550, batch loss 0.0542, batch acc 0.9864
18:30:41.832   Training iter 600, batch loss 0.0591, batch acc 0.9840
18:30:41.833 Training @ 53 epoch...
18:30:41.985   Training iter 50, batch loss 0.0496, batch acc 0.9892
18:30:42.115   Training iter 100, batch loss 0.0540, batch acc 0.9856
18:30:42.245   Training iter 150, batch loss 0.0464, batch acc 0.9894
18:30:42.408   Training iter 200, batch loss 0.0497, batch acc 0.9860
18:30:42.565   Training iter 250, batch loss 0.0516, batch acc 0.9850
18:30:42.718   Training iter 300, batch loss 0.0566, batch acc 0.9856
18:30:42.881   Training iter 350, batch loss 0.0589, batch acc 0.9828
18:30:43.016   Training iter 400, batch loss 0.0527, batch acc 0.9862
18:30:43.142   Training iter 450, batch loss 0.0503, batch acc 0.9882
18:30:43.300   Training iter 500, batch loss 0.0558, batch acc 0.9856
18:30:43.443   Training iter 550, batch loss 0.0523, batch acc 0.9860
18:30:43.598   Training iter 600, batch loss 0.0614, batch acc 0.9836
18:30:43.599 Training @ 54 epoch...
18:30:43.842   Training iter 50, batch loss 0.0506, batch acc 0.9882
18:30:44.007   Training iter 100, batch loss 0.0510, batch acc 0.9878
18:30:44.176   Training iter 150, batch loss 0.0508, batch acc 0.9856
18:30:44.333   Training iter 200, batch loss 0.0586, batch acc 0.9828
18:30:44.493   Training iter 250, batch loss 0.0519, batch acc 0.9884
18:30:44.784   Training iter 300, batch loss 0.0542, batch acc 0.9830
18:30:44.951   Training iter 350, batch loss 0.0520, batch acc 0.9870
18:30:45.097   Training iter 400, batch loss 0.0505, batch acc 0.9876
18:30:45.225   Training iter 450, batch loss 0.0522, batch acc 0.9862
18:30:45.349   Training iter 500, batch loss 0.0569, batch acc 0.9842
18:30:45.500   Training iter 550, batch loss 0.0613, batch acc 0.9838
18:30:45.624   Training iter 600, batch loss 0.0465, batch acc 0.9904
18:30:45.626 Training @ 55 epoch...
18:30:45.760   Training iter 50, batch loss 0.0531, batch acc 0.9874
18:30:46.009   Training iter 100, batch loss 0.0551, batch acc 0.9854
18:30:46.177   Training iter 150, batch loss 0.0529, batch acc 0.9856
18:30:46.352   Training iter 200, batch loss 0.0544, batch acc 0.9864
18:30:46.491   Training iter 250, batch loss 0.0465, batch acc 0.9874
18:30:46.631   Training iter 300, batch loss 0.0527, batch acc 0.9866
18:30:46.785   Training iter 350, batch loss 0.0459, batch acc 0.9882
18:30:46.942   Training iter 400, batch loss 0.0583, batch acc 0.9838
18:30:47.083   Training iter 450, batch loss 0.0589, batch acc 0.9852
18:30:47.262   Training iter 500, batch loss 0.0481, batch acc 0.9886
18:30:47.402   Training iter 550, batch loss 0.0555, batch acc 0.9856
18:30:47.562   Training iter 600, batch loss 0.0534, batch acc 0.9874
18:30:47.563 Testing @ 55 epoch...
18:30:47.624     Testing, total mean loss 0.07780, total acc 0.97580
18:30:47.624 Training @ 56 epoch...
18:30:47.730   Training iter 50, batch loss 0.0497, batch acc 0.9866
18:30:47.839   Training iter 100, batch loss 0.0469, batch acc 0.9872
18:30:47.931   Training iter 150, batch loss 0.0511, batch acc 0.9878
18:30:48.021   Training iter 200, batch loss 0.0546, batch acc 0.9872
18:30:48.108   Training iter 250, batch loss 0.0527, batch acc 0.9868
18:30:48.227   Training iter 300, batch loss 0.0471, batch acc 0.9884
18:30:48.343   Training iter 350, batch loss 0.0527, batch acc 0.9870
18:30:48.433   Training iter 400, batch loss 0.0515, batch acc 0.9870
18:30:48.530   Training iter 450, batch loss 0.0546, batch acc 0.9856
18:30:48.625   Training iter 500, batch loss 0.0552, batch acc 0.9840
18:30:48.734   Training iter 550, batch loss 0.0591, batch acc 0.9840
18:30:48.833   Training iter 600, batch loss 0.0515, batch acc 0.9860
18:30:48.834 Training @ 57 epoch...
18:30:48.937   Training iter 50, batch loss 0.0467, batch acc 0.9888
18:30:49.024   Training iter 100, batch loss 0.0462, batch acc 0.9890
18:30:49.126   Training iter 150, batch loss 0.0465, batch acc 0.9882
18:30:49.232   Training iter 200, batch loss 0.0503, batch acc 0.9868
18:30:49.342   Training iter 250, batch loss 0.0467, batch acc 0.9874
18:30:49.435   Training iter 300, batch loss 0.0508, batch acc 0.9868
18:30:49.550   Training iter 350, batch loss 0.0549, batch acc 0.9848
18:30:49.649   Training iter 400, batch loss 0.0576, batch acc 0.9848
18:30:49.793   Training iter 450, batch loss 0.0561, batch acc 0.9858
18:30:49.911   Training iter 500, batch loss 0.0531, batch acc 0.9854
18:30:50.022   Training iter 550, batch loss 0.0609, batch acc 0.9840
18:30:50.139   Training iter 600, batch loss 0.0534, batch acc 0.9866
18:30:50.141 Training @ 58 epoch...
18:30:50.287   Training iter 50, batch loss 0.0507, batch acc 0.9858
18:30:50.385   Training iter 100, batch loss 0.0439, batch acc 0.9900
18:30:50.476   Training iter 150, batch loss 0.0528, batch acc 0.9854
18:30:50.569   Training iter 200, batch loss 0.0496, batch acc 0.9878
18:30:50.668   Training iter 250, batch loss 0.0577, batch acc 0.9842
18:30:50.787   Training iter 300, batch loss 0.0521, batch acc 0.9868
18:30:50.878   Training iter 350, batch loss 0.0533, batch acc 0.9864
18:30:50.975   Training iter 400, batch loss 0.0520, batch acc 0.9876
18:30:51.088   Training iter 450, batch loss 0.0494, batch acc 0.9884
18:30:51.188   Training iter 500, batch loss 0.0470, batch acc 0.9876
18:30:51.314   Training iter 550, batch loss 0.0527, batch acc 0.9886
18:30:51.439   Training iter 600, batch loss 0.0589, batch acc 0.9842
18:30:51.440 Training @ 59 epoch...
18:30:51.597   Training iter 50, batch loss 0.0535, batch acc 0.9864
18:30:51.733   Training iter 100, batch loss 0.0522, batch acc 0.9880
18:30:51.828   Training iter 150, batch loss 0.0501, batch acc 0.9886
18:30:51.917   Training iter 200, batch loss 0.0569, batch acc 0.9852
18:30:52.007   Training iter 250, batch loss 0.0530, batch acc 0.9870
18:30:52.144   Training iter 300, batch loss 0.0470, batch acc 0.9872
18:30:52.251   Training iter 350, batch loss 0.0481, batch acc 0.9864
18:30:52.377   Training iter 400, batch loss 0.0544, batch acc 0.9870
18:30:52.501   Training iter 450, batch loss 0.0494, batch acc 0.9858
18:30:52.624   Training iter 500, batch loss 0.0503, batch acc 0.9856
18:30:52.759   Training iter 550, batch loss 0.0505, batch acc 0.9874
18:30:52.880   Training iter 600, batch loss 0.0564, batch acc 0.9854
18:30:52.881 Training @ 60 epoch...
18:30:53.007   Training iter 50, batch loss 0.0440, batch acc 0.9886
18:30:53.135   Training iter 100, batch loss 0.0526, batch acc 0.9872
18:30:53.236   Training iter 150, batch loss 0.0521, batch acc 0.9858
18:30:53.345   Training iter 200, batch loss 0.0503, batch acc 0.9872
18:30:53.439   Training iter 250, batch loss 0.0475, batch acc 0.9878
18:30:53.527   Training iter 300, batch loss 0.0503, batch acc 0.9874
18:30:53.627   Training iter 350, batch loss 0.0546, batch acc 0.9862
18:30:53.730   Training iter 400, batch loss 0.0513, batch acc 0.9858
18:30:53.831   Training iter 450, batch loss 0.0504, batch acc 0.9892
18:30:53.929   Training iter 500, batch loss 0.0539, batch acc 0.9848
18:30:54.023   Training iter 550, batch loss 0.0531, batch acc 0.9866
18:30:54.115   Training iter 600, batch loss 0.0524, batch acc 0.9846
18:30:54.116 Testing @ 60 epoch...
18:30:54.180     Testing, total mean loss 0.07746, total acc 0.97690
18:30:54.180 Training @ 61 epoch...
18:30:54.284   Training iter 50, batch loss 0.0509, batch acc 0.9866
18:30:54.393   Training iter 100, batch loss 0.0453, batch acc 0.9888
18:30:54.487   Training iter 150, batch loss 0.0537, batch acc 0.9852
18:30:54.579   Training iter 200, batch loss 0.0479, batch acc 0.9880
18:30:54.665   Training iter 250, batch loss 0.0491, batch acc 0.9876
18:30:54.781   Training iter 300, batch loss 0.0574, batch acc 0.9840
18:30:54.873   Training iter 350, batch loss 0.0504, batch acc 0.9866
18:30:54.960   Training iter 400, batch loss 0.0496, batch acc 0.9872
18:30:55.054   Training iter 450, batch loss 0.0487, batch acc 0.9880
18:30:55.177   Training iter 500, batch loss 0.0496, batch acc 0.9872
18:30:55.304   Training iter 550, batch loss 0.0525, batch acc 0.9868
18:30:55.418   Training iter 600, batch loss 0.0516, batch acc 0.9874
18:30:55.420 Training @ 62 epoch...
18:30:55.542   Training iter 50, batch loss 0.0569, batch acc 0.9868
18:30:55.654   Training iter 100, batch loss 0.0574, batch acc 0.9826
18:30:55.910   Training iter 150, batch loss 0.0461, batch acc 0.9880
18:30:56.241   Training iter 200, batch loss 0.0502, batch acc 0.9880
18:30:56.371   Training iter 250, batch loss 0.0525, batch acc 0.9872
18:30:56.482   Training iter 300, batch loss 0.0498, batch acc 0.9862
18:30:56.584   Training iter 350, batch loss 0.0544, batch acc 0.9844
18:30:56.691   Training iter 400, batch loss 0.0531, batch acc 0.9876
18:30:56.874   Training iter 450, batch loss 0.0433, batch acc 0.9892
18:30:57.033   Training iter 500, batch loss 0.0467, batch acc 0.9876
18:30:57.127   Training iter 550, batch loss 0.0508, batch acc 0.9870
18:30:57.250   Training iter 600, batch loss 0.0483, batch acc 0.9888
18:30:57.250 Training @ 63 epoch...
18:30:57.355   Training iter 50, batch loss 0.0486, batch acc 0.9886
18:30:57.456   Training iter 100, batch loss 0.0537, batch acc 0.9852
18:30:57.554   Training iter 150, batch loss 0.0471, batch acc 0.9892
18:30:57.647   Training iter 200, batch loss 0.0540, batch acc 0.9866
18:30:57.765   Training iter 250, batch loss 0.0490, batch acc 0.9874
18:30:57.858   Training iter 300, batch loss 0.0551, batch acc 0.9842
18:30:57.999   Training iter 350, batch loss 0.0534, batch acc 0.9848
18:30:58.112   Training iter 400, batch loss 0.0493, batch acc 0.9870
18:30:58.248   Training iter 450, batch loss 0.0458, batch acc 0.9888
18:30:58.372   Training iter 500, batch loss 0.0479, batch acc 0.9860
18:30:58.483   Training iter 550, batch loss 0.0525, batch acc 0.9880
18:30:58.600   Training iter 600, batch loss 0.0536, batch acc 0.9860
18:30:58.601 Training @ 64 epoch...
18:30:58.743   Training iter 50, batch loss 0.0478, batch acc 0.9884
18:30:58.951   Training iter 100, batch loss 0.0441, batch acc 0.9906
18:30:59.437   Training iter 150, batch loss 0.0467, batch acc 0.9874
18:30:59.664   Training iter 200, batch loss 0.0505, batch acc 0.9858
18:30:59.816   Training iter 250, batch loss 0.0521, batch acc 0.9874
18:30:59.994   Training iter 300, batch loss 0.0479, batch acc 0.9886
18:31:00.264   Training iter 350, batch loss 0.0543, batch acc 0.9872
18:31:00.469   Training iter 400, batch loss 0.0459, batch acc 0.9900
18:31:00.664   Training iter 450, batch loss 0.0538, batch acc 0.9852
18:31:00.793   Training iter 500, batch loss 0.0540, batch acc 0.9834
18:31:01.173   Training iter 550, batch loss 0.0496, batch acc 0.9874
18:31:01.415   Training iter 600, batch loss 0.0551, batch acc 0.9856
18:31:01.415 Training @ 65 epoch...
18:31:01.683   Training iter 50, batch loss 0.0555, batch acc 0.9854
18:31:02.129   Training iter 100, batch loss 0.0466, batch acc 0.9880
18:31:02.429   Training iter 150, batch loss 0.0465, batch acc 0.9880
18:31:02.588   Training iter 200, batch loss 0.0514, batch acc 0.9860
18:31:02.715   Training iter 250, batch loss 0.0542, batch acc 0.9856
18:31:02.862   Training iter 300, batch loss 0.0525, batch acc 0.9868
18:31:03.118   Training iter 350, batch loss 0.0493, batch acc 0.9886
18:31:03.365   Training iter 400, batch loss 0.0506, batch acc 0.9876
18:31:03.500   Training iter 450, batch loss 0.0485, batch acc 0.9862
18:31:03.670   Training iter 500, batch loss 0.0517, batch acc 0.9852
18:31:03.835   Training iter 550, batch loss 0.0521, batch acc 0.9878
18:31:04.043   Training iter 600, batch loss 0.0525, batch acc 0.9858
18:31:04.044 Testing @ 65 epoch...
18:31:04.184     Testing, total mean loss 0.08125, total acc 0.97480
18:31:04.184 Training @ 66 epoch...
18:31:04.365   Training iter 50, batch loss 0.0511, batch acc 0.9862
18:31:04.530   Training iter 100, batch loss 0.0485, batch acc 0.9888
18:31:04.812   Training iter 150, batch loss 0.0452, batch acc 0.9886
18:31:05.033   Training iter 200, batch loss 0.0440, batch acc 0.9890
18:31:05.250   Training iter 250, batch loss 0.0456, batch acc 0.9874
18:31:05.429   Training iter 300, batch loss 0.0545, batch acc 0.9858
18:31:05.568   Training iter 350, batch loss 0.0461, batch acc 0.9884
18:31:05.804   Training iter 400, batch loss 0.0477, batch acc 0.9882
18:31:05.934   Training iter 450, batch loss 0.0555, batch acc 0.9862
18:31:06.059   Training iter 500, batch loss 0.0586, batch acc 0.9838
18:31:06.202   Training iter 550, batch loss 0.0504, batch acc 0.9872
18:31:06.404   Training iter 600, batch loss 0.0551, batch acc 0.9846
18:31:06.404 Training @ 67 epoch...
18:31:06.546   Training iter 50, batch loss 0.0479, batch acc 0.9872
18:31:06.697   Training iter 100, batch loss 0.0448, batch acc 0.9884
18:31:06.884   Training iter 150, batch loss 0.0513, batch acc 0.9882
18:31:07.054   Training iter 200, batch loss 0.0471, batch acc 0.9878
18:31:07.204   Training iter 250, batch loss 0.0517, batch acc 0.9888
18:31:07.367   Training iter 300, batch loss 0.0513, batch acc 0.9890
18:31:07.545   Training iter 350, batch loss 0.0518, batch acc 0.9846
18:31:07.751   Training iter 400, batch loss 0.0410, batch acc 0.9908
18:31:07.977   Training iter 450, batch loss 0.0543, batch acc 0.9828
18:31:08.118   Training iter 500, batch loss 0.0419, batch acc 0.9898
18:31:08.255   Training iter 550, batch loss 0.0520, batch acc 0.9846
18:31:08.397   Training iter 600, batch loss 0.0582, batch acc 0.9836
18:31:08.398 Training @ 68 epoch...
18:31:08.528   Training iter 50, batch loss 0.0449, batch acc 0.9874
18:31:08.665   Training iter 100, batch loss 0.0459, batch acc 0.9904
18:31:08.788   Training iter 150, batch loss 0.0560, batch acc 0.9850
18:31:08.927   Training iter 200, batch loss 0.0454, batch acc 0.9902
18:31:09.082   Training iter 250, batch loss 0.0528, batch acc 0.9846
18:31:09.221   Training iter 300, batch loss 0.0507, batch acc 0.9852
18:31:09.384   Training iter 350, batch loss 0.0454, batch acc 0.9900
18:31:09.513   Training iter 400, batch loss 0.0485, batch acc 0.9872
18:31:09.647   Training iter 450, batch loss 0.0503, batch acc 0.9860
18:31:09.796   Training iter 500, batch loss 0.0469, batch acc 0.9872
18:31:09.949   Training iter 550, batch loss 0.0496, batch acc 0.9862
18:31:10.166   Training iter 600, batch loss 0.0589, batch acc 0.9832
18:31:10.168 Training @ 69 epoch...
18:31:10.371   Training iter 50, batch loss 0.0421, batch acc 0.9908
18:31:10.649   Training iter 100, batch loss 0.0474, batch acc 0.9884
18:31:10.811   Training iter 150, batch loss 0.0482, batch acc 0.9890
18:31:10.996   Training iter 200, batch loss 0.0516, batch acc 0.9876
18:31:11.146   Training iter 250, batch loss 0.0474, batch acc 0.9888
18:31:11.281   Training iter 300, batch loss 0.0498, batch acc 0.9876
18:31:11.417   Training iter 350, batch loss 0.0512, batch acc 0.9860
18:31:11.567   Training iter 400, batch loss 0.0519, batch acc 0.9866
18:31:11.703   Training iter 450, batch loss 0.0518, batch acc 0.9874
18:31:11.848   Training iter 500, batch loss 0.0461, batch acc 0.9888
18:31:11.981   Training iter 550, batch loss 0.0518, batch acc 0.9860
18:31:12.137   Training iter 600, batch loss 0.0506, batch acc 0.9874
18:31:12.138 Training @ 70 epoch...
18:31:12.333   Training iter 50, batch loss 0.0493, batch acc 0.9874
18:31:12.517   Training iter 100, batch loss 0.0532, batch acc 0.9872
18:31:12.661   Training iter 150, batch loss 0.0459, batch acc 0.9870
18:31:12.814   Training iter 200, batch loss 0.0488, batch acc 0.9884
18:31:13.010   Training iter 250, batch loss 0.0462, batch acc 0.9880
18:31:13.200   Training iter 300, batch loss 0.0488, batch acc 0.9886
18:31:13.363   Training iter 350, batch loss 0.0515, batch acc 0.9860
18:31:13.531   Training iter 400, batch loss 0.0441, batch acc 0.9902
18:31:13.681   Training iter 450, batch loss 0.0492, batch acc 0.9882
18:31:13.847   Training iter 500, batch loss 0.0506, batch acc 0.9864
18:31:13.971   Training iter 550, batch loss 0.0537, batch acc 0.9858
18:31:14.090   Training iter 600, batch loss 0.0453, batch acc 0.9888
18:31:14.090 Testing @ 70 epoch...
18:31:14.173     Testing, total mean loss 0.07723, total acc 0.97640
18:31:14.173 Training @ 71 epoch...
18:31:14.300   Training iter 50, batch loss 0.0471, batch acc 0.9884
18:31:14.465   Training iter 100, batch loss 0.0456, batch acc 0.9904
18:31:14.684   Training iter 150, batch loss 0.0494, batch acc 0.9890
18:31:14.821   Training iter 200, batch loss 0.0486, batch acc 0.9890
18:31:14.950   Training iter 250, batch loss 0.0500, batch acc 0.9858
18:31:15.070   Training iter 300, batch loss 0.0475, batch acc 0.9886
18:31:15.206   Training iter 350, batch loss 0.0506, batch acc 0.9866
18:31:15.334   Training iter 400, batch loss 0.0469, batch acc 0.9890
18:31:15.490   Training iter 450, batch loss 0.0455, batch acc 0.9890
18:31:15.619   Training iter 500, batch loss 0.0508, batch acc 0.9860
18:31:15.769   Training iter 550, batch loss 0.0488, batch acc 0.9876
18:31:15.971   Training iter 600, batch loss 0.0522, batch acc 0.9870
18:31:15.972 Training @ 72 epoch...
18:31:16.135   Training iter 50, batch loss 0.0452, batch acc 0.9910
18:31:16.294   Training iter 100, batch loss 0.0481, batch acc 0.9876
18:31:16.452   Training iter 150, batch loss 0.0461, batch acc 0.9896
18:31:16.619   Training iter 200, batch loss 0.0469, batch acc 0.9888
18:31:16.785   Training iter 250, batch loss 0.0471, batch acc 0.9874
18:31:16.982   Training iter 300, batch loss 0.0460, batch acc 0.9880
18:31:17.103   Training iter 350, batch loss 0.0484, batch acc 0.9884
18:31:17.300   Training iter 400, batch loss 0.0514, batch acc 0.9860
18:31:17.440   Training iter 450, batch loss 0.0525, batch acc 0.9866
18:31:17.629   Training iter 500, batch loss 0.0526, batch acc 0.9880
18:31:17.746   Training iter 550, batch loss 0.0530, batch acc 0.9846
18:31:17.916   Training iter 600, batch loss 0.0506, batch acc 0.9864
18:31:17.916 Training @ 73 epoch...
18:31:18.098   Training iter 50, batch loss 0.0482, batch acc 0.9882
18:31:18.301   Training iter 100, batch loss 0.0462, batch acc 0.9890
18:31:18.435   Training iter 150, batch loss 0.0449, batch acc 0.9898
18:31:18.587   Training iter 200, batch loss 0.0458, batch acc 0.9892
18:31:18.797   Training iter 250, batch loss 0.0486, batch acc 0.9886
18:31:19.038   Training iter 300, batch loss 0.0463, batch acc 0.9880
18:31:19.253   Training iter 350, batch loss 0.0490, batch acc 0.9876
18:31:19.437   Training iter 400, batch loss 0.0505, batch acc 0.9888
18:31:19.646   Training iter 450, batch loss 0.0536, batch acc 0.9852
18:31:19.824   Training iter 500, batch loss 0.0560, batch acc 0.9838
18:31:19.965   Training iter 550, batch loss 0.0466, batch acc 0.9894
18:31:20.101   Training iter 600, batch loss 0.0523, batch acc 0.9858
18:31:20.102 Training @ 74 epoch...
18:31:20.225   Training iter 50, batch loss 0.0460, batch acc 0.9880
18:31:20.402   Training iter 100, batch loss 0.0448, batch acc 0.9896
18:31:20.556   Training iter 150, batch loss 0.0475, batch acc 0.9886
18:31:20.691   Training iter 200, batch loss 0.0522, batch acc 0.9850
18:31:20.838   Training iter 250, batch loss 0.0498, batch acc 0.9858
18:31:20.971   Training iter 300, batch loss 0.0496, batch acc 0.9864
18:31:21.105   Training iter 350, batch loss 0.0455, batch acc 0.9894
18:31:21.320   Training iter 400, batch loss 0.0488, batch acc 0.9876
18:31:21.625   Training iter 450, batch loss 0.0490, batch acc 0.9882
18:31:22.036   Training iter 500, batch loss 0.0467, batch acc 0.9878
18:31:22.447   Training iter 550, batch loss 0.0511, batch acc 0.9872
18:31:22.692   Training iter 600, batch loss 0.0518, batch acc 0.9870
18:31:22.693 Training @ 75 epoch...
18:31:22.936   Training iter 50, batch loss 0.0519, batch acc 0.9884
18:31:23.089   Training iter 100, batch loss 0.0497, batch acc 0.9880
18:31:23.273   Training iter 150, batch loss 0.0484, batch acc 0.9848
18:31:23.455   Training iter 200, batch loss 0.0578, batch acc 0.9840
18:31:23.621   Training iter 250, batch loss 0.0477, batch acc 0.9890
18:31:23.798   Training iter 300, batch loss 0.0409, batch acc 0.9902
18:31:23.973   Training iter 350, batch loss 0.0459, batch acc 0.9860
18:31:24.119   Training iter 400, batch loss 0.0427, batch acc 0.9898
18:31:24.388   Training iter 450, batch loss 0.0527, batch acc 0.9860
18:31:25.360   Training iter 500, batch loss 0.0487, batch acc 0.9876
18:31:27.110   Training iter 550, batch loss 0.0429, batch acc 0.9900
18:31:28.791   Training iter 600, batch loss 0.0486, batch acc 0.9886
18:31:28.792 Testing @ 75 epoch...
18:31:30.088     Testing, total mean loss 0.07876, total acc 0.97600
18:31:30.088 Training @ 76 epoch...
18:31:31.156   Training iter 50, batch loss 0.0455, batch acc 0.9894
18:31:32.708   Training iter 100, batch loss 0.0456, batch acc 0.9890
18:31:33.638   Training iter 150, batch loss 0.0451, batch acc 0.9894
18:31:33.894   Training iter 200, batch loss 0.0531, batch acc 0.9852
18:31:34.055   Training iter 250, batch loss 0.0436, batch acc 0.9898
18:31:34.217   Training iter 300, batch loss 0.0515, batch acc 0.9872
18:31:34.393   Training iter 350, batch loss 0.0515, batch acc 0.9860
18:31:34.595   Training iter 400, batch loss 0.0463, batch acc 0.9888
18:31:34.758   Training iter 450, batch loss 0.0409, batch acc 0.9908
18:31:34.902   Training iter 500, batch loss 0.0513, batch acc 0.9856
18:31:35.101   Training iter 550, batch loss 0.0531, batch acc 0.9874
18:31:35.305   Training iter 600, batch loss 0.0495, batch acc 0.9880
18:31:35.305 Training @ 77 epoch...
18:31:35.476   Training iter 50, batch loss 0.0415, batch acc 0.9900
18:31:35.603   Training iter 100, batch loss 0.0443, batch acc 0.9904
18:31:35.742   Training iter 150, batch loss 0.0508, batch acc 0.9860
18:31:35.884   Training iter 200, batch loss 0.0500, batch acc 0.9874
18:31:36.010   Training iter 250, batch loss 0.0474, batch acc 0.9880
18:31:36.168   Training iter 300, batch loss 0.0443, batch acc 0.9904
18:31:36.317   Training iter 350, batch loss 0.0446, batch acc 0.9882
18:31:36.540   Training iter 400, batch loss 0.0519, batch acc 0.9866
18:31:36.690   Training iter 450, batch loss 0.0500, batch acc 0.9860
18:31:36.857   Training iter 500, batch loss 0.0515, batch acc 0.9852
18:31:37.017   Training iter 550, batch loss 0.0531, batch acc 0.9856
18:31:37.170   Training iter 600, batch loss 0.0468, batch acc 0.9894
18:31:37.172 Training @ 78 epoch...
18:31:37.351   Training iter 50, batch loss 0.0504, batch acc 0.9886
18:31:37.501   Training iter 100, batch loss 0.0430, batch acc 0.9900
18:31:37.759   Training iter 150, batch loss 0.0444, batch acc 0.9906
18:31:37.941   Training iter 200, batch loss 0.0504, batch acc 0.9866
18:31:38.205   Training iter 250, batch loss 0.0440, batch acc 0.9896
18:31:38.392   Training iter 300, batch loss 0.0507, batch acc 0.9870
18:31:38.538   Training iter 350, batch loss 0.0477, batch acc 0.9882
18:31:38.735   Training iter 400, batch loss 0.0417, batch acc 0.9898
18:31:38.955   Training iter 450, batch loss 0.0539, batch acc 0.9884
18:31:39.352   Training iter 500, batch loss 0.0494, batch acc 0.9870
18:31:39.621   Training iter 550, batch loss 0.0481, batch acc 0.9864
18:31:39.806   Training iter 600, batch loss 0.0472, batch acc 0.9868
18:31:39.808 Training @ 79 epoch...
18:31:40.078   Training iter 50, batch loss 0.0462, batch acc 0.9900
18:31:40.252   Training iter 100, batch loss 0.0440, batch acc 0.9896
18:31:40.472   Training iter 150, batch loss 0.0506, batch acc 0.9868
18:31:40.690   Training iter 200, batch loss 0.0463, batch acc 0.9868
18:31:40.852   Training iter 250, batch loss 0.0485, batch acc 0.9888
18:31:41.051   Training iter 300, batch loss 0.0464, batch acc 0.9876
18:31:41.171   Training iter 350, batch loss 0.0558, batch acc 0.9844
18:31:41.309   Training iter 400, batch loss 0.0407, batch acc 0.9902
18:31:41.458   Training iter 450, batch loss 0.0488, batch acc 0.9890
18:31:41.618   Training iter 500, batch loss 0.0522, batch acc 0.9854
18:31:41.770   Training iter 550, batch loss 0.0459, batch acc 0.9882
18:31:41.919   Training iter 600, batch loss 0.0471, batch acc 0.9884
18:31:41.919 Training @ 80 epoch...
18:31:42.142   Training iter 50, batch loss 0.0467, batch acc 0.9874
18:31:42.439   Training iter 100, batch loss 0.0492, batch acc 0.9878
18:31:42.627   Training iter 150, batch loss 0.0472, batch acc 0.9896
18:31:42.819   Training iter 200, batch loss 0.0464, batch acc 0.9880
18:31:43.058   Training iter 250, batch loss 0.0467, batch acc 0.9896
18:31:43.251   Training iter 300, batch loss 0.0431, batch acc 0.9900
18:31:43.483   Training iter 350, batch loss 0.0439, batch acc 0.9878
18:31:43.736   Training iter 400, batch loss 0.0481, batch acc 0.9880
18:31:43.924   Training iter 450, batch loss 0.0505, batch acc 0.9870
18:31:44.076   Training iter 500, batch loss 0.0505, batch acc 0.9880
18:31:44.257   Training iter 550, batch loss 0.0487, batch acc 0.9862
18:31:44.402   Training iter 600, batch loss 0.0477, batch acc 0.9876
18:31:44.403 Testing @ 80 epoch...
18:31:44.552     Testing, total mean loss 0.07551, total acc 0.97690
18:31:44.552 Training @ 81 epoch...
18:31:44.685   Training iter 50, batch loss 0.0475, batch acc 0.9882
18:31:44.935   Training iter 100, batch loss 0.0452, batch acc 0.9882
18:31:45.427   Training iter 150, batch loss 0.0482, batch acc 0.9888
18:31:46.045   Training iter 200, batch loss 0.0484, batch acc 0.9884
18:31:46.204   Training iter 250, batch loss 0.0463, batch acc 0.9906
18:31:46.487   Training iter 300, batch loss 0.0520, batch acc 0.9862
18:31:46.668   Training iter 350, batch loss 0.0456, batch acc 0.9892
18:31:46.884   Training iter 400, batch loss 0.0483, batch acc 0.9886
18:31:47.137   Training iter 450, batch loss 0.0478, batch acc 0.9866
18:31:47.294   Training iter 500, batch loss 0.0519, batch acc 0.9868
18:31:47.493   Training iter 550, batch loss 0.0476, batch acc 0.9870
18:31:47.670   Training iter 600, batch loss 0.0478, batch acc 0.9864
18:31:47.670 Training @ 82 epoch...
18:31:47.867   Training iter 50, batch loss 0.0445, batch acc 0.9886
18:31:48.119   Training iter 100, batch loss 0.0471, batch acc 0.9900
18:31:48.351   Training iter 150, batch loss 0.0466, batch acc 0.9870
18:31:48.523   Training iter 200, batch loss 0.0503, batch acc 0.9866
18:31:48.737   Training iter 250, batch loss 0.0428, batch acc 0.9902
18:31:48.932   Training iter 300, batch loss 0.0468, batch acc 0.9878
18:31:49.139   Training iter 350, batch loss 0.0538, batch acc 0.9866
18:31:49.361   Training iter 400, batch loss 0.0460, batch acc 0.9876
18:31:49.504   Training iter 450, batch loss 0.0438, batch acc 0.9904
18:31:49.678   Training iter 500, batch loss 0.0504, batch acc 0.9892
18:31:49.838   Training iter 550, batch loss 0.0452, batch acc 0.9874
18:31:49.969   Training iter 600, batch loss 0.0498, batch acc 0.9862
18:31:49.971 Training @ 83 epoch...
18:31:50.116   Training iter 50, batch loss 0.0442, batch acc 0.9898
18:31:50.256   Training iter 100, batch loss 0.0500, batch acc 0.9884
18:31:50.404   Training iter 150, batch loss 0.0434, batch acc 0.9898
18:31:50.525   Training iter 200, batch loss 0.0533, batch acc 0.9864
18:31:50.686   Training iter 250, batch loss 0.0464, batch acc 0.9886
18:31:50.819   Training iter 300, batch loss 0.0515, batch acc 0.9870
18:31:50.949   Training iter 350, batch loss 0.0567, batch acc 0.9862
18:31:51.085   Training iter 400, batch loss 0.0455, batch acc 0.9880
18:31:51.239   Training iter 450, batch loss 0.0406, batch acc 0.9908
18:31:51.402   Training iter 500, batch loss 0.0430, batch acc 0.9912
18:31:51.543   Training iter 550, batch loss 0.0416, batch acc 0.9898
18:31:51.694   Training iter 600, batch loss 0.0522, batch acc 0.9860
18:31:51.695 Training @ 84 epoch...
18:31:51.867   Training iter 50, batch loss 0.0487, batch acc 0.9896
18:31:52.067   Training iter 100, batch loss 0.0487, batch acc 0.9856
18:31:52.269   Training iter 150, batch loss 0.0405, batch acc 0.9906
18:31:52.415   Training iter 200, batch loss 0.0417, batch acc 0.9902
18:31:52.619   Training iter 250, batch loss 0.0476, batch acc 0.9874
18:31:52.774   Training iter 300, batch loss 0.0473, batch acc 0.9892
18:31:52.912   Training iter 350, batch loss 0.0437, batch acc 0.9888
18:31:53.038   Training iter 400, batch loss 0.0551, batch acc 0.9842
18:31:53.189   Training iter 450, batch loss 0.0485, batch acc 0.9874
18:31:53.340   Training iter 500, batch loss 0.0501, batch acc 0.9862
18:31:53.459   Training iter 550, batch loss 0.0414, batch acc 0.9912
18:31:53.580   Training iter 600, batch loss 0.0549, batch acc 0.9856
18:31:53.581 Training @ 85 epoch...
18:31:53.700   Training iter 50, batch loss 0.0444, batch acc 0.9904
18:31:53.828   Training iter 100, batch loss 0.0419, batch acc 0.9886
18:31:53.940   Training iter 150, batch loss 0.0467, batch acc 0.9886
18:31:54.103   Training iter 200, batch loss 0.0468, batch acc 0.9886
18:31:54.240   Training iter 250, batch loss 0.0480, batch acc 0.9878
18:31:54.403   Training iter 300, batch loss 0.0427, batch acc 0.9904
18:31:54.544   Training iter 350, batch loss 0.0427, batch acc 0.9898
18:31:54.700   Training iter 400, batch loss 0.0487, batch acc 0.9900
18:31:54.887   Training iter 450, batch loss 0.0508, batch acc 0.9872
18:31:55.038   Training iter 500, batch loss 0.0507, batch acc 0.9864
18:31:55.171   Training iter 550, batch loss 0.0485, batch acc 0.9878
18:31:55.306   Training iter 600, batch loss 0.0521, batch acc 0.9868
18:31:55.307 Testing @ 85 epoch...
18:31:55.404     Testing, total mean loss 0.07436, total acc 0.97820
18:31:55.404 Training @ 86 epoch...
18:31:55.562   Training iter 50, batch loss 0.0460, batch acc 0.9886
18:31:55.735   Training iter 100, batch loss 0.0455, batch acc 0.9884
18:31:55.872   Training iter 150, batch loss 0.0445, batch acc 0.9892
18:31:55.995   Training iter 200, batch loss 0.0453, batch acc 0.9888
18:31:56.118   Training iter 250, batch loss 0.0440, batch acc 0.9878
18:31:56.255   Training iter 300, batch loss 0.0538, batch acc 0.9870
18:31:56.392   Training iter 350, batch loss 0.0458, batch acc 0.9886
18:31:56.537   Training iter 400, batch loss 0.0493, batch acc 0.9864
18:31:56.713   Training iter 450, batch loss 0.0475, batch acc 0.9888
18:31:56.878   Training iter 500, batch loss 0.0460, batch acc 0.9894
18:31:57.031   Training iter 550, batch loss 0.0449, batch acc 0.9888
18:31:57.188   Training iter 600, batch loss 0.0474, batch acc 0.9886
18:31:57.190 Training @ 87 epoch...
18:31:57.359   Training iter 50, batch loss 0.0436, batch acc 0.9894
18:31:57.511   Training iter 100, batch loss 0.0445, batch acc 0.9898
18:31:57.702   Training iter 150, batch loss 0.0404, batch acc 0.9900
18:31:57.877   Training iter 200, batch loss 0.0481, batch acc 0.9868
18:31:58.032   Training iter 250, batch loss 0.0477, batch acc 0.9862
18:31:58.201   Training iter 300, batch loss 0.0468, batch acc 0.9884
18:31:58.366   Training iter 350, batch loss 0.0423, batch acc 0.9906
18:31:58.504   Training iter 400, batch loss 0.0458, batch acc 0.9864
18:31:58.637   Training iter 450, batch loss 0.0517, batch acc 0.9856
18:31:58.786   Training iter 500, batch loss 0.0522, batch acc 0.9858
18:31:58.966   Training iter 550, batch loss 0.0500, batch acc 0.9868
18:31:59.125   Training iter 600, batch loss 0.0447, batch acc 0.9898
18:31:59.126 Training @ 88 epoch...
18:31:59.276   Training iter 50, batch loss 0.0445, batch acc 0.9878
18:31:59.458   Training iter 100, batch loss 0.0492, batch acc 0.9868
18:31:59.587   Training iter 150, batch loss 0.0464, batch acc 0.9890
18:31:59.894   Training iter 200, batch loss 0.0439, batch acc 0.9896
18:32:00.150   Training iter 250, batch loss 0.0490, batch acc 0.9888
18:32:00.306   Training iter 300, batch loss 0.0472, batch acc 0.9882
18:32:00.474   Training iter 350, batch loss 0.0438, batch acc 0.9900
18:32:00.707   Training iter 400, batch loss 0.0443, batch acc 0.9914
18:32:00.883   Training iter 450, batch loss 0.0463, batch acc 0.9880
18:32:01.041   Training iter 500, batch loss 0.0467, batch acc 0.9884
18:32:01.260   Training iter 550, batch loss 0.0444, batch acc 0.9898
18:32:01.411   Training iter 600, batch loss 0.0502, batch acc 0.9874
18:32:01.412 Training @ 89 epoch...
18:32:01.580   Training iter 50, batch loss 0.0440, batch acc 0.9888
18:32:01.878   Training iter 100, batch loss 0.0413, batch acc 0.9908
18:32:02.052   Training iter 150, batch loss 0.0419, batch acc 0.9918
18:32:02.276   Training iter 200, batch loss 0.0502, batch acc 0.9880
18:32:02.424   Training iter 250, batch loss 0.0440, batch acc 0.9882
18:32:02.612   Training iter 300, batch loss 0.0438, batch acc 0.9880
18:32:03.488   Training iter 350, batch loss 0.0494, batch acc 0.9862
18:32:04.343   Training iter 400, batch loss 0.0537, batch acc 0.9878
18:32:05.286   Training iter 450, batch loss 0.0478, batch acc 0.9868
18:32:06.539   Training iter 500, batch loss 0.0427, batch acc 0.9896
18:32:07.676   Training iter 550, batch loss 0.0474, batch acc 0.9884
18:32:08.301   Training iter 600, batch loss 0.0503, batch acc 0.9876
18:32:08.301 Training @ 90 epoch...
18:32:08.824   Training iter 50, batch loss 0.0433, batch acc 0.9902
18:32:10.206   Training iter 100, batch loss 0.0421, batch acc 0.9912
18:32:11.043   Training iter 150, batch loss 0.0453, batch acc 0.9884
18:32:11.427   Training iter 200, batch loss 0.0510, batch acc 0.9876
18:32:11.819   Training iter 250, batch loss 0.0469, batch acc 0.9880
18:32:12.238   Training iter 300, batch loss 0.0469, batch acc 0.9878
18:32:12.674   Training iter 350, batch loss 0.0490, batch acc 0.9866
18:32:12.859   Training iter 400, batch loss 0.0437, batch acc 0.9900
18:32:13.125   Training iter 450, batch loss 0.0433, batch acc 0.9900
18:32:13.419   Training iter 500, batch loss 0.0505, batch acc 0.9862
18:32:13.660   Training iter 550, batch loss 0.0484, batch acc 0.9872
18:32:13.955   Training iter 600, batch loss 0.0518, batch acc 0.9866
18:32:13.956 Testing @ 90 epoch...
18:32:14.156     Testing, total mean loss 0.07379, total acc 0.97890
18:32:14.157 Training @ 91 epoch...
18:32:14.361   Training iter 50, batch loss 0.0493, batch acc 0.9880
18:32:14.558   Training iter 100, batch loss 0.0426, batch acc 0.9910
18:32:14.757   Training iter 150, batch loss 0.0415, batch acc 0.9904
18:32:14.926   Training iter 200, batch loss 0.0388, batch acc 0.9916
18:32:15.104   Training iter 250, batch loss 0.0440, batch acc 0.9894
18:32:15.258   Training iter 300, batch loss 0.0442, batch acc 0.9906
18:32:15.439   Training iter 350, batch loss 0.0468, batch acc 0.9888
18:32:15.611   Training iter 400, batch loss 0.0500, batch acc 0.9866
18:32:15.890   Training iter 450, batch loss 0.0496, batch acc 0.9870
18:32:16.104   Training iter 500, batch loss 0.0493, batch acc 0.9896
18:32:16.339   Training iter 550, batch loss 0.0488, batch acc 0.9868
18:32:16.543   Training iter 600, batch loss 0.0524, batch acc 0.9858
18:32:16.550 Training @ 92 epoch...
18:32:16.873   Training iter 50, batch loss 0.0410, batch acc 0.9894
18:32:17.019   Training iter 100, batch loss 0.0455, batch acc 0.9910
18:32:17.224   Training iter 150, batch loss 0.0440, batch acc 0.9878
18:32:17.426   Training iter 200, batch loss 0.0394, batch acc 0.9910
18:32:17.576   Training iter 250, batch loss 0.0423, batch acc 0.9896
18:32:17.785   Training iter 300, batch loss 0.0490, batch acc 0.9878
18:32:18.023   Training iter 350, batch loss 0.0450, batch acc 0.9894
18:32:18.237   Training iter 400, batch loss 0.0450, batch acc 0.9896
18:32:18.492   Training iter 450, batch loss 0.0413, batch acc 0.9906
18:32:18.728   Training iter 500, batch loss 0.0476, batch acc 0.9898
18:32:19.004   Training iter 550, batch loss 0.0553, batch acc 0.9856
18:32:19.160   Training iter 600, batch loss 0.0541, batch acc 0.9852
18:32:19.161 Training @ 93 epoch...
18:32:19.287   Training iter 50, batch loss 0.0451, batch acc 0.9898
18:32:19.440   Training iter 100, batch loss 0.0435, batch acc 0.9894
18:32:19.641   Training iter 150, batch loss 0.0456, batch acc 0.9878
18:32:19.806   Training iter 200, batch loss 0.0471, batch acc 0.9868
18:32:19.987   Training iter 250, batch loss 0.0443, batch acc 0.9876
18:32:20.225   Training iter 300, batch loss 0.0485, batch acc 0.9866
18:32:20.481   Training iter 350, batch loss 0.0480, batch acc 0.9892
18:32:20.687   Training iter 400, batch loss 0.0463, batch acc 0.9880
18:32:21.224   Training iter 450, batch loss 0.0430, batch acc 0.9900
18:32:21.444   Training iter 500, batch loss 0.0445, batch acc 0.9898
18:32:21.689   Training iter 550, batch loss 0.0465, batch acc 0.9876
18:32:21.852   Training iter 600, batch loss 0.0515, batch acc 0.9878
18:32:21.854 Training @ 94 epoch...
18:32:22.095   Training iter 50, batch loss 0.0474, batch acc 0.9888
18:32:22.303   Training iter 100, batch loss 0.0476, batch acc 0.9880
18:32:22.436   Training iter 150, batch loss 0.0433, batch acc 0.9894
18:32:22.589   Training iter 200, batch loss 0.0439, batch acc 0.9886
18:32:22.770   Training iter 250, batch loss 0.0455, batch acc 0.9892
18:32:23.108   Training iter 300, batch loss 0.0446, batch acc 0.9872
18:32:23.437   Training iter 350, batch loss 0.0445, batch acc 0.9882
18:32:23.705   Training iter 400, batch loss 0.0556, batch acc 0.9848
18:32:23.886   Training iter 450, batch loss 0.0481, batch acc 0.9878
18:32:24.028   Training iter 500, batch loss 0.0419, batch acc 0.9914
18:32:24.190   Training iter 550, batch loss 0.0434, batch acc 0.9900
18:32:24.368   Training iter 600, batch loss 0.0438, batch acc 0.9886
18:32:24.370 Training @ 95 epoch...
18:32:24.592   Training iter 50, batch loss 0.0454, batch acc 0.9888
18:32:24.841   Training iter 100, batch loss 0.0433, batch acc 0.9890
18:32:25.075   Training iter 150, batch loss 0.0455, batch acc 0.9888
18:32:25.270   Training iter 200, batch loss 0.0481, batch acc 0.9884
18:32:25.444   Training iter 250, batch loss 0.0442, batch acc 0.9904
18:32:25.659   Training iter 300, batch loss 0.0444, batch acc 0.9884
18:32:25.876   Training iter 350, batch loss 0.0472, batch acc 0.9892
18:32:26.135   Training iter 400, batch loss 0.0456, batch acc 0.9884
18:32:27.644   Training iter 450, batch loss 0.0417, batch acc 0.9898
18:32:27.801   Training iter 500, batch loss 0.0457, batch acc 0.9876
18:32:27.905   Training iter 550, batch loss 0.0494, batch acc 0.9884
18:32:28.059   Training iter 600, batch loss 0.0482, batch acc 0.9884
18:32:28.061 Testing @ 95 epoch...
18:32:28.246     Testing, total mean loss 0.07441, total acc 0.97780
18:32:28.246 Training @ 96 epoch...
18:32:28.549   Training iter 50, batch loss 0.0426, batch acc 0.9906
18:32:28.743   Training iter 100, batch loss 0.0471, batch acc 0.9864
18:32:28.877   Training iter 150, batch loss 0.0474, batch acc 0.9898
18:32:28.991   Training iter 200, batch loss 0.0494, batch acc 0.9874
18:32:29.105   Training iter 250, batch loss 0.0446, batch acc 0.9898
18:32:29.222   Training iter 300, batch loss 0.0408, batch acc 0.9900
18:32:29.359   Training iter 350, batch loss 0.0468, batch acc 0.9876
18:32:29.521   Training iter 400, batch loss 0.0477, batch acc 0.9870
18:32:29.690   Training iter 450, batch loss 0.0403, batch acc 0.9902
18:32:29.811   Training iter 500, batch loss 0.0484, batch acc 0.9876
18:32:29.926   Training iter 550, batch loss 0.0484, batch acc 0.9872
18:32:30.046   Training iter 600, batch loss 0.0488, batch acc 0.9872
18:32:30.047 Training @ 97 epoch...
18:32:30.181   Training iter 50, batch loss 0.0405, batch acc 0.9914
18:32:30.364   Training iter 100, batch loss 0.0499, batch acc 0.9854
18:32:30.487   Training iter 150, batch loss 0.0425, batch acc 0.9898
18:32:30.617   Training iter 200, batch loss 0.0449, batch acc 0.9894
18:32:30.741   Training iter 250, batch loss 0.0467, batch acc 0.9876
18:32:30.832   Training iter 300, batch loss 0.0399, batch acc 0.9912
18:32:30.977   Training iter 350, batch loss 0.0472, batch acc 0.9888
18:32:31.135   Training iter 400, batch loss 0.0496, batch acc 0.9874
18:32:31.285   Training iter 450, batch loss 0.0557, batch acc 0.9846
18:32:31.389   Training iter 500, batch loss 0.0473, batch acc 0.9894
18:32:31.522   Training iter 550, batch loss 0.0424, batch acc 0.9896
18:32:31.669   Training iter 600, batch loss 0.0476, batch acc 0.9852
18:32:31.670 Training @ 98 epoch...
18:32:31.836   Training iter 50, batch loss 0.0525, batch acc 0.9864
18:32:31.961   Training iter 100, batch loss 0.0461, batch acc 0.9890
18:32:32.091   Training iter 150, batch loss 0.0406, batch acc 0.9912
18:32:32.229   Training iter 200, batch loss 0.0453, batch acc 0.9886
18:32:32.371   Training iter 250, batch loss 0.0424, batch acc 0.9876
18:32:32.492   Training iter 300, batch loss 0.0488, batch acc 0.9886
18:32:32.622   Training iter 350, batch loss 0.0415, batch acc 0.9902
18:32:32.755   Training iter 400, batch loss 0.0472, batch acc 0.9870
18:32:32.879   Training iter 450, batch loss 0.0482, batch acc 0.9870
18:32:33.010   Training iter 500, batch loss 0.0473, batch acc 0.9884
18:32:33.209   Training iter 550, batch loss 0.0467, batch acc 0.9904
18:32:33.340   Training iter 600, batch loss 0.0453, batch acc 0.9884
18:32:33.342 Training @ 99 epoch...
18:32:33.443   Training iter 50, batch loss 0.0438, batch acc 0.9892
18:32:33.537   Training iter 100, batch loss 0.0454, batch acc 0.9894
18:32:33.630   Training iter 150, batch loss 0.0438, batch acc 0.9900
18:32:33.727   Training iter 200, batch loss 0.0476, batch acc 0.9896
18:32:33.846   Training iter 250, batch loss 0.0502, batch acc 0.9876
18:32:33.972   Training iter 300, batch loss 0.0440, batch acc 0.9894
18:32:34.062   Training iter 350, batch loss 0.0464, batch acc 0.9864
18:32:34.178   Training iter 400, batch loss 0.0441, batch acc 0.9896
18:32:34.331   Training iter 450, batch loss 0.0457, batch acc 0.9892
18:32:34.480   Training iter 500, batch loss 0.0447, batch acc 0.9886
18:32:34.587   Training iter 550, batch loss 0.0432, batch acc 0.9890
18:32:34.713   Training iter 600, batch loss 0.0459, batch acc 0.9872
18:32:34.713 Testing @ 99 epoch...
18:32:34.798     Testing, total mean loss 0.07196, total acc 0.97870