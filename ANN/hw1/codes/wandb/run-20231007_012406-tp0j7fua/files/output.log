01:24:11.771 Training @ 0 epoch...
01:24:11.888   Training iter 50, batch loss 2.1418, batch acc 0.3330
01:24:12.034   Training iter 100, batch loss 1.1103, batch acc 0.7340
01:24:12.140   Training iter 150, batch loss 0.5926, batch acc 0.8408
01:24:12.342   Training iter 200, batch loss 0.4821, batch acc 0.8650
01:24:12.450   Training iter 250, batch loss 0.4391, batch acc 0.8810
01:24:12.584   Training iter 300, batch loss 0.3914, batch acc 0.8850
01:24:12.690   Training iter 350, batch loss 0.3607, batch acc 0.8968
01:24:12.784   Training iter 400, batch loss 0.3631, batch acc 0.8908
01:24:12.905   Training iter 450, batch loss 0.3615, batch acc 0.8954
01:24:13.024   Training iter 500, batch loss 0.3369, batch acc 0.9024
01:24:13.163   Training iter 550, batch loss 0.3163, batch acc 0.9048
01:24:13.283   Training iter 600, batch loss 0.3342, batch acc 0.9010
01:24:13.286 Testing @ 0 epoch...
01:24:13.401     Testing, total mean loss 0.33152, total acc 0.90590
01:24:13.402 Training @ 1 epoch...
01:24:13.528   Training iter 50, batch loss 0.3209, batch acc 0.8998
01:24:13.618   Training iter 100, batch loss 0.3224, batch acc 0.9084
01:24:13.725   Training iter 150, batch loss 0.3253, batch acc 0.9040
01:24:13.842   Training iter 200, batch loss 0.3252, batch acc 0.9086
01:24:13.941   Training iter 250, batch loss 0.3129, batch acc 0.9102
01:24:14.056   Training iter 300, batch loss 0.3271, batch acc 0.9022
01:24:14.163   Training iter 350, batch loss 0.2912, batch acc 0.9158
01:24:14.264   Training iter 400, batch loss 0.2957, batch acc 0.9108
01:24:14.374   Training iter 450, batch loss 0.2986, batch acc 0.9118
01:24:14.481   Training iter 500, batch loss 0.3098, batch acc 0.9114
01:24:14.585   Training iter 550, batch loss 0.2738, batch acc 0.9198
01:24:14.693   Training iter 600, batch loss 0.2889, batch acc 0.9172
01:24:14.693 Training @ 2 epoch...
01:24:14.806   Training iter 50, batch loss 0.2824, batch acc 0.9152
01:24:14.899   Training iter 100, batch loss 0.2842, batch acc 0.9186
01:24:15.020   Training iter 150, batch loss 0.2896, batch acc 0.9166
01:24:15.125   Training iter 200, batch loss 0.2853, batch acc 0.9180
01:24:15.227   Training iter 250, batch loss 0.2724, batch acc 0.9220
01:24:15.322   Training iter 300, batch loss 0.2787, batch acc 0.9158
01:24:15.484   Training iter 350, batch loss 0.2689, batch acc 0.9224
01:24:15.639   Training iter 400, batch loss 0.2608, batch acc 0.9260
01:24:15.804   Training iter 450, batch loss 0.2679, batch acc 0.9216
01:24:15.967   Training iter 500, batch loss 0.2783, batch acc 0.9224
01:24:16.124   Training iter 550, batch loss 0.2608, batch acc 0.9252
01:24:16.276   Training iter 600, batch loss 0.2543, batch acc 0.9232
01:24:16.276 Training @ 3 epoch...
01:24:16.457   Training iter 50, batch loss 0.2550, batch acc 0.9280
01:24:16.724   Training iter 100, batch loss 0.2423, batch acc 0.9344
01:24:16.850   Training iter 150, batch loss 0.2341, batch acc 0.9332
01:24:17.034   Training iter 200, batch loss 0.2545, batch acc 0.9274
01:24:17.155   Training iter 250, batch loss 0.2451, batch acc 0.9304
01:24:17.283   Training iter 300, batch loss 0.2479, batch acc 0.9306
01:24:17.372   Training iter 350, batch loss 0.2414, batch acc 0.9320
01:24:17.573   Training iter 400, batch loss 0.2430, batch acc 0.9300
01:24:17.711   Training iter 450, batch loss 0.2436, batch acc 0.9322
01:24:17.809   Training iter 500, batch loss 0.2311, batch acc 0.9302
01:24:17.910   Training iter 550, batch loss 0.2527, batch acc 0.9272
01:24:18.037   Training iter 600, batch loss 0.2325, batch acc 0.9324
01:24:18.038 Training @ 4 epoch...
01:24:18.137   Training iter 50, batch loss 0.2204, batch acc 0.9374
01:24:18.299   Training iter 100, batch loss 0.2235, batch acc 0.9330
01:24:18.410   Training iter 150, batch loss 0.2294, batch acc 0.9348
01:24:18.544   Training iter 200, batch loss 0.2296, batch acc 0.9312
01:24:19.710   Training iter 250, batch loss 0.1934, batch acc 0.9466
01:24:19.807   Training iter 300, batch loss 0.2068, batch acc 0.9440
01:24:19.927   Training iter 350, batch loss 0.2323, batch acc 0.9360
01:24:20.034   Training iter 400, batch loss 0.2233, batch acc 0.9344
01:24:20.127   Training iter 450, batch loss 0.2022, batch acc 0.9452
01:24:20.249   Training iter 500, batch loss 0.1887, batch acc 0.9472
01:24:20.373   Training iter 550, batch loss 0.1897, batch acc 0.9436
01:24:20.536   Training iter 600, batch loss 0.2061, batch acc 0.9384
01:24:20.537 Training @ 5 epoch...
01:24:20.827   Training iter 50, batch loss 0.2006, batch acc 0.9440
01:24:20.932   Training iter 100, batch loss 0.1972, batch acc 0.9436
01:24:21.055   Training iter 150, batch loss 0.1816, batch acc 0.9440
01:24:21.147   Training iter 200, batch loss 0.1918, batch acc 0.9468
01:24:21.257   Training iter 250, batch loss 0.1825, batch acc 0.9486
01:24:21.523   Training iter 300, batch loss 0.1800, batch acc 0.9500
01:24:21.640   Training iter 350, batch loss 0.1979, batch acc 0.9442
01:24:21.801   Training iter 400, batch loss 0.1868, batch acc 0.9462
01:24:21.926   Training iter 450, batch loss 0.1885, batch acc 0.9462
01:24:22.048   Training iter 500, batch loss 0.1846, batch acc 0.9504
01:24:22.189   Training iter 550, batch loss 0.1826, batch acc 0.9454
01:24:22.317   Training iter 600, batch loss 0.1906, batch acc 0.9470
01:24:22.318 Testing @ 5 epoch...
01:24:22.444     Testing, total mean loss 0.18204, total acc 0.94870
01:24:22.444 Training @ 6 epoch...
01:24:22.542   Training iter 50, batch loss 0.1743, batch acc 0.9500
01:24:22.672   Training iter 100, batch loss 0.1741, batch acc 0.9500
01:24:23.000   Training iter 150, batch loss 0.1799, batch acc 0.9502
01:24:23.085   Training iter 200, batch loss 0.1756, batch acc 0.9524
01:24:23.232   Training iter 250, batch loss 0.1763, batch acc 0.9498
01:24:23.327   Training iter 300, batch loss 0.1864, batch acc 0.9474
01:24:23.603   Training iter 350, batch loss 0.1686, batch acc 0.9486
01:24:23.699   Training iter 400, batch loss 0.1717, batch acc 0.9506
01:24:23.793   Training iter 450, batch loss 0.1719, batch acc 0.9510
01:24:23.899   Training iter 500, batch loss 0.1674, batch acc 0.9504
01:24:24.019   Training iter 550, batch loss 0.1586, batch acc 0.9570
01:24:24.240   Training iter 600, batch loss 0.1626, batch acc 0.9558
01:24:24.242 Training @ 7 epoch...
01:24:24.464   Training iter 50, batch loss 0.1751, batch acc 0.9516
01:24:24.587   Training iter 100, batch loss 0.1578, batch acc 0.9574
01:24:24.781   Training iter 150, batch loss 0.1605, batch acc 0.9534
01:24:24.876   Training iter 200, batch loss 0.1745, batch acc 0.9478
01:24:24.960   Training iter 250, batch loss 0.1500, batch acc 0.9560
01:24:25.070   Training iter 300, batch loss 0.1474, batch acc 0.9586
01:24:25.152   Training iter 350, batch loss 0.1428, batch acc 0.9580
01:24:25.255   Training iter 400, batch loss 0.1516, batch acc 0.9580
01:24:25.347   Training iter 450, batch loss 0.1475, batch acc 0.9586
01:24:25.426   Training iter 500, batch loss 0.1525, batch acc 0.9542
01:24:25.531   Training iter 550, batch loss 0.1555, batch acc 0.9542
01:24:25.718   Training iter 600, batch loss 0.1599, batch acc 0.9554
01:24:25.718 Training @ 8 epoch...
01:24:25.864   Training iter 50, batch loss 0.1411, batch acc 0.9584
01:24:25.985   Training iter 100, batch loss 0.1525, batch acc 0.9552
01:24:26.073   Training iter 150, batch loss 0.1428, batch acc 0.9572
01:24:26.242   Training iter 200, batch loss 0.1371, batch acc 0.9594
01:24:26.419   Training iter 250, batch loss 0.1462, batch acc 0.9598
01:24:26.540   Training iter 300, batch loss 0.1459, batch acc 0.9622
01:24:26.738   Training iter 350, batch loss 0.1427, batch acc 0.9612
01:24:26.869   Training iter 400, batch loss 0.1315, batch acc 0.9610
01:24:27.019   Training iter 450, batch loss 0.1421, batch acc 0.9578
01:24:27.165   Training iter 500, batch loss 0.1462, batch acc 0.9610
01:24:27.300   Training iter 550, batch loss 0.1442, batch acc 0.9594
01:24:27.415   Training iter 600, batch loss 0.1533, batch acc 0.9556
01:24:27.416 Training @ 9 epoch...
01:24:27.573   Training iter 50, batch loss 0.1349, batch acc 0.9642
01:24:27.685   Training iter 100, batch loss 0.1230, batch acc 0.9644
01:24:28.222   Training iter 150, batch loss 0.1381, batch acc 0.9590
01:24:28.341   Training iter 200, batch loss 0.1383, batch acc 0.9578
01:24:28.488   Training iter 250, batch loss 0.1431, batch acc 0.9606
01:24:28.586   Training iter 300, batch loss 0.1389, batch acc 0.9624
01:24:28.887   Training iter 350, batch loss 0.1431, batch acc 0.9580
01:24:29.067   Training iter 400, batch loss 0.1265, batch acc 0.9620
01:24:29.235   Training iter 450, batch loss 0.1219, batch acc 0.9618
01:24:29.330   Training iter 500, batch loss 0.1303, batch acc 0.9608
01:24:29.448   Training iter 550, batch loss 0.1252, batch acc 0.9620
01:24:29.559   Training iter 600, batch loss 0.1354, batch acc 0.9610
01:24:29.560 Training @ 10 epoch...
01:24:29.656   Training iter 50, batch loss 0.1209, batch acc 0.9672
01:24:29.742   Training iter 100, batch loss 0.1277, batch acc 0.9652
01:24:29.873   Training iter 150, batch loss 0.1227, batch acc 0.9636
01:24:30.015   Training iter 200, batch loss 0.1342, batch acc 0.9632
01:24:30.116   Training iter 250, batch loss 0.1237, batch acc 0.9682
01:24:30.282   Training iter 300, batch loss 0.1271, batch acc 0.9656
01:24:30.397   Training iter 350, batch loss 0.1141, batch acc 0.9692
01:24:30.534   Training iter 400, batch loss 0.1281, batch acc 0.9638
01:24:30.858   Training iter 450, batch loss 0.1204, batch acc 0.9662
01:24:31.004   Training iter 500, batch loss 0.1337, batch acc 0.9608
01:24:31.123   Training iter 550, batch loss 0.1227, batch acc 0.9610
01:24:31.376   Training iter 600, batch loss 0.1312, batch acc 0.9610
01:24:31.376 Testing @ 10 epoch...
01:24:31.461     Testing, total mean loss 0.12978, total acc 0.96160
01:24:31.461 Training @ 11 epoch...
01:24:31.599   Training iter 50, batch loss 0.1042, batch acc 0.9700
01:24:31.705   Training iter 100, batch loss 0.1099, batch acc 0.9674
01:24:31.815   Training iter 150, batch loss 0.1078, batch acc 0.9680
01:24:31.920   Training iter 200, batch loss 0.1121, batch acc 0.9698
01:24:32.053   Training iter 250, batch loss 0.1133, batch acc 0.9652
01:24:32.155   Training iter 300, batch loss 0.1262, batch acc 0.9602
01:24:32.251   Training iter 350, batch loss 0.1330, batch acc 0.9622
01:24:32.336   Training iter 400, batch loss 0.1117, batch acc 0.9678
01:24:32.450   Training iter 450, batch loss 0.1347, batch acc 0.9598
01:24:32.552   Training iter 500, batch loss 0.1295, batch acc 0.9620
01:24:32.653   Training iter 550, batch loss 0.1075, batch acc 0.9698
01:24:32.751   Training iter 600, batch loss 0.1269, batch acc 0.9628
01:24:32.752 Training @ 12 epoch...
01:24:32.870   Training iter 50, batch loss 0.1116, batch acc 0.9666
01:24:33.002   Training iter 100, batch loss 0.1220, batch acc 0.9660
01:24:33.114   Training iter 150, batch loss 0.1152, batch acc 0.9686
01:24:33.221   Training iter 200, batch loss 0.1033, batch acc 0.9700
01:24:33.330   Training iter 250, batch loss 0.1171, batch acc 0.9672
01:24:33.433   Training iter 300, batch loss 0.1097, batch acc 0.9676
01:24:33.617   Training iter 350, batch loss 0.1045, batch acc 0.9714
01:24:33.711   Training iter 400, batch loss 0.1072, batch acc 0.9678
01:24:33.800   Training iter 450, batch loss 0.1050, batch acc 0.9690
01:24:33.913   Training iter 500, batch loss 0.1169, batch acc 0.9682
01:24:34.005   Training iter 550, batch loss 0.1035, batch acc 0.9694
01:24:34.103   Training iter 600, batch loss 0.1168, batch acc 0.9672
01:24:34.104 Training @ 13 epoch...
01:24:34.210   Training iter 50, batch loss 0.1063, batch acc 0.9704
01:24:34.351   Training iter 100, batch loss 0.1077, batch acc 0.9690
01:24:34.441   Training iter 150, batch loss 0.1057, batch acc 0.9722
01:24:34.532   Training iter 200, batch loss 0.0982, batch acc 0.9710
01:24:34.619   Training iter 250, batch loss 0.1027, batch acc 0.9708
01:24:34.710   Training iter 300, batch loss 0.1122, batch acc 0.9650
01:24:34.810   Training iter 350, batch loss 0.0995, batch acc 0.9732
01:24:34.904   Training iter 400, batch loss 0.0964, batch acc 0.9752
01:24:34.996   Training iter 450, batch loss 0.1127, batch acc 0.9708
01:24:35.110   Training iter 500, batch loss 0.1189, batch acc 0.9662
01:24:35.201   Training iter 550, batch loss 0.0995, batch acc 0.9734
01:24:35.299   Training iter 600, batch loss 0.1066, batch acc 0.9680
01:24:35.301 Training @ 14 epoch...
01:24:35.393   Training iter 50, batch loss 0.0923, batch acc 0.9740
01:24:35.486   Training iter 100, batch loss 0.1005, batch acc 0.9726
01:24:35.582   Training iter 150, batch loss 0.1073, batch acc 0.9670
01:24:35.688   Training iter 200, batch loss 0.1064, batch acc 0.9708
01:24:35.784   Training iter 250, batch loss 0.1009, batch acc 0.9732
01:24:35.901   Training iter 300, batch loss 0.1027, batch acc 0.9672
01:24:36.005   Training iter 350, batch loss 0.1069, batch acc 0.9692
01:24:36.107   Training iter 400, batch loss 0.1005, batch acc 0.9712
01:24:36.226   Training iter 450, batch loss 0.1021, batch acc 0.9746
01:24:36.356   Training iter 500, batch loss 0.0952, batch acc 0.9734
01:24:36.450   Training iter 550, batch loss 0.1005, batch acc 0.9682
01:24:36.563   Training iter 600, batch loss 0.1120, batch acc 0.9676
01:24:36.563 Training @ 15 epoch...
01:24:36.651   Training iter 50, batch loss 0.0963, batch acc 0.9726
01:24:36.763   Training iter 100, batch loss 0.0905, batch acc 0.9752
01:24:36.874   Training iter 150, batch loss 0.0975, batch acc 0.9716
01:24:36.984   Training iter 200, batch loss 0.1070, batch acc 0.9672
01:24:37.107   Training iter 250, batch loss 0.0868, batch acc 0.9752
01:24:37.228   Training iter 300, batch loss 0.1063, batch acc 0.9720
01:24:37.329   Training iter 350, batch loss 0.0970, batch acc 0.9720
01:24:37.424   Training iter 400, batch loss 0.0912, batch acc 0.9746
01:24:37.508   Training iter 450, batch loss 0.0973, batch acc 0.9724
01:24:37.622   Training iter 500, batch loss 0.0935, batch acc 0.9728
01:24:37.740   Training iter 550, batch loss 0.1047, batch acc 0.9692
01:24:37.851   Training iter 600, batch loss 0.1058, batch acc 0.9700
01:24:37.852 Testing @ 15 epoch...
01:24:37.939     Testing, total mean loss 0.11149, total acc 0.96630
01:24:37.940 Training @ 16 epoch...
01:24:38.063   Training iter 50, batch loss 0.0961, batch acc 0.9744
01:24:38.153   Training iter 100, batch loss 0.0833, batch acc 0.9764
01:24:38.335   Training iter 150, batch loss 0.1068, batch acc 0.9672
01:24:38.492   Training iter 200, batch loss 0.0908, batch acc 0.9750
01:24:38.647   Training iter 250, batch loss 0.0915, batch acc 0.9752
01:24:38.775   Training iter 300, batch loss 0.0832, batch acc 0.9778
01:24:38.906   Training iter 350, batch loss 0.0900, batch acc 0.9770
01:24:39.159   Training iter 400, batch loss 0.0964, batch acc 0.9752
01:24:39.297   Training iter 450, batch loss 0.1033, batch acc 0.9692
01:24:39.498   Training iter 500, batch loss 0.0957, batch acc 0.9734
01:24:39.641   Training iter 550, batch loss 0.0923, batch acc 0.9714
01:24:39.726   Training iter 600, batch loss 0.0872, batch acc 0.9764
01:24:39.729 Training @ 17 epoch...
01:24:39.871   Training iter 50, batch loss 0.0891, batch acc 0.9768
01:24:40.070   Training iter 100, batch loss 0.0981, batch acc 0.9722
01:24:40.161   Training iter 150, batch loss 0.0959, batch acc 0.9744
01:24:40.239   Training iter 200, batch loss 0.0895, batch acc 0.9738
01:24:40.351   Training iter 250, batch loss 0.0823, batch acc 0.9778
01:24:40.448   Training iter 300, batch loss 0.0854, batch acc 0.9762
01:24:40.540   Training iter 350, batch loss 0.0880, batch acc 0.9750
01:24:40.765   Training iter 400, batch loss 0.0924, batch acc 0.9722
01:24:40.871   Training iter 450, batch loss 0.0852, batch acc 0.9760
01:24:40.960   Training iter 500, batch loss 0.0947, batch acc 0.9756
01:24:41.175   Training iter 550, batch loss 0.0977, batch acc 0.9696
01:24:41.292   Training iter 600, batch loss 0.0835, batch acc 0.9754
01:24:41.293 Training @ 18 epoch...
01:24:41.429   Training iter 50, batch loss 0.0818, batch acc 0.9766
01:24:41.529   Training iter 100, batch loss 0.0862, batch acc 0.9764
01:24:41.676   Training iter 150, batch loss 0.0905, batch acc 0.9750
01:24:41.818   Training iter 200, batch loss 0.0916, batch acc 0.9754
01:24:41.927   Training iter 250, batch loss 0.0826, batch acc 0.9744
01:24:42.053   Training iter 300, batch loss 0.0883, batch acc 0.9724
01:24:42.196   Training iter 350, batch loss 0.0840, batch acc 0.9744
01:24:42.313   Training iter 400, batch loss 0.0846, batch acc 0.9764
01:24:42.416   Training iter 450, batch loss 0.0844, batch acc 0.9746
01:24:42.539   Training iter 500, batch loss 0.0870, batch acc 0.9784
01:24:42.647   Training iter 550, batch loss 0.0846, batch acc 0.9744
01:24:42.746   Training iter 600, batch loss 0.0919, batch acc 0.9754
01:24:42.747 Training @ 19 epoch...
01:24:42.854   Training iter 50, batch loss 0.0786, batch acc 0.9772
01:24:42.949   Training iter 100, batch loss 0.0741, batch acc 0.9812
01:24:43.053   Training iter 150, batch loss 0.0807, batch acc 0.9760
01:24:43.153   Training iter 200, batch loss 0.0927, batch acc 0.9744
01:24:43.235   Training iter 250, batch loss 0.0913, batch acc 0.9740
01:24:43.333   Training iter 300, batch loss 0.0808, batch acc 0.9776
01:24:43.424   Training iter 350, batch loss 0.0784, batch acc 0.9786
01:24:43.523   Training iter 400, batch loss 0.0971, batch acc 0.9718
01:24:43.750   Training iter 450, batch loss 0.0841, batch acc 0.9750
01:24:43.867   Training iter 500, batch loss 0.0804, batch acc 0.9752
01:24:44.014   Training iter 550, batch loss 0.0844, batch acc 0.9758
01:24:44.190   Training iter 600, batch loss 0.0877, batch acc 0.9742
01:24:44.192 Training @ 20 epoch...
01:24:44.434   Training iter 50, batch loss 0.0787, batch acc 0.9766
01:24:44.569   Training iter 100, batch loss 0.0803, batch acc 0.9784
01:24:44.724   Training iter 150, batch loss 0.0759, batch acc 0.9782
01:24:44.902   Training iter 200, batch loss 0.0746, batch acc 0.9788
01:24:45.075   Training iter 250, batch loss 0.0861, batch acc 0.9752
01:24:45.170   Training iter 300, batch loss 0.0785, batch acc 0.9788
01:24:45.274   Training iter 350, batch loss 0.0819, batch acc 0.9770
01:24:45.402   Training iter 400, batch loss 0.0804, batch acc 0.9756
01:24:45.509   Training iter 450, batch loss 0.0877, batch acc 0.9736
01:24:45.606   Training iter 500, batch loss 0.0749, batch acc 0.9792
01:24:45.709   Training iter 550, batch loss 0.0937, batch acc 0.9716
01:24:45.837   Training iter 600, batch loss 0.0895, batch acc 0.9754
01:24:45.839 Testing @ 20 epoch...
01:24:45.934     Testing, total mean loss 0.10068, total acc 0.96900
01:24:45.934 Training @ 21 epoch...
01:24:46.049   Training iter 50, batch loss 0.0856, batch acc 0.9736
01:24:46.169   Training iter 100, batch loss 0.0752, batch acc 0.9782
01:24:46.318   Training iter 150, batch loss 0.0854, batch acc 0.9764
01:24:46.445   Training iter 200, batch loss 0.0736, batch acc 0.9804
01:24:46.551   Training iter 250, batch loss 0.0807, batch acc 0.9762
01:24:46.651   Training iter 300, batch loss 0.0823, batch acc 0.9742
01:24:46.734   Training iter 350, batch loss 0.0894, batch acc 0.9746
01:24:46.859   Training iter 400, batch loss 0.0724, batch acc 0.9796
01:24:47.007   Training iter 450, batch loss 0.0770, batch acc 0.9776
01:24:47.134   Training iter 500, batch loss 0.0751, batch acc 0.9804
01:24:47.252   Training iter 550, batch loss 0.0742, batch acc 0.9786
01:24:47.371   Training iter 600, batch loss 0.0792, batch acc 0.9762
01:24:47.371 Training @ 22 epoch...
01:24:47.510   Training iter 50, batch loss 0.0691, batch acc 0.9804
01:24:47.653   Training iter 100, batch loss 0.0764, batch acc 0.9778
01:24:47.756   Training iter 150, batch loss 0.0730, batch acc 0.9800
01:24:47.879   Training iter 200, batch loss 0.0842, batch acc 0.9782
01:24:47.972   Training iter 250, batch loss 0.0762, batch acc 0.9770
01:24:48.073   Training iter 300, batch loss 0.0797, batch acc 0.9792
01:24:48.162   Training iter 350, batch loss 0.0712, batch acc 0.9790
01:24:48.268   Training iter 400, batch loss 0.0730, batch acc 0.9794
01:24:48.354   Training iter 450, batch loss 0.0781, batch acc 0.9770
01:24:48.455   Training iter 500, batch loss 0.0870, batch acc 0.9734
01:24:48.558   Training iter 550, batch loss 0.0689, batch acc 0.9818
01:24:48.658   Training iter 600, batch loss 0.0805, batch acc 0.9768
01:24:48.660 Training @ 23 epoch...
01:24:48.768   Training iter 50, batch loss 0.0713, batch acc 0.9822
01:24:48.866   Training iter 100, batch loss 0.0813, batch acc 0.9778
01:24:48.955   Training iter 150, batch loss 0.0710, batch acc 0.9788
01:24:49.048   Training iter 200, batch loss 0.0765, batch acc 0.9780
01:24:49.148   Training iter 250, batch loss 0.0740, batch acc 0.9812
01:24:49.234   Training iter 300, batch loss 0.0712, batch acc 0.9800
01:24:49.340   Training iter 350, batch loss 0.0735, batch acc 0.9776
01:24:49.439   Training iter 400, batch loss 0.0811, batch acc 0.9766
01:24:49.540   Training iter 450, batch loss 0.0905, batch acc 0.9708
01:24:49.635   Training iter 500, batch loss 0.0764, batch acc 0.9788
01:24:49.801   Training iter 550, batch loss 0.0712, batch acc 0.9814
01:24:49.908   Training iter 600, batch loss 0.0757, batch acc 0.9784
01:24:49.909 Training @ 24 epoch...
01:24:50.015   Training iter 50, batch loss 0.0825, batch acc 0.9764
01:24:50.131   Training iter 100, batch loss 0.0668, batch acc 0.9820
01:24:50.244   Training iter 150, batch loss 0.0728, batch acc 0.9788
01:24:50.374   Training iter 200, batch loss 0.0713, batch acc 0.9788
01:24:50.492   Training iter 250, batch loss 0.0760, batch acc 0.9774
01:24:50.585   Training iter 300, batch loss 0.0741, batch acc 0.9796
01:24:50.681   Training iter 350, batch loss 0.0757, batch acc 0.9790
01:24:50.768   Training iter 400, batch loss 0.0660, batch acc 0.9832
01:24:50.901   Training iter 450, batch loss 0.0704, batch acc 0.9794
01:24:50.999   Training iter 500, batch loss 0.0739, batch acc 0.9782
01:24:51.100   Training iter 550, batch loss 0.0798, batch acc 0.9770
01:24:51.209   Training iter 600, batch loss 0.0761, batch acc 0.9800
01:24:51.211 Training @ 25 epoch...
01:24:51.308   Training iter 50, batch loss 0.0785, batch acc 0.9802
01:24:51.402   Training iter 100, batch loss 0.0741, batch acc 0.9804
01:24:51.506   Training iter 150, batch loss 0.0720, batch acc 0.9792
01:24:51.623   Training iter 200, batch loss 0.0708, batch acc 0.9822
01:24:51.726   Training iter 250, batch loss 0.0643, batch acc 0.9828
01:24:51.835   Training iter 300, batch loss 0.0690, batch acc 0.9822
01:24:51.924   Training iter 350, batch loss 0.0716, batch acc 0.9808
01:24:52.020   Training iter 400, batch loss 0.0633, batch acc 0.9820
01:24:52.113   Training iter 450, batch loss 0.0778, batch acc 0.9760
01:24:52.220   Training iter 500, batch loss 0.0800, batch acc 0.9784
01:24:52.325   Training iter 550, batch loss 0.0698, batch acc 0.9802
01:24:52.460   Training iter 600, batch loss 0.0749, batch acc 0.9800
01:24:52.461 Testing @ 25 epoch...
01:24:52.555     Testing, total mean loss 0.08857, total acc 0.97280
01:24:52.555 Training @ 26 epoch...
01:24:52.702   Training iter 50, batch loss 0.0708, batch acc 0.9810
01:24:52.833   Training iter 100, batch loss 0.0674, batch acc 0.9804
01:24:53.022   Training iter 150, batch loss 0.0707, batch acc 0.9778
01:24:53.150   Training iter 200, batch loss 0.0714, batch acc 0.9814
01:24:53.331   Training iter 250, batch loss 0.0708, batch acc 0.9784
01:24:53.437   Training iter 300, batch loss 0.0695, batch acc 0.9810
01:24:53.552   Training iter 350, batch loss 0.0602, batch acc 0.9846
01:24:53.786   Training iter 400, batch loss 0.0788, batch acc 0.9764
01:24:53.904   Training iter 450, batch loss 0.0727, batch acc 0.9792
01:24:54.016   Training iter 500, batch loss 0.0742, batch acc 0.9812
01:24:54.124   Training iter 550, batch loss 0.0647, batch acc 0.9810
01:24:54.315   Training iter 600, batch loss 0.0755, batch acc 0.9794
01:24:54.316 Training @ 27 epoch...
01:24:54.422   Training iter 50, batch loss 0.0672, batch acc 0.9816
01:24:54.597   Training iter 100, batch loss 0.0668, batch acc 0.9832
01:24:54.689   Training iter 150, batch loss 0.0622, batch acc 0.9830
01:24:54.806   Training iter 200, batch loss 0.0582, batch acc 0.9830
01:24:54.913   Training iter 250, batch loss 0.0665, batch acc 0.9808
01:24:55.018   Training iter 300, batch loss 0.0726, batch acc 0.9786
01:24:55.154   Training iter 350, batch loss 0.0737, batch acc 0.9788
01:24:55.258   Training iter 400, batch loss 0.0802, batch acc 0.9768
01:24:55.383   Training iter 450, batch loss 0.0797, batch acc 0.9774
01:24:55.529   Training iter 500, batch loss 0.0686, batch acc 0.9818
01:24:55.659   Training iter 550, batch loss 0.0642, batch acc 0.9836
01:24:55.806   Training iter 600, batch loss 0.0734, batch acc 0.9796
01:24:55.808 Training @ 28 epoch...
01:24:55.925   Training iter 50, batch loss 0.0736, batch acc 0.9776
01:24:56.040   Training iter 100, batch loss 0.0699, batch acc 0.9818
01:24:56.187   Training iter 150, batch loss 0.0677, batch acc 0.9806
01:24:56.285   Training iter 200, batch loss 0.0638, batch acc 0.9846
01:24:56.371   Training iter 250, batch loss 0.0639, batch acc 0.9834
01:24:56.472   Training iter 300, batch loss 0.0630, batch acc 0.9840
01:24:56.598   Training iter 350, batch loss 0.0719, batch acc 0.9784
01:24:56.702   Training iter 400, batch loss 0.0685, batch acc 0.9782
01:24:56.812   Training iter 450, batch loss 0.0649, batch acc 0.9808
01:24:56.937   Training iter 500, batch loss 0.0718, batch acc 0.9796
01:24:57.060   Training iter 550, batch loss 0.0660, batch acc 0.9826
01:24:57.181   Training iter 600, batch loss 0.0639, batch acc 0.9842
01:24:57.182 Training @ 29 epoch...
01:24:57.383   Training iter 50, batch loss 0.0612, batch acc 0.9838
01:24:57.520   Training iter 100, batch loss 0.0692, batch acc 0.9818
01:24:57.689   Training iter 150, batch loss 0.0700, batch acc 0.9806
01:24:57.783   Training iter 200, batch loss 0.0637, batch acc 0.9838
01:24:57.906   Training iter 250, batch loss 0.0654, batch acc 0.9808
01:24:58.070   Training iter 300, batch loss 0.0649, batch acc 0.9826
01:24:58.186   Training iter 350, batch loss 0.0703, batch acc 0.9784
01:24:58.324   Training iter 400, batch loss 0.0705, batch acc 0.9782
01:24:58.438   Training iter 450, batch loss 0.0685, batch acc 0.9810
01:24:58.564   Training iter 500, batch loss 0.0674, batch acc 0.9830
01:24:58.699   Training iter 550, batch loss 0.0687, batch acc 0.9824
01:24:58.809   Training iter 600, batch loss 0.0671, batch acc 0.9826
01:24:58.813 Training @ 30 epoch...
01:24:58.948   Training iter 50, batch loss 0.0522, batch acc 0.9862
01:24:59.039   Training iter 100, batch loss 0.0639, batch acc 0.9844
01:24:59.135   Training iter 150, batch loss 0.0663, batch acc 0.9814
01:24:59.222   Training iter 200, batch loss 0.0658, batch acc 0.9810
01:24:59.318   Training iter 250, batch loss 0.0641, batch acc 0.9840
01:24:59.413   Training iter 300, batch loss 0.0694, batch acc 0.9806
01:24:59.528   Training iter 350, batch loss 0.0636, batch acc 0.9826
01:24:59.621   Training iter 400, batch loss 0.0679, batch acc 0.9812
01:24:59.700   Training iter 450, batch loss 0.0619, batch acc 0.9822
01:24:59.898   Training iter 500, batch loss 0.0744, batch acc 0.9780
01:25:00.023   Training iter 550, batch loss 0.0753, batch acc 0.9798
01:25:00.123   Training iter 600, batch loss 0.0659, batch acc 0.9832
01:25:00.125 Testing @ 30 epoch...
01:25:00.200     Testing, total mean loss 0.08413, total acc 0.97510
01:25:00.200 Training @ 31 epoch...
01:25:00.363   Training iter 50, batch loss 0.0606, batch acc 0.9842
01:25:00.485   Training iter 100, batch loss 0.0582, batch acc 0.9850
01:25:00.570   Training iter 150, batch loss 0.0568, batch acc 0.9864
01:25:00.684   Training iter 200, batch loss 0.0599, batch acc 0.9820
01:25:00.774   Training iter 250, batch loss 0.0760, batch acc 0.9770
01:25:00.884   Training iter 300, batch loss 0.0627, batch acc 0.9840
01:25:01.015   Training iter 350, batch loss 0.0569, batch acc 0.9846
01:25:01.136   Training iter 400, batch loss 0.0691, batch acc 0.9808
01:25:01.234   Training iter 450, batch loss 0.0626, batch acc 0.9834
01:25:01.343   Training iter 500, batch loss 0.0673, batch acc 0.9804
01:25:01.466   Training iter 550, batch loss 0.0712, batch acc 0.9798
01:25:01.586   Training iter 600, batch loss 0.0636, batch acc 0.9816
01:25:01.587 Training @ 32 epoch...
01:25:01.804   Training iter 50, batch loss 0.0636, batch acc 0.9808
01:25:01.909   Training iter 100, batch loss 0.0578, batch acc 0.9844
01:25:02.019   Training iter 150, batch loss 0.0667, batch acc 0.9822
01:25:02.192   Training iter 200, batch loss 0.0696, batch acc 0.9810
01:25:02.288   Training iter 250, batch loss 0.0647, batch acc 0.9826
01:25:02.388   Training iter 300, batch loss 0.0629, batch acc 0.9834
01:25:02.534   Training iter 350, batch loss 0.0569, batch acc 0.9842
01:25:02.673   Training iter 400, batch loss 0.0666, batch acc 0.9812
01:25:02.834   Training iter 450, batch loss 0.0665, batch acc 0.9816
01:25:03.056   Training iter 500, batch loss 0.0659, batch acc 0.9824
01:25:03.204   Training iter 550, batch loss 0.0641, batch acc 0.9826
01:25:03.308   Training iter 600, batch loss 0.0712, batch acc 0.9812
01:25:03.310 Training @ 33 epoch...
01:25:03.513   Training iter 50, batch loss 0.0617, batch acc 0.9844
01:25:03.643   Training iter 100, batch loss 0.0604, batch acc 0.9852
01:25:03.867   Training iter 150, batch loss 0.0701, batch acc 0.9784
01:25:04.052   Training iter 200, batch loss 0.0618, batch acc 0.9822
01:25:04.243   Training iter 250, batch loss 0.0690, batch acc 0.9812
01:25:04.541   Training iter 300, batch loss 0.0587, batch acc 0.9860
01:25:04.651   Training iter 350, batch loss 0.0593, batch acc 0.9850
01:25:04.776   Training iter 400, batch loss 0.0685, batch acc 0.9802
01:25:04.898   Training iter 450, batch loss 0.0582, batch acc 0.9860
01:25:05.001   Training iter 500, batch loss 0.0634, batch acc 0.9834
01:25:05.098   Training iter 550, batch loss 0.0576, batch acc 0.9830
01:25:05.199   Training iter 600, batch loss 0.0648, batch acc 0.9786
01:25:05.201 Training @ 34 epoch...
01:25:05.329   Training iter 50, batch loss 0.0557, batch acc 0.9842
01:25:05.466   Training iter 100, batch loss 0.0552, batch acc 0.9864
01:25:05.558   Training iter 150, batch loss 0.0589, batch acc 0.9846
01:25:05.667   Training iter 200, batch loss 0.0639, batch acc 0.9848
01:25:05.797   Training iter 250, batch loss 0.0648, batch acc 0.9808
01:25:05.917   Training iter 300, batch loss 0.0619, batch acc 0.9830
01:25:06.052   Training iter 350, batch loss 0.0669, batch acc 0.9814
01:25:06.157   Training iter 400, batch loss 0.0713, batch acc 0.9784
01:25:06.241   Training iter 450, batch loss 0.0679, batch acc 0.9808
01:25:06.416   Training iter 500, batch loss 0.0631, batch acc 0.9828
01:25:06.536   Training iter 550, batch loss 0.0621, batch acc 0.9840
01:25:06.656   Training iter 600, batch loss 0.0710, batch acc 0.9802
01:25:06.656 Training @ 35 epoch...
01:25:06.818   Training iter 50, batch loss 0.0593, batch acc 0.9834
01:25:06.941   Training iter 100, batch loss 0.0581, batch acc 0.9832
01:25:07.158   Training iter 150, batch loss 0.0626, batch acc 0.9834
01:25:07.300   Training iter 200, batch loss 0.0605, batch acc 0.9830
01:25:07.390   Training iter 250, batch loss 0.0686, batch acc 0.9798
01:25:07.496   Training iter 300, batch loss 0.0680, batch acc 0.9786
01:25:07.602   Training iter 350, batch loss 0.0640, batch acc 0.9802
01:25:07.691   Training iter 400, batch loss 0.0642, batch acc 0.9816
01:25:07.781   Training iter 450, batch loss 0.0568, batch acc 0.9852
01:25:07.869   Training iter 500, batch loss 0.0627, batch acc 0.9818
01:25:07.956   Training iter 550, batch loss 0.0582, batch acc 0.9864
01:25:08.050   Training iter 600, batch loss 0.0589, batch acc 0.9850
01:25:08.050 Testing @ 35 epoch...
01:25:08.149     Testing, total mean loss 0.08287, total acc 0.97570
01:25:08.149 Training @ 36 epoch...
01:25:08.304   Training iter 50, batch loss 0.0553, batch acc 0.9850
01:25:08.435   Training iter 100, batch loss 0.0582, batch acc 0.9864
01:25:08.613   Training iter 150, batch loss 0.0541, batch acc 0.9852
01:25:08.762   Training iter 200, batch loss 0.0598, batch acc 0.9846
01:25:08.902   Training iter 250, batch loss 0.0637, batch acc 0.9846
01:25:09.016   Training iter 300, batch loss 0.0616, batch acc 0.9836
01:25:09.179   Training iter 350, batch loss 0.0638, batch acc 0.9832
01:25:09.405   Training iter 400, batch loss 0.0596, batch acc 0.9836
01:25:09.592   Training iter 450, batch loss 0.0586, batch acc 0.9844
01:25:09.764   Training iter 500, batch loss 0.0611, batch acc 0.9846
01:25:09.897   Training iter 550, batch loss 0.0579, batch acc 0.9848
01:25:10.137   Training iter 600, batch loss 0.0674, batch acc 0.9790
01:25:10.137 Training @ 37 epoch...
01:25:10.306   Training iter 50, batch loss 0.0661, batch acc 0.9824
01:25:10.466   Training iter 100, batch loss 0.0582, batch acc 0.9852
01:25:10.648   Training iter 150, batch loss 0.0585, batch acc 0.9850
01:25:10.748   Training iter 200, batch loss 0.0619, batch acc 0.9814
01:25:10.862   Training iter 250, batch loss 0.0640, batch acc 0.9816
01:25:11.043   Training iter 300, batch loss 0.0613, batch acc 0.9836
01:25:11.216   Training iter 350, batch loss 0.0548, batch acc 0.9848
01:25:11.318   Training iter 400, batch loss 0.0662, batch acc 0.9810
01:25:11.446   Training iter 450, batch loss 0.0566, batch acc 0.9872
01:25:11.557   Training iter 500, batch loss 0.0568, batch acc 0.9836
01:25:11.800   Training iter 550, batch loss 0.0550, batch acc 0.9852
01:25:12.016   Training iter 600, batch loss 0.0542, batch acc 0.9862
01:25:12.016 Training @ 38 epoch...
01:25:12.208   Training iter 50, batch loss 0.0544, batch acc 0.9866
01:25:12.334   Training iter 100, batch loss 0.0558, batch acc 0.9852
01:25:12.497   Training iter 150, batch loss 0.0512, batch acc 0.9866
01:25:12.628   Training iter 200, batch loss 0.0575, batch acc 0.9832
01:25:12.809   Training iter 250, batch loss 0.0580, batch acc 0.9824
01:25:12.901   Training iter 300, batch loss 0.0577, batch acc 0.9850
01:25:12.990   Training iter 350, batch loss 0.0658, batch acc 0.9792
01:25:13.059   Training iter 400, batch loss 0.0640, batch acc 0.9808
01:25:13.250   Training iter 450, batch loss 0.0565, batch acc 0.9834
01:25:13.401   Training iter 500, batch loss 0.0614, batch acc 0.9838
01:25:13.506   Training iter 550, batch loss 0.0599, batch acc 0.9830
01:25:13.626   Training iter 600, batch loss 0.0620, batch acc 0.9850
01:25:13.627 Training @ 39 epoch...
01:25:13.752   Training iter 50, batch loss 0.0550, batch acc 0.9862
01:25:13.875   Training iter 100, batch loss 0.0527, batch acc 0.9880
01:25:14.021   Training iter 150, batch loss 0.0536, batch acc 0.9868
01:25:14.202   Training iter 200, batch loss 0.0634, batch acc 0.9834
01:25:14.332   Training iter 250, batch loss 0.0591, batch acc 0.9850
01:25:14.452   Training iter 300, batch loss 0.0578, batch acc 0.9838
01:25:14.582   Training iter 350, batch loss 0.0552, batch acc 0.9862
01:25:14.708   Training iter 400, batch loss 0.0566, batch acc 0.9850
01:25:14.903   Training iter 450, batch loss 0.0563, batch acc 0.9844
01:25:15.064   Training iter 500, batch loss 0.0584, batch acc 0.9838
01:25:15.206   Training iter 550, batch loss 0.0618, batch acc 0.9848
01:25:15.351   Training iter 600, batch loss 0.0657, batch acc 0.9830
01:25:15.352 Training @ 40 epoch...
01:25:15.508   Training iter 50, batch loss 0.0566, batch acc 0.9862
01:25:15.642   Training iter 100, batch loss 0.0541, batch acc 0.9844
01:25:15.736   Training iter 150, batch loss 0.0574, batch acc 0.9850
01:25:16.002   Training iter 200, batch loss 0.0591, batch acc 0.9848
01:25:16.200   Training iter 250, batch loss 0.0585, batch acc 0.9838
01:25:16.386   Training iter 300, batch loss 0.0551, batch acc 0.9844
01:25:16.520   Training iter 350, batch loss 0.0562, batch acc 0.9872
01:25:16.774   Training iter 400, batch loss 0.0569, batch acc 0.9846
01:25:16.875   Training iter 450, batch loss 0.0613, batch acc 0.9838
01:25:16.979   Training iter 500, batch loss 0.0533, batch acc 0.9862
01:25:17.071   Training iter 550, batch loss 0.0575, batch acc 0.9836
01:25:17.166   Training iter 600, batch loss 0.0528, batch acc 0.9870
01:25:17.169 Testing @ 40 epoch...
01:25:17.316     Testing, total mean loss 0.08204, total acc 0.97450
01:25:17.316 Training @ 41 epoch...
01:25:17.489   Training iter 50, batch loss 0.0556, batch acc 0.9872
01:25:17.597   Training iter 100, batch loss 0.0532, batch acc 0.9866
01:25:17.735   Training iter 150, batch loss 0.0563, batch acc 0.9858
01:25:17.871   Training iter 200, batch loss 0.0574, batch acc 0.9852
01:25:18.004   Training iter 250, batch loss 0.0558, batch acc 0.9862
01:25:18.129   Training iter 300, batch loss 0.0519, batch acc 0.9862
01:25:18.285   Training iter 350, batch loss 0.0508, batch acc 0.9882
01:25:18.491   Training iter 400, batch loss 0.0596, batch acc 0.9830
01:25:18.604   Training iter 450, batch loss 0.0556, batch acc 0.9866
01:25:18.724   Training iter 500, batch loss 0.0518, batch acc 0.9866
01:25:18.883   Training iter 550, batch loss 0.0627, batch acc 0.9830
01:25:19.001   Training iter 600, batch loss 0.0592, batch acc 0.9844
01:25:19.003 Training @ 42 epoch...
01:25:19.126   Training iter 50, batch loss 0.0486, batch acc 0.9902
01:25:19.234   Training iter 100, batch loss 0.0602, batch acc 0.9852
01:25:19.335   Training iter 150, batch loss 0.0545, batch acc 0.9846
01:25:19.422   Training iter 200, batch loss 0.0526, batch acc 0.9868
01:25:19.529   Training iter 250, batch loss 0.0529, batch acc 0.9856
01:25:19.615   Training iter 300, batch loss 0.0584, batch acc 0.9842
01:25:19.755   Training iter 350, batch loss 0.0482, batch acc 0.9868
01:25:19.866   Training iter 400, batch loss 0.0534, batch acc 0.9856
01:25:19.980   Training iter 450, batch loss 0.0569, batch acc 0.9834
01:25:20.085   Training iter 500, batch loss 0.0704, batch acc 0.9806
01:25:20.202   Training iter 550, batch loss 0.0485, batch acc 0.9884
01:25:20.323   Training iter 600, batch loss 0.0573, batch acc 0.9836
01:25:20.325 Training @ 43 epoch...
01:25:20.450   Training iter 50, batch loss 0.0573, batch acc 0.9848
01:25:20.591   Training iter 100, batch loss 0.0445, batch acc 0.9902
01:25:20.722   Training iter 150, batch loss 0.0594, batch acc 0.9844
01:25:20.880   Training iter 200, batch loss 0.0550, batch acc 0.9854
01:25:20.998   Training iter 250, batch loss 0.0532, batch acc 0.9856
01:25:21.115   Training iter 300, batch loss 0.0539, batch acc 0.9870
01:25:21.252   Training iter 350, batch loss 0.0536, batch acc 0.9852
01:25:21.372   Training iter 400, batch loss 0.0657, batch acc 0.9798
01:25:21.467   Training iter 450, batch loss 0.0554, batch acc 0.9858
01:25:21.566   Training iter 500, batch loss 0.0540, batch acc 0.9868
01:25:21.658   Training iter 550, batch loss 0.0582, batch acc 0.9830
01:25:21.764   Training iter 600, batch loss 0.0616, batch acc 0.9818
01:25:21.764 Training @ 44 epoch...
01:25:21.859   Training iter 50, batch loss 0.0572, batch acc 0.9848
01:25:21.948   Training iter 100, batch loss 0.0463, batch acc 0.9892
01:25:22.038   Training iter 150, batch loss 0.0553, batch acc 0.9854
01:25:22.125   Training iter 200, batch loss 0.0636, batch acc 0.9838
01:25:22.303   Training iter 250, batch loss 0.0516, batch acc 0.9878
01:25:22.414   Training iter 300, batch loss 0.0547, batch acc 0.9854
01:25:22.571   Training iter 350, batch loss 0.0591, batch acc 0.9836
01:25:22.675   Training iter 400, batch loss 0.0519, batch acc 0.9862
01:25:22.787   Training iter 450, batch loss 0.0534, batch acc 0.9854
01:25:22.909   Training iter 500, batch loss 0.0647, batch acc 0.9826
01:25:23.012   Training iter 550, batch loss 0.0549, batch acc 0.9858
01:25:23.119   Training iter 600, batch loss 0.0543, batch acc 0.9854
01:25:23.120 Training @ 45 epoch...
01:25:23.225   Training iter 50, batch loss 0.0432, batch acc 0.9892
01:25:23.378   Training iter 100, batch loss 0.0551, batch acc 0.9848
01:25:23.499   Training iter 150, batch loss 0.0570, batch acc 0.9856
01:25:23.631   Training iter 200, batch loss 0.0545, batch acc 0.9864
01:25:23.765   Training iter 250, batch loss 0.0499, batch acc 0.9856
01:25:23.901   Training iter 300, batch loss 0.0490, batch acc 0.9872
01:25:24.024   Training iter 350, batch loss 0.0550, batch acc 0.9854
01:25:24.147   Training iter 400, batch loss 0.0586, batch acc 0.9842
01:25:24.241   Training iter 450, batch loss 0.0528, batch acc 0.9878
01:25:24.332   Training iter 500, batch loss 0.0490, batch acc 0.9890
01:25:24.430   Training iter 550, batch loss 0.0688, batch acc 0.9828
01:25:24.539   Training iter 600, batch loss 0.0657, batch acc 0.9818
01:25:24.539 Testing @ 45 epoch...
01:25:24.604     Testing, total mean loss 0.07916, total acc 0.97540
01:25:24.604 Training @ 46 epoch...
01:25:24.714   Training iter 50, batch loss 0.0492, batch acc 0.9872
01:25:24.825   Training iter 100, batch loss 0.0523, batch acc 0.9858
01:25:24.937   Training iter 150, batch loss 0.0539, batch acc 0.9858
01:25:25.042   Training iter 200, batch loss 0.0576, batch acc 0.9824
01:25:25.199   Training iter 250, batch loss 0.0556, batch acc 0.9864
01:25:25.297   Training iter 300, batch loss 0.0531, batch acc 0.9854
01:25:25.392   Training iter 350, batch loss 0.0495, batch acc 0.9894
01:25:25.506   Training iter 400, batch loss 0.0567, batch acc 0.9852
01:25:25.622   Training iter 450, batch loss 0.0618, batch acc 0.9838
01:25:25.732   Training iter 500, batch loss 0.0603, batch acc 0.9814
01:25:25.848   Training iter 550, batch loss 0.0492, batch acc 0.9868
01:25:25.956   Training iter 600, batch loss 0.0553, batch acc 0.9850
01:25:25.957 Training @ 47 epoch...
01:25:26.073   Training iter 50, batch loss 0.0536, batch acc 0.9852
01:25:26.237   Training iter 100, batch loss 0.0478, batch acc 0.9864
01:25:26.364   Training iter 150, batch loss 0.0454, batch acc 0.9892
01:25:26.477   Training iter 200, batch loss 0.0587, batch acc 0.9846
01:25:26.605   Training iter 250, batch loss 0.0531, batch acc 0.9846
01:25:26.749   Training iter 300, batch loss 0.0567, batch acc 0.9848
01:25:26.872   Training iter 350, batch loss 0.0536, batch acc 0.9870
01:25:27.005   Training iter 400, batch loss 0.0551, batch acc 0.9858
01:25:27.119   Training iter 450, batch loss 0.0555, batch acc 0.9866
01:25:27.219   Training iter 500, batch loss 0.0602, batch acc 0.9820
01:25:27.316   Training iter 550, batch loss 0.0520, batch acc 0.9858
01:25:27.415   Training iter 600, batch loss 0.0504, batch acc 0.9854
01:25:27.417 Training @ 48 epoch...
01:25:27.505   Training iter 50, batch loss 0.0465, batch acc 0.9884
01:25:27.617   Training iter 100, batch loss 0.0613, batch acc 0.9838
01:25:27.721   Training iter 150, batch loss 0.0510, batch acc 0.9870
01:25:27.819   Training iter 200, batch loss 0.0555, batch acc 0.9862
01:25:27.923   Training iter 250, batch loss 0.0619, batch acc 0.9846
01:25:28.031   Training iter 300, batch loss 0.0483, batch acc 0.9882
01:25:28.151   Training iter 350, batch loss 0.0507, batch acc 0.9860
01:25:28.255   Training iter 400, batch loss 0.0504, batch acc 0.9896
01:25:28.353   Training iter 450, batch loss 0.0569, batch acc 0.9864
01:25:28.458   Training iter 500, batch loss 0.0585, batch acc 0.9838
01:25:28.570   Training iter 550, batch loss 0.0537, batch acc 0.9872
01:25:28.712   Training iter 600, batch loss 0.0503, batch acc 0.9862
01:25:28.713 Training @ 49 epoch...
01:25:28.815   Training iter 50, batch loss 0.0493, batch acc 0.9878
01:25:28.923   Training iter 100, batch loss 0.0557, batch acc 0.9856
01:25:29.239   Training iter 150, batch loss 0.0462, batch acc 0.9880
01:25:29.404   Training iter 200, batch loss 0.0599, batch acc 0.9854
01:25:29.559   Training iter 250, batch loss 0.0522, batch acc 0.9876
01:25:29.742   Training iter 300, batch loss 0.0501, batch acc 0.9858
01:25:29.908   Training iter 350, batch loss 0.0543, batch acc 0.9852
01:25:30.022   Training iter 400, batch loss 0.0515, batch acc 0.9868
01:25:30.118   Training iter 450, batch loss 0.0553, batch acc 0.9862
01:25:30.222   Training iter 500, batch loss 0.0509, batch acc 0.9880
01:25:30.329   Training iter 550, batch loss 0.0545, batch acc 0.9852
01:25:30.448   Training iter 600, batch loss 0.0575, batch acc 0.9840
01:25:30.448 Training @ 50 epoch...
01:25:30.562   Training iter 50, batch loss 0.0530, batch acc 0.9866
01:25:30.669   Training iter 100, batch loss 0.0506, batch acc 0.9870
01:25:30.770   Training iter 150, batch loss 0.0511, batch acc 0.9874
01:25:31.014   Training iter 200, batch loss 0.0548, batch acc 0.9856
01:25:31.232   Training iter 250, batch loss 0.0491, batch acc 0.9866
01:25:31.433   Training iter 300, batch loss 0.0550, batch acc 0.9856
01:25:31.628   Training iter 350, batch loss 0.0538, batch acc 0.9870
01:25:31.741   Training iter 400, batch loss 0.0508, batch acc 0.9868
01:25:31.892   Training iter 450, batch loss 0.0563, batch acc 0.9864
01:25:32.259   Training iter 500, batch loss 0.0551, batch acc 0.9844
01:25:32.388   Training iter 550, batch loss 0.0512, batch acc 0.9846
01:25:32.517   Training iter 600, batch loss 0.0535, batch acc 0.9852
01:25:32.519 Testing @ 50 epoch...
01:25:32.607     Testing, total mean loss 0.07933, total acc 0.97610
01:25:32.607 Training @ 51 epoch...
01:25:32.731   Training iter 50, batch loss 0.0507, batch acc 0.9884
01:25:33.042   Training iter 100, batch loss 0.0475, batch acc 0.9870
01:25:33.299   Training iter 150, batch loss 0.0501, batch acc 0.9868
01:25:33.580   Training iter 200, batch loss 0.0482, batch acc 0.9886
01:25:33.746   Training iter 250, batch loss 0.0577, batch acc 0.9842
01:25:33.887   Training iter 300, batch loss 0.0569, batch acc 0.9836
01:25:33.988   Training iter 350, batch loss 0.0513, batch acc 0.9880
01:25:34.076   Training iter 400, batch loss 0.0500, batch acc 0.9872
01:25:34.208   Training iter 450, batch loss 0.0540, batch acc 0.9862
01:25:34.371   Training iter 500, batch loss 0.0497, batch acc 0.9864
01:25:34.488   Training iter 550, batch loss 0.0574, batch acc 0.9840
01:25:34.636   Training iter 600, batch loss 0.0509, batch acc 0.9860
01:25:34.636 Training @ 52 epoch...
01:25:34.754   Training iter 50, batch loss 0.0498, batch acc 0.9872
01:25:34.920   Training iter 100, batch loss 0.0474, batch acc 0.9902
01:25:35.049   Training iter 150, batch loss 0.0483, batch acc 0.9882
01:25:35.174   Training iter 200, batch loss 0.0500, batch acc 0.9870
01:25:35.289   Training iter 250, batch loss 0.0429, batch acc 0.9908
01:25:35.427   Training iter 300, batch loss 0.0537, batch acc 0.9850
01:25:35.548   Training iter 350, batch loss 0.0508, batch acc 0.9884
01:25:35.664   Training iter 400, batch loss 0.0607, batch acc 0.9830
01:25:35.747   Training iter 450, batch loss 0.0533, batch acc 0.9868
01:25:35.838   Training iter 500, batch loss 0.0525, batch acc 0.9852
01:25:35.984   Training iter 550, batch loss 0.0624, batch acc 0.9824
01:25:36.090   Training iter 600, batch loss 0.0449, batch acc 0.9886
01:25:36.092 Training @ 53 epoch...
01:25:36.200   Training iter 50, batch loss 0.0421, batch acc 0.9922
01:25:36.316   Training iter 100, batch loss 0.0508, batch acc 0.9882
01:25:36.419   Training iter 150, batch loss 0.0494, batch acc 0.9864
01:25:36.628   Training iter 200, batch loss 0.0564, batch acc 0.9822
01:25:36.880   Training iter 250, batch loss 0.0516, batch acc 0.9864
01:25:37.015   Training iter 300, batch loss 0.0533, batch acc 0.9860
01:25:37.166   Training iter 350, batch loss 0.0566, batch acc 0.9858
01:25:37.299   Training iter 400, batch loss 0.0491, batch acc 0.9874
01:25:37.415   Training iter 450, batch loss 0.0478, batch acc 0.9872
01:25:37.544   Training iter 500, batch loss 0.0487, batch acc 0.9874
01:25:37.675   Training iter 550, batch loss 0.0548, batch acc 0.9838
01:25:37.818   Training iter 600, batch loss 0.0544, batch acc 0.9856
01:25:37.819 Training @ 54 epoch...
01:25:37.976   Training iter 50, batch loss 0.0481, batch acc 0.9876
01:25:38.104   Training iter 100, batch loss 0.0467, batch acc 0.9892
01:25:38.218   Training iter 150, batch loss 0.0526, batch acc 0.9872
01:25:38.388   Training iter 200, batch loss 0.0512, batch acc 0.9872
01:25:38.506   Training iter 250, batch loss 0.0474, batch acc 0.9866
01:25:38.638   Training iter 300, batch loss 0.0502, batch acc 0.9868
01:25:38.747   Training iter 350, batch loss 0.0509, batch acc 0.9858
01:25:38.849   Training iter 400, batch loss 0.0477, batch acc 0.9878
01:25:38.958   Training iter 450, batch loss 0.0486, batch acc 0.9864
01:25:39.067   Training iter 500, batch loss 0.0513, batch acc 0.9872
01:25:39.165   Training iter 550, batch loss 0.0600, batch acc 0.9828
01:25:39.283   Training iter 600, batch loss 0.0592, batch acc 0.9854
01:25:39.284 Training @ 55 epoch...
01:25:39.645   Training iter 50, batch loss 0.0499, batch acc 0.9882
01:25:39.952   Training iter 100, batch loss 0.0485, batch acc 0.9864
01:25:40.065   Training iter 150, batch loss 0.0594, batch acc 0.9854
01:25:40.173   Training iter 200, batch loss 0.0520, batch acc 0.9868
01:25:40.272   Training iter 250, batch loss 0.0466, batch acc 0.9900
01:25:40.386   Training iter 300, batch loss 0.0517, batch acc 0.9846
01:25:40.512   Training iter 350, batch loss 0.0534, batch acc 0.9862
01:25:40.650   Training iter 400, batch loss 0.0486, batch acc 0.9874
01:25:40.834   Training iter 450, batch loss 0.0505, batch acc 0.9888
01:25:40.950   Training iter 500, batch loss 0.0505, batch acc 0.9886
01:25:41.083   Training iter 550, batch loss 0.0516, batch acc 0.9858
01:25:41.202   Training iter 600, batch loss 0.0491, batch acc 0.9876
01:25:41.203 Testing @ 55 epoch...
01:25:41.326     Testing, total mean loss 0.07797, total acc 0.97640
01:25:41.326 Training @ 56 epoch...
01:25:41.590   Training iter 50, batch loss 0.0446, batch acc 0.9910
01:25:41.723   Training iter 100, batch loss 0.0486, batch acc 0.9856
01:25:41.858   Training iter 150, batch loss 0.0517, batch acc 0.9864
01:25:42.111   Training iter 200, batch loss 0.0469, batch acc 0.9890
01:25:42.239   Training iter 250, batch loss 0.0504, batch acc 0.9874
01:25:42.359   Training iter 300, batch loss 0.0542, batch acc 0.9878
01:25:42.465   Training iter 350, batch loss 0.0504, batch acc 0.9864
01:25:42.583   Training iter 400, batch loss 0.0485, batch acc 0.9880
01:25:42.674   Training iter 450, batch loss 0.0496, batch acc 0.9878
01:25:42.772   Training iter 500, batch loss 0.0503, batch acc 0.9872
01:25:42.898   Training iter 550, batch loss 0.0513, batch acc 0.9870
01:25:43.053   Training iter 600, batch loss 0.0518, batch acc 0.9882
01:25:43.053 Training @ 57 epoch...
01:25:43.168   Training iter 50, batch loss 0.0558, batch acc 0.9868
01:25:43.283   Training iter 100, batch loss 0.0443, batch acc 0.9890
01:25:43.407   Training iter 150, batch loss 0.0454, batch acc 0.9884
01:25:43.536   Training iter 200, batch loss 0.0474, batch acc 0.9884
01:25:43.643   Training iter 250, batch loss 0.0495, batch acc 0.9888
01:25:43.764   Training iter 300, batch loss 0.0510, batch acc 0.9864
01:25:43.905   Training iter 350, batch loss 0.0458, batch acc 0.9902
01:25:44.039   Training iter 400, batch loss 0.0478, batch acc 0.9870
01:25:44.141   Training iter 450, batch loss 0.0505, batch acc 0.9862
01:25:44.259   Training iter 500, batch loss 0.0547, batch acc 0.9878
01:25:44.421   Training iter 550, batch loss 0.0554, batch acc 0.9858
01:25:44.522   Training iter 600, batch loss 0.0538, batch acc 0.9874
01:25:44.523 Training @ 58 epoch...
01:25:44.638   Training iter 50, batch loss 0.0499, batch acc 0.9878
01:25:44.764   Training iter 100, batch loss 0.0500, batch acc 0.9868
01:25:44.858   Training iter 150, batch loss 0.0487, batch acc 0.9854
01:25:45.064   Training iter 200, batch loss 0.0504, batch acc 0.9868
01:25:45.186   Training iter 250, batch loss 0.0504, batch acc 0.9876
01:25:45.303   Training iter 300, batch loss 0.0460, batch acc 0.9886
01:25:45.416   Training iter 350, batch loss 0.0492, batch acc 0.9878
01:25:45.516   Training iter 400, batch loss 0.0505, batch acc 0.9886
01:25:45.610   Training iter 450, batch loss 0.0426, batch acc 0.9888
01:25:45.720   Training iter 500, batch loss 0.0530, batch acc 0.9858
01:25:45.822   Training iter 550, batch loss 0.0540, batch acc 0.9866
01:25:45.935   Training iter 600, batch loss 0.0553, batch acc 0.9846
01:25:45.935 Training @ 59 epoch...
01:25:46.054   Training iter 50, batch loss 0.0452, batch acc 0.9870
01:25:46.189   Training iter 100, batch loss 0.0494, batch acc 0.9888
01:25:46.332   Training iter 150, batch loss 0.0513, batch acc 0.9878
01:25:46.470   Training iter 200, batch loss 0.0461, batch acc 0.9884
01:25:46.599   Training iter 250, batch loss 0.0514, batch acc 0.9864
01:25:46.725   Training iter 300, batch loss 0.0484, batch acc 0.9868
01:25:46.823   Training iter 350, batch loss 0.0521, batch acc 0.9888
01:25:46.945   Training iter 400, batch loss 0.0419, batch acc 0.9908
01:25:47.070   Training iter 450, batch loss 0.0477, batch acc 0.9884
01:25:47.188   Training iter 500, batch loss 0.0583, batch acc 0.9848
01:25:47.301   Training iter 550, batch loss 0.0477, batch acc 0.9878
01:25:47.403   Training iter 600, batch loss 0.0491, batch acc 0.9896
01:25:47.403 Training @ 60 epoch...
01:25:47.502   Training iter 50, batch loss 0.0419, batch acc 0.9918
01:25:47.808   Training iter 100, batch loss 0.0402, batch acc 0.9912
01:25:47.922   Training iter 150, batch loss 0.0506, batch acc 0.9860
01:25:48.051   Training iter 200, batch loss 0.0533, batch acc 0.9850
01:25:48.154   Training iter 250, batch loss 0.0523, batch acc 0.9862
01:25:48.264   Training iter 300, batch loss 0.0517, batch acc 0.9864
01:25:48.380   Training iter 350, batch loss 0.0503, batch acc 0.9882
01:25:48.485   Training iter 400, batch loss 0.0482, batch acc 0.9884
01:25:48.590   Training iter 450, batch loss 0.0504, batch acc 0.9890
01:25:48.713   Training iter 500, batch loss 0.0551, batch acc 0.9864
01:25:48.851   Training iter 550, batch loss 0.0498, batch acc 0.9862
01:25:48.991   Training iter 600, batch loss 0.0486, batch acc 0.9862
01:25:48.992 Testing @ 60 epoch...
01:25:49.083     Testing, total mean loss 0.07588, total acc 0.97740
01:25:49.083 Training @ 61 epoch...
01:25:49.216   Training iter 50, batch loss 0.0432, batch acc 0.9884
01:25:49.340   Training iter 100, batch loss 0.0447, batch acc 0.9890
01:25:49.490   Training iter 150, batch loss 0.0575, batch acc 0.9866
01:25:49.618   Training iter 200, batch loss 0.0526, batch acc 0.9862
01:25:49.813   Training iter 250, batch loss 0.0457, batch acc 0.9884
01:25:49.927   Training iter 300, batch loss 0.0503, batch acc 0.9862
01:25:50.090   Training iter 350, batch loss 0.0497, batch acc 0.9882
01:25:50.248   Training iter 400, batch loss 0.0533, batch acc 0.9880
01:25:50.385   Training iter 450, batch loss 0.0495, batch acc 0.9862
01:25:50.501   Training iter 500, batch loss 0.0517, batch acc 0.9860
01:25:50.622   Training iter 550, batch loss 0.0471, batch acc 0.9888
01:25:50.714   Training iter 600, batch loss 0.0466, batch acc 0.9882
01:25:50.716 Training @ 62 epoch...
01:25:50.806   Training iter 50, batch loss 0.0416, batch acc 0.9906
01:25:50.937   Training iter 100, batch loss 0.0434, batch acc 0.9902
01:25:51.059   Training iter 150, batch loss 0.0567, batch acc 0.9860
01:25:51.188   Training iter 200, batch loss 0.0418, batch acc 0.9908
01:25:51.297   Training iter 250, batch loss 0.0500, batch acc 0.9878
01:25:51.398   Training iter 300, batch loss 0.0553, batch acc 0.9858
01:25:51.495   Training iter 350, batch loss 0.0502, batch acc 0.9870
01:25:51.614   Training iter 400, batch loss 0.0487, batch acc 0.9874
01:25:51.752   Training iter 450, batch loss 0.0435, batch acc 0.9888
01:25:51.899   Training iter 500, batch loss 0.0578, batch acc 0.9838
01:25:52.026   Training iter 550, batch loss 0.0465, batch acc 0.9898
01:25:52.153   Training iter 600, batch loss 0.0523, batch acc 0.9856
01:25:52.154 Training @ 63 epoch...
01:25:52.295   Training iter 50, batch loss 0.0439, batch acc 0.9894
01:25:52.411   Training iter 100, batch loss 0.0504, batch acc 0.9872
01:25:52.704   Training iter 150, batch loss 0.0476, batch acc 0.9862
01:25:52.835   Training iter 200, batch loss 0.0538, batch acc 0.9862
01:25:52.947   Training iter 250, batch loss 0.0489, batch acc 0.9872
01:25:53.070   Training iter 300, batch loss 0.0439, batch acc 0.9900
01:25:53.181   Training iter 350, batch loss 0.0495, batch acc 0.9884
01:25:53.287   Training iter 400, batch loss 0.0524, batch acc 0.9864
01:25:53.382   Training iter 450, batch loss 0.0462, batch acc 0.9868
01:25:53.472   Training iter 500, batch loss 0.0526, batch acc 0.9846
01:25:53.582   Training iter 550, batch loss 0.0484, batch acc 0.9876
01:25:53.686   Training iter 600, batch loss 0.0484, batch acc 0.9892
01:25:53.687 Training @ 64 epoch...
01:25:53.855   Training iter 50, batch loss 0.0481, batch acc 0.9876
01:25:54.004   Training iter 100, batch loss 0.0456, batch acc 0.9898
01:25:54.100   Training iter 150, batch loss 0.0501, batch acc 0.9860
01:25:54.198   Training iter 200, batch loss 0.0423, batch acc 0.9908
01:25:54.315   Training iter 250, batch loss 0.0469, batch acc 0.9908
01:25:54.418   Training iter 300, batch loss 0.0458, batch acc 0.9882
01:25:54.524   Training iter 350, batch loss 0.0498, batch acc 0.9880
01:25:54.641   Training iter 400, batch loss 0.0528, batch acc 0.9862
01:25:54.756   Training iter 450, batch loss 0.0530, batch acc 0.9870
01:25:54.907   Training iter 500, batch loss 0.0530, batch acc 0.9850
01:25:55.032   Training iter 550, batch loss 0.0494, batch acc 0.9864
01:25:55.170   Training iter 600, batch loss 0.0526, batch acc 0.9864
01:25:55.171 Training @ 65 epoch...
01:25:55.313   Training iter 50, batch loss 0.0428, batch acc 0.9896
01:25:55.408   Training iter 100, batch loss 0.0461, batch acc 0.9912
01:25:55.508   Training iter 150, batch loss 0.0480, batch acc 0.9872
01:25:55.616   Training iter 200, batch loss 0.0475, batch acc 0.9880
01:25:55.700   Training iter 250, batch loss 0.0471, batch acc 0.9878
01:25:55.813   Training iter 300, batch loss 0.0407, batch acc 0.9916
01:25:55.907   Training iter 350, batch loss 0.0515, batch acc 0.9862
01:25:55.991   Training iter 400, batch loss 0.0531, batch acc 0.9858
01:25:56.086   Training iter 450, batch loss 0.0520, batch acc 0.9872
01:25:56.190   Training iter 500, batch loss 0.0556, batch acc 0.9852
01:25:56.404   Training iter 550, batch loss 0.0546, batch acc 0.9856
01:25:56.496   Training iter 600, batch loss 0.0438, batch acc 0.9898
01:25:56.497 Testing @ 65 epoch...
01:25:56.555     Testing, total mean loss 0.07383, total acc 0.97830
01:25:56.555 Training @ 66 epoch...
01:25:56.671   Training iter 50, batch loss 0.0456, batch acc 0.9884
01:25:56.782   Training iter 100, batch loss 0.0455, batch acc 0.9872
01:25:56.900   Training iter 150, batch loss 0.0510, batch acc 0.9900
01:25:56.982   Training iter 200, batch loss 0.0536, batch acc 0.9856
01:25:57.071   Training iter 250, batch loss 0.0492, batch acc 0.9890
01:25:57.180   Training iter 300, batch loss 0.0492, batch acc 0.9874
01:25:57.295   Training iter 350, batch loss 0.0468, batch acc 0.9884
01:25:57.408   Training iter 400, batch loss 0.0460, batch acc 0.9880
01:25:57.538   Training iter 450, batch loss 0.0453, batch acc 0.9904
01:25:57.658   Training iter 500, batch loss 0.0505, batch acc 0.9874
01:25:57.804   Training iter 550, batch loss 0.0459, batch acc 0.9872
01:25:57.936   Training iter 600, batch loss 0.0521, batch acc 0.9870
01:25:57.937 Training @ 67 epoch...
01:25:58.065   Training iter 50, batch loss 0.0445, batch acc 0.9898
01:25:58.203   Training iter 100, batch loss 0.0443, batch acc 0.9898
01:25:58.299   Training iter 150, batch loss 0.0432, batch acc 0.9902
01:25:58.397   Training iter 200, batch loss 0.0504, batch acc 0.9874
01:25:58.511   Training iter 250, batch loss 0.0513, batch acc 0.9864
01:25:58.604   Training iter 300, batch loss 0.0505, batch acc 0.9864
01:25:58.686   Training iter 350, batch loss 0.0493, batch acc 0.9862
01:25:58.783   Training iter 400, batch loss 0.0452, batch acc 0.9890
01:25:58.879   Training iter 450, batch loss 0.0537, batch acc 0.9860
01:25:58.970   Training iter 500, batch loss 0.0482, batch acc 0.9888
01:25:59.060   Training iter 550, batch loss 0.0490, batch acc 0.9874
01:25:59.157   Training iter 600, batch loss 0.0509, batch acc 0.9868
01:25:59.158 Training @ 68 epoch...
01:25:59.267   Training iter 50, batch loss 0.0512, batch acc 0.9850
01:25:59.355   Training iter 100, batch loss 0.0487, batch acc 0.9878
01:25:59.455   Training iter 150, batch loss 0.0467, batch acc 0.9896
01:25:59.554   Training iter 200, batch loss 0.0417, batch acc 0.9904
01:25:59.651   Training iter 250, batch loss 0.0525, batch acc 0.9856
01:25:59.738   Training iter 300, batch loss 0.0446, batch acc 0.9892
01:25:59.843   Training iter 350, batch loss 0.0494, batch acc 0.9866
01:25:59.923   Training iter 400, batch loss 0.0478, batch acc 0.9888
01:26:00.034   Training iter 450, batch loss 0.0437, batch acc 0.9888
01:26:00.138   Training iter 500, batch loss 0.0523, batch acc 0.9848
01:26:00.250   Training iter 550, batch loss 0.0492, batch acc 0.9872
01:26:00.357   Training iter 600, batch loss 0.0496, batch acc 0.9880
01:26:00.358 Training @ 69 epoch...
01:26:00.468   Training iter 50, batch loss 0.0456, batch acc 0.9906
01:26:00.581   Training iter 100, batch loss 0.0488, batch acc 0.9878
01:26:00.699   Training iter 150, batch loss 0.0426, batch acc 0.9910
01:26:00.848   Training iter 200, batch loss 0.0436, batch acc 0.9896
01:26:00.934   Training iter 250, batch loss 0.0456, batch acc 0.9900
01:26:01.037   Training iter 300, batch loss 0.0461, batch acc 0.9890
01:26:01.119   Training iter 350, batch loss 0.0482, batch acc 0.9880
01:26:01.206   Training iter 400, batch loss 0.0454, batch acc 0.9894
01:26:01.293   Training iter 450, batch loss 0.0533, batch acc 0.9858
01:26:01.407   Training iter 500, batch loss 0.0510, batch acc 0.9864
01:26:01.498   Training iter 550, batch loss 0.0508, batch acc 0.9886
01:26:01.604   Training iter 600, batch loss 0.0447, batch acc 0.9888
01:26:01.606 Training @ 70 epoch...
01:26:01.715   Training iter 50, batch loss 0.0468, batch acc 0.9868
01:26:01.912   Training iter 100, batch loss 0.0383, batch acc 0.9926
01:26:02.015   Training iter 150, batch loss 0.0457, batch acc 0.9884
01:26:02.098   Training iter 200, batch loss 0.0507, batch acc 0.9860
01:26:02.190   Training iter 250, batch loss 0.0501, batch acc 0.9880
01:26:02.289   Training iter 300, batch loss 0.0466, batch acc 0.9888
01:26:02.387   Training iter 350, batch loss 0.0482, batch acc 0.9870
01:26:02.469   Training iter 400, batch loss 0.0465, batch acc 0.9888
01:26:02.553   Training iter 450, batch loss 0.0444, batch acc 0.9886
01:26:02.645   Training iter 500, batch loss 0.0505, batch acc 0.9862
01:26:02.738   Training iter 550, batch loss 0.0496, batch acc 0.9880
01:26:02.819   Training iter 600, batch loss 0.0461, batch acc 0.9896
01:26:02.819 Testing @ 70 epoch...
01:26:02.902     Testing, total mean loss 0.07855, total acc 0.97530
01:26:02.902 Training @ 71 epoch...
01:26:03.022   Training iter 50, batch loss 0.0446, batch acc 0.9896
01:26:03.122   Training iter 100, batch loss 0.0400, batch acc 0.9912
01:26:03.248   Training iter 150, batch loss 0.0429, batch acc 0.9890
01:26:03.373   Training iter 200, batch loss 0.0474, batch acc 0.9900
01:26:03.482   Training iter 250, batch loss 0.0431, batch acc 0.9882
01:26:03.597   Training iter 300, batch loss 0.0482, batch acc 0.9876
01:26:03.727   Training iter 350, batch loss 0.0471, batch acc 0.9888
01:26:03.847   Training iter 400, batch loss 0.0523, batch acc 0.9856
01:26:03.969   Training iter 450, batch loss 0.0482, batch acc 0.9874
01:26:04.060   Training iter 500, batch loss 0.0460, batch acc 0.9882
01:26:04.152   Training iter 550, batch loss 0.0500, batch acc 0.9860
01:26:04.235   Training iter 600, batch loss 0.0510, batch acc 0.9876
01:26:04.236 Training @ 72 epoch...
01:26:04.344   Training iter 50, batch loss 0.0507, batch acc 0.9872
01:26:04.438   Training iter 100, batch loss 0.0428, batch acc 0.9904
01:26:04.565   Training iter 150, batch loss 0.0425, batch acc 0.9894
01:26:04.670   Training iter 200, batch loss 0.0471, batch acc 0.9868
01:26:04.762   Training iter 250, batch loss 0.0500, batch acc 0.9862
01:26:04.844   Training iter 300, batch loss 0.0424, batch acc 0.9904
01:26:04.928   Training iter 350, batch loss 0.0490, batch acc 0.9884
01:26:05.014   Training iter 400, batch loss 0.0481, batch acc 0.9880
01:26:05.107   Training iter 450, batch loss 0.0520, batch acc 0.9868
01:26:05.239   Training iter 500, batch loss 0.0469, batch acc 0.9904
01:26:05.339   Training iter 550, batch loss 0.0465, batch acc 0.9888
01:26:05.507   Training iter 600, batch loss 0.0441, batch acc 0.9900
01:26:05.508 Training @ 73 epoch...
01:26:05.646   Training iter 50, batch loss 0.0449, batch acc 0.9900
01:26:05.789   Training iter 100, batch loss 0.0502, batch acc 0.9884
01:26:05.911   Training iter 150, batch loss 0.0439, batch acc 0.9890
01:26:06.052   Training iter 200, batch loss 0.0446, batch acc 0.9900
01:26:06.193   Training iter 250, batch loss 0.0477, batch acc 0.9888
01:26:06.321   Training iter 300, batch loss 0.0492, batch acc 0.9874
01:26:06.497   Training iter 350, batch loss 0.0498, batch acc 0.9876
01:26:06.656   Training iter 400, batch loss 0.0471, batch acc 0.9884
01:26:06.786   Training iter 450, batch loss 0.0457, batch acc 0.9878
01:26:06.912   Training iter 500, batch loss 0.0400, batch acc 0.9904
01:26:07.011   Training iter 550, batch loss 0.0492, batch acc 0.9860
01:26:07.108   Training iter 600, batch loss 0.0438, batch acc 0.9896
01:26:07.108 Training @ 74 epoch...
01:26:07.191   Training iter 50, batch loss 0.0425, batch acc 0.9910
01:26:07.297   Training iter 100, batch loss 0.0403, batch acc 0.9918
01:26:07.402   Training iter 150, batch loss 0.0448, batch acc 0.9882
01:26:07.516   Training iter 200, batch loss 0.0469, batch acc 0.9880
01:26:07.607   Training iter 250, batch loss 0.0392, batch acc 0.9922
01:26:07.712   Training iter 300, batch loss 0.0515, batch acc 0.9856
01:26:07.798   Training iter 350, batch loss 0.0491, batch acc 0.9866
01:26:07.913   Training iter 400, batch loss 0.0469, batch acc 0.9880
01:26:08.007   Training iter 450, batch loss 0.0496, batch acc 0.9900
01:26:08.108   Training iter 500, batch loss 0.0504, batch acc 0.9880
01:26:08.238   Training iter 550, batch loss 0.0466, batch acc 0.9882
01:26:08.349   Training iter 600, batch loss 0.0467, batch acc 0.9884
01:26:08.349 Training @ 75 epoch...
01:26:08.460   Training iter 50, batch loss 0.0391, batch acc 0.9914
01:26:08.566   Training iter 100, batch loss 0.0408, batch acc 0.9898
01:26:08.698   Training iter 150, batch loss 0.0499, batch acc 0.9876
01:26:08.830   Training iter 200, batch loss 0.0475, batch acc 0.9884
01:26:08.971   Training iter 250, batch loss 0.0478, batch acc 0.9888
01:26:09.096   Training iter 300, batch loss 0.0425, batch acc 0.9902
01:26:09.720   Training iter 350, batch loss 0.0472, batch acc 0.9886
01:26:09.836   Training iter 400, batch loss 0.0483, batch acc 0.9880
01:26:09.970   Training iter 450, batch loss 0.0496, batch acc 0.9874
01:26:10.079   Training iter 500, batch loss 0.0501, batch acc 0.9874
01:26:10.203   Training iter 550, batch loss 0.0500, batch acc 0.9892
01:26:10.306   Training iter 600, batch loss 0.0518, batch acc 0.9858
01:26:10.310 Testing @ 75 epoch...
01:26:10.399     Testing, total mean loss 0.07721, total acc 0.97610
01:26:10.399 Training @ 76 epoch...
01:26:10.522   Training iter 50, batch loss 0.0500, batch acc 0.9870
01:26:10.636   Training iter 100, batch loss 0.0484, batch acc 0.9886
01:26:10.760   Training iter 150, batch loss 0.0425, batch acc 0.9900
01:26:10.881   Training iter 200, batch loss 0.0412, batch acc 0.9906
01:26:10.973   Training iter 250, batch loss 0.0478, batch acc 0.9878
01:26:11.239   Training iter 300, batch loss 0.0456, batch acc 0.9880
01:26:11.368   Training iter 350, batch loss 0.0420, batch acc 0.9908
01:26:11.487   Training iter 400, batch loss 0.0526, batch acc 0.9856
01:26:11.597   Training iter 450, batch loss 0.0458, batch acc 0.9874
01:26:11.737   Training iter 500, batch loss 0.0453, batch acc 0.9894
01:26:11.872   Training iter 550, batch loss 0.0458, batch acc 0.9878
01:26:12.014   Training iter 600, batch loss 0.0495, batch acc 0.9880
01:26:12.015 Training @ 77 epoch...
01:26:12.226   Training iter 50, batch loss 0.0413, batch acc 0.9900
01:26:12.571   Training iter 100, batch loss 0.0445, batch acc 0.9912
01:26:12.685   Training iter 150, batch loss 0.0442, batch acc 0.9892
01:26:12.930   Training iter 200, batch loss 0.0456, batch acc 0.9878
01:26:13.039   Training iter 250, batch loss 0.0378, batch acc 0.9918
01:26:13.132   Training iter 300, batch loss 0.0476, batch acc 0.9856
01:26:13.228   Training iter 350, batch loss 0.0476, batch acc 0.9890
01:26:13.322   Training iter 400, batch loss 0.0476, batch acc 0.9868
01:26:13.428   Training iter 450, batch loss 0.0456, batch acc 0.9900
01:26:13.534   Training iter 500, batch loss 0.0492, batch acc 0.9870
01:26:13.636   Training iter 550, batch loss 0.0552, batch acc 0.9840
01:26:13.735   Training iter 600, batch loss 0.0474, batch acc 0.9880
01:26:13.736 Training @ 78 epoch...
01:26:13.830   Training iter 50, batch loss 0.0508, batch acc 0.9876
01:26:13.964   Training iter 100, batch loss 0.0447, batch acc 0.9876
01:26:14.081   Training iter 150, batch loss 0.0454, batch acc 0.9910
01:26:14.167   Training iter 200, batch loss 0.0470, batch acc 0.9876
01:26:14.280   Training iter 250, batch loss 0.0399, batch acc 0.9902
01:26:14.386   Training iter 300, batch loss 0.0485, batch acc 0.9882
01:26:14.522   Training iter 350, batch loss 0.0413, batch acc 0.9914
01:26:14.641   Training iter 400, batch loss 0.0442, batch acc 0.9878
01:26:14.783   Training iter 450, batch loss 0.0440, batch acc 0.9898
01:26:14.905   Training iter 500, batch loss 0.0448, batch acc 0.9868
01:26:15.103   Training iter 550, batch loss 0.0545, batch acc 0.9846
01:26:15.218   Training iter 600, batch loss 0.0448, batch acc 0.9874
01:26:15.220 Training @ 79 epoch...
01:26:15.339   Training iter 50, batch loss 0.0432, batch acc 0.9888
01:26:15.503   Training iter 100, batch loss 0.0410, batch acc 0.9888
01:26:15.590   Training iter 150, batch loss 0.0384, batch acc 0.9928
01:26:15.685   Training iter 200, batch loss 0.0465, batch acc 0.9886
01:26:15.779   Training iter 250, batch loss 0.0440, batch acc 0.9900
01:26:15.870   Training iter 300, batch loss 0.0454, batch acc 0.9898
01:26:16.006   Training iter 350, batch loss 0.0476, batch acc 0.9898
01:26:16.097   Training iter 400, batch loss 0.0454, batch acc 0.9898
01:26:16.195   Training iter 450, batch loss 0.0479, batch acc 0.9880
01:26:16.436   Training iter 500, batch loss 0.0450, batch acc 0.9894
01:26:16.540   Training iter 550, batch loss 0.0548, batch acc 0.9854
01:26:16.712   Training iter 600, batch loss 0.0488, batch acc 0.9866
01:26:16.714 Training @ 80 epoch...
01:26:16.865   Training iter 50, batch loss 0.0435, batch acc 0.9888
01:26:17.012   Training iter 100, batch loss 0.0430, batch acc 0.9902
01:26:17.186   Training iter 150, batch loss 0.0462, batch acc 0.9884
01:26:17.354   Training iter 200, batch loss 0.0444, batch acc 0.9894
01:26:17.527   Training iter 250, batch loss 0.0426, batch acc 0.9894
01:26:17.627   Training iter 300, batch loss 0.0463, batch acc 0.9900
01:26:17.933   Training iter 350, batch loss 0.0479, batch acc 0.9884
01:26:18.145   Training iter 400, batch loss 0.0477, batch acc 0.9886
01:26:18.296   Training iter 450, batch loss 0.0434, batch acc 0.9910
01:26:18.388   Training iter 500, batch loss 0.0439, batch acc 0.9894
01:26:18.483   Training iter 550, batch loss 0.0495, batch acc 0.9880
01:26:18.574   Training iter 600, batch loss 0.0430, batch acc 0.9900
01:26:18.577 Testing @ 80 epoch...
01:26:18.770     Testing, total mean loss 0.07464, total acc 0.97690
01:26:18.770 Training @ 81 epoch...
01:26:18.881   Training iter 50, batch loss 0.0434, batch acc 0.9900
01:26:18.984   Training iter 100, batch loss 0.0441, batch acc 0.9890
01:26:19.139   Training iter 150, batch loss 0.0429, batch acc 0.9892
01:26:19.238   Training iter 200, batch loss 0.0438, batch acc 0.9890
01:26:19.336   Training iter 250, batch loss 0.0455, batch acc 0.9892
01:26:19.475   Training iter 300, batch loss 0.0487, batch acc 0.9894
01:26:19.584   Training iter 350, batch loss 0.0435, batch acc 0.9894
01:26:19.720   Training iter 400, batch loss 0.0437, batch acc 0.9906
01:26:19.824   Training iter 450, batch loss 0.0564, batch acc 0.9846
01:26:19.934   Training iter 500, batch loss 0.0425, batch acc 0.9898
01:26:20.044   Training iter 550, batch loss 0.0456, batch acc 0.9914
01:26:20.165   Training iter 600, batch loss 0.0443, batch acc 0.9880
01:26:20.166 Training @ 82 epoch...
01:26:20.281   Training iter 50, batch loss 0.0498, batch acc 0.9884
01:26:20.392   Training iter 100, batch loss 0.0417, batch acc 0.9910
01:26:20.540   Training iter 150, batch loss 0.0458, batch acc 0.9876
01:26:20.665   Training iter 200, batch loss 0.0380, batch acc 0.9916
01:26:20.753   Training iter 250, batch loss 0.0425, batch acc 0.9904
01:26:20.848   Training iter 300, batch loss 0.0486, batch acc 0.9854
01:26:20.993   Training iter 350, batch loss 0.0461, batch acc 0.9884
01:26:21.079   Training iter 400, batch loss 0.0421, batch acc 0.9892
01:26:21.172   Training iter 450, batch loss 0.0405, batch acc 0.9922
01:26:21.273   Training iter 500, batch loss 0.0518, batch acc 0.9876
01:26:21.372   Training iter 550, batch loss 0.0460, batch acc 0.9886
01:26:21.470   Training iter 600, batch loss 0.0445, batch acc 0.9882
01:26:21.471 Training @ 83 epoch...
01:26:21.579   Training iter 50, batch loss 0.0388, batch acc 0.9904
01:26:21.669   Training iter 100, batch loss 0.0410, batch acc 0.9908
01:26:21.760   Training iter 150, batch loss 0.0471, batch acc 0.9884
01:26:21.878   Training iter 200, batch loss 0.0444, batch acc 0.9888
01:26:22.020   Training iter 250, batch loss 0.0469, batch acc 0.9884
01:26:22.126   Training iter 300, batch loss 0.0421, batch acc 0.9908
01:26:22.296   Training iter 350, batch loss 0.0457, batch acc 0.9894
01:26:22.384   Training iter 400, batch loss 0.0471, batch acc 0.9870
01:26:22.486   Training iter 450, batch loss 0.0432, batch acc 0.9892
01:26:22.574   Training iter 500, batch loss 0.0495, batch acc 0.9886
01:26:22.762   Training iter 550, batch loss 0.0514, batch acc 0.9866
01:26:22.880   Training iter 600, batch loss 0.0441, batch acc 0.9896
01:26:22.880 Training @ 84 epoch...
01:26:22.984   Training iter 50, batch loss 0.0429, batch acc 0.9886
01:26:23.079   Training iter 100, batch loss 0.0427, batch acc 0.9884
01:26:23.169   Training iter 150, batch loss 0.0437, batch acc 0.9896
01:26:23.269   Training iter 200, batch loss 0.0489, batch acc 0.9880
01:26:23.401   Training iter 250, batch loss 0.0410, batch acc 0.9904
01:26:23.550   Training iter 300, batch loss 0.0447, batch acc 0.9886
01:26:23.657   Training iter 350, batch loss 0.0439, batch acc 0.9894
01:26:23.838   Training iter 400, batch loss 0.0459, batch acc 0.9898
01:26:23.952   Training iter 450, batch loss 0.0453, batch acc 0.9898
01:26:24.105   Training iter 500, batch loss 0.0444, batch acc 0.9906
01:26:24.253   Training iter 550, batch loss 0.0551, batch acc 0.9848
01:26:24.380   Training iter 600, batch loss 0.0438, batch acc 0.9906
01:26:24.380 Training @ 85 epoch...
01:26:24.562   Training iter 50, batch loss 0.0443, batch acc 0.9890
01:26:24.664   Training iter 100, batch loss 0.0430, batch acc 0.9910
01:26:24.790   Training iter 150, batch loss 0.0443, batch acc 0.9886
01:26:24.896   Training iter 200, batch loss 0.0478, batch acc 0.9888
01:26:24.997   Training iter 250, batch loss 0.0467, batch acc 0.9878
01:26:25.088   Training iter 300, batch loss 0.0402, batch acc 0.9908
01:26:25.173   Training iter 350, batch loss 0.0469, batch acc 0.9876
01:26:25.280   Training iter 400, batch loss 0.0516, batch acc 0.9884
01:26:25.379   Training iter 450, batch loss 0.0377, batch acc 0.9926
01:26:25.493   Training iter 500, batch loss 0.0519, batch acc 0.9850
01:26:25.658   Training iter 550, batch loss 0.0455, batch acc 0.9896
01:26:25.789   Training iter 600, batch loss 0.0450, batch acc 0.9884
01:26:25.793 Testing @ 85 epoch...
01:26:25.893     Testing, total mean loss 0.07488, total acc 0.97720
01:26:25.893 Training @ 86 epoch...
01:26:26.026   Training iter 50, batch loss 0.0454, batch acc 0.9888
01:26:26.146   Training iter 100, batch loss 0.0452, batch acc 0.9898
01:26:26.451   Training iter 150, batch loss 0.0476, batch acc 0.9898
01:26:26.601   Training iter 200, batch loss 0.0451, batch acc 0.9888
01:26:26.750   Training iter 250, batch loss 0.0406, batch acc 0.9910
01:26:26.870   Training iter 300, batch loss 0.0464, batch acc 0.9882
01:26:26.972   Training iter 350, batch loss 0.0456, batch acc 0.9898
01:26:27.105   Training iter 400, batch loss 0.0380, batch acc 0.9914
01:26:27.217   Training iter 450, batch loss 0.0400, batch acc 0.9892
01:26:27.401   Training iter 500, batch loss 0.0454, batch acc 0.9898
01:26:27.707   Training iter 550, batch loss 0.0458, batch acc 0.9890
01:26:27.950   Training iter 600, batch loss 0.0424, batch acc 0.9888
01:26:27.953 Training @ 87 epoch...
01:26:28.062   Training iter 50, batch loss 0.0402, batch acc 0.9908
01:26:28.171   Training iter 100, batch loss 0.0424, batch acc 0.9906
01:26:28.299   Training iter 150, batch loss 0.0418, batch acc 0.9902
01:26:28.417   Training iter 200, batch loss 0.0400, batch acc 0.9896
01:26:28.539   Training iter 250, batch loss 0.0440, batch acc 0.9900
01:26:28.672   Training iter 300, batch loss 0.0436, batch acc 0.9898
01:26:28.945   Training iter 350, batch loss 0.0438, batch acc 0.9908
01:26:29.040   Training iter 400, batch loss 0.0413, batch acc 0.9906
01:26:29.170   Training iter 450, batch loss 0.0498, batch acc 0.9878
01:26:29.317   Training iter 500, batch loss 0.0514, batch acc 0.9870
01:26:29.433   Training iter 550, batch loss 0.0474, batch acc 0.9866
01:26:29.539   Training iter 600, batch loss 0.0488, batch acc 0.9878
01:26:29.540 Training @ 88 epoch...
01:26:29.648   Training iter 50, batch loss 0.0417, batch acc 0.9904
01:26:29.736   Training iter 100, batch loss 0.0392, batch acc 0.9912
01:26:29.833   Training iter 150, batch loss 0.0385, batch acc 0.9924
01:26:29.929   Training iter 200, batch loss 0.0475, batch acc 0.9880
01:26:30.024   Training iter 250, batch loss 0.0526, batch acc 0.9864
01:26:30.199   Training iter 300, batch loss 0.0465, batch acc 0.9872
01:26:30.384   Training iter 350, batch loss 0.0464, batch acc 0.9898
01:26:30.511   Training iter 400, batch loss 0.0414, batch acc 0.9906
01:26:30.632   Training iter 450, batch loss 0.0459, batch acc 0.9880
01:26:30.754   Training iter 500, batch loss 0.0451, batch acc 0.9900
01:26:30.939   Training iter 550, batch loss 0.0427, batch acc 0.9904
01:26:31.069   Training iter 600, batch loss 0.0445, batch acc 0.9894
01:26:31.070 Training @ 89 epoch...
01:26:31.214   Training iter 50, batch loss 0.0474, batch acc 0.9874
01:26:31.388   Training iter 100, batch loss 0.0385, batch acc 0.9912
01:26:31.533   Training iter 150, batch loss 0.0406, batch acc 0.9904
01:26:31.669   Training iter 200, batch loss 0.0519, batch acc 0.9868
01:26:31.824   Training iter 250, batch loss 0.0441, batch acc 0.9900
01:26:31.985   Training iter 300, batch loss 0.0399, batch acc 0.9918
01:26:32.120   Training iter 350, batch loss 0.0450, batch acc 0.9896
01:26:32.282   Training iter 400, batch loss 0.0436, batch acc 0.9900
01:26:32.413   Training iter 450, batch loss 0.0469, batch acc 0.9884
01:26:32.581   Training iter 500, batch loss 0.0441, batch acc 0.9888
01:26:32.897   Training iter 550, batch loss 0.0456, batch acc 0.9880
01:26:33.067   Training iter 600, batch loss 0.0444, batch acc 0.9898
01:26:33.068 Training @ 90 epoch...
01:26:33.298   Training iter 50, batch loss 0.0478, batch acc 0.9878
01:26:33.437   Training iter 100, batch loss 0.0377, batch acc 0.9938
01:26:33.572   Training iter 150, batch loss 0.0440, batch acc 0.9888
01:26:33.750   Training iter 200, batch loss 0.0412, batch acc 0.9918
01:26:33.926   Training iter 250, batch loss 0.0396, batch acc 0.9920
01:26:34.086   Training iter 300, batch loss 0.0406, batch acc 0.9906
01:26:34.379   Training iter 350, batch loss 0.0432, batch acc 0.9906
01:26:34.551   Training iter 400, batch loss 0.0474, batch acc 0.9874
01:26:34.656   Training iter 450, batch loss 0.0475, batch acc 0.9888
01:26:34.789   Training iter 500, batch loss 0.0459, batch acc 0.9882
01:26:34.976   Training iter 550, batch loss 0.0470, batch acc 0.9884
01:26:35.138   Training iter 600, batch loss 0.0482, batch acc 0.9842
01:26:35.139 Testing @ 90 epoch...
01:26:35.267     Testing, total mean loss 0.07766, total acc 0.97680
01:26:35.267 Training @ 91 epoch...
01:26:35.412   Training iter 50, batch loss 0.0371, batch acc 0.9920
01:26:35.498   Training iter 100, batch loss 0.0400, batch acc 0.9894
01:26:35.602   Training iter 150, batch loss 0.0436, batch acc 0.9886
01:26:35.706   Training iter 200, batch loss 0.0400, batch acc 0.9912
01:26:35.805   Training iter 250, batch loss 0.0437, batch acc 0.9910
01:26:35.932   Training iter 300, batch loss 0.0453, batch acc 0.9886
01:26:36.021   Training iter 350, batch loss 0.0479, batch acc 0.9892
01:26:36.120   Training iter 400, batch loss 0.0422, batch acc 0.9898
01:26:36.224   Training iter 450, batch loss 0.0481, batch acc 0.9884
01:26:36.355   Training iter 500, batch loss 0.0452, batch acc 0.9900
01:26:36.454   Training iter 550, batch loss 0.0445, batch acc 0.9876
01:26:36.564   Training iter 600, batch loss 0.0506, batch acc 0.9880
01:26:36.564 Training @ 92 epoch...
01:26:36.668   Training iter 50, batch loss 0.0455, batch acc 0.9892
01:26:36.772   Training iter 100, batch loss 0.0438, batch acc 0.9884
01:26:36.863   Training iter 150, batch loss 0.0426, batch acc 0.9894
01:26:36.960   Training iter 200, batch loss 0.0395, batch acc 0.9918
01:26:37.053   Training iter 250, batch loss 0.0428, batch acc 0.9906
01:26:37.262   Training iter 300, batch loss 0.0472, batch acc 0.9866
01:26:37.379   Training iter 350, batch loss 0.0516, batch acc 0.9866
01:26:37.505   Training iter 400, batch loss 0.0463, batch acc 0.9876
01:26:37.609   Training iter 450, batch loss 0.0439, batch acc 0.9904
01:26:37.705   Training iter 500, batch loss 0.0465, batch acc 0.9882
01:26:37.819   Training iter 550, batch loss 0.0485, batch acc 0.9884
01:26:37.954   Training iter 600, batch loss 0.0395, batch acc 0.9914
01:26:37.955 Training @ 93 epoch...
01:26:38.063   Training iter 50, batch loss 0.0483, batch acc 0.9894
01:26:38.172   Training iter 100, batch loss 0.0426, batch acc 0.9896
01:26:38.267   Training iter 150, batch loss 0.0420, batch acc 0.9910
01:26:38.362   Training iter 200, batch loss 0.0441, batch acc 0.9896
01:26:38.451   Training iter 250, batch loss 0.0461, batch acc 0.9890
01:26:38.537   Training iter 300, batch loss 0.0402, batch acc 0.9906
01:26:38.630   Training iter 350, batch loss 0.0377, batch acc 0.9912
01:26:38.718   Training iter 400, batch loss 0.0452, batch acc 0.9886
01:26:38.806   Training iter 450, batch loss 0.0425, batch acc 0.9902
01:26:38.896   Training iter 500, batch loss 0.0486, batch acc 0.9894
01:26:39.039   Training iter 550, batch loss 0.0460, batch acc 0.9886
01:26:39.144   Training iter 600, batch loss 0.0454, batch acc 0.9880
01:26:39.144 Training @ 94 epoch...
01:26:39.246   Training iter 50, batch loss 0.0412, batch acc 0.9902
01:26:39.352   Training iter 100, batch loss 0.0416, batch acc 0.9900
01:26:39.470   Training iter 150, batch loss 0.0396, batch acc 0.9914
01:26:39.582   Training iter 200, batch loss 0.0411, batch acc 0.9914
01:26:39.765   Training iter 250, batch loss 0.0463, batch acc 0.9902
01:26:39.888   Training iter 300, batch loss 0.0471, batch acc 0.9886
01:26:39.987   Training iter 350, batch loss 0.0405, batch acc 0.9918
01:26:40.079   Training iter 400, batch loss 0.0425, batch acc 0.9890
01:26:40.227   Training iter 450, batch loss 0.0453, batch acc 0.9882
01:26:40.457   Training iter 500, batch loss 0.0460, batch acc 0.9880
01:26:40.612   Training iter 550, batch loss 0.0502, batch acc 0.9864
01:26:40.734   Training iter 600, batch loss 0.0419, batch acc 0.9894
01:26:40.736 Training @ 95 epoch...
01:26:40.879   Training iter 50, batch loss 0.0381, batch acc 0.9922
01:26:40.992   Training iter 100, batch loss 0.0404, batch acc 0.9928
01:26:41.096   Training iter 150, batch loss 0.0426, batch acc 0.9886
01:26:41.210   Training iter 200, batch loss 0.0444, batch acc 0.9892
01:26:41.315   Training iter 250, batch loss 0.0439, batch acc 0.9884
01:26:41.411   Training iter 300, batch loss 0.0440, batch acc 0.9902
01:26:41.515   Training iter 350, batch loss 0.0443, batch acc 0.9898
01:26:41.621   Training iter 400, batch loss 0.0456, batch acc 0.9872
01:26:41.719   Training iter 450, batch loss 0.0429, batch acc 0.9892
01:26:41.838   Training iter 500, batch loss 0.0441, batch acc 0.9898
01:26:41.936   Training iter 550, batch loss 0.0460, batch acc 0.9894
01:26:42.047   Training iter 600, batch loss 0.0424, batch acc 0.9890
01:26:42.048 Testing @ 95 epoch...
01:26:42.117     Testing, total mean loss 0.07608, total acc 0.97630
01:26:42.118 Training @ 96 epoch...
01:26:42.233   Training iter 50, batch loss 0.0454, batch acc 0.9890
01:26:42.340   Training iter 100, batch loss 0.0387, batch acc 0.9910
01:26:42.509   Training iter 150, batch loss 0.0452, batch acc 0.9894
01:26:42.611   Training iter 200, batch loss 0.0416, batch acc 0.9908
01:26:42.713   Training iter 250, batch loss 0.0442, batch acc 0.9898
01:26:42.851   Training iter 300, batch loss 0.0506, batch acc 0.9864
01:26:42.990   Training iter 350, batch loss 0.0424, batch acc 0.9898
01:26:43.142   Training iter 400, batch loss 0.0509, batch acc 0.9862
01:26:43.289   Training iter 450, batch loss 0.0426, batch acc 0.9870
01:26:43.436   Training iter 500, batch loss 0.0448, batch acc 0.9888
01:26:43.551   Training iter 550, batch loss 0.0433, batch acc 0.9902
01:26:43.668   Training iter 600, batch loss 0.0412, batch acc 0.9896
01:26:43.670 Training @ 97 epoch...
01:26:43.914   Training iter 50, batch loss 0.0441, batch acc 0.9896
01:26:44.021   Training iter 100, batch loss 0.0394, batch acc 0.9922
01:26:44.133   Training iter 150, batch loss 0.0387, batch acc 0.9922
01:26:44.268   Training iter 200, batch loss 0.0410, batch acc 0.9904
01:26:44.366   Training iter 250, batch loss 0.0406, batch acc 0.9896
01:26:44.461   Training iter 300, batch loss 0.0450, batch acc 0.9880
01:26:44.550   Training iter 350, batch loss 0.0466, batch acc 0.9888
01:26:44.645   Training iter 400, batch loss 0.0482, batch acc 0.9870
01:26:44.739   Training iter 450, batch loss 0.0471, batch acc 0.9864
01:26:44.847   Training iter 500, batch loss 0.0404, batch acc 0.9916
01:26:44.954   Training iter 550, batch loss 0.0429, batch acc 0.9910
01:26:45.048   Training iter 600, batch loss 0.0465, batch acc 0.9880
01:26:45.049 Training @ 98 epoch...
01:26:45.144   Training iter 50, batch loss 0.0461, batch acc 0.9884
01:26:45.246   Training iter 100, batch loss 0.0439, batch acc 0.9896
01:26:45.349   Training iter 150, batch loss 0.0448, batch acc 0.9880
01:26:45.475   Training iter 200, batch loss 0.0422, batch acc 0.9902
01:26:45.612   Training iter 250, batch loss 0.0408, batch acc 0.9908
01:26:45.733   Training iter 300, batch loss 0.0416, batch acc 0.9908
01:26:45.857   Training iter 350, batch loss 0.0509, batch acc 0.9872
01:26:45.979   Training iter 400, batch loss 0.0488, batch acc 0.9880
01:26:46.077   Training iter 450, batch loss 0.0378, batch acc 0.9930
01:26:46.187   Training iter 500, batch loss 0.0411, batch acc 0.9906
01:26:46.313   Training iter 550, batch loss 0.0393, batch acc 0.9902
01:26:46.406   Training iter 600, batch loss 0.0454, batch acc 0.9872
01:26:46.407 Training @ 99 epoch...
01:26:46.552   Training iter 50, batch loss 0.0364, batch acc 0.9946
01:26:46.663   Training iter 100, batch loss 0.0399, batch acc 0.9920
01:26:46.771   Training iter 150, batch loss 0.0443, batch acc 0.9884
01:26:46.883   Training iter 200, batch loss 0.0465, batch acc 0.9888
01:26:46.976   Training iter 250, batch loss 0.0383, batch acc 0.9934
01:26:47.061   Training iter 300, batch loss 0.0389, batch acc 0.9914
01:26:47.163   Training iter 350, batch loss 0.0460, batch acc 0.9908
01:26:47.263   Training iter 400, batch loss 0.0410, batch acc 0.9894
01:26:47.368   Training iter 450, batch loss 0.0455, batch acc 0.9890
01:26:47.460   Training iter 500, batch loss 0.0424, batch acc 0.9886
01:26:47.556   Training iter 550, batch loss 0.0489, batch acc 0.9880
01:26:47.663   Training iter 600, batch loss 0.0453, batch acc 0.9898