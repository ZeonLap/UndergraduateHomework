18:44:30.261 Training @ 0 epoch...
18:44:30.446   Training iter 50, batch loss 2.2830, batch acc 0.1776
18:44:30.598   Training iter 100, batch loss 1.9712, batch acc 0.3566
18:44:30.932   Training iter 150, batch loss 1.0357, batch acc 0.7190
18:44:31.125   Training iter 200, batch loss 0.6282, batch acc 0.8154
18:44:31.357   Training iter 250, batch loss 0.5024, batch acc 0.8542
18:44:31.641   Training iter 300, batch loss 0.4817, batch acc 0.8568
18:44:31.846   Training iter 350, batch loss 0.4053, batch acc 0.8854
18:44:32.077   Training iter 400, batch loss 0.3616, batch acc 0.8982
18:44:32.331   Training iter 450, batch loss 0.3746, batch acc 0.8912
18:44:32.554   Training iter 500, batch loss 0.3683, batch acc 0.8946
18:44:32.722   Training iter 550, batch loss 0.3440, batch acc 0.9030
18:44:32.896   Training iter 600, batch loss 0.3597, batch acc 0.8942
18:44:32.897 Testing @ 0 epoch...
18:44:33.012     Testing, total mean loss 0.32050, total acc 0.90580
18:44:33.012 Training @ 1 epoch...
18:44:33.199   Training iter 50, batch loss 0.3368, batch acc 0.9066
18:44:33.400   Training iter 100, batch loss 0.3332, batch acc 0.9034
18:44:33.509   Training iter 150, batch loss 0.3235, batch acc 0.9094
18:44:33.613   Training iter 200, batch loss 0.3107, batch acc 0.9098
18:44:33.761   Training iter 250, batch loss 0.3019, batch acc 0.9164
18:44:33.894   Training iter 300, batch loss 0.3056, batch acc 0.9090
18:44:33.994   Training iter 350, batch loss 0.2972, batch acc 0.9158
18:44:34.100   Training iter 400, batch loss 0.2824, batch acc 0.9146
18:44:34.203   Training iter 450, batch loss 0.2916, batch acc 0.9132
18:44:34.308   Training iter 500, batch loss 0.2991, batch acc 0.9142
18:44:34.388   Training iter 550, batch loss 0.2811, batch acc 0.9184
18:44:34.492   Training iter 600, batch loss 0.2818, batch acc 0.9188
18:44:34.493 Training @ 2 epoch...
18:44:34.604   Training iter 50, batch loss 0.2466, batch acc 0.9276
18:44:34.730   Training iter 100, batch loss 0.2622, batch acc 0.9220
18:44:34.831   Training iter 150, batch loss 0.2429, batch acc 0.9336
18:44:34.935   Training iter 200, batch loss 0.2534, batch acc 0.9262
18:44:35.053   Training iter 250, batch loss 0.2614, batch acc 0.9258
18:44:35.179   Training iter 300, batch loss 0.2472, batch acc 0.9256
18:44:35.310   Training iter 350, batch loss 0.2478, batch acc 0.9282
18:44:35.423   Training iter 400, batch loss 0.2581, batch acc 0.9260
18:44:35.511   Training iter 450, batch loss 0.2355, batch acc 0.9276
18:44:35.606   Training iter 500, batch loss 0.2516, batch acc 0.9288
18:44:35.700   Training iter 550, batch loss 0.2532, batch acc 0.9236
18:44:35.811   Training iter 600, batch loss 0.2451, batch acc 0.9284
18:44:35.811 Training @ 3 epoch...
18:44:35.921   Training iter 50, batch loss 0.2244, batch acc 0.9350
18:44:36.024   Training iter 100, batch loss 0.2176, batch acc 0.9400
18:44:36.128   Training iter 150, batch loss 0.2051, batch acc 0.9412
18:44:36.222   Training iter 200, batch loss 0.2190, batch acc 0.9376
18:44:36.325   Training iter 250, batch loss 0.2068, batch acc 0.9392
18:44:36.424   Training iter 300, batch loss 0.2143, batch acc 0.9364
18:44:36.521   Training iter 350, batch loss 0.2195, batch acc 0.9340
18:44:36.624   Training iter 400, batch loss 0.2136, batch acc 0.9362
18:44:36.766   Training iter 450, batch loss 0.2093, batch acc 0.9378
18:44:36.878   Training iter 500, batch loss 0.2116, batch acc 0.9424
18:44:36.973   Training iter 550, batch loss 0.1935, batch acc 0.9442
18:44:37.067   Training iter 600, batch loss 0.2204, batch acc 0.9370
18:44:37.072 Training @ 4 epoch...
18:44:37.176   Training iter 50, batch loss 0.1950, batch acc 0.9440
18:44:37.289   Training iter 100, batch loss 0.1917, batch acc 0.9444
18:44:37.406   Training iter 150, batch loss 0.1990, batch acc 0.9430
18:44:37.506   Training iter 200, batch loss 0.1919, batch acc 0.9444
18:44:37.612   Training iter 250, batch loss 0.1859, batch acc 0.9452
18:44:37.765   Training iter 300, batch loss 0.1819, batch acc 0.9500
18:44:37.915   Training iter 350, batch loss 0.1677, batch acc 0.9490
18:44:38.035   Training iter 400, batch loss 0.1764, batch acc 0.9504
18:44:38.145   Training iter 450, batch loss 0.1731, batch acc 0.9508
18:44:38.247   Training iter 500, batch loss 0.1860, batch acc 0.9444
18:44:38.345   Training iter 550, batch loss 0.1787, batch acc 0.9466
18:44:38.431   Training iter 600, batch loss 0.1931, batch acc 0.9400
18:44:38.431 Training @ 5 epoch...
18:44:38.529   Training iter 50, batch loss 0.1791, batch acc 0.9482
18:44:38.638   Training iter 100, batch loss 0.1755, batch acc 0.9468
18:44:38.739   Training iter 150, batch loss 0.1447, batch acc 0.9552
18:44:38.843   Training iter 200, batch loss 0.1535, batch acc 0.9558
18:44:38.939   Training iter 250, batch loss 0.1614, batch acc 0.9526
18:44:39.041   Training iter 300, batch loss 0.1645, batch acc 0.9496
18:44:39.149   Training iter 350, batch loss 0.1779, batch acc 0.9492
18:44:39.246   Training iter 400, batch loss 0.1730, batch acc 0.9494
18:44:39.353   Training iter 450, batch loss 0.1510, batch acc 0.9538
18:44:39.456   Training iter 500, batch loss 0.1570, batch acc 0.9550
18:44:39.552   Training iter 550, batch loss 0.1766, batch acc 0.9486
18:44:39.789   Training iter 600, batch loss 0.1701, batch acc 0.9536
18:44:39.789 Testing @ 5 epoch...
18:44:39.936     Testing, total mean loss 0.16290, total acc 0.95190
18:44:39.936 Training @ 6 epoch...
18:44:40.041   Training iter 50, batch loss 0.1586, batch acc 0.9532
18:44:40.142   Training iter 100, batch loss 0.1500, batch acc 0.9568
18:44:40.264   Training iter 150, batch loss 0.1641, batch acc 0.9494
18:44:40.365   Training iter 200, batch loss 0.1571, batch acc 0.9538
18:44:40.463   Training iter 250, batch loss 0.1385, batch acc 0.9594
18:44:40.571   Training iter 300, batch loss 0.1560, batch acc 0.9530
18:44:40.676   Training iter 350, batch loss 0.1409, batch acc 0.9614
18:44:40.789   Training iter 400, batch loss 0.1452, batch acc 0.9584
18:44:40.883   Training iter 450, batch loss 0.1496, batch acc 0.9584
18:44:41.080   Training iter 500, batch loss 0.1414, batch acc 0.9584
18:44:41.496   Training iter 550, batch loss 0.1496, batch acc 0.9558
18:44:41.903   Training iter 600, batch loss 0.1489, batch acc 0.9550
18:44:41.904 Training @ 7 epoch...
18:44:42.551   Training iter 50, batch loss 0.1417, batch acc 0.9582
18:44:43.239   Training iter 100, batch loss 0.1533, batch acc 0.9582
18:44:44.536   Training iter 150, batch loss 0.1422, batch acc 0.9580
18:44:45.389   Training iter 200, batch loss 0.1296, batch acc 0.9618
18:44:45.901   Training iter 250, batch loss 0.1438, batch acc 0.9620
18:44:46.357   Training iter 300, batch loss 0.1247, batch acc 0.9646
18:44:47.500   Training iter 350, batch loss 0.1273, batch acc 0.9616
18:44:47.992   Training iter 400, batch loss 0.1276, batch acc 0.9636
18:44:48.347   Training iter 450, batch loss 0.1287, batch acc 0.9644
18:44:48.497   Training iter 500, batch loss 0.1300, batch acc 0.9586
18:44:48.617   Training iter 550, batch loss 0.1439, batch acc 0.9584
18:44:48.731   Training iter 600, batch loss 0.1440, batch acc 0.9570
18:44:48.738 Training @ 8 epoch...
18:44:48.902   Training iter 50, batch loss 0.1318, batch acc 0.9626
18:44:49.179   Training iter 100, batch loss 0.1288, batch acc 0.9604
18:44:49.430   Training iter 150, batch loss 0.1277, batch acc 0.9610
18:44:49.612   Training iter 200, batch loss 0.1307, batch acc 0.9626
18:44:49.830   Training iter 250, batch loss 0.1244, batch acc 0.9646
18:44:50.065   Training iter 300, batch loss 0.1369, batch acc 0.9612
18:44:50.215   Training iter 350, batch loss 0.1222, batch acc 0.9644
18:44:50.331   Training iter 400, batch loss 0.1201, batch acc 0.9644
18:44:50.460   Training iter 450, batch loss 0.1278, batch acc 0.9632
18:44:50.625   Training iter 500, batch loss 0.1215, batch acc 0.9650
18:44:50.745   Training iter 550, batch loss 0.1302, batch acc 0.9634
18:44:50.869   Training iter 600, batch loss 0.1153, batch acc 0.9678
18:44:50.870 Training @ 9 epoch...
18:44:51.008   Training iter 50, batch loss 0.1085, batch acc 0.9702
18:44:51.147   Training iter 100, batch loss 0.1190, batch acc 0.9662
18:44:51.258   Training iter 150, batch loss 0.1114, batch acc 0.9670
18:44:51.411   Training iter 200, batch loss 0.1292, batch acc 0.9642
18:44:51.525   Training iter 250, batch loss 0.1227, batch acc 0.9640
18:44:51.645   Training iter 300, batch loss 0.1362, batch acc 0.9622
18:44:51.781   Training iter 350, batch loss 0.1269, batch acc 0.9628
18:44:51.933   Training iter 400, batch loss 0.1141, batch acc 0.9684
18:44:52.086   Training iter 450, batch loss 0.1061, batch acc 0.9704
18:44:52.213   Training iter 500, batch loss 0.1142, batch acc 0.9666
18:44:52.381   Training iter 550, batch loss 0.1133, batch acc 0.9704
18:44:52.592   Training iter 600, batch loss 0.1104, batch acc 0.9680
18:44:52.594 Training @ 10 epoch...
18:44:52.751   Training iter 50, batch loss 0.1161, batch acc 0.9662
18:44:52.860   Training iter 100, batch loss 0.1220, batch acc 0.9656
18:44:52.971   Training iter 150, batch loss 0.1089, batch acc 0.9694
18:44:53.083   Training iter 200, batch loss 0.1047, batch acc 0.9704
18:44:53.192   Training iter 250, batch loss 0.1021, batch acc 0.9674
18:44:53.305   Training iter 300, batch loss 0.1240, batch acc 0.9628
18:44:53.417   Training iter 350, batch loss 0.1025, batch acc 0.9708
18:44:53.528   Training iter 400, batch loss 0.1043, batch acc 0.9724
18:44:53.631   Training iter 450, batch loss 0.1154, batch acc 0.9658
18:44:53.734   Training iter 500, batch loss 0.1084, batch acc 0.9664
18:44:53.853   Training iter 550, batch loss 0.1107, batch acc 0.9694
18:44:53.956   Training iter 600, batch loss 0.1108, batch acc 0.9698
18:44:53.958 Testing @ 10 epoch...
18:44:54.044     Testing, total mean loss 0.11456, total acc 0.96700
18:44:54.044 Training @ 11 epoch...
18:44:54.150   Training iter 50, batch loss 0.1074, batch acc 0.9704
18:44:54.261   Training iter 100, batch loss 0.1072, batch acc 0.9690
18:44:54.368   Training iter 150, batch loss 0.0994, batch acc 0.9688
18:44:54.475   Training iter 200, batch loss 0.0969, batch acc 0.9748
18:44:54.589   Training iter 250, batch loss 0.1031, batch acc 0.9718
18:44:54.710   Training iter 300, batch loss 0.1041, batch acc 0.9716
18:44:54.836   Training iter 350, batch loss 0.1123, batch acc 0.9674
18:44:54.959   Training iter 400, batch loss 0.1043, batch acc 0.9694
18:44:55.076   Training iter 450, batch loss 0.0955, batch acc 0.9750
18:44:55.206   Training iter 500, batch loss 0.0986, batch acc 0.9732
18:44:55.366   Training iter 550, batch loss 0.1045, batch acc 0.9698
18:44:55.517   Training iter 600, batch loss 0.1116, batch acc 0.9656
18:44:55.519 Training @ 12 epoch...
18:44:55.634   Training iter 50, batch loss 0.0869, batch acc 0.9758
18:44:55.773   Training iter 100, batch loss 0.0940, batch acc 0.9734
18:44:55.945   Training iter 150, batch loss 0.1035, batch acc 0.9714
18:44:56.110   Training iter 200, batch loss 0.1017, batch acc 0.9702
18:44:56.220   Training iter 250, batch loss 0.1024, batch acc 0.9718
18:44:56.359   Training iter 300, batch loss 0.1021, batch acc 0.9706
18:44:56.601   Training iter 350, batch loss 0.0974, batch acc 0.9732
18:44:56.715   Training iter 400, batch loss 0.1091, batch acc 0.9654
18:44:56.838   Training iter 450, batch loss 0.0977, batch acc 0.9704
18:44:56.967   Training iter 500, batch loss 0.0978, batch acc 0.9722
18:44:57.066   Training iter 550, batch loss 0.0981, batch acc 0.9708
18:44:57.167   Training iter 600, batch loss 0.0959, batch acc 0.9740
18:44:57.168 Training @ 13 epoch...
18:44:57.272   Training iter 50, batch loss 0.0818, batch acc 0.9776
18:44:57.451   Training iter 100, batch loss 0.0948, batch acc 0.9740
18:44:57.639   Training iter 150, batch loss 0.0898, batch acc 0.9752
18:44:57.941   Training iter 200, batch loss 0.0937, batch acc 0.9740
18:44:58.113   Training iter 250, batch loss 0.0857, batch acc 0.9774
18:44:58.315   Training iter 300, batch loss 0.1034, batch acc 0.9716
18:44:58.561   Training iter 350, batch loss 0.1087, batch acc 0.9692
18:44:58.753   Training iter 400, batch loss 0.0992, batch acc 0.9698
18:44:58.898   Training iter 450, batch loss 0.0874, batch acc 0.9744
18:44:59.096   Training iter 500, batch loss 0.1004, batch acc 0.9700
18:44:59.273   Training iter 550, batch loss 0.0890, batch acc 0.9732
18:44:59.464   Training iter 600, batch loss 0.0944, batch acc 0.9732
18:44:59.467 Training @ 14 epoch...
18:44:59.647   Training iter 50, batch loss 0.0903, batch acc 0.9748
18:44:59.854   Training iter 100, batch loss 0.0876, batch acc 0.9758
18:45:00.056   Training iter 150, batch loss 0.0914, batch acc 0.9734
18:45:00.212   Training iter 200, batch loss 0.0908, batch acc 0.9748
18:45:00.370   Training iter 250, batch loss 0.0947, batch acc 0.9726
18:45:00.590   Training iter 300, batch loss 0.0917, batch acc 0.9740
18:45:00.782   Training iter 350, batch loss 0.0897, batch acc 0.9718
18:45:00.957   Training iter 400, batch loss 0.0875, batch acc 0.9762
18:45:01.162   Training iter 450, batch loss 0.0880, batch acc 0.9772
18:45:01.316   Training iter 500, batch loss 0.0905, batch acc 0.9734
18:45:01.576   Training iter 550, batch loss 0.0806, batch acc 0.9794
18:45:01.746   Training iter 600, batch loss 0.0874, batch acc 0.9758
18:45:01.747 Training @ 15 epoch...
18:45:01.914   Training iter 50, batch loss 0.0826, batch acc 0.9750
18:45:02.112   Training iter 100, batch loss 0.0900, batch acc 0.9764
18:45:02.281   Training iter 150, batch loss 0.0896, batch acc 0.9750
18:45:02.511   Training iter 200, batch loss 0.0879, batch acc 0.9748
18:45:02.674   Training iter 250, batch loss 0.0817, batch acc 0.9764
18:45:02.836   Training iter 300, batch loss 0.0848, batch acc 0.9744
18:45:03.181   Training iter 350, batch loss 0.0860, batch acc 0.9752
18:45:03.449   Training iter 400, batch loss 0.0871, batch acc 0.9756
18:45:03.710   Training iter 450, batch loss 0.0826, batch acc 0.9782
18:45:03.909   Training iter 500, batch loss 0.0796, batch acc 0.9764
18:45:04.192   Training iter 550, batch loss 0.0931, batch acc 0.9730
18:45:04.443   Training iter 600, batch loss 0.0803, batch acc 0.9784
18:45:04.451 Testing @ 15 epoch...
18:45:04.663     Testing, total mean loss 0.09930, total acc 0.96910
18:45:04.663 Training @ 16 epoch...
18:45:04.846   Training iter 50, batch loss 0.0856, batch acc 0.9784
18:45:05.061   Training iter 100, batch loss 0.0757, batch acc 0.9786
18:45:05.206   Training iter 150, batch loss 0.0777, batch acc 0.9774
18:45:05.397   Training iter 200, batch loss 0.0859, batch acc 0.9762
18:45:05.543   Training iter 250, batch loss 0.0772, batch acc 0.9812
18:45:05.679   Training iter 300, batch loss 0.0829, batch acc 0.9750
18:45:05.862   Training iter 350, batch loss 0.0803, batch acc 0.9752
18:45:06.015   Training iter 400, batch loss 0.0982, batch acc 0.9720
18:45:06.207   Training iter 450, batch loss 0.0743, batch acc 0.9808
18:45:06.497   Training iter 500, batch loss 0.0849, batch acc 0.9758
18:45:06.675   Training iter 550, batch loss 0.0926, batch acc 0.9732
18:45:06.878   Training iter 600, batch loss 0.0834, batch acc 0.9786
18:45:06.878 Training @ 17 epoch...
18:45:07.110   Training iter 50, batch loss 0.0656, batch acc 0.9842
18:45:07.364   Training iter 100, batch loss 0.0828, batch acc 0.9774
18:45:07.513   Training iter 150, batch loss 0.0820, batch acc 0.9764
18:45:07.754   Training iter 200, batch loss 0.0916, batch acc 0.9756
18:45:07.921   Training iter 250, batch loss 0.0734, batch acc 0.9786
18:45:08.098   Training iter 300, batch loss 0.0692, batch acc 0.9804
18:45:08.296   Training iter 350, batch loss 0.0877, batch acc 0.9750
18:45:08.573   Training iter 400, batch loss 0.0867, batch acc 0.9774
18:45:08.713   Training iter 450, batch loss 0.0841, batch acc 0.9770
18:45:08.856   Training iter 500, batch loss 0.0763, batch acc 0.9796
18:45:09.006   Training iter 550, batch loss 0.0770, batch acc 0.9786
18:45:09.163   Training iter 600, batch loss 0.0709, batch acc 0.9802
18:45:09.164 Training @ 18 epoch...
18:45:09.321   Training iter 50, batch loss 0.0754, batch acc 0.9778
18:45:09.462   Training iter 100, batch loss 0.0703, batch acc 0.9808
18:45:09.617   Training iter 150, batch loss 0.0824, batch acc 0.9756
18:45:09.759   Training iter 200, batch loss 0.0762, batch acc 0.9774
18:45:09.947   Training iter 250, batch loss 0.0724, batch acc 0.9816
18:45:10.068   Training iter 300, batch loss 0.0704, batch acc 0.9824
18:45:10.210   Training iter 350, batch loss 0.0767, batch acc 0.9780
18:45:10.348   Training iter 400, batch loss 0.0825, batch acc 0.9760
18:45:10.508   Training iter 450, batch loss 0.0799, batch acc 0.9770
18:45:10.648   Training iter 500, batch loss 0.0761, batch acc 0.9798
18:45:10.791   Training iter 550, batch loss 0.0727, batch acc 0.9782
18:45:10.939   Training iter 600, batch loss 0.0782, batch acc 0.9800
18:45:10.940 Training @ 19 epoch...
18:45:11.093   Training iter 50, batch loss 0.0739, batch acc 0.9796
18:45:11.225   Training iter 100, batch loss 0.0621, batch acc 0.9842
18:45:11.373   Training iter 150, batch loss 0.0818, batch acc 0.9778
18:45:11.528   Training iter 200, batch loss 0.0657, batch acc 0.9806
18:45:11.666   Training iter 250, batch loss 0.0769, batch acc 0.9756
18:45:11.809   Training iter 300, batch loss 0.0724, batch acc 0.9808
18:45:11.997   Training iter 350, batch loss 0.0745, batch acc 0.9806
18:45:12.175   Training iter 400, batch loss 0.0765, batch acc 0.9772
18:45:12.355   Training iter 450, batch loss 0.0745, batch acc 0.9808
18:45:12.530   Training iter 500, batch loss 0.0780, batch acc 0.9786
18:45:12.847   Training iter 550, batch loss 0.0760, batch acc 0.9778
18:45:13.029   Training iter 600, batch loss 0.0761, batch acc 0.9794
18:45:13.029 Training @ 20 epoch...
18:45:13.152   Training iter 50, batch loss 0.0680, batch acc 0.9848
18:45:13.266   Training iter 100, batch loss 0.0703, batch acc 0.9816
18:45:13.381   Training iter 150, batch loss 0.0719, batch acc 0.9808
18:45:13.492   Training iter 200, batch loss 0.0664, batch acc 0.9842
18:45:13.593   Training iter 250, batch loss 0.0764, batch acc 0.9764
18:45:13.711   Training iter 300, batch loss 0.0753, batch acc 0.9808
18:45:13.816   Training iter 350, batch loss 0.0622, batch acc 0.9828
18:45:13.924   Training iter 400, batch loss 0.0687, batch acc 0.9806
18:45:14.039   Training iter 450, batch loss 0.0727, batch acc 0.9798
18:45:14.148   Training iter 500, batch loss 0.0731, batch acc 0.9786
18:45:14.268   Training iter 550, batch loss 0.0710, batch acc 0.9792
18:45:14.384   Training iter 600, batch loss 0.0788, batch acc 0.9774
18:45:14.384 Testing @ 20 epoch...
18:45:14.498     Testing, total mean loss 0.09016, total acc 0.97320
18:45:14.498 Training @ 21 epoch...
18:45:14.682   Training iter 50, batch loss 0.0677, batch acc 0.9824
18:45:14.792   Training iter 100, batch loss 0.0611, batch acc 0.9858
18:45:14.920   Training iter 150, batch loss 0.0704, batch acc 0.9792
18:45:15.066   Training iter 200, batch loss 0.0683, batch acc 0.9832
18:45:15.200   Training iter 250, batch loss 0.0756, batch acc 0.9776
18:45:15.393   Training iter 300, batch loss 0.0726, batch acc 0.9812
18:45:15.535   Training iter 350, batch loss 0.0758, batch acc 0.9748
18:45:15.675   Training iter 400, batch loss 0.0670, batch acc 0.9816
18:45:15.865   Training iter 450, batch loss 0.0734, batch acc 0.9788
18:45:15.990   Training iter 500, batch loss 0.0680, batch acc 0.9818
18:45:16.098   Training iter 550, batch loss 0.0713, batch acc 0.9792
18:45:16.210   Training iter 600, batch loss 0.0695, batch acc 0.9814
18:45:16.211 Training @ 22 epoch...
18:45:16.340   Training iter 50, batch loss 0.0662, batch acc 0.9816
18:45:16.463   Training iter 100, batch loss 0.0648, batch acc 0.9844
18:45:16.568   Training iter 150, batch loss 0.0653, batch acc 0.9822
18:45:16.673   Training iter 200, batch loss 0.0689, batch acc 0.9800
18:45:16.782   Training iter 250, batch loss 0.0632, batch acc 0.9838
18:45:16.896   Training iter 300, batch loss 0.0611, batch acc 0.9814
18:45:17.015   Training iter 350, batch loss 0.0625, batch acc 0.9834
18:45:17.125   Training iter 400, batch loss 0.0688, batch acc 0.9806
18:45:17.235   Training iter 450, batch loss 0.0707, batch acc 0.9816
18:45:17.342   Training iter 500, batch loss 0.0742, batch acc 0.9806
18:45:17.473   Training iter 550, batch loss 0.0726, batch acc 0.9788
18:45:17.581   Training iter 600, batch loss 0.0760, batch acc 0.9796
18:45:17.581 Training @ 23 epoch...
18:45:17.687   Training iter 50, batch loss 0.0671, batch acc 0.9840
18:45:17.832   Training iter 100, batch loss 0.0642, batch acc 0.9814
18:45:17.971   Training iter 150, batch loss 0.0600, batch acc 0.9856
18:45:18.122   Training iter 200, batch loss 0.0538, batch acc 0.9854
18:45:18.256   Training iter 250, batch loss 0.0664, batch acc 0.9796
18:45:18.391   Training iter 300, batch loss 0.0662, batch acc 0.9804
18:45:18.536   Training iter 350, batch loss 0.0651, batch acc 0.9796
18:45:18.693   Training iter 400, batch loss 0.0609, batch acc 0.9846
18:45:18.805   Training iter 450, batch loss 0.0680, batch acc 0.9818
18:45:18.917   Training iter 500, batch loss 0.0716, batch acc 0.9800
18:45:19.045   Training iter 550, batch loss 0.0749, batch acc 0.9786
18:45:19.147   Training iter 600, batch loss 0.0774, batch acc 0.9772
18:45:19.148 Training @ 24 epoch...
18:45:19.257   Training iter 50, batch loss 0.0581, batch acc 0.9832
18:45:19.375   Training iter 100, batch loss 0.0633, batch acc 0.9834
18:45:19.499   Training iter 150, batch loss 0.0690, batch acc 0.9816
18:45:19.619   Training iter 200, batch loss 0.0683, batch acc 0.9798
18:45:19.775   Training iter 250, batch loss 0.0619, batch acc 0.9842
18:45:19.884   Training iter 300, batch loss 0.0561, batch acc 0.9844
18:45:20.085   Training iter 350, batch loss 0.0663, batch acc 0.9814
18:45:20.212   Training iter 400, batch loss 0.0623, batch acc 0.9832
18:45:20.375   Training iter 450, batch loss 0.0636, batch acc 0.9820
18:45:20.562   Training iter 500, batch loss 0.0717, batch acc 0.9774
18:45:20.713   Training iter 550, batch loss 0.0653, batch acc 0.9826
18:45:20.876   Training iter 600, batch loss 0.0695, batch acc 0.9806
18:45:20.877 Training @ 25 epoch...
18:45:21.052   Training iter 50, batch loss 0.0660, batch acc 0.9812
18:45:21.211   Training iter 100, batch loss 0.0600, batch acc 0.9854
18:45:21.388   Training iter 150, batch loss 0.0592, batch acc 0.9842
18:45:21.542   Training iter 200, batch loss 0.0722, batch acc 0.9810
18:45:21.679   Training iter 250, batch loss 0.0731, batch acc 0.9796
18:45:21.819   Training iter 300, batch loss 0.0621, batch acc 0.9822
18:45:21.950   Training iter 350, batch loss 0.0666, batch acc 0.9838
18:45:22.105   Training iter 400, batch loss 0.0550, batch acc 0.9850
18:45:22.218   Training iter 450, batch loss 0.0611, batch acc 0.9836
18:45:22.337   Training iter 500, batch loss 0.0536, batch acc 0.9854
18:45:22.444   Training iter 550, batch loss 0.0586, batch acc 0.9834
18:45:22.554   Training iter 600, batch loss 0.0678, batch acc 0.9804
18:45:22.554 Testing @ 25 epoch...
18:45:22.640     Testing, total mean loss 0.08565, total acc 0.97490
18:45:22.640 Training @ 26 epoch...
18:45:22.755   Training iter 50, batch loss 0.0602, batch acc 0.9834
18:45:22.896   Training iter 100, batch loss 0.0558, batch acc 0.9860
18:45:23.026   Training iter 150, batch loss 0.0634, batch acc 0.9848
18:45:23.172   Training iter 200, batch loss 0.0653, batch acc 0.9840
18:45:23.311   Training iter 250, batch loss 0.0592, batch acc 0.9836
18:45:23.463   Training iter 300, batch loss 0.0598, batch acc 0.9840
18:45:23.629   Training iter 350, batch loss 0.0678, batch acc 0.9794
18:45:23.791   Training iter 400, batch loss 0.0673, batch acc 0.9816
18:45:23.971   Training iter 450, batch loss 0.0659, batch acc 0.9832
18:45:24.137   Training iter 500, batch loss 0.0631, batch acc 0.9830
18:45:24.303   Training iter 550, batch loss 0.0526, batch acc 0.9866
18:45:24.440   Training iter 600, batch loss 0.0656, batch acc 0.9818
18:45:24.441 Training @ 27 epoch...
18:45:24.590   Training iter 50, batch loss 0.0533, batch acc 0.9858
18:45:24.731   Training iter 100, batch loss 0.0592, batch acc 0.9840
18:45:24.866   Training iter 150, batch loss 0.0620, batch acc 0.9838
18:45:25.010   Training iter 200, batch loss 0.0576, batch acc 0.9848
18:45:25.149   Training iter 250, batch loss 0.0615, batch acc 0.9834
18:45:25.268   Training iter 300, batch loss 0.0564, batch acc 0.9858
18:45:25.413   Training iter 350, batch loss 0.0648, batch acc 0.9826
18:45:25.538   Training iter 400, batch loss 0.0560, batch acc 0.9856
18:45:25.697   Training iter 450, batch loss 0.0659, batch acc 0.9804
18:45:25.843   Training iter 500, batch loss 0.0609, batch acc 0.9832
18:45:25.986   Training iter 550, batch loss 0.0715, batch acc 0.9816
18:45:26.127   Training iter 600, batch loss 0.0529, batch acc 0.9850
18:45:26.129 Training @ 28 epoch...
18:45:26.287   Training iter 50, batch loss 0.0588, batch acc 0.9844
18:45:26.443   Training iter 100, batch loss 0.0581, batch acc 0.9824
18:45:26.618   Training iter 150, batch loss 0.0617, batch acc 0.9846
18:45:26.764   Training iter 200, batch loss 0.0588, batch acc 0.9844
18:45:26.962   Training iter 250, batch loss 0.0558, batch acc 0.9872
18:45:27.186   Training iter 300, batch loss 0.0606, batch acc 0.9840
18:45:27.327   Training iter 350, batch loss 0.0574, batch acc 0.9848
18:45:27.456   Training iter 400, batch loss 0.0620, batch acc 0.9826
18:45:27.652   Training iter 450, batch loss 0.0512, batch acc 0.9888
18:45:27.797   Training iter 500, batch loss 0.0548, batch acc 0.9858
18:45:28.085   Training iter 550, batch loss 0.0587, batch acc 0.9834
18:45:28.226   Training iter 600, batch loss 0.0675, batch acc 0.9810
18:45:28.226 Training @ 29 epoch...
18:45:28.384   Training iter 50, batch loss 0.0674, batch acc 0.9838
18:45:28.497   Training iter 100, batch loss 0.0583, batch acc 0.9834
18:45:28.663   Training iter 150, batch loss 0.0576, batch acc 0.9852
18:45:28.834   Training iter 200, batch loss 0.0537, batch acc 0.9870
18:45:28.991   Training iter 250, batch loss 0.0511, batch acc 0.9866
18:45:29.333   Training iter 300, batch loss 0.0637, batch acc 0.9836
18:45:29.577   Training iter 350, batch loss 0.0576, batch acc 0.9852
18:45:29.731   Training iter 400, batch loss 0.0577, batch acc 0.9840
18:45:29.911   Training iter 450, batch loss 0.0626, batch acc 0.9834
18:45:30.059   Training iter 500, batch loss 0.0616, batch acc 0.9834
18:45:30.170   Training iter 550, batch loss 0.0582, batch acc 0.9840
18:45:30.278   Training iter 600, batch loss 0.0573, batch acc 0.9848
18:45:30.279 Training @ 30 epoch...
18:45:30.399   Training iter 50, batch loss 0.0552, batch acc 0.9864
18:45:30.509   Training iter 100, batch loss 0.0522, batch acc 0.9878
18:45:30.634   Training iter 150, batch loss 0.0610, batch acc 0.9838
18:45:30.818   Training iter 200, batch loss 0.0570, batch acc 0.9852
18:45:30.936   Training iter 250, batch loss 0.0585, batch acc 0.9836
18:45:31.083   Training iter 300, batch loss 0.0589, batch acc 0.9852
18:45:31.190   Training iter 350, batch loss 0.0525, batch acc 0.9856
18:45:31.291   Training iter 400, batch loss 0.0536, batch acc 0.9850
18:45:31.392   Training iter 450, batch loss 0.0591, batch acc 0.9840
18:45:31.500   Training iter 500, batch loss 0.0575, batch acc 0.9852
18:45:31.616   Training iter 550, batch loss 0.0586, batch acc 0.9856
18:45:31.719   Training iter 600, batch loss 0.0621, batch acc 0.9816
18:45:31.720 Testing @ 30 epoch...
18:45:31.839     Testing, total mean loss 0.07927, total acc 0.97590
18:45:31.839 Training @ 31 epoch...
18:45:31.957   Training iter 50, batch loss 0.0525, batch acc 0.9878
18:45:32.113   Training iter 100, batch loss 0.0569, batch acc 0.9860
18:45:32.260   Training iter 150, batch loss 0.0572, batch acc 0.9868
18:45:32.395   Training iter 200, batch loss 0.0595, batch acc 0.9840
18:45:32.541   Training iter 250, batch loss 0.0472, batch acc 0.9894
18:45:32.688   Training iter 300, batch loss 0.0517, batch acc 0.9852
18:45:32.803   Training iter 350, batch loss 0.0579, batch acc 0.9842
18:45:32.945   Training iter 400, batch loss 0.0622, batch acc 0.9808
18:45:33.058   Training iter 450, batch loss 0.0581, batch acc 0.9838
18:45:33.166   Training iter 500, batch loss 0.0568, batch acc 0.9854
18:45:33.273   Training iter 550, batch loss 0.0586, batch acc 0.9848
18:45:33.381   Training iter 600, batch loss 0.0581, batch acc 0.9822
18:45:33.381 Training @ 32 epoch...
18:45:33.500   Training iter 50, batch loss 0.0539, batch acc 0.9864
18:45:33.622   Training iter 100, batch loss 0.0531, batch acc 0.9862
18:45:33.729   Training iter 150, batch loss 0.0542, batch acc 0.9850
18:45:33.835   Training iter 200, batch loss 0.0511, batch acc 0.9870
18:45:33.955   Training iter 250, batch loss 0.0569, batch acc 0.9850
18:45:34.064   Training iter 300, batch loss 0.0567, batch acc 0.9854
18:45:34.227   Training iter 350, batch loss 0.0474, batch acc 0.9880
18:45:34.336   Training iter 400, batch loss 0.0563, batch acc 0.9856
18:45:34.433   Training iter 450, batch loss 0.0620, batch acc 0.9828
18:45:34.540   Training iter 500, batch loss 0.0570, batch acc 0.9842
18:45:34.664   Training iter 550, batch loss 0.0573, batch acc 0.9834
18:45:34.779   Training iter 600, batch loss 0.0603, batch acc 0.9836
18:45:34.781 Training @ 33 epoch...
18:45:34.908   Training iter 50, batch loss 0.0550, batch acc 0.9868
18:45:35.059   Training iter 100, batch loss 0.0554, batch acc 0.9846
18:45:35.203   Training iter 150, batch loss 0.0531, batch acc 0.9852
18:45:35.337   Training iter 200, batch loss 0.0505, batch acc 0.9874
18:45:35.468   Training iter 250, batch loss 0.0521, batch acc 0.9874
18:45:35.614   Training iter 300, batch loss 0.0519, batch acc 0.9872
18:45:35.847   Training iter 350, batch loss 0.0617, batch acc 0.9840
18:45:36.075   Training iter 400, batch loss 0.0531, batch acc 0.9866
18:45:36.197   Training iter 450, batch loss 0.0537, batch acc 0.9864
18:45:36.316   Training iter 500, batch loss 0.0518, batch acc 0.9858
18:45:36.442   Training iter 550, batch loss 0.0531, batch acc 0.9852
18:45:36.572   Training iter 600, batch loss 0.0627, batch acc 0.9820
18:45:36.574 Training @ 34 epoch...
18:45:36.693   Training iter 50, batch loss 0.0556, batch acc 0.9840
18:45:36.810   Training iter 100, batch loss 0.0505, batch acc 0.9868
18:45:36.913   Training iter 150, batch loss 0.0530, batch acc 0.9854
18:45:37.022   Training iter 200, batch loss 0.0509, batch acc 0.9866
18:45:37.149   Training iter 250, batch loss 0.0499, batch acc 0.9872
18:45:37.277   Training iter 300, batch loss 0.0556, batch acc 0.9870
18:45:37.385   Training iter 350, batch loss 0.0552, batch acc 0.9846
18:45:37.532   Training iter 400, batch loss 0.0512, batch acc 0.9882
18:45:37.647   Training iter 450, batch loss 0.0520, batch acc 0.9852
18:45:37.836   Training iter 500, batch loss 0.0536, batch acc 0.9844
18:45:37.967   Training iter 550, batch loss 0.0570, batch acc 0.9874
18:45:38.107   Training iter 600, batch loss 0.0587, batch acc 0.9848
18:45:38.109 Training @ 35 epoch...
18:45:38.260   Training iter 50, batch loss 0.0473, batch acc 0.9882
18:45:38.404   Training iter 100, batch loss 0.0522, batch acc 0.9874
18:45:38.558   Training iter 150, batch loss 0.0510, batch acc 0.9872
18:45:38.674   Training iter 200, batch loss 0.0518, batch acc 0.9874
18:45:38.790   Training iter 250, batch loss 0.0525, batch acc 0.9852
18:45:38.898   Training iter 300, batch loss 0.0533, batch acc 0.9860
18:45:39.010   Training iter 350, batch loss 0.0542, batch acc 0.9846
18:45:39.138   Training iter 400, batch loss 0.0573, batch acc 0.9854
18:45:39.250   Training iter 450, batch loss 0.0615, batch acc 0.9838
18:45:39.359   Training iter 500, batch loss 0.0445, batch acc 0.9894
18:45:39.479   Training iter 550, batch loss 0.0575, batch acc 0.9850
18:45:39.617   Training iter 600, batch loss 0.0545, batch acc 0.9860
18:45:39.617 Testing @ 35 epoch...
18:45:39.710     Testing, total mean loss 0.08073, total acc 0.97700
18:45:39.710 Training @ 36 epoch...
18:45:39.823   Training iter 50, batch loss 0.0566, batch acc 0.9844
18:45:39.982   Training iter 100, batch loss 0.0587, batch acc 0.9848
18:45:40.108   Training iter 150, batch loss 0.0454, batch acc 0.9898
18:45:40.212   Training iter 200, batch loss 0.0465, batch acc 0.9882
18:45:40.335   Training iter 250, batch loss 0.0516, batch acc 0.9870
18:45:40.444   Training iter 300, batch loss 0.0523, batch acc 0.9866
18:45:40.576   Training iter 350, batch loss 0.0512, batch acc 0.9872
18:45:40.695   Training iter 400, batch loss 0.0515, batch acc 0.9854
18:45:40.822   Training iter 450, batch loss 0.0568, batch acc 0.9848
18:45:40.960   Training iter 500, batch loss 0.0494, batch acc 0.9870
18:45:41.116   Training iter 550, batch loss 0.0570, batch acc 0.9858
18:45:41.242   Training iter 600, batch loss 0.0484, batch acc 0.9888
18:45:41.244 Training @ 37 epoch...
18:45:41.378   Training iter 50, batch loss 0.0530, batch acc 0.9854
18:45:41.487   Training iter 100, batch loss 0.0520, batch acc 0.9872
18:45:41.612   Training iter 150, batch loss 0.0480, batch acc 0.9892
18:45:41.717   Training iter 200, batch loss 0.0462, batch acc 0.9878
18:45:41.829   Training iter 250, batch loss 0.0487, batch acc 0.9878
18:45:41.953   Training iter 300, batch loss 0.0512, batch acc 0.9878
18:45:42.075   Training iter 350, batch loss 0.0488, batch acc 0.9882
18:45:42.194   Training iter 400, batch loss 0.0549, batch acc 0.9844
18:45:42.302   Training iter 450, batch loss 0.0540, batch acc 0.9872
18:45:42.409   Training iter 500, batch loss 0.0525, batch acc 0.9870
18:45:42.518   Training iter 550, batch loss 0.0522, batch acc 0.9864
18:45:42.638   Training iter 600, batch loss 0.0614, batch acc 0.9822
18:45:42.638 Training @ 38 epoch...
18:45:42.752   Training iter 50, batch loss 0.0536, batch acc 0.9866
18:45:42.865   Training iter 100, batch loss 0.0523, batch acc 0.9856
18:45:42.982   Training iter 150, batch loss 0.0476, batch acc 0.9888
18:45:43.106   Training iter 200, batch loss 0.0458, batch acc 0.9888
18:45:43.213   Training iter 250, batch loss 0.0552, batch acc 0.9842
18:45:43.322   Training iter 300, batch loss 0.0476, batch acc 0.9886
18:45:43.449   Training iter 350, batch loss 0.0535, batch acc 0.9862
18:45:43.599   Training iter 400, batch loss 0.0536, batch acc 0.9850
18:45:43.742   Training iter 450, batch loss 0.0512, batch acc 0.9876
18:45:43.887   Training iter 500, batch loss 0.0514, batch acc 0.9864
18:45:44.025   Training iter 550, batch loss 0.0519, batch acc 0.9872
18:45:44.154   Training iter 600, batch loss 0.0511, batch acc 0.9856
18:45:44.155 Training @ 39 epoch...
18:45:44.298   Training iter 50, batch loss 0.0482, batch acc 0.9890
18:45:44.405   Training iter 100, batch loss 0.0509, batch acc 0.9872
18:45:44.511   Training iter 150, batch loss 0.0532, batch acc 0.9856
18:45:44.646   Training iter 200, batch loss 0.0523, batch acc 0.9856
18:45:44.756   Training iter 250, batch loss 0.0463, batch acc 0.9882
18:45:44.865   Training iter 300, batch loss 0.0481, batch acc 0.9892
18:45:44.971   Training iter 350, batch loss 0.0491, batch acc 0.9878
18:45:45.093   Training iter 400, batch loss 0.0559, batch acc 0.9856
18:45:45.208   Training iter 450, batch loss 0.0559, batch acc 0.9850
18:45:45.454   Training iter 500, batch loss 0.0521, batch acc 0.9868
18:45:45.574   Training iter 550, batch loss 0.0467, batch acc 0.9900
18:45:45.729   Training iter 600, batch loss 0.0521, batch acc 0.9854
18:45:45.730 Training @ 40 epoch...
18:45:45.930   Training iter 50, batch loss 0.0453, batch acc 0.9890
18:45:46.080   Training iter 100, batch loss 0.0501, batch acc 0.9904
18:45:46.239   Training iter 150, batch loss 0.0485, batch acc 0.9882
18:45:46.493   Training iter 200, batch loss 0.0459, batch acc 0.9904
18:45:46.692   Training iter 250, batch loss 0.0526, batch acc 0.9864
18:45:46.873   Training iter 300, batch loss 0.0460, batch acc 0.9886
18:45:47.039   Training iter 350, batch loss 0.0554, batch acc 0.9856
18:45:47.263   Training iter 400, batch loss 0.0549, batch acc 0.9852
18:45:47.411   Training iter 450, batch loss 0.0502, batch acc 0.9868
18:45:47.549   Training iter 500, batch loss 0.0464, batch acc 0.9894
18:45:47.700   Training iter 550, batch loss 0.0504, batch acc 0.9870
18:45:47.883   Training iter 600, batch loss 0.0507, batch acc 0.9858
18:45:47.884 Testing @ 40 epoch...
18:45:48.081     Testing, total mean loss 0.07412, total acc 0.97760
18:45:48.081 Training @ 41 epoch...
18:45:48.273   Training iter 50, batch loss 0.0410, batch acc 0.9902
18:45:48.477   Training iter 100, batch loss 0.0469, batch acc 0.9876
18:45:48.650   Training iter 150, batch loss 0.0461, batch acc 0.9892
18:45:48.805   Training iter 200, batch loss 0.0453, batch acc 0.9880
18:45:48.936   Training iter 250, batch loss 0.0524, batch acc 0.9856
18:45:49.048   Training iter 300, batch loss 0.0497, batch acc 0.9888
18:45:49.203   Training iter 350, batch loss 0.0542, batch acc 0.9846
18:45:49.332   Training iter 400, batch loss 0.0494, batch acc 0.9876
18:45:49.517   Training iter 450, batch loss 0.0587, batch acc 0.9860
18:45:49.763   Training iter 500, batch loss 0.0516, batch acc 0.9890
18:45:49.934   Training iter 550, batch loss 0.0534, batch acc 0.9870
18:45:50.103   Training iter 600, batch loss 0.0511, batch acc 0.9882
18:45:50.103 Training @ 42 epoch...
18:45:50.321   Training iter 50, batch loss 0.0440, batch acc 0.9898
18:45:50.484   Training iter 100, batch loss 0.0446, batch acc 0.9880
18:45:50.646   Training iter 150, batch loss 0.0443, batch acc 0.9896
18:45:50.790   Training iter 200, batch loss 0.0504, batch acc 0.9874
18:45:51.063   Training iter 250, batch loss 0.0537, batch acc 0.9858
18:45:51.246   Training iter 300, batch loss 0.0500, batch acc 0.9882
18:45:51.493   Training iter 350, batch loss 0.0490, batch acc 0.9880
18:45:51.672   Training iter 400, batch loss 0.0457, batch acc 0.9890
18:45:51.810   Training iter 450, batch loss 0.0528, batch acc 0.9852
18:45:52.431   Training iter 500, batch loss 0.0502, batch acc 0.9866
18:45:52.873   Training iter 550, batch loss 0.0457, batch acc 0.9882
18:45:53.302   Training iter 600, batch loss 0.0558, batch acc 0.9852
18:45:53.303 Training @ 43 epoch...
18:45:53.580   Training iter 50, batch loss 0.0515, batch acc 0.9850
18:45:53.809   Training iter 100, batch loss 0.0464, batch acc 0.9896
18:45:54.051   Training iter 150, batch loss 0.0502, batch acc 0.9870
18:45:54.376   Training iter 200, batch loss 0.0466, batch acc 0.9890
18:45:54.733   Training iter 250, batch loss 0.0505, batch acc 0.9880
18:45:55.010   Training iter 300, batch loss 0.0474, batch acc 0.9890
18:45:55.346   Training iter 350, batch loss 0.0483, batch acc 0.9878
18:45:55.577   Training iter 400, batch loss 0.0500, batch acc 0.9864
18:45:55.731   Training iter 450, batch loss 0.0443, batch acc 0.9878
18:45:55.880   Training iter 500, batch loss 0.0499, batch acc 0.9854
18:45:56.389   Training iter 550, batch loss 0.0475, batch acc 0.9874
18:45:56.753   Training iter 600, batch loss 0.0531, batch acc 0.9864
18:45:56.754 Training @ 44 epoch...
18:45:57.031   Training iter 50, batch loss 0.0469, batch acc 0.9882
18:45:57.528   Training iter 100, batch loss 0.0449, batch acc 0.9902
18:45:57.805   Training iter 150, batch loss 0.0446, batch acc 0.9890
18:45:58.197   Training iter 200, batch loss 0.0510, batch acc 0.9888
18:45:58.468   Training iter 250, batch loss 0.0479, batch acc 0.9874
18:45:58.638   Training iter 300, batch loss 0.0508, batch acc 0.9858
18:45:58.809   Training iter 350, batch loss 0.0513, batch acc 0.9882
18:45:59.073   Training iter 400, batch loss 0.0389, batch acc 0.9888
18:45:59.412   Training iter 450, batch loss 0.0532, batch acc 0.9848
18:45:59.739   Training iter 500, batch loss 0.0521, batch acc 0.9866
18:45:59.980   Training iter 550, batch loss 0.0481, batch acc 0.9888
18:46:00.243   Training iter 600, batch loss 0.0496, batch acc 0.9866
18:46:00.244 Training @ 45 epoch...
18:46:00.549   Training iter 50, batch loss 0.0425, batch acc 0.9902
18:46:00.816   Training iter 100, batch loss 0.0476, batch acc 0.9868
18:46:01.231   Training iter 150, batch loss 0.0493, batch acc 0.9862
18:46:01.523   Training iter 200, batch loss 0.0453, batch acc 0.9890
18:46:01.750   Training iter 250, batch loss 0.0483, batch acc 0.9894
18:46:02.127   Training iter 300, batch loss 0.0503, batch acc 0.9858
18:46:02.351   Training iter 350, batch loss 0.0477, batch acc 0.9882
18:46:02.495   Training iter 400, batch loss 0.0499, batch acc 0.9862
18:46:02.704   Training iter 450, batch loss 0.0485, batch acc 0.9882
18:46:02.875   Training iter 500, batch loss 0.0452, batch acc 0.9884
18:46:03.181   Training iter 550, batch loss 0.0496, batch acc 0.9892
18:46:03.322   Training iter 600, batch loss 0.0507, batch acc 0.9864
18:46:03.323 Testing @ 45 epoch...
18:46:03.499     Testing, total mean loss 0.07347, total acc 0.97790
18:46:03.500 Training @ 46 epoch...
18:46:03.622   Training iter 50, batch loss 0.0412, batch acc 0.9918
18:46:03.764   Training iter 100, batch loss 0.0473, batch acc 0.9878
18:46:03.914   Training iter 150, batch loss 0.0544, batch acc 0.9848
18:46:04.099   Training iter 200, batch loss 0.0576, batch acc 0.9872
18:46:04.273   Training iter 250, batch loss 0.0459, batch acc 0.9888
18:46:04.459   Training iter 300, batch loss 0.0449, batch acc 0.9894
18:46:04.625   Training iter 350, batch loss 0.0445, batch acc 0.9882
18:46:04.891   Training iter 400, batch loss 0.0479, batch acc 0.9876
18:46:05.085   Training iter 450, batch loss 0.0556, batch acc 0.9850
18:46:05.340   Training iter 500, batch loss 0.0468, batch acc 0.9884
18:46:05.598   Training iter 550, batch loss 0.0446, batch acc 0.9888
18:46:05.988   Training iter 600, batch loss 0.0489, batch acc 0.9864
18:46:05.990 Training @ 47 epoch...
18:46:06.232   Training iter 50, batch loss 0.0434, batch acc 0.9896
18:46:06.451   Training iter 100, batch loss 0.0506, batch acc 0.9878
18:46:06.639   Training iter 150, batch loss 0.0471, batch acc 0.9882
18:46:06.830   Training iter 200, batch loss 0.0456, batch acc 0.9880
18:46:07.091   Training iter 250, batch loss 0.0437, batch acc 0.9900
18:46:07.373   Training iter 300, batch loss 0.0498, batch acc 0.9874
18:46:07.724   Training iter 350, batch loss 0.0463, batch acc 0.9882
18:46:08.282   Training iter 400, batch loss 0.0454, batch acc 0.9890
18:46:08.523   Training iter 450, batch loss 0.0432, batch acc 0.9892
18:46:08.693   Training iter 500, batch loss 0.0467, batch acc 0.9882
18:46:08.949   Training iter 550, batch loss 0.0520, batch acc 0.9860
18:46:09.096   Training iter 600, batch loss 0.0526, batch acc 0.9864
18:46:09.098 Training @ 48 epoch...
18:46:09.297   Training iter 50, batch loss 0.0422, batch acc 0.9914
18:46:09.426   Training iter 100, batch loss 0.0446, batch acc 0.9902
18:46:09.599   Training iter 150, batch loss 0.0425, batch acc 0.9898
18:46:09.751   Training iter 200, batch loss 0.0515, batch acc 0.9884
18:46:09.897   Training iter 250, batch loss 0.0459, batch acc 0.9884
18:46:10.057   Training iter 300, batch loss 0.0463, batch acc 0.9906
18:46:10.257   Training iter 350, batch loss 0.0534, batch acc 0.9834
18:46:10.383   Training iter 400, batch loss 0.0478, batch acc 0.9886
18:46:10.573   Training iter 450, batch loss 0.0432, batch acc 0.9898
18:46:10.775   Training iter 500, batch loss 0.0516, batch acc 0.9868
18:46:10.955   Training iter 550, batch loss 0.0415, batch acc 0.9896
18:46:11.216   Training iter 600, batch loss 0.0507, batch acc 0.9862
18:46:11.217 Training @ 49 epoch...
18:46:11.430   Training iter 50, batch loss 0.0438, batch acc 0.9908
18:46:11.592   Training iter 100, batch loss 0.0459, batch acc 0.9868
18:46:11.783   Training iter 150, batch loss 0.0424, batch acc 0.9896
18:46:12.134   Training iter 200, batch loss 0.0497, batch acc 0.9876
18:46:12.343   Training iter 250, batch loss 0.0453, batch acc 0.9892
18:46:12.535   Training iter 300, batch loss 0.0496, batch acc 0.9868
18:46:12.701   Training iter 350, batch loss 0.0470, batch acc 0.9902
18:46:12.894   Training iter 400, batch loss 0.0475, batch acc 0.9872
18:46:13.065   Training iter 450, batch loss 0.0451, batch acc 0.9890
18:46:13.251   Training iter 500, batch loss 0.0457, batch acc 0.9884
18:46:13.493   Training iter 550, batch loss 0.0511, batch acc 0.9850
18:46:13.601   Training iter 600, batch loss 0.0477, batch acc 0.9894
18:46:13.603 Training @ 50 epoch...
18:46:13.726   Training iter 50, batch loss 0.0442, batch acc 0.9894
18:46:13.862   Training iter 100, batch loss 0.0487, batch acc 0.9878
18:46:14.093   Training iter 150, batch loss 0.0427, batch acc 0.9906
18:46:14.328   Training iter 200, batch loss 0.0405, batch acc 0.9924
18:46:14.713   Training iter 250, batch loss 0.0512, batch acc 0.9858
18:46:15.160   Training iter 300, batch loss 0.0446, batch acc 0.9896
18:46:15.455   Training iter 350, batch loss 0.0469, batch acc 0.9884
18:46:15.741   Training iter 400, batch loss 0.0471, batch acc 0.9880
18:46:15.941   Training iter 450, batch loss 0.0481, batch acc 0.9892
18:46:16.225   Training iter 500, batch loss 0.0476, batch acc 0.9886
18:46:16.416   Training iter 550, batch loss 0.0471, batch acc 0.9896
18:46:16.630   Training iter 600, batch loss 0.0481, batch acc 0.9870
18:46:16.631 Testing @ 50 epoch...
18:46:16.964     Testing, total mean loss 0.07275, total acc 0.97770
18:46:16.964 Training @ 51 epoch...
18:46:17.276   Training iter 50, batch loss 0.0433, batch acc 0.9902
18:46:17.466   Training iter 100, batch loss 0.0475, batch acc 0.9872
18:46:17.707   Training iter 150, batch loss 0.0438, batch acc 0.9884
18:46:17.978   Training iter 200, batch loss 0.0445, batch acc 0.9896
18:46:18.208   Training iter 250, batch loss 0.0504, batch acc 0.9862
18:46:18.394   Training iter 300, batch loss 0.0462, batch acc 0.9898
18:46:18.550   Training iter 350, batch loss 0.0421, batch acc 0.9904
18:46:18.711   Training iter 400, batch loss 0.0438, batch acc 0.9884
18:46:18.890   Training iter 450, batch loss 0.0521, batch acc 0.9862
18:46:19.081   Training iter 500, batch loss 0.0459, batch acc 0.9878
18:46:19.340   Training iter 550, batch loss 0.0451, batch acc 0.9912
18:46:19.526   Training iter 600, batch loss 0.0450, batch acc 0.9878
18:46:19.527 Training @ 52 epoch...
18:46:19.772   Training iter 50, batch loss 0.0452, batch acc 0.9870
18:46:20.178   Training iter 100, batch loss 0.0425, batch acc 0.9906
18:46:20.607   Training iter 150, batch loss 0.0482, batch acc 0.9886
18:46:20.878   Training iter 200, batch loss 0.0404, batch acc 0.9914
18:46:21.045   Training iter 250, batch loss 0.0472, batch acc 0.9872
18:46:21.208   Training iter 300, batch loss 0.0455, batch acc 0.9894
18:46:21.384   Training iter 350, batch loss 0.0468, batch acc 0.9894
18:46:21.610   Training iter 400, batch loss 0.0462, batch acc 0.9890
18:46:21.857   Training iter 450, batch loss 0.0503, batch acc 0.9880
18:46:22.096   Training iter 500, batch loss 0.0420, batch acc 0.9906
18:46:22.324   Training iter 550, batch loss 0.0481, batch acc 0.9868
18:46:22.707   Training iter 600, batch loss 0.0485, batch acc 0.9890
18:46:22.709 Training @ 53 epoch...
18:46:22.972   Training iter 50, batch loss 0.0495, batch acc 0.9880
18:46:23.245   Training iter 100, batch loss 0.0398, batch acc 0.9918
18:46:23.479   Training iter 150, batch loss 0.0472, batch acc 0.9876
18:46:23.793   Training iter 200, batch loss 0.0435, batch acc 0.9906
18:46:24.113   Training iter 250, batch loss 0.0422, batch acc 0.9902
18:46:24.321   Training iter 300, batch loss 0.0413, batch acc 0.9920
18:46:24.704   Training iter 350, batch loss 0.0519, batch acc 0.9866
18:46:24.971   Training iter 400, batch loss 0.0479, batch acc 0.9862
18:46:25.213   Training iter 450, batch loss 0.0418, batch acc 0.9902
18:46:25.367   Training iter 500, batch loss 0.0464, batch acc 0.9886
18:46:25.481   Training iter 550, batch loss 0.0515, batch acc 0.9868
18:46:25.587   Training iter 600, batch loss 0.0435, batch acc 0.9898
18:46:25.589 Training @ 54 epoch...
18:46:25.803   Training iter 50, batch loss 0.0409, batch acc 0.9886
18:46:26.047   Training iter 100, batch loss 0.0421, batch acc 0.9896
18:46:26.222   Training iter 150, batch loss 0.0404, batch acc 0.9926
18:46:26.375   Training iter 200, batch loss 0.0486, batch acc 0.9870
18:46:26.627   Training iter 250, batch loss 0.0435, batch acc 0.9882
18:46:26.926   Training iter 300, batch loss 0.0415, batch acc 0.9910
18:46:27.172   Training iter 350, batch loss 0.0451, batch acc 0.9886
18:46:27.361   Training iter 400, batch loss 0.0525, batch acc 0.9874
18:46:27.563   Training iter 450, batch loss 0.0468, batch acc 0.9906
18:46:27.733   Training iter 500, batch loss 0.0415, batch acc 0.9918
18:46:27.980   Training iter 550, batch loss 0.0434, batch acc 0.9902
18:46:28.216   Training iter 600, batch loss 0.0478, batch acc 0.9882
18:46:28.217 Training @ 55 epoch...
18:46:28.511   Training iter 50, batch loss 0.0438, batch acc 0.9898
18:46:28.698   Training iter 100, batch loss 0.0455, batch acc 0.9888
18:46:28.917   Training iter 150, batch loss 0.0457, batch acc 0.9876
18:46:29.172   Training iter 200, batch loss 0.0388, batch acc 0.9916
18:46:29.396   Training iter 250, batch loss 0.0410, batch acc 0.9898
18:46:29.665   Training iter 300, batch loss 0.0473, batch acc 0.9894
18:46:29.918   Training iter 350, batch loss 0.0511, batch acc 0.9860
18:46:30.090   Training iter 400, batch loss 0.0436, batch acc 0.9916
18:46:30.248   Training iter 450, batch loss 0.0453, batch acc 0.9882
18:46:30.586   Training iter 500, batch loss 0.0482, batch acc 0.9878
18:46:30.840   Training iter 550, batch loss 0.0449, batch acc 0.9886
18:46:31.108   Training iter 600, batch loss 0.0454, batch acc 0.9890
18:46:31.109 Testing @ 55 epoch...
18:46:31.260     Testing, total mean loss 0.07219, total acc 0.97740
18:46:31.260 Training @ 56 epoch...
18:46:31.549   Training iter 50, batch loss 0.0443, batch acc 0.9900
18:46:31.848   Training iter 100, batch loss 0.0388, batch acc 0.9912
18:46:32.225   Training iter 150, batch loss 0.0417, batch acc 0.9912
18:46:32.428   Training iter 200, batch loss 0.0508, batch acc 0.9848
18:46:32.843   Training iter 250, batch loss 0.0440, batch acc 0.9904
18:46:33.160   Training iter 300, batch loss 0.0436, batch acc 0.9906
18:46:33.414   Training iter 350, batch loss 0.0466, batch acc 0.9876
18:46:33.756   Training iter 400, batch loss 0.0491, batch acc 0.9888
18:46:34.061   Training iter 450, batch loss 0.0439, batch acc 0.9902
18:46:34.474   Training iter 500, batch loss 0.0451, batch acc 0.9872
18:46:34.762   Training iter 550, batch loss 0.0437, batch acc 0.9884
18:46:34.895   Training iter 600, batch loss 0.0466, batch acc 0.9900
18:46:34.896 Training @ 57 epoch...
18:46:35.124   Training iter 50, batch loss 0.0438, batch acc 0.9890
18:46:35.382   Training iter 100, batch loss 0.0418, batch acc 0.9900
18:46:35.651   Training iter 150, batch loss 0.0439, batch acc 0.9896
18:46:35.948   Training iter 200, batch loss 0.0464, batch acc 0.9888
18:46:36.165   Training iter 250, batch loss 0.0456, batch acc 0.9872
18:46:36.362   Training iter 300, batch loss 0.0423, batch acc 0.9916
18:46:36.601   Training iter 350, batch loss 0.0457, batch acc 0.9878
18:46:36.811   Training iter 400, batch loss 0.0442, batch acc 0.9884
18:46:37.066   Training iter 450, batch loss 0.0425, batch acc 0.9892
18:46:37.234   Training iter 500, batch loss 0.0448, batch acc 0.9880
18:46:37.370   Training iter 550, batch loss 0.0402, batch acc 0.9918
18:46:37.477   Training iter 600, batch loss 0.0475, batch acc 0.9888
18:46:37.477 Training @ 58 epoch...
18:46:37.892   Training iter 50, batch loss 0.0350, batch acc 0.9932
18:46:38.134   Training iter 100, batch loss 0.0441, batch acc 0.9896
18:46:38.411   Training iter 150, batch loss 0.0400, batch acc 0.9892
18:46:38.757   Training iter 200, batch loss 0.0411, batch acc 0.9890
18:46:38.930   Training iter 250, batch loss 0.0434, batch acc 0.9908
18:46:39.242   Training iter 300, batch loss 0.0479, batch acc 0.9870
18:46:39.441   Training iter 350, batch loss 0.0451, batch acc 0.9896
18:46:40.042   Training iter 400, batch loss 0.0451, batch acc 0.9878
18:46:40.328   Training iter 450, batch loss 0.0468, batch acc 0.9882
18:46:40.492   Training iter 500, batch loss 0.0478, batch acc 0.9884
18:46:40.667   Training iter 550, batch loss 0.0455, batch acc 0.9884
18:46:40.839   Training iter 600, batch loss 0.0493, batch acc 0.9878
18:46:40.840 Training @ 59 epoch...
18:46:41.022   Training iter 50, batch loss 0.0449, batch acc 0.9882
18:46:41.158   Training iter 100, batch loss 0.0376, batch acc 0.9930
18:46:41.310   Training iter 150, batch loss 0.0426, batch acc 0.9906
18:46:41.429   Training iter 200, batch loss 0.0427, batch acc 0.9892
18:46:41.580   Training iter 250, batch loss 0.0448, batch acc 0.9896
18:46:41.713   Training iter 300, batch loss 0.0429, batch acc 0.9894
18:46:41.831   Training iter 350, batch loss 0.0409, batch acc 0.9900
18:46:41.995   Training iter 400, batch loss 0.0457, batch acc 0.9886
18:46:42.151   Training iter 450, batch loss 0.0498, batch acc 0.9872
18:46:42.293   Training iter 500, batch loss 0.0428, batch acc 0.9904
18:46:42.511   Training iter 550, batch loss 0.0409, batch acc 0.9902
18:46:42.664   Training iter 600, batch loss 0.0474, batch acc 0.9884
18:46:42.665 Training @ 60 epoch...
18:46:42.811   Training iter 50, batch loss 0.0433, batch acc 0.9896
18:46:43.006   Training iter 100, batch loss 0.0531, batch acc 0.9868
18:46:43.155   Training iter 150, batch loss 0.0438, batch acc 0.9888
18:46:43.299   Training iter 200, batch loss 0.0419, batch acc 0.9908
18:46:43.416   Training iter 250, batch loss 0.0417, batch acc 0.9914
18:46:43.542   Training iter 300, batch loss 0.0455, batch acc 0.9874
18:46:43.673   Training iter 350, batch loss 0.0424, batch acc 0.9910
18:46:43.806   Training iter 400, batch loss 0.0412, batch acc 0.9898
18:46:43.967   Training iter 450, batch loss 0.0453, batch acc 0.9892
18:46:44.233   Training iter 500, batch loss 0.0410, batch acc 0.9922
18:46:44.421   Training iter 550, batch loss 0.0456, batch acc 0.9888
18:46:44.558   Training iter 600, batch loss 0.0467, batch acc 0.9890
18:46:44.561 Testing @ 60 epoch...
18:46:44.740     Testing, total mean loss 0.07235, total acc 0.97900
18:46:44.740 Training @ 61 epoch...
18:46:44.916   Training iter 50, batch loss 0.0465, batch acc 0.9888
18:46:45.073   Training iter 100, batch loss 0.0408, batch acc 0.9904
18:46:45.267   Training iter 150, batch loss 0.0423, batch acc 0.9904
18:46:45.433   Training iter 200, batch loss 0.0415, batch acc 0.9906
18:46:45.610   Training iter 250, batch loss 0.0416, batch acc 0.9902
18:46:46.047   Training iter 300, batch loss 0.0415, batch acc 0.9908
18:46:46.318   Training iter 350, batch loss 0.0426, batch acc 0.9892
18:46:46.472   Training iter 400, batch loss 0.0435, batch acc 0.9882
18:46:46.575   Training iter 450, batch loss 0.0446, batch acc 0.9896
18:46:46.833   Training iter 500, batch loss 0.0475, batch acc 0.9870
18:46:47.009   Training iter 550, batch loss 0.0425, batch acc 0.9892
18:46:47.121   Training iter 600, batch loss 0.0467, batch acc 0.9892
18:46:47.121 Training @ 62 epoch...
18:46:47.292   Training iter 50, batch loss 0.0381, batch acc 0.9920
18:46:47.411   Training iter 100, batch loss 0.0463, batch acc 0.9880
18:46:47.538   Training iter 150, batch loss 0.0414, batch acc 0.9904
18:46:47.765   Training iter 200, batch loss 0.0467, batch acc 0.9886
18:46:47.927   Training iter 250, batch loss 0.0465, batch acc 0.9888
18:46:48.082   Training iter 300, batch loss 0.0421, batch acc 0.9898
18:46:48.369   Training iter 350, batch loss 0.0407, batch acc 0.9900
18:46:48.681   Training iter 400, batch loss 0.0441, batch acc 0.9904
18:46:48.917   Training iter 450, batch loss 0.0493, batch acc 0.9870
18:46:49.171   Training iter 500, batch loss 0.0380, batch acc 0.9914
18:46:49.378   Training iter 550, batch loss 0.0420, batch acc 0.9896
18:46:49.504   Training iter 600, batch loss 0.0473, batch acc 0.9880
18:46:49.505 Training @ 63 epoch...
18:46:49.657   Training iter 50, batch loss 0.0443, batch acc 0.9906
18:46:49.803   Training iter 100, batch loss 0.0388, batch acc 0.9912
18:46:50.066   Training iter 150, batch loss 0.0408, batch acc 0.9904
18:46:50.326   Training iter 200, batch loss 0.0427, batch acc 0.9904
18:46:50.615   Training iter 250, batch loss 0.0479, batch acc 0.9884
18:46:50.825   Training iter 300, batch loss 0.0426, batch acc 0.9896
18:46:51.060   Training iter 350, batch loss 0.0389, batch acc 0.9908
18:46:51.225   Training iter 400, batch loss 0.0458, batch acc 0.9892
18:46:51.388   Training iter 450, batch loss 0.0466, batch acc 0.9878
18:46:51.588   Training iter 500, batch loss 0.0419, batch acc 0.9902
18:46:51.731   Training iter 550, batch loss 0.0442, batch acc 0.9880
18:46:51.879   Training iter 600, batch loss 0.0426, batch acc 0.9898
18:46:51.880 Training @ 64 epoch...
18:46:52.013   Training iter 50, batch loss 0.0442, batch acc 0.9902
18:46:52.156   Training iter 100, batch loss 0.0418, batch acc 0.9908
18:46:52.277   Training iter 150, batch loss 0.0419, batch acc 0.9906
18:46:52.397   Training iter 200, batch loss 0.0430, batch acc 0.9894
18:46:52.524   Training iter 250, batch loss 0.0389, batch acc 0.9916
18:46:52.664   Training iter 300, batch loss 0.0421, batch acc 0.9896
18:46:52.787   Training iter 350, batch loss 0.0402, batch acc 0.9900
18:46:52.942   Training iter 400, batch loss 0.0439, batch acc 0.9908
18:46:53.070   Training iter 450, batch loss 0.0465, batch acc 0.9886
18:46:53.304   Training iter 500, batch loss 0.0439, batch acc 0.9906
18:46:53.468   Training iter 550, batch loss 0.0433, batch acc 0.9892
18:46:53.622   Training iter 600, batch loss 0.0447, batch acc 0.9876
18:46:53.622 Training @ 65 epoch...
18:46:53.762   Training iter 50, batch loss 0.0489, batch acc 0.9888
18:46:54.047   Training iter 100, batch loss 0.0374, batch acc 0.9914
18:46:54.316   Training iter 150, batch loss 0.0451, batch acc 0.9894
18:46:54.468   Training iter 200, batch loss 0.0424, batch acc 0.9890
18:46:54.621   Training iter 250, batch loss 0.0434, batch acc 0.9902
18:46:54.743   Training iter 300, batch loss 0.0424, batch acc 0.9892
18:46:54.877   Training iter 350, batch loss 0.0399, batch acc 0.9904
18:46:55.016   Training iter 400, batch loss 0.0449, batch acc 0.9890
18:46:55.145   Training iter 450, batch loss 0.0398, batch acc 0.9916
18:46:55.279   Training iter 500, batch loss 0.0395, batch acc 0.9902
18:46:55.416   Training iter 550, batch loss 0.0461, batch acc 0.9880
18:46:55.555   Training iter 600, batch loss 0.0444, batch acc 0.9900
18:46:55.557 Testing @ 65 epoch...
18:46:55.683     Testing, total mean loss 0.06759, total acc 0.97940
18:46:55.683 Training @ 66 epoch...
18:46:55.823   Training iter 50, batch loss 0.0370, batch acc 0.9916
18:46:55.960   Training iter 100, batch loss 0.0426, batch acc 0.9902
18:46:56.113   Training iter 150, batch loss 0.0386, batch acc 0.9926
18:46:56.358   Training iter 200, batch loss 0.0392, batch acc 0.9896
18:46:56.543   Training iter 250, batch loss 0.0450, batch acc 0.9900
18:46:56.703   Training iter 300, batch loss 0.0444, batch acc 0.9902
18:46:56.861   Training iter 350, batch loss 0.0420, batch acc 0.9908
18:46:57.006   Training iter 400, batch loss 0.0446, batch acc 0.9898
18:46:57.200   Training iter 450, batch loss 0.0408, batch acc 0.9900
18:46:57.358   Training iter 500, batch loss 0.0466, batch acc 0.9872
18:46:57.485   Training iter 550, batch loss 0.0436, batch acc 0.9908
18:46:57.628   Training iter 600, batch loss 0.0429, batch acc 0.9884
18:46:57.629 Training @ 67 epoch...
18:46:57.779   Training iter 50, batch loss 0.0401, batch acc 0.9888
18:46:57.958   Training iter 100, batch loss 0.0370, batch acc 0.9918
18:46:58.093   Training iter 150, batch loss 0.0441, batch acc 0.9896
18:46:58.216   Training iter 200, batch loss 0.0452, batch acc 0.9884
18:46:58.350   Training iter 250, batch loss 0.0445, batch acc 0.9898
18:46:58.472   Training iter 300, batch loss 0.0490, batch acc 0.9896
18:46:58.603   Training iter 350, batch loss 0.0427, batch acc 0.9890
18:46:58.737   Training iter 400, batch loss 0.0449, batch acc 0.9872
18:46:58.879   Training iter 450, batch loss 0.0390, batch acc 0.9904
18:46:59.013   Training iter 500, batch loss 0.0414, batch acc 0.9908
18:46:59.150   Training iter 550, batch loss 0.0420, batch acc 0.9912
18:46:59.349   Training iter 600, batch loss 0.0452, batch acc 0.9898
18:46:59.350 Training @ 68 epoch...
18:46:59.510   Training iter 50, batch loss 0.0432, batch acc 0.9900
18:46:59.688   Training iter 100, batch loss 0.0367, batch acc 0.9924
18:46:59.860   Training iter 150, batch loss 0.0447, batch acc 0.9894
18:47:00.104   Training iter 200, batch loss 0.0399, batch acc 0.9906
18:47:00.243   Training iter 250, batch loss 0.0441, batch acc 0.9902
18:47:00.411   Training iter 300, batch loss 0.0408, batch acc 0.9906
18:47:00.558   Training iter 350, batch loss 0.0377, batch acc 0.9926
18:47:00.703   Training iter 400, batch loss 0.0454, batch acc 0.9888
18:47:00.844   Training iter 450, batch loss 0.0472, batch acc 0.9874
18:47:01.008   Training iter 500, batch loss 0.0427, batch acc 0.9882
18:47:01.170   Training iter 550, batch loss 0.0401, batch acc 0.9906
18:47:01.367   Training iter 600, batch loss 0.0444, batch acc 0.9902
18:47:01.370 Training @ 69 epoch...
18:47:01.514   Training iter 50, batch loss 0.0368, batch acc 0.9930
18:47:01.663   Training iter 100, batch loss 0.0382, batch acc 0.9920
18:47:01.806   Training iter 150, batch loss 0.0416, batch acc 0.9920
18:47:01.928   Training iter 200, batch loss 0.0371, batch acc 0.9904
18:47:02.078   Training iter 250, batch loss 0.0476, batch acc 0.9882
18:47:02.231   Training iter 300, batch loss 0.0450, batch acc 0.9906
18:47:02.358   Training iter 350, batch loss 0.0447, batch acc 0.9890
18:47:02.528   Training iter 400, batch loss 0.0400, batch acc 0.9928
18:47:02.758   Training iter 450, batch loss 0.0429, batch acc 0.9888
18:47:02.979   Training iter 500, batch loss 0.0434, batch acc 0.9896
18:47:03.105   Training iter 550, batch loss 0.0428, batch acc 0.9900
18:47:03.357   Training iter 600, batch loss 0.0417, batch acc 0.9908
18:47:03.357 Training @ 70 epoch...
18:47:03.519   Training iter 50, batch loss 0.0388, batch acc 0.9918
18:47:03.666   Training iter 100, batch loss 0.0404, batch acc 0.9908
18:47:03.839   Training iter 150, batch loss 0.0419, batch acc 0.9902
18:47:03.971   Training iter 200, batch loss 0.0431, batch acc 0.9890
18:47:04.124   Training iter 250, batch loss 0.0372, batch acc 0.9910
18:47:04.263   Training iter 300, batch loss 0.0381, batch acc 0.9902
18:47:04.415   Training iter 350, batch loss 0.0365, batch acc 0.9928
18:47:04.562   Training iter 400, batch loss 0.0435, batch acc 0.9906
18:47:04.709   Training iter 450, batch loss 0.0448, batch acc 0.9894
18:47:04.893   Training iter 500, batch loss 0.0431, batch acc 0.9894
18:47:05.048   Training iter 550, batch loss 0.0479, batch acc 0.9872
18:47:05.242   Training iter 600, batch loss 0.0453, batch acc 0.9884
18:47:05.243 Testing @ 70 epoch...
18:47:05.385     Testing, total mean loss 0.06887, total acc 0.97940
18:47:05.385 Training @ 71 epoch...
18:47:05.553   Training iter 50, batch loss 0.0437, batch acc 0.9910
18:47:05.721   Training iter 100, batch loss 0.0323, batch acc 0.9948
18:47:05.898   Training iter 150, batch loss 0.0427, batch acc 0.9914
18:47:06.059   Training iter 200, batch loss 0.0423, batch acc 0.9904
18:47:06.211   Training iter 250, batch loss 0.0389, batch acc 0.9912
18:47:06.343   Training iter 300, batch loss 0.0475, batch acc 0.9872
18:47:06.491   Training iter 350, batch loss 0.0423, batch acc 0.9908
18:47:06.611   Training iter 400, batch loss 0.0445, batch acc 0.9888
18:47:06.750   Training iter 450, batch loss 0.0401, batch acc 0.9912
18:47:06.885   Training iter 500, batch loss 0.0427, batch acc 0.9892
18:47:06.996   Training iter 550, batch loss 0.0456, batch acc 0.9894
18:47:07.152   Training iter 600, batch loss 0.0422, batch acc 0.9906
18:47:07.154 Training @ 72 epoch...
18:47:07.341   Training iter 50, batch loss 0.0348, batch acc 0.9920
18:47:07.505   Training iter 100, batch loss 0.0394, batch acc 0.9904
18:47:07.647   Training iter 150, batch loss 0.0418, batch acc 0.9896
18:47:07.868   Training iter 200, batch loss 0.0400, batch acc 0.9910
18:47:08.016   Training iter 250, batch loss 0.0431, batch acc 0.9914
18:47:08.176   Training iter 300, batch loss 0.0391, batch acc 0.9918
18:47:08.325   Training iter 350, batch loss 0.0446, batch acc 0.9896
18:47:08.508   Training iter 400, batch loss 0.0389, batch acc 0.9916
18:47:08.697   Training iter 450, batch loss 0.0434, batch acc 0.9902
18:47:08.914   Training iter 500, batch loss 0.0462, batch acc 0.9886
18:47:09.149   Training iter 550, batch loss 0.0446, batch acc 0.9878
18:47:09.456   Training iter 600, batch loss 0.0460, batch acc 0.9888
18:47:09.456 Training @ 73 epoch...
18:47:09.626   Training iter 50, batch loss 0.0407, batch acc 0.9892
18:47:09.801   Training iter 100, batch loss 0.0392, batch acc 0.9906
18:47:10.039   Training iter 150, batch loss 0.0426, batch acc 0.9910
18:47:10.271   Training iter 200, batch loss 0.0369, batch acc 0.9916
18:47:10.460   Training iter 250, batch loss 0.0398, batch acc 0.9904
18:47:10.593   Training iter 300, batch loss 0.0421, batch acc 0.9902
18:47:10.746   Training iter 350, batch loss 0.0450, batch acc 0.9890
18:47:10.877   Training iter 400, batch loss 0.0441, batch acc 0.9894
18:47:11.032   Training iter 450, batch loss 0.0425, batch acc 0.9890
18:47:11.165   Training iter 500, batch loss 0.0451, batch acc 0.9894
18:47:11.350   Training iter 550, batch loss 0.0405, batch acc 0.9916
18:47:11.653   Training iter 600, batch loss 0.0405, batch acc 0.9902
18:47:11.654 Training @ 74 epoch...
18:47:11.875   Training iter 50, batch loss 0.0449, batch acc 0.9894
18:47:12.026   Training iter 100, batch loss 0.0443, batch acc 0.9882
18:47:12.175   Training iter 150, batch loss 0.0428, batch acc 0.9914
18:47:12.331   Training iter 200, batch loss 0.0404, batch acc 0.9908
18:47:12.498   Training iter 250, batch loss 0.0435, batch acc 0.9896
18:47:12.640   Training iter 300, batch loss 0.0362, batch acc 0.9928
18:47:12.767   Training iter 350, batch loss 0.0372, batch acc 0.9926
18:47:12.909   Training iter 400, batch loss 0.0413, batch acc 0.9892
18:47:13.016   Training iter 450, batch loss 0.0385, batch acc 0.9924
18:47:13.159   Training iter 500, batch loss 0.0446, batch acc 0.9886
18:47:13.273   Training iter 550, batch loss 0.0432, batch acc 0.9900
18:47:13.393   Training iter 600, batch loss 0.0408, batch acc 0.9894
18:47:13.394 Training @ 75 epoch...
18:47:13.527   Training iter 50, batch loss 0.0423, batch acc 0.9900
18:47:13.665   Training iter 100, batch loss 0.0466, batch acc 0.9910
18:47:13.824   Training iter 150, batch loss 0.0428, batch acc 0.9918
18:47:14.031   Training iter 200, batch loss 0.0413, batch acc 0.9890
18:47:14.249   Training iter 250, batch loss 0.0391, batch acc 0.9886
18:47:14.438   Training iter 300, batch loss 0.0452, batch acc 0.9886
18:47:14.668   Training iter 350, batch loss 0.0401, batch acc 0.9896
18:47:14.863   Training iter 400, batch loss 0.0391, batch acc 0.9900
18:47:15.006   Training iter 450, batch loss 0.0379, batch acc 0.9924
18:47:15.208   Training iter 500, batch loss 0.0384, batch acc 0.9930
18:47:15.384   Training iter 550, batch loss 0.0383, batch acc 0.9924
18:47:15.546   Training iter 600, batch loss 0.0430, batch acc 0.9884
18:47:15.548 Testing @ 75 epoch...
18:47:15.741     Testing, total mean loss 0.06722, total acc 0.98000
18:47:15.741 Training @ 76 epoch...
18:47:15.908   Training iter 50, batch loss 0.0397, batch acc 0.9906
18:47:16.076   Training iter 100, batch loss 0.0435, batch acc 0.9904
18:47:16.225   Training iter 150, batch loss 0.0406, batch acc 0.9902
18:47:16.359   Training iter 200, batch loss 0.0379, batch acc 0.9920
18:47:16.500   Training iter 250, batch loss 0.0407, batch acc 0.9926
18:47:16.666   Training iter 300, batch loss 0.0395, batch acc 0.9904
18:47:16.847   Training iter 350, batch loss 0.0424, batch acc 0.9910
18:47:17.027   Training iter 400, batch loss 0.0431, batch acc 0.9906
18:47:17.207   Training iter 450, batch loss 0.0420, batch acc 0.9886
18:47:17.426   Training iter 500, batch loss 0.0364, batch acc 0.9906
18:47:17.642   Training iter 550, batch loss 0.0435, batch acc 0.9886
18:47:17.942   Training iter 600, batch loss 0.0474, batch acc 0.9880
18:47:17.942 Training @ 77 epoch...
18:47:18.114   Training iter 50, batch loss 0.0431, batch acc 0.9908
18:47:18.307   Training iter 100, batch loss 0.0404, batch acc 0.9906
18:47:18.447   Training iter 150, batch loss 0.0397, batch acc 0.9908
18:47:18.610   Training iter 200, batch loss 0.0340, batch acc 0.9942
18:47:18.757   Training iter 250, batch loss 0.0382, batch acc 0.9902
18:47:18.949   Training iter 300, batch loss 0.0371, batch acc 0.9928
18:47:19.087   Training iter 350, batch loss 0.0442, batch acc 0.9894
18:47:19.252   Training iter 400, batch loss 0.0421, batch acc 0.9898
18:47:19.381   Training iter 450, batch loss 0.0431, batch acc 0.9912
18:47:19.579   Training iter 500, batch loss 0.0435, batch acc 0.9906
18:47:19.751   Training iter 550, batch loss 0.0447, batch acc 0.9886
18:47:19.947   Training iter 600, batch loss 0.0431, batch acc 0.9896
18:47:19.949 Training @ 78 epoch...
18:47:20.133   Training iter 50, batch loss 0.0361, batch acc 0.9920
18:47:20.362   Training iter 100, batch loss 0.0419, batch acc 0.9910
18:47:20.591   Training iter 150, batch loss 0.0425, batch acc 0.9904
18:47:20.762   Training iter 200, batch loss 0.0369, batch acc 0.9928
18:47:20.950   Training iter 250, batch loss 0.0381, batch acc 0.9902
18:47:21.101   Training iter 300, batch loss 0.0382, batch acc 0.9894
18:47:21.284   Training iter 350, batch loss 0.0401, batch acc 0.9910
18:47:21.449   Training iter 400, batch loss 0.0461, batch acc 0.9890
18:47:21.592   Training iter 450, batch loss 0.0451, batch acc 0.9894
18:47:21.740   Training iter 500, batch loss 0.0431, batch acc 0.9906
18:47:21.912   Training iter 550, batch loss 0.0408, batch acc 0.9904
18:47:22.128   Training iter 600, batch loss 0.0427, batch acc 0.9904
18:47:22.128 Training @ 79 epoch...
18:47:22.283   Training iter 50, batch loss 0.0368, batch acc 0.9926
18:47:22.443   Training iter 100, batch loss 0.0392, batch acc 0.9910
18:47:22.601   Training iter 150, batch loss 0.0372, batch acc 0.9900
18:47:22.784   Training iter 200, batch loss 0.0367, batch acc 0.9926
18:47:22.999   Training iter 250, batch loss 0.0428, batch acc 0.9906
18:47:23.236   Training iter 300, batch loss 0.0422, batch acc 0.9902
18:47:23.466   Training iter 350, batch loss 0.0416, batch acc 0.9906
18:47:23.715   Training iter 400, batch loss 0.0424, batch acc 0.9898
18:47:23.884   Training iter 450, batch loss 0.0427, batch acc 0.9886
18:47:24.115   Training iter 500, batch loss 0.0460, batch acc 0.9892
18:47:24.323   Training iter 550, batch loss 0.0412, batch acc 0.9906
18:47:24.499   Training iter 600, batch loss 0.0420, batch acc 0.9902
18:47:24.500 Training @ 80 epoch...
18:47:24.658   Training iter 50, batch loss 0.0385, batch acc 0.9920
18:47:24.855   Training iter 100, batch loss 0.0404, batch acc 0.9910
18:47:25.323   Training iter 150, batch loss 0.0415, batch acc 0.9902
18:47:25.503   Training iter 200, batch loss 0.0366, batch acc 0.9918
18:47:25.728   Training iter 250, batch loss 0.0391, batch acc 0.9930
18:47:25.928   Training iter 300, batch loss 0.0426, batch acc 0.9908
18:47:26.141   Training iter 350, batch loss 0.0375, batch acc 0.9920
18:47:26.417   Training iter 400, batch loss 0.0385, batch acc 0.9918
18:47:27.422   Training iter 450, batch loss 0.0399, batch acc 0.9906
18:47:28.199   Training iter 500, batch loss 0.0468, batch acc 0.9890
18:47:29.823   Training iter 550, batch loss 0.0408, batch acc 0.9900
18:47:31.117   Training iter 600, batch loss 0.0501, batch acc 0.9874
18:47:31.118 Testing @ 80 epoch...
18:47:31.855     Testing, total mean loss 0.06814, total acc 0.97870
18:47:31.855 Training @ 81 epoch...
18:47:32.901   Training iter 50, batch loss 0.0426, batch acc 0.9918
18:47:34.079   Training iter 100, batch loss 0.0379, batch acc 0.9930
18:47:35.062   Training iter 150, batch loss 0.0360, batch acc 0.9920
18:47:36.181   Training iter 200, batch loss 0.0429, batch acc 0.9884
18:47:37.591   Training iter 250, batch loss 0.0437, batch acc 0.9896
18:47:38.882   Training iter 300, batch loss 0.0404, batch acc 0.9886
18:47:39.555   Training iter 350, batch loss 0.0425, batch acc 0.9902
18:47:40.110   Training iter 400, batch loss 0.0399, batch acc 0.9906
18:47:41.599   Training iter 450, batch loss 0.0398, batch acc 0.9904
18:47:42.551   Training iter 500, batch loss 0.0418, batch acc 0.9894
18:47:43.816   Training iter 550, batch loss 0.0390, batch acc 0.9910
18:47:44.838   Training iter 600, batch loss 0.0453, batch acc 0.9886
18:47:44.839 Training @ 82 epoch...
18:47:45.827   Training iter 50, batch loss 0.0370, batch acc 0.9922
18:47:46.611   Training iter 100, batch loss 0.0342, batch acc 0.9936
18:47:47.335   Training iter 150, batch loss 0.0387, batch acc 0.9908
18:47:48.127   Training iter 200, batch loss 0.0395, batch acc 0.9916
18:47:48.958   Training iter 250, batch loss 0.0445, batch acc 0.9900
18:47:49.271   Training iter 300, batch loss 0.0411, batch acc 0.9902
18:47:49.507   Training iter 350, batch loss 0.0424, batch acc 0.9884
18:47:49.662   Training iter 400, batch loss 0.0457, batch acc 0.9890
18:47:49.810   Training iter 450, batch loss 0.0408, batch acc 0.9932
18:47:49.962   Training iter 500, batch loss 0.0422, batch acc 0.9898
18:47:50.130   Training iter 550, batch loss 0.0412, batch acc 0.9900
18:47:50.274   Training iter 600, batch loss 0.0433, batch acc 0.9888
18:47:50.274 Training @ 83 epoch...
18:47:50.424   Training iter 50, batch loss 0.0405, batch acc 0.9914
18:47:50.575   Training iter 100, batch loss 0.0369, batch acc 0.9918
18:47:50.684   Training iter 150, batch loss 0.0417, batch acc 0.9920
18:47:50.843   Training iter 200, batch loss 0.0426, batch acc 0.9882
18:47:50.961   Training iter 250, batch loss 0.0470, batch acc 0.9896
18:47:51.078   Training iter 300, batch loss 0.0373, batch acc 0.9926
18:47:51.186   Training iter 350, batch loss 0.0415, batch acc 0.9906
18:47:51.298   Training iter 400, batch loss 0.0410, batch acc 0.9900
18:47:51.412   Training iter 450, batch loss 0.0392, batch acc 0.9906
18:47:51.526   Training iter 500, batch loss 0.0398, batch acc 0.9914
18:47:51.652   Training iter 550, batch loss 0.0390, batch acc 0.9908
18:47:51.761   Training iter 600, batch loss 0.0434, batch acc 0.9896
18:47:51.761 Training @ 84 epoch...
18:47:51.874   Training iter 50, batch loss 0.0363, batch acc 0.9918
18:47:51.984   Training iter 100, batch loss 0.0413, batch acc 0.9910
18:47:52.104   Training iter 150, batch loss 0.0435, batch acc 0.9902
18:47:52.252   Training iter 200, batch loss 0.0379, batch acc 0.9904
18:47:52.387   Training iter 250, batch loss 0.0374, batch acc 0.9904
18:47:52.518   Training iter 300, batch loss 0.0369, batch acc 0.9924
18:47:52.663   Training iter 350, batch loss 0.0418, batch acc 0.9906
18:47:52.793   Training iter 400, batch loss 0.0400, batch acc 0.9892
18:47:52.925   Training iter 450, batch loss 0.0441, batch acc 0.9900
18:47:53.084   Training iter 500, batch loss 0.0423, batch acc 0.9888
18:47:53.194   Training iter 550, batch loss 0.0434, batch acc 0.9916
18:47:53.304   Training iter 600, batch loss 0.0423, batch acc 0.9906
18:47:53.304 Training @ 85 epoch...
18:47:53.416   Training iter 50, batch loss 0.0421, batch acc 0.9908
18:47:53.534   Training iter 100, batch loss 0.0351, batch acc 0.9938
18:47:53.656   Training iter 150, batch loss 0.0354, batch acc 0.9936
18:47:53.767   Training iter 200, batch loss 0.0443, batch acc 0.9884
18:47:53.876   Training iter 250, batch loss 0.0371, batch acc 0.9920
18:47:53.998   Training iter 300, batch loss 0.0378, batch acc 0.9916
18:47:54.118   Training iter 350, batch loss 0.0428, batch acc 0.9892
18:47:54.236   Training iter 400, batch loss 0.0441, batch acc 0.9886
18:47:54.341   Training iter 450, batch loss 0.0426, batch acc 0.9902
18:47:54.458   Training iter 500, batch loss 0.0432, batch acc 0.9900
18:47:54.566   Training iter 550, batch loss 0.0374, batch acc 0.9922
18:47:54.680   Training iter 600, batch loss 0.0483, batch acc 0.9874
18:47:54.681 Testing @ 85 epoch...
18:47:54.777     Testing, total mean loss 0.06813, total acc 0.97930
18:47:54.777 Training @ 86 epoch...
18:47:54.919   Training iter 50, batch loss 0.0349, batch acc 0.9936
18:47:55.056   Training iter 100, batch loss 0.0412, batch acc 0.9914
18:47:55.203   Training iter 150, batch loss 0.0377, batch acc 0.9906
18:47:55.336   Training iter 200, batch loss 0.0340, batch acc 0.9928
18:47:55.472   Training iter 250, batch loss 0.0427, batch acc 0.9892
18:47:55.626   Training iter 300, batch loss 0.0405, batch acc 0.9906
18:47:55.764   Training iter 350, batch loss 0.0435, batch acc 0.9908
18:47:55.895   Training iter 400, batch loss 0.0391, batch acc 0.9900
18:47:55.991   Training iter 450, batch loss 0.0409, batch acc 0.9898
18:47:56.117   Training iter 500, batch loss 0.0391, batch acc 0.9912
18:47:56.227   Training iter 550, batch loss 0.0473, batch acc 0.9884
18:47:56.339   Training iter 600, batch loss 0.0455, batch acc 0.9880
18:47:56.341 Training @ 87 epoch...
18:47:56.458   Training iter 50, batch loss 0.0371, batch acc 0.9930
18:47:56.588   Training iter 100, batch loss 0.0393, batch acc 0.9916
18:47:56.693   Training iter 150, batch loss 0.0418, batch acc 0.9908
18:47:56.800   Training iter 200, batch loss 0.0385, batch acc 0.9910
18:47:56.911   Training iter 250, batch loss 0.0403, batch acc 0.9934
18:47:57.033   Training iter 300, batch loss 0.0386, batch acc 0.9920
18:47:57.152   Training iter 350, batch loss 0.0387, batch acc 0.9908
18:47:57.264   Training iter 400, batch loss 0.0375, batch acc 0.9904
18:47:57.358   Training iter 450, batch loss 0.0427, batch acc 0.9900
18:47:57.551   Training iter 500, batch loss 0.0409, batch acc 0.9906
18:47:57.769   Training iter 550, batch loss 0.0416, batch acc 0.9900
18:47:57.884   Training iter 600, batch loss 0.0463, batch acc 0.9898
18:47:57.885 Training @ 88 epoch...
18:47:58.040   Training iter 50, batch loss 0.0401, batch acc 0.9928
18:47:58.190   Training iter 100, batch loss 0.0389, batch acc 0.9916
18:47:58.315   Training iter 150, batch loss 0.0395, batch acc 0.9908
18:47:58.430   Training iter 200, batch loss 0.0415, batch acc 0.9908
18:47:58.566   Training iter 250, batch loss 0.0376, batch acc 0.9918
18:47:58.716   Training iter 300, batch loss 0.0389, batch acc 0.9926
18:47:58.827   Training iter 350, batch loss 0.0404, batch acc 0.9898
18:47:58.946   Training iter 400, batch loss 0.0399, batch acc 0.9930
18:47:59.063   Training iter 450, batch loss 0.0392, batch acc 0.9904
18:47:59.180   Training iter 500, batch loss 0.0439, batch acc 0.9888
18:47:59.294   Training iter 550, batch loss 0.0432, batch acc 0.9900
18:47:59.406   Training iter 600, batch loss 0.0403, batch acc 0.9914
18:47:59.406 Training @ 89 epoch...
18:47:59.538   Training iter 50, batch loss 0.0369, batch acc 0.9916
18:47:59.653   Training iter 100, batch loss 0.0408, batch acc 0.9900
18:47:59.761   Training iter 150, batch loss 0.0418, batch acc 0.9894
18:47:59.870   Training iter 200, batch loss 0.0350, batch acc 0.9916
18:47:59.983   Training iter 250, batch loss 0.0401, batch acc 0.9902
18:48:00.127   Training iter 300, batch loss 0.0378, batch acc 0.9920
18:48:00.390   Training iter 350, batch loss 0.0437, batch acc 0.9902
18:48:00.590   Training iter 400, batch loss 0.0324, batch acc 0.9944
18:48:00.745   Training iter 450, batch loss 0.0449, batch acc 0.9894
18:48:00.909   Training iter 500, batch loss 0.0410, batch acc 0.9904
18:48:01.080   Training iter 550, batch loss 0.0410, batch acc 0.9902
18:48:01.215   Training iter 600, batch loss 0.0446, batch acc 0.9888
18:48:01.216 Training @ 90 epoch...
18:48:01.352   Training iter 50, batch loss 0.0377, batch acc 0.9924
18:48:01.528   Training iter 100, batch loss 0.0385, batch acc 0.9918
18:48:01.652   Training iter 150, batch loss 0.0339, batch acc 0.9938
18:48:01.795   Training iter 200, batch loss 0.0429, batch acc 0.9900
18:48:01.914   Training iter 250, batch loss 0.0397, batch acc 0.9910
18:48:02.087   Training iter 300, batch loss 0.0367, batch acc 0.9928
18:48:02.236   Training iter 350, batch loss 0.0432, batch acc 0.9892
18:48:02.353   Training iter 400, batch loss 0.0387, batch acc 0.9908
18:48:02.476   Training iter 450, batch loss 0.0392, batch acc 0.9896
18:48:02.614   Training iter 500, batch loss 0.0450, batch acc 0.9890
18:48:02.762   Training iter 550, batch loss 0.0414, batch acc 0.9906
18:48:02.865   Training iter 600, batch loss 0.0431, batch acc 0.9904
18:48:02.866 Testing @ 90 epoch...
18:48:02.950     Testing, total mean loss 0.06780, total acc 0.97940
18:48:02.951 Training @ 91 epoch...
18:48:03.057   Training iter 50, batch loss 0.0367, batch acc 0.9926
18:48:03.190   Training iter 100, batch loss 0.0419, batch acc 0.9892
18:48:03.305   Training iter 150, batch loss 0.0434, batch acc 0.9904
18:48:03.403   Training iter 200, batch loss 0.0428, batch acc 0.9902
18:48:03.544   Training iter 250, batch loss 0.0358, batch acc 0.9930
18:48:03.708   Training iter 300, batch loss 0.0411, batch acc 0.9910
18:48:03.842   Training iter 350, batch loss 0.0409, batch acc 0.9916
18:48:04.017   Training iter 400, batch loss 0.0366, batch acc 0.9922
18:48:04.190   Training iter 450, batch loss 0.0399, batch acc 0.9908
18:48:04.296   Training iter 500, batch loss 0.0418, batch acc 0.9896
18:48:04.412   Training iter 550, batch loss 0.0399, batch acc 0.9922
18:48:04.527   Training iter 600, batch loss 0.0374, batch acc 0.9926
18:48:04.529 Training @ 92 epoch...
18:48:04.662   Training iter 50, batch loss 0.0409, batch acc 0.9904
18:48:04.811   Training iter 100, batch loss 0.0364, batch acc 0.9950
18:48:04.930   Training iter 150, batch loss 0.0390, batch acc 0.9914
18:48:05.070   Training iter 200, batch loss 0.0379, batch acc 0.9920
18:48:05.234   Training iter 250, batch loss 0.0427, batch acc 0.9908
18:48:05.347   Training iter 300, batch loss 0.0366, batch acc 0.9936
18:48:05.453   Training iter 350, batch loss 0.0379, batch acc 0.9912
18:48:05.622   Training iter 400, batch loss 0.0435, batch acc 0.9908
18:48:05.733   Training iter 450, batch loss 0.0411, batch acc 0.9900
18:48:05.840   Training iter 500, batch loss 0.0406, batch acc 0.9892
18:48:05.945   Training iter 550, batch loss 0.0374, batch acc 0.9928
18:48:06.058   Training iter 600, batch loss 0.0420, batch acc 0.9900
18:48:06.059 Training @ 93 epoch...
18:48:06.218   Training iter 50, batch loss 0.0385, batch acc 0.9906
18:48:06.382   Training iter 100, batch loss 0.0381, batch acc 0.9922
18:48:06.548   Training iter 150, batch loss 0.0440, batch acc 0.9882
18:48:06.705   Training iter 200, batch loss 0.0387, batch acc 0.9918
18:48:06.872   Training iter 250, batch loss 0.0402, batch acc 0.9912
18:48:07.004   Training iter 300, batch loss 0.0407, batch acc 0.9908
18:48:07.155   Training iter 350, batch loss 0.0381, batch acc 0.9904
18:48:07.261   Training iter 400, batch loss 0.0387, batch acc 0.9904
18:48:07.367   Training iter 450, batch loss 0.0372, batch acc 0.9924
18:48:07.480   Training iter 500, batch loss 0.0403, batch acc 0.9916
18:48:07.636   Training iter 550, batch loss 0.0424, batch acc 0.9886
18:48:07.782   Training iter 600, batch loss 0.0359, batch acc 0.9922
18:48:07.783 Training @ 94 epoch...
18:48:07.905   Training iter 50, batch loss 0.0410, batch acc 0.9904
18:48:08.032   Training iter 100, batch loss 0.0407, batch acc 0.9910
18:48:08.168   Training iter 150, batch loss 0.0364, batch acc 0.9938
18:48:08.308   Training iter 200, batch loss 0.0387, batch acc 0.9916
18:48:08.432   Training iter 250, batch loss 0.0367, batch acc 0.9926
18:48:08.580   Training iter 300, batch loss 0.0367, batch acc 0.9928
18:48:08.785   Training iter 350, batch loss 0.0412, batch acc 0.9900
18:48:08.944   Training iter 400, batch loss 0.0397, batch acc 0.9916
18:48:09.125   Training iter 450, batch loss 0.0429, batch acc 0.9890
18:48:09.333   Training iter 500, batch loss 0.0473, batch acc 0.9890
18:48:09.551   Training iter 550, batch loss 0.0382, batch acc 0.9908
18:48:09.750   Training iter 600, batch loss 0.0371, batch acc 0.9926
18:48:09.750 Training @ 95 epoch...
18:48:09.928   Training iter 50, batch loss 0.0445, batch acc 0.9902
18:48:10.059   Training iter 100, batch loss 0.0360, batch acc 0.9902
18:48:10.189   Training iter 150, batch loss 0.0440, batch acc 0.9896
18:48:10.318   Training iter 200, batch loss 0.0383, batch acc 0.9900
18:48:10.451   Training iter 250, batch loss 0.0341, batch acc 0.9952
18:48:10.766   Training iter 300, batch loss 0.0405, batch acc 0.9920
18:48:11.153   Training iter 350, batch loss 0.0428, batch acc 0.9882
18:48:11.454   Training iter 400, batch loss 0.0368, batch acc 0.9908
18:48:11.570   Training iter 450, batch loss 0.0413, batch acc 0.9898
18:48:11.728   Training iter 500, batch loss 0.0340, batch acc 0.9936
18:48:11.843   Training iter 550, batch loss 0.0430, batch acc 0.9880
18:48:12.001   Training iter 600, batch loss 0.0399, batch acc 0.9900
18:48:12.002 Testing @ 95 epoch...
18:48:12.157     Testing, total mean loss 0.07030, total acc 0.97730
18:48:12.157 Training @ 96 epoch...
18:48:12.332   Training iter 50, batch loss 0.0369, batch acc 0.9916
18:48:12.468   Training iter 100, batch loss 0.0407, batch acc 0.9906
18:48:12.577   Training iter 150, batch loss 0.0387, batch acc 0.9916
18:48:12.746   Training iter 200, batch loss 0.0380, batch acc 0.9916
18:48:12.858   Training iter 250, batch loss 0.0432, batch acc 0.9898
18:48:12.992   Training iter 300, batch loss 0.0360, batch acc 0.9930
18:48:13.129   Training iter 350, batch loss 0.0366, batch acc 0.9918
18:48:13.318   Training iter 400, batch loss 0.0385, batch acc 0.9922
18:48:13.573   Training iter 450, batch loss 0.0464, batch acc 0.9888
18:48:13.733   Training iter 500, batch loss 0.0340, batch acc 0.9934
18:48:13.885   Training iter 550, batch loss 0.0412, batch acc 0.9920
18:48:14.014   Training iter 600, batch loss 0.0379, batch acc 0.9906
18:48:14.015 Training @ 97 epoch...
18:48:14.150   Training iter 50, batch loss 0.0346, batch acc 0.9928
18:48:14.278   Training iter 100, batch loss 0.0371, batch acc 0.9926
18:48:14.392   Training iter 150, batch loss 0.0392, batch acc 0.9924
18:48:14.518   Training iter 200, batch loss 0.0413, batch acc 0.9894
18:48:14.654   Training iter 250, batch loss 0.0393, batch acc 0.9918
18:48:14.799   Training iter 300, batch loss 0.0418, batch acc 0.9884
18:48:14.942   Training iter 350, batch loss 0.0387, batch acc 0.9924
18:48:15.109   Training iter 400, batch loss 0.0378, batch acc 0.9908
18:48:15.344   Training iter 450, batch loss 0.0391, batch acc 0.9918
18:48:15.623   Training iter 500, batch loss 0.0377, batch acc 0.9908
18:48:15.844   Training iter 550, batch loss 0.0466, batch acc 0.9872
18:48:15.994   Training iter 600, batch loss 0.0384, batch acc 0.9904
18:48:15.995 Training @ 98 epoch...
18:48:16.189   Training iter 50, batch loss 0.0396, batch acc 0.9908
18:48:16.326   Training iter 100, batch loss 0.0348, batch acc 0.9936
18:48:16.452   Training iter 150, batch loss 0.0447, batch acc 0.9902
18:48:16.572   Training iter 200, batch loss 0.0408, batch acc 0.9904
18:48:16.758   Training iter 250, batch loss 0.0393, batch acc 0.9910
18:48:16.918   Training iter 300, batch loss 0.0425, batch acc 0.9898
18:48:17.027   Training iter 350, batch loss 0.0398, batch acc 0.9918
18:48:17.175   Training iter 400, batch loss 0.0367, batch acc 0.9926
18:48:17.330   Training iter 450, batch loss 0.0413, batch acc 0.9898
18:48:17.644   Training iter 500, batch loss 0.0416, batch acc 0.9898
18:48:17.819   Training iter 550, batch loss 0.0419, batch acc 0.9900
18:48:18.060   Training iter 600, batch loss 0.0332, batch acc 0.9930
18:48:18.061 Training @ 99 epoch...
18:48:18.274   Training iter 50, batch loss 0.0420, batch acc 0.9898
18:48:18.463   Training iter 100, batch loss 0.0405, batch acc 0.9914
18:48:18.577   Training iter 150, batch loss 0.0401, batch acc 0.9904
18:48:18.687   Training iter 200, batch loss 0.0371, batch acc 0.9922
18:48:18.797   Training iter 250, batch loss 0.0382, batch acc 0.9914
18:48:18.912   Training iter 300, batch loss 0.0389, batch acc 0.9906
18:48:19.078   Training iter 350, batch loss 0.0387, batch acc 0.9910
18:48:19.216   Training iter 400, batch loss 0.0388, batch acc 0.9914
18:48:19.327   Training iter 450, batch loss 0.0448, batch acc 0.9906
18:48:19.449   Training iter 500, batch loss 0.0385, batch acc 0.9918
18:48:19.593   Training iter 550, batch loss 0.0386, batch acc 0.9906
18:48:19.709   Training iter 600, batch loss 0.0428, batch acc 0.9876
18:48:19.710 Testing @ 99 epoch...
18:48:19.860     Testing, total mean loss 0.06818, total acc 0.97950