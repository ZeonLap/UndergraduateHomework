20:21:10.597 Training @ 0 epoch...
20:21:10.944   Training iter 50, batch loss 44.9553, batch acc 0.1068
20:21:11.322   Training iter 100, batch loss 39.4532, batch acc 0.1798
20:21:11.694   Training iter 150, batch loss 10.8588, batch acc 0.5798
20:21:12.051   Training iter 200, batch loss 4.5758, batch acc 0.7952
20:21:12.355   Training iter 250, batch loss 3.9517, batch acc 0.8472
20:21:12.770   Training iter 300, batch loss 3.0566, batch acc 0.8724
20:21:13.207   Training iter 350, batch loss 2.9188, batch acc 0.8758
20:21:13.564   Training iter 400, batch loss 2.1989, batch acc 0.8982
20:21:13.878   Training iter 450, batch loss 1.9692, batch acc 0.9070
20:21:14.158   Training iter 500, batch loss 2.0985, batch acc 0.9082
20:21:14.468   Training iter 550, batch loss 1.7964, batch acc 0.9154
20:21:14.811   Training iter 600, batch loss 1.7619, batch acc 0.9128
20:21:14.814 Testing @ 0 epoch...
20:21:15.120     Testing, total mean loss 1.86609, total acc 0.90170
20:21:15.120 Training @ 1 epoch...
20:21:15.408   Training iter 50, batch loss 1.4390, batch acc 0.9328
20:21:15.732   Training iter 100, batch loss 1.4742, batch acc 0.9292
20:21:16.022   Training iter 150, batch loss 1.3720, batch acc 0.9346
20:21:16.329   Training iter 200, batch loss 1.2705, batch acc 0.9404
20:21:16.615   Training iter 250, batch loss 1.0965, batch acc 0.9434
20:21:16.928   Training iter 300, batch loss 1.1842, batch acc 0.9406
20:21:17.210   Training iter 350, batch loss 1.2357, batch acc 0.9390
20:21:17.486   Training iter 400, batch loss 1.0990, batch acc 0.9470
20:21:17.780   Training iter 450, batch loss 0.9557, batch acc 0.9474
20:21:18.097   Training iter 500, batch loss 0.9952, batch acc 0.9476
20:21:18.454   Training iter 550, batch loss 1.0982, batch acc 0.9474
20:21:18.747   Training iter 600, batch loss 0.9965, batch acc 0.9508
20:21:18.748 Training @ 2 epoch...
20:21:19.011   Training iter 50, batch loss 0.8519, batch acc 0.9556
20:21:19.249   Training iter 100, batch loss 0.7727, batch acc 0.9598
20:21:19.532   Training iter 150, batch loss 0.8938, batch acc 0.9576
20:21:19.765   Training iter 200, batch loss 0.8753, batch acc 0.9532
20:21:20.050   Training iter 250, batch loss 0.8086, batch acc 0.9574
20:21:20.328   Training iter 300, batch loss 0.8782, batch acc 0.9548
20:21:20.657   Training iter 350, batch loss 0.8111, batch acc 0.9590
20:21:20.941   Training iter 400, batch loss 0.9764, batch acc 0.9500
20:21:21.198   Training iter 450, batch loss 0.7170, batch acc 0.9614
20:21:21.461   Training iter 500, batch loss 0.7926, batch acc 0.9594
20:21:21.754   Training iter 550, batch loss 0.6953, batch acc 0.9616
20:21:21.995   Training iter 600, batch loss 0.7578, batch acc 0.9580
20:21:21.996 Training @ 3 epoch...
20:21:22.261   Training iter 50, batch loss 0.5576, batch acc 0.9674
20:21:22.503   Training iter 100, batch loss 0.6678, batch acc 0.9628
20:21:22.757   Training iter 150, batch loss 0.6584, batch acc 0.9626
20:21:22.973   Training iter 200, batch loss 0.6831, batch acc 0.9654
20:21:23.239   Training iter 250, batch loss 0.7035, batch acc 0.9638
20:21:23.519   Training iter 300, batch loss 0.6372, batch acc 0.9656
20:21:23.811   Training iter 350, batch loss 0.5832, batch acc 0.9676
20:21:24.102   Training iter 400, batch loss 0.5666, batch acc 0.9678
20:21:24.417   Training iter 450, batch loss 0.5825, batch acc 0.9662
20:21:24.693   Training iter 500, batch loss 0.6279, batch acc 0.9694
20:21:24.977   Training iter 550, batch loss 0.5649, batch acc 0.9664
20:21:25.212   Training iter 600, batch loss 0.5366, batch acc 0.9688
20:21:25.212 Training @ 4 epoch...
20:21:25.478   Training iter 50, batch loss 0.4377, batch acc 0.9702
20:21:25.761   Training iter 100, batch loss 0.5063, batch acc 0.9696
20:21:26.009   Training iter 150, batch loss 0.5219, batch acc 0.9714
20:21:26.312   Training iter 200, batch loss 0.4782, batch acc 0.9718
20:21:26.606   Training iter 250, batch loss 0.5662, batch acc 0.9660
20:21:26.933   Training iter 300, batch loss 0.5124, batch acc 0.9682
20:21:27.221   Training iter 350, batch loss 0.5379, batch acc 0.9692
20:21:27.488   Training iter 400, batch loss 0.4527, batch acc 0.9772
20:21:27.748   Training iter 450, batch loss 0.4875, batch acc 0.9746
20:21:28.075   Training iter 500, batch loss 0.4183, batch acc 0.9758
20:21:28.419   Training iter 550, batch loss 0.5322, batch acc 0.9712
20:21:28.748   Training iter 600, batch loss 0.4668, batch acc 0.9724
20:21:28.750 Training @ 5 epoch...
20:21:29.099   Training iter 50, batch loss 0.3944, batch acc 0.9760
20:21:29.435   Training iter 100, batch loss 0.4153, batch acc 0.9734
20:21:29.730   Training iter 150, batch loss 0.3984, batch acc 0.9766
20:21:30.034   Training iter 200, batch loss 0.4402, batch acc 0.9746
20:21:30.311   Training iter 250, batch loss 0.4069, batch acc 0.9740
20:21:30.581   Training iter 300, batch loss 0.3753, batch acc 0.9780
20:21:30.855   Training iter 350, batch loss 0.4638, batch acc 0.9754
20:21:31.215   Training iter 400, batch loss 0.3873, batch acc 0.9768
20:21:31.604   Training iter 450, batch loss 0.4186, batch acc 0.9762
20:21:32.005   Training iter 500, batch loss 0.4474, batch acc 0.9776
20:21:32.347   Training iter 550, batch loss 0.3556, batch acc 0.9780
20:21:32.806   Training iter 600, batch loss 0.4501, batch acc 0.9740
20:21:32.807 Testing @ 5 epoch...
20:21:33.093     Testing, total mean loss 0.57761, total acc 0.97030
20:21:33.093 Training @ 6 epoch...
20:21:33.418   Training iter 50, batch loss 0.3419, batch acc 0.9790
20:21:33.812   Training iter 100, batch loss 0.3316, batch acc 0.9800
20:21:34.135   Training iter 150, batch loss 0.3477, batch acc 0.9790
20:21:34.460   Training iter 200, batch loss 0.3219, batch acc 0.9804
20:21:34.863   Training iter 250, batch loss 0.3457, batch acc 0.9794
20:21:35.206   Training iter 300, batch loss 0.3260, batch acc 0.9808
20:21:35.591   Training iter 350, batch loss 0.3641, batch acc 0.9756
20:21:35.910   Training iter 400, batch loss 0.3807, batch acc 0.9766
20:21:36.205   Training iter 450, batch loss 0.3190, batch acc 0.9800
20:21:36.481   Training iter 500, batch loss 0.4100, batch acc 0.9752
20:21:36.792   Training iter 550, batch loss 0.4088, batch acc 0.9752
20:21:37.109   Training iter 600, batch loss 0.3211, batch acc 0.9802
20:21:37.111 Training @ 7 epoch...
20:21:37.475   Training iter 50, batch loss 0.2805, batch acc 0.9848
20:21:37.933   Training iter 100, batch loss 0.2859, batch acc 0.9820
20:21:38.273   Training iter 150, batch loss 0.2244, batch acc 0.9850
20:21:38.609   Training iter 200, batch loss 0.3125, batch acc 0.9836
20:21:38.959   Training iter 250, batch loss 0.3231, batch acc 0.9784
20:21:39.373   Training iter 300, batch loss 0.2971, batch acc 0.9804
20:21:39.706   Training iter 350, batch loss 0.3464, batch acc 0.9790
20:21:39.972   Training iter 400, batch loss 0.3403, batch acc 0.9794
20:21:40.284   Training iter 450, batch loss 0.2449, batch acc 0.9846
20:21:40.604   Training iter 500, batch loss 0.3141, batch acc 0.9820
20:21:41.017   Training iter 550, batch loss 0.3668, batch acc 0.9800
20:21:41.411   Training iter 600, batch loss 0.3260, batch acc 0.9800
20:21:41.413 Training @ 8 epoch...
20:21:41.689   Training iter 50, batch loss 0.2592, batch acc 0.9832
20:21:42.431   Training iter 100, batch loss 0.2532, batch acc 0.9834
20:21:43.137   Training iter 150, batch loss 0.2923, batch acc 0.9830
20:21:43.930   Training iter 200, batch loss 0.2234, batch acc 0.9850
20:21:44.432   Training iter 250, batch loss 0.2112, batch acc 0.9866
20:21:44.808   Training iter 300, batch loss 0.2574, batch acc 0.9826
20:21:45.194   Training iter 350, batch loss 0.3212, batch acc 0.9810
20:21:45.714   Training iter 400, batch loss 0.2630, batch acc 0.9844
20:21:46.030   Training iter 450, batch loss 0.2829, batch acc 0.9808
20:21:46.560   Training iter 500, batch loss 0.2797, batch acc 0.9828
20:21:46.984   Training iter 550, batch loss 0.2085, batch acc 0.9866
20:21:47.555   Training iter 600, batch loss 0.3004, batch acc 0.9796
20:21:47.557 Training @ 9 epoch...
20:21:48.314   Training iter 50, batch loss 0.2680, batch acc 0.9840
20:21:48.732   Training iter 100, batch loss 0.2191, batch acc 0.9876
20:21:49.222   Training iter 150, batch loss 0.2131, batch acc 0.9878
20:21:50.040   Training iter 200, batch loss 0.2732, batch acc 0.9840
20:21:50.584   Training iter 250, batch loss 0.2087, batch acc 0.9868
20:21:50.976   Training iter 300, batch loss 0.1958, batch acc 0.9860
20:21:51.282   Training iter 350, batch loss 0.1958, batch acc 0.9878
20:21:51.970   Training iter 400, batch loss 0.2201, batch acc 0.9856
20:21:52.483   Training iter 450, batch loss 0.2301, batch acc 0.9836
20:21:53.099   Training iter 500, batch loss 0.2236, batch acc 0.9858
20:21:53.826   Training iter 550, batch loss 0.2837, batch acc 0.9824
20:21:54.193   Training iter 600, batch loss 0.2996, batch acc 0.9820
20:21:54.194 Training @ 10 epoch...
20:21:54.528   Training iter 50, batch loss 0.2127, batch acc 0.9868
20:21:54.993   Training iter 100, batch loss 0.1893, batch acc 0.9892
20:21:55.349   Training iter 150, batch loss 0.1755, batch acc 0.9882
20:21:56.044   Training iter 200, batch loss 0.2110, batch acc 0.9866
20:21:56.722   Training iter 250, batch loss 0.2393, batch acc 0.9846
20:21:57.252   Training iter 300, batch loss 0.2072, batch acc 0.9884
20:21:57.803   Training iter 350, batch loss 0.1746, batch acc 0.9890
20:21:58.212   Training iter 400, batch loss 0.2074, batch acc 0.9882
20:21:58.579   Training iter 450, batch loss 0.1942, batch acc 0.9880
20:21:58.920   Training iter 500, batch loss 0.1758, batch acc 0.9884
20:21:59.481   Training iter 550, batch loss 0.2092, batch acc 0.9874
20:22:00.396   Training iter 600, batch loss 0.2355, batch acc 0.9846
20:22:00.397 Testing @ 10 epoch...
20:22:00.678     Testing, total mean loss 0.43791, total acc 0.97610
20:22:00.678 Training @ 11 epoch...
20:22:01.082   Training iter 50, batch loss 0.1690, batch acc 0.9890
20:22:01.477   Training iter 100, batch loss 0.1893, batch acc 0.9888
20:22:01.853   Training iter 150, batch loss 0.1933, batch acc 0.9870
20:22:02.306   Training iter 200, batch loss 0.1460, batch acc 0.9908
20:22:02.608   Training iter 250, batch loss 0.1462, batch acc 0.9906
20:22:02.921   Training iter 300, batch loss 0.1951, batch acc 0.9866
20:22:03.481   Training iter 350, batch loss 0.2094, batch acc 0.9852
20:22:03.933   Training iter 400, batch loss 0.2015, batch acc 0.9866
20:22:04.311   Training iter 450, batch loss 0.1864, batch acc 0.9878
20:22:04.789   Training iter 500, batch loss 0.2071, batch acc 0.9868
20:22:05.142   Training iter 550, batch loss 0.2413, batch acc 0.9842
20:22:05.757   Training iter 600, batch loss 0.2267, batch acc 0.9866
20:22:05.758 Training @ 12 epoch...
20:22:06.180   Training iter 50, batch loss 0.1533, batch acc 0.9904
20:22:06.511   Training iter 100, batch loss 0.1496, batch acc 0.9912
20:22:06.850   Training iter 150, batch loss 0.2162, batch acc 0.9866
20:22:07.343   Training iter 200, batch loss 0.1892, batch acc 0.9876
20:22:07.838   Training iter 250, batch loss 0.1458, batch acc 0.9908
20:22:08.231   Training iter 300, batch loss 0.1980, batch acc 0.9882
20:22:08.596   Training iter 350, batch loss 0.1340, batch acc 0.9912
20:22:08.920   Training iter 400, batch loss 0.1767, batch acc 0.9896
20:22:09.227   Training iter 450, batch loss 0.1628, batch acc 0.9894
20:22:09.526   Training iter 500, batch loss 0.1629, batch acc 0.9886
20:22:10.148   Training iter 550, batch loss 0.1724, batch acc 0.9888
20:22:10.531   Training iter 600, batch loss 0.1837, batch acc 0.9872
20:22:10.532 Training @ 13 epoch...
20:22:11.038   Training iter 50, batch loss 0.1392, batch acc 0.9918
20:22:11.401   Training iter 100, batch loss 0.1597, batch acc 0.9898
20:22:11.814   Training iter 150, batch loss 0.1211, batch acc 0.9926
20:22:12.241   Training iter 200, batch loss 0.1436, batch acc 0.9908
20:22:12.786   Training iter 250, batch loss 0.1844, batch acc 0.9874
20:22:13.208   Training iter 300, batch loss 0.1367, batch acc 0.9916
20:22:13.657   Training iter 350, batch loss 0.1698, batch acc 0.9892
20:22:14.372   Training iter 400, batch loss 0.1642, batch acc 0.9898
20:22:14.722   Training iter 450, batch loss 0.1678, batch acc 0.9890
20:22:15.077   Training iter 500, batch loss 0.1467, batch acc 0.9912
20:22:15.467   Training iter 550, batch loss 0.1671, batch acc 0.9902
20:22:15.829   Training iter 600, batch loss 0.1877, batch acc 0.9894
20:22:15.830 Training @ 14 epoch...
20:22:16.167   Training iter 50, batch loss 0.1451, batch acc 0.9900
20:22:16.563   Training iter 100, batch loss 0.1217, batch acc 0.9922
20:22:17.022   Training iter 150, batch loss 0.1356, batch acc 0.9918
20:22:17.423   Training iter 200, batch loss 0.1367, batch acc 0.9908
20:22:17.796   Training iter 250, batch loss 0.1459, batch acc 0.9908
20:22:18.560   Training iter 300, batch loss 0.1637, batch acc 0.9892
20:22:19.103   Training iter 350, batch loss 0.1233, batch acc 0.9920
20:22:19.522   Training iter 400, batch loss 0.1712, batch acc 0.9902
20:22:19.998   Training iter 450, batch loss 0.1349, batch acc 0.9918
20:22:20.501   Training iter 500, batch loss 0.1655, batch acc 0.9890
20:22:20.957   Training iter 550, batch loss 0.1325, batch acc 0.9928
20:22:21.450   Training iter 600, batch loss 0.1492, batch acc 0.9898
20:22:21.452 Training @ 15 epoch...
20:22:21.895   Training iter 50, batch loss 0.1354, batch acc 0.9904
20:22:22.243   Training iter 100, batch loss 0.1336, batch acc 0.9924
20:22:22.701   Training iter 150, batch loss 0.1703, batch acc 0.9882
20:22:23.102   Training iter 200, batch loss 0.1407, batch acc 0.9898
20:22:23.461   Training iter 250, batch loss 0.1296, batch acc 0.9926
20:22:23.814   Training iter 300, batch loss 0.0923, batch acc 0.9948
20:22:24.163   Training iter 350, batch loss 0.1302, batch acc 0.9912
20:22:24.640   Training iter 400, batch loss 0.1491, batch acc 0.9894
20:22:25.003   Training iter 450, batch loss 0.1435, batch acc 0.9910
20:22:25.482   Training iter 500, batch loss 0.1388, batch acc 0.9912
20:22:26.300   Training iter 550, batch loss 0.1413, batch acc 0.9910
20:22:26.638   Training iter 600, batch loss 0.1141, batch acc 0.9932
20:22:26.642 Testing @ 15 epoch...
20:22:26.915     Testing, total mean loss 0.37256, total acc 0.97950
20:22:26.915 Training @ 16 epoch...
20:22:27.271   Training iter 50, batch loss 0.1332, batch acc 0.9910
20:22:27.573   Training iter 100, batch loss 0.1333, batch acc 0.9926
20:22:27.918   Training iter 150, batch loss 0.1392, batch acc 0.9922
20:22:28.229   Training iter 200, batch loss 0.1076, batch acc 0.9936
20:22:28.552   Training iter 250, batch loss 0.1172, batch acc 0.9932
20:22:28.920   Training iter 300, batch loss 0.1139, batch acc 0.9928
20:22:29.341   Training iter 350, batch loss 0.1424, batch acc 0.9914
20:22:29.728   Training iter 400, batch loss 0.1148, batch acc 0.9932
20:22:30.229   Training iter 450, batch loss 0.0982, batch acc 0.9940
20:22:30.728   Training iter 500, batch loss 0.1105, batch acc 0.9940
20:22:31.342   Training iter 550, batch loss 0.1551, batch acc 0.9892
20:22:31.932   Training iter 600, batch loss 0.1396, batch acc 0.9914
20:22:31.934 Training @ 17 epoch...
20:22:32.358   Training iter 50, batch loss 0.1002, batch acc 0.9932
20:22:32.781   Training iter 100, batch loss 0.0993, batch acc 0.9942
20:22:33.735   Training iter 150, batch loss 0.0965, batch acc 0.9944
20:22:34.388   Training iter 200, batch loss 0.1365, batch acc 0.9908
20:22:34.914   Training iter 250, batch loss 0.1101, batch acc 0.9922
20:22:35.778   Training iter 300, batch loss 0.1078, batch acc 0.9942
20:22:36.361   Training iter 350, batch loss 0.1283, batch acc 0.9920
20:22:36.764   Training iter 400, batch loss 0.1046, batch acc 0.9950
20:22:37.175   Training iter 450, batch loss 0.1296, batch acc 0.9926
20:22:38.275   Training iter 500, batch loss 0.1029, batch acc 0.9942
20:22:38.649   Training iter 550, batch loss 0.1087, batch acc 0.9930
20:22:39.039   Training iter 600, batch loss 0.1341, batch acc 0.9934
20:22:39.039 Training @ 18 epoch...
20:22:39.407   Training iter 50, batch loss 0.0801, batch acc 0.9948
20:22:39.737   Training iter 100, batch loss 0.0889, batch acc 0.9946
20:22:40.070   Training iter 150, batch loss 0.1012, batch acc 0.9952
20:22:40.428   Training iter 200, batch loss 0.0805, batch acc 0.9956
20:22:40.900   Training iter 250, batch loss 0.0950, batch acc 0.9944
20:22:41.526   Training iter 300, batch loss 0.0957, batch acc 0.9948
20:22:41.909   Training iter 350, batch loss 0.1035, batch acc 0.9950
20:22:42.342   Training iter 400, batch loss 0.1303, batch acc 0.9920
20:22:42.802   Training iter 450, batch loss 0.1066, batch acc 0.9926
20:22:43.486   Training iter 500, batch loss 0.0978, batch acc 0.9944
20:22:44.108   Training iter 550, batch loss 0.1028, batch acc 0.9928
20:22:44.578   Training iter 600, batch loss 0.1344, batch acc 0.9926
20:22:44.578 Training @ 19 epoch...
20:22:45.015   Training iter 50, batch loss 0.1256, batch acc 0.9928
20:22:45.647   Training iter 100, batch loss 0.0909, batch acc 0.9944
20:22:46.137   Training iter 150, batch loss 0.0801, batch acc 0.9942
20:22:46.581   Training iter 200, batch loss 0.0820, batch acc 0.9948
20:22:47.062   Training iter 250, batch loss 0.1239, batch acc 0.9930
20:22:47.396   Training iter 300, batch loss 0.0969, batch acc 0.9940
20:22:47.705   Training iter 350, batch loss 0.0946, batch acc 0.9940
20:22:48.077   Training iter 400, batch loss 0.1060, batch acc 0.9936
20:22:48.459   Training iter 450, batch loss 0.1121, batch acc 0.9926
20:22:49.096   Training iter 500, batch loss 0.0975, batch acc 0.9950
20:22:49.607   Training iter 550, batch loss 0.1116, batch acc 0.9930
20:22:50.404   Training iter 600, batch loss 0.1253, batch acc 0.9920
20:22:50.404 Training @ 20 epoch...
20:22:50.813   Training iter 50, batch loss 0.0982, batch acc 0.9934
20:22:51.370   Training iter 100, batch loss 0.0867, batch acc 0.9946
20:22:51.720   Training iter 150, batch loss 0.0765, batch acc 0.9956
20:22:52.072   Training iter 200, batch loss 0.0959, batch acc 0.9936
20:22:52.390   Training iter 250, batch loss 0.0932, batch acc 0.9950
20:22:52.819   Training iter 300, batch loss 0.1080, batch acc 0.9930
20:22:53.163   Training iter 350, batch loss 0.0972, batch acc 0.9946
20:22:53.468   Training iter 400, batch loss 0.0941, batch acc 0.9946
20:22:53.761   Training iter 450, batch loss 0.1019, batch acc 0.9946
20:22:54.033   Training iter 500, batch loss 0.1379, batch acc 0.9906
20:22:54.417   Training iter 550, batch loss 0.1254, batch acc 0.9908
20:22:54.757   Training iter 600, batch loss 0.1472, batch acc 0.9918
20:22:54.758 Testing @ 20 epoch...
20:22:55.103     Testing, total mean loss 0.36469, total acc 0.98120
20:22:55.103 Training @ 21 epoch...
20:22:55.515   Training iter 50, batch loss 0.1004, batch acc 0.9942
20:22:55.909   Training iter 100, batch loss 0.0995, batch acc 0.9946
20:22:56.333   Training iter 150, batch loss 0.1140, batch acc 0.9916
20:22:56.613   Training iter 200, batch loss 0.0874, batch acc 0.9954
20:22:57.154   Training iter 250, batch loss 0.0723, batch acc 0.9962
20:22:57.742   Training iter 300, batch loss 0.0873, batch acc 0.9948
20:22:58.227   Training iter 350, batch loss 0.0769, batch acc 0.9962
20:22:58.623   Training iter 400, batch loss 0.1002, batch acc 0.9946
20:22:59.118   Training iter 450, batch loss 0.1181, batch acc 0.9914
20:22:59.676   Training iter 500, batch loss 0.1178, batch acc 0.9918
20:23:00.092   Training iter 550, batch loss 0.0785, batch acc 0.9954
20:23:00.470   Training iter 600, batch loss 0.0975, batch acc 0.9940
20:23:00.471 Training @ 22 epoch...
20:23:00.967   Training iter 50, batch loss 0.0797, batch acc 0.9950
20:23:01.428   Training iter 100, batch loss 0.0730, batch acc 0.9958
20:23:01.809   Training iter 150, batch loss 0.1003, batch acc 0.9946
20:23:02.143   Training iter 200, batch loss 0.0765, batch acc 0.9954
20:23:02.521   Training iter 250, batch loss 0.0939, batch acc 0.9938
20:23:02.912   Training iter 300, batch loss 0.0946, batch acc 0.9948
20:23:03.319   Training iter 350, batch loss 0.1185, batch acc 0.9916
20:23:03.701   Training iter 400, batch loss 0.0950, batch acc 0.9944
20:23:04.161   Training iter 450, batch loss 0.0998, batch acc 0.9942
20:23:04.525   Training iter 500, batch loss 0.0964, batch acc 0.9942
20:23:04.978   Training iter 550, batch loss 0.0927, batch acc 0.9942
20:23:05.348   Training iter 600, batch loss 0.1263, batch acc 0.9916
20:23:05.348 Training @ 23 epoch...
20:23:05.731   Training iter 50, batch loss 0.0953, batch acc 0.9944
20:23:06.328   Training iter 100, batch loss 0.0795, batch acc 0.9958
20:23:06.789   Training iter 150, batch loss 0.0932, batch acc 0.9940
20:23:07.549   Training iter 200, batch loss 0.0738, batch acc 0.9952
20:23:08.380   Training iter 250, batch loss 0.0958, batch acc 0.9940
20:23:08.722   Training iter 300, batch loss 0.0903, batch acc 0.9952
20:23:09.062   Training iter 350, batch loss 0.0787, batch acc 0.9952
20:23:09.452   Training iter 400, batch loss 0.0865, batch acc 0.9946
20:23:09.834   Training iter 450, batch loss 0.1155, batch acc 0.9918
20:23:10.225   Training iter 500, batch loss 0.0939, batch acc 0.9948
20:23:10.726   Training iter 550, batch loss 0.0993, batch acc 0.9946
20:23:11.133   Training iter 600, batch loss 0.1038, batch acc 0.9938
20:23:11.133 Training @ 24 epoch...
20:23:11.476   Training iter 50, batch loss 0.1053, batch acc 0.9932
20:23:11.793   Training iter 100, batch loss 0.0761, batch acc 0.9954
20:23:12.217   Training iter 150, batch loss 0.0902, batch acc 0.9944
20:23:12.608   Training iter 200, batch loss 0.0754, batch acc 0.9956
20:23:13.017   Training iter 250, batch loss 0.0753, batch acc 0.9962
20:23:13.313   Training iter 300, batch loss 0.0787, batch acc 0.9960
20:23:13.563   Training iter 350, batch loss 0.0980, batch acc 0.9944
20:23:13.988   Training iter 400, batch loss 0.1078, batch acc 0.9936
20:23:14.323   Training iter 450, batch loss 0.0923, batch acc 0.9952
20:23:14.635   Training iter 500, batch loss 0.0742, batch acc 0.9960
20:23:14.972   Training iter 550, batch loss 0.0571, batch acc 0.9968
20:23:15.292   Training iter 600, batch loss 0.0776, batch acc 0.9952
20:23:15.293 Training @ 25 epoch...
20:23:15.648   Training iter 50, batch loss 0.0998, batch acc 0.9942
20:23:16.017   Training iter 100, batch loss 0.0894, batch acc 0.9948
20:23:16.305   Training iter 150, batch loss 0.0884, batch acc 0.9946
20:23:16.606   Training iter 200, batch loss 0.0946, batch acc 0.9936
20:23:16.940   Training iter 250, batch loss 0.1090, batch acc 0.9932
20:23:17.294   Training iter 300, batch loss 0.0807, batch acc 0.9954
20:23:17.591   Training iter 350, batch loss 0.1025, batch acc 0.9934
20:23:17.954   Training iter 400, batch loss 0.1182, batch acc 0.9932
20:23:18.470   Training iter 450, batch loss 0.1156, batch acc 0.9916
20:23:19.030   Training iter 500, batch loss 0.0952, batch acc 0.9938
20:23:19.436   Training iter 550, batch loss 0.0956, batch acc 0.9942
20:23:19.753   Training iter 600, batch loss 0.1170, batch acc 0.9926
20:23:19.755 Testing @ 25 epoch...
20:23:20.034     Testing, total mean loss 0.39449, total acc 0.98050
20:23:20.035 Training @ 26 epoch...
20:23:20.505   Training iter 50, batch loss 0.0936, batch acc 0.9938
20:23:20.852   Training iter 100, batch loss 0.0737, batch acc 0.9962
20:23:21.349   Training iter 150, batch loss 0.1032, batch acc 0.9940
20:23:21.803   Training iter 200, batch loss 0.0680, batch acc 0.9964
20:23:22.109   Training iter 250, batch loss 0.1116, batch acc 0.9932
20:23:22.459   Training iter 300, batch loss 0.0853, batch acc 0.9952
20:23:22.750   Training iter 350, batch loss 0.0792, batch acc 0.9960
20:23:23.050   Training iter 400, batch loss 0.0874, batch acc 0.9952
20:23:23.343   Training iter 450, batch loss 0.0965, batch acc 0.9944
20:23:23.619   Training iter 500, batch loss 0.0713, batch acc 0.9964
20:23:23.943   Training iter 550, batch loss 0.0894, batch acc 0.9938
20:23:24.303   Training iter 600, batch loss 0.0854, batch acc 0.9940
20:23:24.305 Training @ 27 epoch...
20:23:24.620   Training iter 50, batch loss 0.0702, batch acc 0.9970
20:23:24.899   Training iter 100, batch loss 0.0989, batch acc 0.9952
20:23:25.172   Training iter 150, batch loss 0.0812, batch acc 0.9954
20:23:25.479   Training iter 200, batch loss 0.0794, batch acc 0.9954
20:23:25.766   Training iter 250, batch loss 0.0624, batch acc 0.9966
20:23:26.050   Training iter 300, batch loss 0.0972, batch acc 0.9930
20:23:26.347   Training iter 350, batch loss 0.0763, batch acc 0.9956
20:23:26.648   Training iter 400, batch loss 0.0876, batch acc 0.9942
20:23:26.982   Training iter 450, batch loss 0.0889, batch acc 0.9946
20:23:27.327   Training iter 500, batch loss 0.0770, batch acc 0.9954
20:23:27.622   Training iter 550, batch loss 0.0582, batch acc 0.9962
20:23:27.914   Training iter 600, batch loss 0.0935, batch acc 0.9950
20:23:27.914 Training @ 28 epoch...
20:23:28.189   Training iter 50, batch loss 0.0520, batch acc 0.9972
20:23:28.496   Training iter 100, batch loss 0.0550, batch acc 0.9974
20:23:28.855   Training iter 150, batch loss 0.0688, batch acc 0.9960
20:23:29.230   Training iter 200, batch loss 0.0640, batch acc 0.9968
20:23:29.727   Training iter 250, batch loss 0.0876, batch acc 0.9952
20:23:30.108   Training iter 300, batch loss 0.1022, batch acc 0.9938
20:23:30.475   Training iter 350, batch loss 0.1093, batch acc 0.9920
20:23:30.773   Training iter 400, batch loss 0.0830, batch acc 0.9946
20:23:31.104   Training iter 450, batch loss 0.0809, batch acc 0.9952
20:23:31.430   Training iter 500, batch loss 0.0579, batch acc 0.9978
20:23:31.853   Training iter 550, batch loss 0.0897, batch acc 0.9942
20:23:32.271   Training iter 600, batch loss 0.1108, batch acc 0.9930
20:23:32.272 Training @ 29 epoch...
20:23:32.701   Training iter 50, batch loss 0.0687, batch acc 0.9960
20:23:33.125   Training iter 100, batch loss 0.0560, batch acc 0.9970
20:23:33.595   Training iter 150, batch loss 0.0610, batch acc 0.9968
20:23:34.462   Training iter 200, batch loss 0.0843, batch acc 0.9954
20:23:34.950   Training iter 250, batch loss 0.1332, batch acc 0.9916
20:23:35.755   Training iter 300, batch loss 0.0627, batch acc 0.9964
20:23:36.172   Training iter 350, batch loss 0.0943, batch acc 0.9950
20:23:36.781   Training iter 400, batch loss 0.0720, batch acc 0.9954
20:23:37.135   Training iter 450, batch loss 0.0979, batch acc 0.9942
20:23:37.632   Training iter 500, batch loss 0.0948, batch acc 0.9946
20:23:37.988   Training iter 550, batch loss 0.0725, batch acc 0.9970
20:23:38.328   Training iter 600, batch loss 0.0644, batch acc 0.9962
20:23:38.328 Training @ 30 epoch...
20:23:38.715   Training iter 50, batch loss 0.0648, batch acc 0.9962
20:23:39.231   Training iter 100, batch loss 0.0758, batch acc 0.9964
20:23:39.539   Training iter 150, batch loss 0.0617, batch acc 0.9966
20:23:39.879   Training iter 200, batch loss 0.0773, batch acc 0.9950
20:23:40.142   Training iter 250, batch loss 0.0696, batch acc 0.9964
20:23:40.794   Training iter 300, batch loss 0.0627, batch acc 0.9968
20:23:41.148   Training iter 350, batch loss 0.1040, batch acc 0.9954
20:23:41.804   Training iter 400, batch loss 0.0701, batch acc 0.9960
20:23:42.295   Training iter 450, batch loss 0.0703, batch acc 0.9968
20:23:42.747   Training iter 500, batch loss 0.0866, batch acc 0.9946
20:23:43.088   Training iter 550, batch loss 0.0775, batch acc 0.9966
20:23:43.427   Training iter 600, batch loss 0.0854, batch acc 0.9956
20:23:43.428 Testing @ 30 epoch...
20:23:43.754     Testing, total mean loss 0.35189, total acc 0.98130
20:23:43.754 Training @ 31 epoch...
20:23:44.061   Training iter 50, batch loss 0.0628, batch acc 0.9964
20:23:44.408   Training iter 100, batch loss 0.0781, batch acc 0.9956
20:23:44.727   Training iter 150, batch loss 0.0753, batch acc 0.9962
20:23:45.128   Training iter 200, batch loss 0.0642, batch acc 0.9970
20:23:45.539   Training iter 250, batch loss 0.0707, batch acc 0.9950
20:23:45.900   Training iter 300, batch loss 0.0599, batch acc 0.9958
20:23:46.556   Training iter 350, batch loss 0.0767, batch acc 0.9948
20:23:46.965   Training iter 400, batch loss 0.1185, batch acc 0.9930
20:23:47.359   Training iter 450, batch loss 0.0698, batch acc 0.9966
20:23:47.741   Training iter 500, batch loss 0.0728, batch acc 0.9950
20:23:48.145   Training iter 550, batch loss 0.0525, batch acc 0.9972
20:23:48.657   Training iter 600, batch loss 0.0732, batch acc 0.9960
20:23:48.657 Training @ 32 epoch...
20:23:49.110   Training iter 50, batch loss 0.0630, batch acc 0.9968
20:23:49.604   Training iter 100, batch loss 0.0583, batch acc 0.9964
20:23:50.286   Training iter 150, batch loss 0.0854, batch acc 0.9942
20:23:51.004   Training iter 200, batch loss 0.0695, batch acc 0.9968
20:23:51.893   Training iter 250, batch loss 0.0648, batch acc 0.9960
20:23:52.543   Training iter 300, batch loss 0.0849, batch acc 0.9948
20:23:53.118   Training iter 350, batch loss 0.0629, batch acc 0.9960
20:23:53.785   Training iter 400, batch loss 0.0720, batch acc 0.9958
20:23:54.324   Training iter 450, batch loss 0.0938, batch acc 0.9952
20:23:54.875   Training iter 500, batch loss 0.0715, batch acc 0.9944
20:23:55.310   Training iter 550, batch loss 0.0870, batch acc 0.9944
20:23:55.876   Training iter 600, batch loss 0.0901, batch acc 0.9954
20:23:55.878 Training @ 33 epoch...
20:23:56.404   Training iter 50, batch loss 0.0780, batch acc 0.9960
20:23:56.859   Training iter 100, batch loss 0.0593, batch acc 0.9960
20:23:57.288   Training iter 150, batch loss 0.0582, batch acc 0.9964
20:23:57.607   Training iter 200, batch loss 0.0717, batch acc 0.9958
20:23:57.950   Training iter 250, batch loss 0.0719, batch acc 0.9958
20:23:58.342   Training iter 300, batch loss 0.0837, batch acc 0.9952
20:23:58.692   Training iter 350, batch loss 0.0761, batch acc 0.9960
20:23:59.001   Training iter 400, batch loss 0.0924, batch acc 0.9934
20:23:59.393   Training iter 450, batch loss 0.0634, batch acc 0.9964
20:23:59.760   Training iter 500, batch loss 0.0978, batch acc 0.9938
20:24:00.157   Training iter 550, batch loss 0.0841, batch acc 0.9942
20:24:00.502   Training iter 600, batch loss 0.0685, batch acc 0.9964
20:24:00.504 Training @ 34 epoch...
20:24:00.943   Training iter 50, batch loss 0.0575, batch acc 0.9964
20:24:01.359   Training iter 100, batch loss 0.0588, batch acc 0.9970
20:24:01.704   Training iter 150, batch loss 0.0431, batch acc 0.9978
20:24:02.277   Training iter 200, batch loss 0.0357, batch acc 0.9990
20:24:02.688   Training iter 250, batch loss 0.0730, batch acc 0.9966
20:24:03.210   Training iter 300, batch loss 0.0654, batch acc 0.9950
20:24:03.623   Training iter 350, batch loss 0.0795, batch acc 0.9954
20:24:04.062   Training iter 400, batch loss 0.0581, batch acc 0.9970
20:24:04.491   Training iter 450, batch loss 0.0789, batch acc 0.9962
20:24:04.925   Training iter 500, batch loss 0.0776, batch acc 0.9952
20:24:05.282   Training iter 550, batch loss 0.0684, batch acc 0.9962
20:24:05.663   Training iter 600, batch loss 0.0622, batch acc 0.9954
20:24:05.663 Training @ 35 epoch...
20:24:06.159   Training iter 50, batch loss 0.0451, batch acc 0.9974
20:24:06.615   Training iter 100, batch loss 0.0387, batch acc 0.9982
20:24:07.084   Training iter 150, batch loss 0.0506, batch acc 0.9972
20:24:07.708   Training iter 200, batch loss 0.0579, batch acc 0.9964
20:24:08.194   Training iter 250, batch loss 0.0875, batch acc 0.9948
20:24:08.665   Training iter 300, batch loss 0.1133, batch acc 0.9926
20:24:09.258   Training iter 350, batch loss 0.0924, batch acc 0.9954
20:24:09.588   Training iter 400, batch loss 0.1200, batch acc 0.9930
20:24:09.956   Training iter 450, batch loss 0.0705, batch acc 0.9960
20:24:10.379   Training iter 500, batch loss 0.0866, batch acc 0.9946
20:24:10.740   Training iter 550, batch loss 0.0903, batch acc 0.9950
20:24:11.146   Training iter 600, batch loss 0.0877, batch acc 0.9952
20:24:11.148 Testing @ 35 epoch...
20:24:11.558     Testing, total mean loss 0.38091, total acc 0.98010
20:24:11.558 Training @ 36 epoch...
20:24:12.008   Training iter 50, batch loss 0.0513, batch acc 0.9974
20:24:12.605   Training iter 100, batch loss 0.0521, batch acc 0.9974
20:24:13.673   Training iter 150, batch loss 0.0550, batch acc 0.9974
20:24:14.203   Training iter 200, batch loss 0.0696, batch acc 0.9956
20:24:14.775   Training iter 250, batch loss 0.0720, batch acc 0.9966
20:24:15.339   Training iter 300, batch loss 0.0798, batch acc 0.9948
20:24:15.846   Training iter 350, batch loss 0.0859, batch acc 0.9952
20:24:16.811   Training iter 400, batch loss 0.0629, batch acc 0.9966
20:24:17.238   Training iter 450, batch loss 0.0690, batch acc 0.9964
20:24:17.636   Training iter 500, batch loss 0.0605, batch acc 0.9974
20:24:18.010   Training iter 550, batch loss 0.0819, batch acc 0.9946
20:24:18.362   Training iter 600, batch loss 0.0853, batch acc 0.9940
20:24:18.363 Training @ 37 epoch...
20:24:18.903   Training iter 50, batch loss 0.0660, batch acc 0.9962
20:24:19.318   Training iter 100, batch loss 0.0555, batch acc 0.9976
20:24:19.632   Training iter 150, batch loss 0.0769, batch acc 0.9944
20:24:20.181   Training iter 200, batch loss 0.0497, batch acc 0.9980
20:24:20.694   Training iter 250, batch loss 0.0742, batch acc 0.9962
20:24:21.073   Training iter 300, batch loss 0.0573, batch acc 0.9968
20:24:21.418   Training iter 350, batch loss 0.0617, batch acc 0.9964
20:24:21.794   Training iter 400, batch loss 0.0794, batch acc 0.9944
20:24:22.140   Training iter 450, batch loss 0.0698, batch acc 0.9966
20:24:22.454   Training iter 500, batch loss 0.0687, batch acc 0.9966
20:24:22.878   Training iter 550, batch loss 0.0939, batch acc 0.9942
20:24:23.452   Training iter 600, batch loss 0.0940, batch acc 0.9942
20:24:23.454 Training @ 38 epoch...
20:24:23.939   Training iter 50, batch loss 0.0747, batch acc 0.9954
20:24:24.342   Training iter 100, batch loss 0.0442, batch acc 0.9984
20:24:24.627   Training iter 150, batch loss 0.0448, batch acc 0.9976
20:24:24.937   Training iter 200, batch loss 0.0387, batch acc 0.9980
20:24:25.309   Training iter 250, batch loss 0.0560, batch acc 0.9964
20:24:26.224   Training iter 300, batch loss 0.0588, batch acc 0.9964
20:24:27.128   Training iter 350, batch loss 0.0804, batch acc 0.9952
20:24:27.627   Training iter 400, batch loss 0.0796, batch acc 0.9950
20:24:28.098   Training iter 450, batch loss 0.0850, batch acc 0.9950
20:24:28.487   Training iter 500, batch loss 0.0849, batch acc 0.9950
20:24:28.889   Training iter 550, batch loss 0.0832, batch acc 0.9952
20:24:29.314   Training iter 600, batch loss 0.1014, batch acc 0.9944
20:24:29.316 Training @ 39 epoch...
20:24:29.754   Training iter 50, batch loss 0.0553, batch acc 0.9970
20:24:30.406   Training iter 100, batch loss 0.0641, batch acc 0.9964
20:24:30.809   Training iter 150, batch loss 0.0664, batch acc 0.9958
20:24:31.411   Training iter 200, batch loss 0.0570, batch acc 0.9964
20:24:32.208   Training iter 250, batch loss 0.0406, batch acc 0.9986
20:24:33.709   Training iter 300, batch loss 0.0605, batch acc 0.9968
20:24:34.191   Training iter 350, batch loss 0.0661, batch acc 0.9956
20:24:34.582   Training iter 400, batch loss 0.0628, batch acc 0.9968
20:24:35.241   Training iter 450, batch loss 0.1056, batch acc 0.9936
20:24:35.826   Training iter 500, batch loss 0.0751, batch acc 0.9952
20:24:36.388   Training iter 550, batch loss 0.0707, batch acc 0.9962
20:24:36.699   Training iter 600, batch loss 0.0731, batch acc 0.9952
20:24:36.699 Training @ 40 epoch...
20:24:36.995   Training iter 50, batch loss 0.0762, batch acc 0.9948
20:24:37.488   Training iter 100, batch loss 0.0572, batch acc 0.9972
20:24:37.962   Training iter 150, batch loss 0.0821, batch acc 0.9948
20:24:38.613   Training iter 200, batch loss 0.0724, batch acc 0.9954
20:24:39.295   Training iter 250, batch loss 0.0393, batch acc 0.9986
20:24:40.050   Training iter 300, batch loss 0.0440, batch acc 0.9976
20:24:40.423   Training iter 350, batch loss 0.0701, batch acc 0.9960
20:24:40.902   Training iter 400, batch loss 0.0694, batch acc 0.9954
20:24:41.541   Training iter 450, batch loss 0.0611, batch acc 0.9962
20:24:42.052   Training iter 500, batch loss 0.0494, batch acc 0.9970
20:24:42.564   Training iter 550, batch loss 0.0558, batch acc 0.9974
20:24:43.240   Training iter 600, batch loss 0.0727, batch acc 0.9952
20:24:43.240 Testing @ 40 epoch...
20:24:43.511     Testing, total mean loss 0.34971, total acc 0.98110
20:24:43.511 Training @ 41 epoch...
20:24:43.939   Training iter 50, batch loss 0.0480, batch acc 0.9978
20:24:44.351   Training iter 100, batch loss 0.0639, batch acc 0.9964
20:24:44.786   Training iter 150, batch loss 0.0710, batch acc 0.9958
20:24:45.233   Training iter 200, batch loss 0.0634, batch acc 0.9968
20:24:45.600   Training iter 250, batch loss 0.0580, batch acc 0.9972
20:24:46.620   Training iter 300, batch loss 0.0542, batch acc 0.9972
20:24:47.035   Training iter 350, batch loss 0.0821, batch acc 0.9958
20:24:47.448   Training iter 400, batch loss 0.0552, batch acc 0.9972
20:24:47.818   Training iter 450, batch loss 0.0516, batch acc 0.9974
20:24:48.189   Training iter 500, batch loss 0.0987, batch acc 0.9940
20:24:48.489   Training iter 550, batch loss 0.0843, batch acc 0.9948
20:24:48.787   Training iter 600, batch loss 0.0803, batch acc 0.9956
20:24:48.788 Training @ 42 epoch...
20:24:49.137   Training iter 50, batch loss 0.0623, batch acc 0.9964
20:24:49.645   Training iter 100, batch loss 0.0446, batch acc 0.9982
20:24:50.054   Training iter 150, batch loss 0.0465, batch acc 0.9974
20:24:50.458   Training iter 200, batch loss 0.0505, batch acc 0.9968
20:24:51.080   Training iter 250, batch loss 0.0776, batch acc 0.9958
20:24:51.479   Training iter 300, batch loss 0.0706, batch acc 0.9974
20:24:51.967   Training iter 350, batch loss 0.0701, batch acc 0.9954
20:24:52.420   Training iter 400, batch loss 0.0862, batch acc 0.9940
20:24:52.963   Training iter 450, batch loss 0.0537, batch acc 0.9968
20:24:53.345   Training iter 500, batch loss 0.0760, batch acc 0.9948
20:24:53.806   Training iter 550, batch loss 0.0609, batch acc 0.9974
20:24:54.174   Training iter 600, batch loss 0.0700, batch acc 0.9954
20:24:54.176 Training @ 43 epoch...
20:24:54.540   Training iter 50, batch loss 0.0591, batch acc 0.9972
20:24:54.847   Training iter 100, batch loss 0.0539, batch acc 0.9968
20:24:55.174   Training iter 150, batch loss 0.0543, batch acc 0.9976
20:24:55.489   Training iter 200, batch loss 0.0436, batch acc 0.9974
20:24:55.844   Training iter 250, batch loss 0.0519, batch acc 0.9974
20:24:56.181   Training iter 300, batch loss 0.0578, batch acc 0.9974
20:24:56.512   Training iter 350, batch loss 0.0504, batch acc 0.9984
20:24:57.494   Training iter 400, batch loss 0.0634, batch acc 0.9968
20:24:57.831   Training iter 450, batch loss 0.0698, batch acc 0.9964
20:24:58.196   Training iter 500, batch loss 0.0763, batch acc 0.9952
20:24:58.506   Training iter 550, batch loss 0.0572, batch acc 0.9966
20:24:58.806   Training iter 600, batch loss 0.0570, batch acc 0.9974
20:24:58.807 Training @ 44 epoch...
20:24:59.272   Training iter 50, batch loss 0.0406, batch acc 0.9980
20:24:59.699   Training iter 100, batch loss 0.0431, batch acc 0.9980
20:25:00.263   Training iter 150, batch loss 0.0796, batch acc 0.9954
20:25:00.824   Training iter 200, batch loss 0.0793, batch acc 0.9956
20:25:01.388   Training iter 250, batch loss 0.1029, batch acc 0.9946
20:25:01.854   Training iter 300, batch loss 0.0638, batch acc 0.9970
20:25:02.216   Training iter 350, batch loss 0.0581, batch acc 0.9968
20:25:02.734   Training iter 400, batch loss 0.0577, batch acc 0.9968
20:25:03.178   Training iter 450, batch loss 0.0664, batch acc 0.9972
20:25:03.577   Training iter 500, batch loss 0.0516, batch acc 0.9972
20:25:04.013   Training iter 550, batch loss 0.0551, batch acc 0.9968
20:25:04.361   Training iter 600, batch loss 0.0740, batch acc 0.9956
20:25:04.361 Training @ 45 epoch...
20:25:04.820   Training iter 50, batch loss 0.0418, batch acc 0.9982
20:25:05.616   Training iter 100, batch loss 0.0324, batch acc 0.9984
20:25:06.097   Training iter 150, batch loss 0.0547, batch acc 0.9980
20:25:06.597   Training iter 200, batch loss 0.0731, batch acc 0.9954
20:25:06.948   Training iter 250, batch loss 0.0786, batch acc 0.9956
20:25:07.562   Training iter 300, batch loss 0.0464, batch acc 0.9978
20:25:07.985   Training iter 350, batch loss 0.0603, batch acc 0.9956
20:25:08.545   Training iter 400, batch loss 0.0565, batch acc 0.9968
20:25:09.021   Training iter 450, batch loss 0.0650, batch acc 0.9968
20:25:09.389   Training iter 500, batch loss 0.0446, batch acc 0.9980
20:25:09.661   Training iter 550, batch loss 0.0735, batch acc 0.9958
20:25:10.011   Training iter 600, batch loss 0.0785, batch acc 0.9954
20:25:10.011 Testing @ 45 epoch...
20:25:10.322     Testing, total mean loss 0.45866, total acc 0.97590
20:25:10.322 Training @ 46 epoch...
20:25:10.619   Training iter 50, batch loss 0.0713, batch acc 0.9970
20:25:11.037   Training iter 100, batch loss 0.0655, batch acc 0.9954
20:25:11.901   Training iter 150, batch loss 0.0649, batch acc 0.9970
20:25:12.375   Training iter 200, batch loss 0.0731, batch acc 0.9960
20:25:12.806   Training iter 250, batch loss 0.0569, batch acc 0.9976
20:25:13.443   Training iter 300, batch loss 0.0448, batch acc 0.9974
20:25:13.856   Training iter 350, batch loss 0.0357, batch acc 0.9984
20:25:14.290   Training iter 400, batch loss 0.0637, batch acc 0.9964
20:25:14.906   Training iter 450, batch loss 0.0701, batch acc 0.9968
20:25:15.528   Training iter 500, batch loss 0.0500, batch acc 0.9980
20:25:16.680   Training iter 550, batch loss 0.0759, batch acc 0.9948
20:25:17.166   Training iter 600, batch loss 0.0685, batch acc 0.9962
20:25:17.170 Training @ 47 epoch...
20:25:17.872   Training iter 50, batch loss 0.0500, batch acc 0.9968
20:25:18.553   Training iter 100, batch loss 0.0600, batch acc 0.9972
20:25:19.035   Training iter 150, batch loss 0.0757, batch acc 0.9952
20:25:19.425   Training iter 200, batch loss 0.0478, batch acc 0.9968
20:25:20.026   Training iter 250, batch loss 0.0519, batch acc 0.9978
20:25:20.659   Training iter 300, batch loss 0.0743, batch acc 0.9956
20:25:21.088   Training iter 350, batch loss 0.0658, batch acc 0.9968
20:25:21.677   Training iter 400, batch loss 0.0564, batch acc 0.9968
20:25:22.297   Training iter 450, batch loss 0.0690, batch acc 0.9950
20:25:22.798   Training iter 500, batch loss 0.0894, batch acc 0.9936
20:25:23.108   Training iter 550, batch loss 0.0730, batch acc 0.9962
20:25:23.483   Training iter 600, batch loss 0.0631, batch acc 0.9968
20:25:23.484 Training @ 48 epoch...
20:25:23.928   Training iter 50, batch loss 0.0406, batch acc 0.9982
20:25:24.340   Training iter 100, batch loss 0.0384, batch acc 0.9982
20:25:24.655   Training iter 150, batch loss 0.0576, batch acc 0.9976
20:25:25.006   Training iter 200, batch loss 0.0436, batch acc 0.9978
20:25:25.771   Training iter 250, batch loss 0.0445, batch acc 0.9976
20:25:26.227   Training iter 300, batch loss 0.0619, batch acc 0.9970
20:25:26.612   Training iter 350, batch loss 0.0466, batch acc 0.9974
20:25:27.060   Training iter 400, batch loss 0.0481, batch acc 0.9984
20:25:27.525   Training iter 450, batch loss 0.0448, batch acc 0.9976
20:25:28.174   Training iter 500, batch loss 0.0840, batch acc 0.9954
20:25:28.917   Training iter 550, batch loss 0.0434, batch acc 0.9978
20:25:29.823   Training iter 600, batch loss 0.0798, batch acc 0.9948
20:25:29.824 Training @ 49 epoch...
20:25:30.395   Training iter 50, batch loss 0.0458, batch acc 0.9974
20:25:30.882   Training iter 100, batch loss 0.0443, batch acc 0.9974
20:25:31.328   Training iter 150, batch loss 0.0563, batch acc 0.9970
20:25:32.018   Training iter 200, batch loss 0.0435, batch acc 0.9982
20:25:32.615   Training iter 250, batch loss 0.0504, batch acc 0.9976
20:25:33.229   Training iter 300, batch loss 0.0552, batch acc 0.9970
20:25:33.793   Training iter 350, batch loss 0.0700, batch acc 0.9956
20:25:34.468   Training iter 400, batch loss 0.0794, batch acc 0.9958
20:25:34.895   Training iter 450, batch loss 0.0644, batch acc 0.9966
20:25:35.363   Training iter 500, batch loss 0.0389, batch acc 0.9984
20:25:36.062   Training iter 550, batch loss 0.0487, batch acc 0.9976
20:25:36.598   Training iter 600, batch loss 0.0592, batch acc 0.9972
20:25:36.599 Training @ 50 epoch...
20:25:37.100   Training iter 50, batch loss 0.0608, batch acc 0.9976
20:25:37.790   Training iter 100, batch loss 0.0423, batch acc 0.9974
20:25:38.219   Training iter 150, batch loss 0.0487, batch acc 0.9972
20:25:39.551   Training iter 200, batch loss 0.0412, batch acc 0.9982
20:25:40.003   Training iter 250, batch loss 0.0668, batch acc 0.9966
20:25:40.511   Training iter 300, batch loss 0.0836, batch acc 0.9964
20:25:40.856   Training iter 350, batch loss 0.0683, batch acc 0.9958
20:25:41.149   Training iter 400, batch loss 0.0626, batch acc 0.9958
20:25:41.492   Training iter 450, batch loss 0.0351, batch acc 0.9982
20:25:41.858   Training iter 500, batch loss 0.0527, batch acc 0.9974
20:25:42.308   Training iter 550, batch loss 0.0600, batch acc 0.9980
20:25:42.922   Training iter 600, batch loss 0.0858, batch acc 0.9962
20:25:42.924 Testing @ 50 epoch...
20:25:43.280     Testing, total mean loss 0.38124, total acc 0.98100
20:25:43.280 Training @ 51 epoch...
20:25:44.132   Training iter 50, batch loss 0.0712, batch acc 0.9962
20:25:44.588   Training iter 100, batch loss 0.0558, batch acc 0.9968
20:25:45.338   Training iter 150, batch loss 0.0641, batch acc 0.9962
20:25:45.904   Training iter 200, batch loss 0.0489, batch acc 0.9986
20:25:46.417   Training iter 250, batch loss 0.0509, batch acc 0.9974
20:25:46.987   Training iter 300, batch loss 0.0689, batch acc 0.9954
20:25:47.505   Training iter 350, batch loss 0.0824, batch acc 0.9956
20:25:47.934   Training iter 400, batch loss 0.0863, batch acc 0.9950
20:25:48.377   Training iter 450, batch loss 0.0483, batch acc 0.9982
20:25:48.707   Training iter 500, batch loss 0.0484, batch acc 0.9982
20:25:49.064   Training iter 550, batch loss 0.0755, batch acc 0.9968
20:25:49.367   Training iter 600, batch loss 0.0667, batch acc 0.9972
20:25:49.367 Training @ 52 epoch...
20:25:49.673   Training iter 50, batch loss 0.0539, batch acc 0.9960
20:25:50.036   Training iter 100, batch loss 0.0525, batch acc 0.9976
20:25:50.405   Training iter 150, batch loss 0.0683, batch acc 0.9962
20:25:50.824   Training iter 200, batch loss 0.0422, batch acc 0.9988
20:25:51.172   Training iter 250, batch loss 0.0617, batch acc 0.9974
20:25:51.461   Training iter 300, batch loss 0.0612, batch acc 0.9968
20:25:52.175   Training iter 350, batch loss 0.0691, batch acc 0.9970
20:25:52.755   Training iter 400, batch loss 0.0569, batch acc 0.9970
20:25:53.195   Training iter 450, batch loss 0.0644, batch acc 0.9966
20:25:53.541   Training iter 500, batch loss 0.0428, batch acc 0.9976
20:25:53.903   Training iter 550, batch loss 0.0567, batch acc 0.9968
20:25:54.188   Training iter 600, batch loss 0.0388, batch acc 0.9982
20:25:54.189 Training @ 53 epoch...
20:25:54.496   Training iter 50, batch loss 0.0791, batch acc 0.9958
20:25:54.781   Training iter 100, batch loss 0.0835, batch acc 0.9954
20:25:55.181   Training iter 150, batch loss 0.0522, batch acc 0.9968
20:25:55.484   Training iter 200, batch loss 0.0398, batch acc 0.9984
20:25:55.772   Training iter 250, batch loss 0.0425, batch acc 0.9976
20:25:56.218   Training iter 300, batch loss 0.0437, batch acc 0.9982
20:25:56.509   Training iter 350, batch loss 0.0423, batch acc 0.9976
20:25:56.838   Training iter 400, batch loss 0.0516, batch acc 0.9966
20:25:57.131   Training iter 450, batch loss 0.0589, batch acc 0.9954
20:25:57.787   Training iter 500, batch loss 0.0770, batch acc 0.9954
20:25:58.226   Training iter 550, batch loss 0.0584, batch acc 0.9972
20:25:58.599   Training iter 600, batch loss 0.0595, batch acc 0.9962
20:25:58.602 Training @ 54 epoch...
20:25:59.045   Training iter 50, batch loss 0.0472, batch acc 0.9982
20:25:59.490   Training iter 100, batch loss 0.0467, batch acc 0.9980
20:25:59.816   Training iter 150, batch loss 0.0760, batch acc 0.9950
20:26:00.196   Training iter 200, batch loss 0.0779, batch acc 0.9954
20:26:00.573   Training iter 250, batch loss 0.0530, batch acc 0.9976
20:26:00.909   Training iter 300, batch loss 0.0715, batch acc 0.9966
20:26:01.259   Training iter 350, batch loss 0.0490, batch acc 0.9976
20:26:01.726   Training iter 400, batch loss 0.0635, batch acc 0.9964
20:26:02.335   Training iter 450, batch loss 0.0592, batch acc 0.9962
20:26:02.696   Training iter 500, batch loss 0.0596, batch acc 0.9966
20:26:02.981   Training iter 550, batch loss 0.0693, batch acc 0.9958
20:26:03.297   Training iter 600, batch loss 0.0899, batch acc 0.9944
20:26:03.298 Training @ 55 epoch...
20:26:03.595   Training iter 50, batch loss 0.0627, batch acc 0.9962
20:26:03.870   Training iter 100, batch loss 0.0768, batch acc 0.9950
20:26:04.158   Training iter 150, batch loss 0.0753, batch acc 0.9958
20:26:04.425   Training iter 200, batch loss 0.0684, batch acc 0.9960
20:26:04.747   Training iter 250, batch loss 0.0454, batch acc 0.9978
20:26:05.070   Training iter 300, batch loss 0.0461, batch acc 0.9970
20:26:05.495   Training iter 350, batch loss 0.0438, batch acc 0.9984
20:26:05.892   Training iter 400, batch loss 0.0640, batch acc 0.9964
20:26:06.214   Training iter 450, batch loss 0.0621, batch acc 0.9970
20:26:06.755   Training iter 500, batch loss 0.0542, batch acc 0.9972
20:26:07.866   Training iter 550, batch loss 0.0692, batch acc 0.9960
20:26:09.063   Training iter 600, batch loss 0.0639, batch acc 0.9966
20:26:09.067 Testing @ 55 epoch...
20:26:10.037     Testing, total mean loss 0.33916, total acc 0.98320
20:26:10.037 Training @ 56 epoch...
20:26:10.585   Training iter 50, batch loss 0.0447, batch acc 0.9982
20:26:11.228   Training iter 100, batch loss 0.0645, batch acc 0.9970
20:26:11.681   Training iter 150, batch loss 0.0860, batch acc 0.9954
20:26:12.092   Training iter 200, batch loss 0.0675, batch acc 0.9956
20:26:12.497   Training iter 250, batch loss 0.0500, batch acc 0.9970
20:26:12.855   Training iter 300, batch loss 0.0598, batch acc 0.9968
20:26:13.235   Training iter 350, batch loss 0.0685, batch acc 0.9964
20:26:13.613   Training iter 400, batch loss 0.0583, batch acc 0.9970
20:26:15.132   Training iter 450, batch loss 0.0692, batch acc 0.9966
20:26:15.706   Training iter 500, batch loss 0.0586, batch acc 0.9964
20:26:16.235   Training iter 550, batch loss 0.0653, batch acc 0.9964
20:26:16.792   Training iter 600, batch loss 0.0578, batch acc 0.9964
20:26:16.793 Training @ 57 epoch...
20:26:17.456   Training iter 50, batch loss 0.0572, batch acc 0.9960
20:26:18.044   Training iter 100, batch loss 0.0476, batch acc 0.9974
20:26:18.405   Training iter 150, batch loss 0.0778, batch acc 0.9956
20:26:18.807   Training iter 200, batch loss 0.0543, batch acc 0.9978
20:26:19.172   Training iter 250, batch loss 0.0501, batch acc 0.9978
20:26:19.595   Training iter 300, batch loss 0.0397, batch acc 0.9986
20:26:20.004   Training iter 350, batch loss 0.0672, batch acc 0.9960
20:26:20.465   Training iter 400, batch loss 0.0612, batch acc 0.9968
20:26:20.817   Training iter 450, batch loss 0.0712, batch acc 0.9966
20:26:21.218   Training iter 500, batch loss 0.0712, batch acc 0.9964
20:26:21.513   Training iter 550, batch loss 0.0594, batch acc 0.9970
20:26:21.834   Training iter 600, batch loss 0.0853, batch acc 0.9954
20:26:21.835 Training @ 58 epoch...
20:26:22.173   Training iter 50, batch loss 0.0729, batch acc 0.9956
20:26:22.479   Training iter 100, batch loss 0.0594, batch acc 0.9968
20:26:22.797   Training iter 150, batch loss 0.0487, batch acc 0.9974
20:26:23.078   Training iter 200, batch loss 0.0561, batch acc 0.9974
20:26:23.419   Training iter 250, batch loss 0.0434, batch acc 0.9982
20:26:23.757   Training iter 300, batch loss 0.0734, batch acc 0.9964
20:26:24.278   Training iter 350, batch loss 0.0770, batch acc 0.9964
20:26:24.668   Training iter 400, batch loss 0.0477, batch acc 0.9972
20:26:24.981   Training iter 450, batch loss 0.0614, batch acc 0.9966
20:26:25.260   Training iter 500, batch loss 0.0539, batch acc 0.9970
20:26:25.563   Training iter 550, batch loss 0.0670, batch acc 0.9962
20:26:25.864   Training iter 600, batch loss 0.0502, batch acc 0.9974
20:26:25.865 Training @ 59 epoch...
20:26:26.510   Training iter 50, batch loss 0.0431, batch acc 0.9984
20:26:27.131   Training iter 100, batch loss 0.0374, batch acc 0.9982
20:26:27.611   Training iter 150, batch loss 0.0397, batch acc 0.9982
20:26:28.079   Training iter 200, batch loss 0.0286, batch acc 0.9984
20:26:28.509   Training iter 250, batch loss 0.0468, batch acc 0.9974
20:26:28.901   Training iter 300, batch loss 0.0404, batch acc 0.9982
20:26:29.253   Training iter 350, batch loss 0.0367, batch acc 0.9980
20:26:29.617   Training iter 400, batch loss 0.0471, batch acc 0.9974
20:26:30.191   Training iter 450, batch loss 0.0497, batch acc 0.9980
20:26:30.729   Training iter 500, batch loss 0.0608, batch acc 0.9970
20:26:31.321   Training iter 550, batch loss 0.0688, batch acc 0.9964
20:26:31.638   Training iter 600, batch loss 0.0709, batch acc 0.9970
20:26:31.640 Training @ 60 epoch...
20:26:32.222   Training iter 50, batch loss 0.0532, batch acc 0.9972
20:26:32.781   Training iter 100, batch loss 0.0466, batch acc 0.9982
20:26:33.220   Training iter 150, batch loss 0.0517, batch acc 0.9976
20:26:33.680   Training iter 200, batch loss 0.0529, batch acc 0.9978
20:26:34.232   Training iter 250, batch loss 0.0542, batch acc 0.9972
20:26:34.630   Training iter 300, batch loss 0.1021, batch acc 0.9942
20:26:34.949   Training iter 350, batch loss 0.0611, batch acc 0.9980
20:26:35.412   Training iter 400, batch loss 0.0591, batch acc 0.9976
20:26:35.843   Training iter 450, batch loss 0.0580, batch acc 0.9972
20:26:36.244   Training iter 500, batch loss 0.0422, batch acc 0.9978
20:26:36.661   Training iter 550, batch loss 0.0467, batch acc 0.9982
20:26:37.089   Training iter 600, batch loss 0.0493, batch acc 0.9974
20:26:37.089 Testing @ 60 epoch...
20:26:37.534     Testing, total mean loss 0.32816, total acc 0.98330
20:26:37.534 Training @ 61 epoch...
20:26:37.911   Training iter 50, batch loss 0.0376, batch acc 0.9980
20:26:38.260   Training iter 100, batch loss 0.0326, batch acc 0.9980
20:26:38.604   Training iter 150, batch loss 0.0547, batch acc 0.9968
20:26:38.947   Training iter 200, batch loss 0.0492, batch acc 0.9978
20:26:39.250   Training iter 250, batch loss 0.0483, batch acc 0.9976
20:26:39.533   Training iter 300, batch loss 0.0450, batch acc 0.9978
20:26:40.061   Training iter 350, batch loss 0.0396, batch acc 0.9986
20:26:40.363   Training iter 400, batch loss 0.0384, batch acc 0.9982
20:26:40.662   Training iter 450, batch loss 0.0412, batch acc 0.9984
20:26:41.003   Training iter 500, batch loss 0.0697, batch acc 0.9964
20:26:41.409   Training iter 550, batch loss 0.0898, batch acc 0.9950
20:26:41.855   Training iter 600, batch loss 0.0473, batch acc 0.9986
20:26:41.857 Training @ 62 epoch...
20:26:42.157   Training iter 50, batch loss 0.0592, batch acc 0.9968
20:26:42.437   Training iter 100, batch loss 0.0482, batch acc 0.9978
20:26:42.722   Training iter 150, batch loss 0.0710, batch acc 0.9972
20:26:43.079   Training iter 200, batch loss 0.0724, batch acc 0.9962
20:26:43.421   Training iter 250, batch loss 0.0738, batch acc 0.9962
20:26:43.796   Training iter 300, batch loss 0.0368, batch acc 0.9982
20:26:44.214   Training iter 350, batch loss 0.0700, batch acc 0.9964
20:26:44.960   Training iter 400, batch loss 0.0847, batch acc 0.9956
20:26:45.576   Training iter 450, batch loss 0.0935, batch acc 0.9946
20:26:45.900   Training iter 500, batch loss 0.0525, batch acc 0.9970
20:26:46.223   Training iter 550, batch loss 0.0662, batch acc 0.9972
20:26:46.521   Training iter 600, batch loss 0.0665, batch acc 0.9972
20:26:46.522 Training @ 63 epoch...
20:26:46.789   Training iter 50, batch loss 0.0475, batch acc 0.9984
20:26:47.096   Training iter 100, batch loss 0.0668, batch acc 0.9960
20:26:47.478   Training iter 150, batch loss 0.0641, batch acc 0.9970
20:26:47.826   Training iter 200, batch loss 0.0485, batch acc 0.9978
20:26:48.133   Training iter 250, batch loss 0.0491, batch acc 0.9974
20:26:48.393   Training iter 300, batch loss 0.0663, batch acc 0.9960
20:26:48.672   Training iter 350, batch loss 0.0447, batch acc 0.9980
20:26:48.958   Training iter 400, batch loss 0.0748, batch acc 0.9960
20:26:49.229   Training iter 450, batch loss 0.0743, batch acc 0.9960
20:26:50.115   Training iter 500, batch loss 0.0765, batch acc 0.9956
20:26:50.556   Training iter 550, batch loss 0.0990, batch acc 0.9940
20:26:51.152   Training iter 600, batch loss 0.0968, batch acc 0.9952
20:26:51.152 Training @ 64 epoch...
20:26:51.750   Training iter 50, batch loss 0.0680, batch acc 0.9952
20:26:52.520   Training iter 100, batch loss 0.0383, batch acc 0.9984
20:26:52.960   Training iter 150, batch loss 0.0666, batch acc 0.9960
20:26:53.300   Training iter 200, batch loss 0.0597, batch acc 0.9968
20:26:53.624   Training iter 250, batch loss 0.0478, batch acc 0.9972
20:26:53.976   Training iter 300, batch loss 0.0416, batch acc 0.9982
20:26:54.269   Training iter 350, batch loss 0.0507, batch acc 0.9980
20:26:54.531   Training iter 400, batch loss 0.0517, batch acc 0.9980
20:26:54.796   Training iter 450, batch loss 0.0428, batch acc 0.9974
20:26:55.091   Training iter 500, batch loss 0.0415, batch acc 0.9978
20:26:55.354   Training iter 550, batch loss 0.0598, batch acc 0.9968
20:26:55.614   Training iter 600, batch loss 0.0509, batch acc 0.9978
20:26:55.615 Training @ 65 epoch...
20:26:55.912   Training iter 50, batch loss 0.0428, batch acc 0.9984
20:26:56.257   Training iter 100, batch loss 0.0357, batch acc 0.9986
20:26:56.630   Training iter 150, batch loss 0.0633, batch acc 0.9960
20:26:57.248   Training iter 200, batch loss 0.0434, batch acc 0.9974
20:26:57.510   Training iter 250, batch loss 0.0351, batch acc 0.9986
20:26:57.935   Training iter 300, batch loss 0.0568, batch acc 0.9962
20:26:58.449   Training iter 350, batch loss 0.0539, batch acc 0.9972
20:26:58.902   Training iter 400, batch loss 0.0562, batch acc 0.9962
20:26:59.296   Training iter 450, batch loss 0.0508, batch acc 0.9974
20:26:59.761   Training iter 500, batch loss 0.0831, batch acc 0.9958
20:27:00.175   Training iter 550, batch loss 0.0770, batch acc 0.9958
20:27:00.589   Training iter 600, batch loss 0.0824, batch acc 0.9950
20:27:00.591 Testing @ 65 epoch...
20:27:00.867     Testing, total mean loss 0.34965, total acc 0.98130
20:27:00.867 Training @ 66 epoch...
20:27:01.225   Training iter 50, batch loss 0.0687, batch acc 0.9964
20:27:01.805   Training iter 100, batch loss 0.0820, batch acc 0.9942
20:27:02.408   Training iter 150, batch loss 0.0595, batch acc 0.9982
20:27:02.928   Training iter 200, batch loss 0.0640, batch acc 0.9970
20:27:03.426   Training iter 250, batch loss 0.0477, batch acc 0.9974
20:27:03.773   Training iter 300, batch loss 0.0385, batch acc 0.9980
20:27:04.294   Training iter 350, batch loss 0.0498, batch acc 0.9978
20:27:04.619   Training iter 400, batch loss 0.0505, batch acc 0.9974
20:27:05.041   Training iter 450, batch loss 0.0543, batch acc 0.9972
20:27:05.437   Training iter 500, batch loss 0.0663, batch acc 0.9954
20:27:05.743   Training iter 550, batch loss 0.0781, batch acc 0.9956
20:27:06.313   Training iter 600, batch loss 0.0530, batch acc 0.9972
20:27:06.314 Training @ 67 epoch...
20:27:06.755   Training iter 50, batch loss 0.0470, batch acc 0.9974
20:27:07.098   Training iter 100, batch loss 0.0494, batch acc 0.9978
20:27:07.544   Training iter 150, batch loss 0.0462, batch acc 0.9972
20:27:07.993   Training iter 200, batch loss 0.0510, batch acc 0.9982
20:27:08.360   Training iter 250, batch loss 0.0412, batch acc 0.9986
20:27:08.706   Training iter 300, batch loss 0.0411, batch acc 0.9976
20:27:09.087   Training iter 350, batch loss 0.0403, batch acc 0.9982
20:27:09.465   Training iter 400, batch loss 0.0433, batch acc 0.9976
20:27:09.823   Training iter 450, batch loss 0.0368, batch acc 0.9984
20:27:10.342   Training iter 500, batch loss 0.0357, batch acc 0.9984
20:27:10.745   Training iter 550, batch loss 0.0495, batch acc 0.9976
20:27:11.222   Training iter 600, batch loss 0.0462, batch acc 0.9984
20:27:11.223 Training @ 68 epoch...
20:27:11.536   Training iter 50, batch loss 0.0372, batch acc 0.9984
20:27:11.825   Training iter 100, batch loss 0.0511, batch acc 0.9982
20:27:12.317   Training iter 150, batch loss 0.0544, batch acc 0.9970
20:27:12.926   Training iter 200, batch loss 0.0362, batch acc 0.9988
20:27:13.343   Training iter 250, batch loss 0.0459, batch acc 0.9970
20:27:13.709   Training iter 300, batch loss 0.0532, batch acc 0.9978
20:27:14.041   Training iter 350, batch loss 0.0571, batch acc 0.9970
20:27:14.378   Training iter 400, batch loss 0.0710, batch acc 0.9960
20:27:14.674   Training iter 450, batch loss 0.0673, batch acc 0.9970
20:27:14.955   Training iter 500, batch loss 0.0659, batch acc 0.9962
20:27:15.231   Training iter 550, batch loss 0.0507, batch acc 0.9974
20:27:15.530   Training iter 600, batch loss 0.0511, batch acc 0.9976
20:27:15.530 Training @ 69 epoch...
20:27:16.115   Training iter 50, batch loss 0.0650, batch acc 0.9964
20:27:16.613   Training iter 100, batch loss 0.0451, batch acc 0.9984
20:27:16.982   Training iter 150, batch loss 0.0539, batch acc 0.9976
20:27:17.439   Training iter 200, batch loss 0.0373, batch acc 0.9984
20:27:17.732   Training iter 250, batch loss 0.0368, batch acc 0.9976
20:27:18.062   Training iter 300, batch loss 0.0414, batch acc 0.9978
20:27:18.388   Training iter 350, batch loss 0.0514, batch acc 0.9980
20:27:18.760   Training iter 400, batch loss 0.0487, batch acc 0.9976
20:27:19.091   Training iter 450, batch loss 0.0453, batch acc 0.9982
20:27:19.504   Training iter 500, batch loss 0.0491, batch acc 0.9980
20:27:20.011   Training iter 550, batch loss 0.0712, batch acc 0.9964
20:27:20.310   Training iter 600, batch loss 0.0471, batch acc 0.9982
20:27:20.311 Training @ 70 epoch...
20:27:20.590   Training iter 50, batch loss 0.0427, batch acc 0.9984
20:27:20.868   Training iter 100, batch loss 0.0372, batch acc 0.9984
20:27:21.174   Training iter 150, batch loss 0.0442, batch acc 0.9976
20:27:21.595   Training iter 200, batch loss 0.0446, batch acc 0.9978
20:27:21.846   Training iter 250, batch loss 0.0453, batch acc 0.9976
20:27:22.678   Training iter 300, batch loss 0.0554, batch acc 0.9962
20:27:23.136   Training iter 350, batch loss 0.0509, batch acc 0.9974
20:27:23.542   Training iter 400, batch loss 0.0534, batch acc 0.9980
20:27:23.897   Training iter 450, batch loss 0.0652, batch acc 0.9966
20:27:24.211   Training iter 500, batch loss 0.0528, batch acc 0.9966
20:27:24.483   Training iter 550, batch loss 0.0571, batch acc 0.9964
20:27:24.772   Training iter 600, batch loss 0.0655, batch acc 0.9964
20:27:24.774 Testing @ 70 epoch...
20:27:25.157     Testing, total mean loss 0.36781, total acc 0.98240
20:27:25.157 Training @ 71 epoch...
20:27:25.557   Training iter 50, batch loss 0.0666, batch acc 0.9956
20:27:25.967   Training iter 100, batch loss 0.0497, batch acc 0.9978
20:27:26.242   Training iter 150, batch loss 0.0511, batch acc 0.9974
20:27:26.645   Training iter 200, batch loss 0.0484, batch acc 0.9982
20:27:27.170   Training iter 250, batch loss 0.0491, batch acc 0.9970
20:27:27.564   Training iter 300, batch loss 0.0279, batch acc 0.9992
20:27:27.907   Training iter 350, batch loss 0.0429, batch acc 0.9974
20:27:28.372   Training iter 400, batch loss 0.0369, batch acc 0.9982
20:27:28.845   Training iter 450, batch loss 0.0297, batch acc 0.9990
20:27:29.289   Training iter 500, batch loss 0.0512, batch acc 0.9968
20:27:29.955   Training iter 550, batch loss 0.0449, batch acc 0.9980
20:27:30.229   Training iter 600, batch loss 0.0517, batch acc 0.9978
20:27:30.231 Training @ 72 epoch...
20:27:30.717   Training iter 50, batch loss 0.0503, batch acc 0.9974
20:27:31.110   Training iter 100, batch loss 0.0343, batch acc 0.9982
20:27:31.479   Training iter 150, batch loss 0.0556, batch acc 0.9972
20:27:31.806   Training iter 200, batch loss 0.0617, batch acc 0.9962
20:27:32.281   Training iter 250, batch loss 0.0364, batch acc 0.9980
20:27:33.115   Training iter 300, batch loss 0.0405, batch acc 0.9988
20:27:33.460   Training iter 350, batch loss 0.0417, batch acc 0.9978
20:27:33.919   Training iter 400, batch loss 0.0469, batch acc 0.9968
20:27:34.378   Training iter 450, batch loss 0.0433, batch acc 0.9984
20:27:34.813   Training iter 500, batch loss 0.0481, batch acc 0.9976
20:27:35.296   Training iter 550, batch loss 0.0632, batch acc 0.9972
20:27:35.693   Training iter 600, batch loss 0.0501, batch acc 0.9974
20:27:35.695 Training @ 73 epoch...
20:27:36.033   Training iter 50, batch loss 0.0410, batch acc 0.9976
20:27:36.438   Training iter 100, batch loss 0.0511, batch acc 0.9978
20:27:36.812   Training iter 150, batch loss 0.0506, batch acc 0.9976
20:27:37.166   Training iter 200, batch loss 0.0549, batch acc 0.9960
20:27:37.530   Training iter 250, batch loss 0.0545, batch acc 0.9976
20:27:37.855   Training iter 300, batch loss 0.0507, batch acc 0.9968
20:27:38.126   Training iter 350, batch loss 0.0325, batch acc 0.9988
20:27:38.386   Training iter 400, batch loss 0.0390, batch acc 0.9986
20:27:38.667   Training iter 450, batch loss 0.0328, batch acc 0.9990
20:27:38.930   Training iter 500, batch loss 0.0622, batch acc 0.9964
20:27:39.229   Training iter 550, batch loss 0.0717, batch acc 0.9962
20:27:39.502   Training iter 600, batch loss 0.0514, batch acc 0.9980
20:27:39.504 Training @ 74 epoch...
20:27:39.805   Training iter 50, batch loss 0.0380, batch acc 0.9980
20:27:40.128   Training iter 100, batch loss 0.0645, batch acc 0.9958
20:27:40.416   Training iter 150, batch loss 0.0662, batch acc 0.9960
20:27:40.662   Training iter 200, batch loss 0.0553, batch acc 0.9968
20:27:41.043   Training iter 250, batch loss 0.0487, batch acc 0.9972
20:27:41.354   Training iter 300, batch loss 0.0558, batch acc 0.9976
20:27:41.707   Training iter 350, batch loss 0.0563, batch acc 0.9964
20:27:42.057   Training iter 400, batch loss 0.0698, batch acc 0.9970
20:27:42.429   Training iter 450, batch loss 0.0587, batch acc 0.9972
20:27:42.723   Training iter 500, batch loss 0.0642, batch acc 0.9970
20:27:43.116   Training iter 550, batch loss 0.0608, batch acc 0.9972
20:27:43.423   Training iter 600, batch loss 0.0584, batch acc 0.9968
20:27:43.424 Training @ 75 epoch...
20:27:43.707   Training iter 50, batch loss 0.0607, batch acc 0.9972
20:27:44.005   Training iter 100, batch loss 0.0500, batch acc 0.9980
20:27:44.360   Training iter 150, batch loss 0.0582, batch acc 0.9970
20:27:44.675   Training iter 200, batch loss 0.0468, batch acc 0.9982
20:27:45.476   Training iter 250, batch loss 0.0609, batch acc 0.9970
20:27:46.247   Training iter 300, batch loss 0.0679, batch acc 0.9968
20:27:46.793   Training iter 350, batch loss 0.0681, batch acc 0.9966
20:27:47.472   Training iter 400, batch loss 0.0481, batch acc 0.9974
20:27:47.862   Training iter 450, batch loss 0.0579, batch acc 0.9980
20:27:48.280   Training iter 500, batch loss 0.0571, batch acc 0.9970
20:27:48.673   Training iter 550, batch loss 0.0560, batch acc 0.9982
20:27:49.124   Training iter 600, batch loss 0.0864, batch acc 0.9942
20:27:49.125 Testing @ 75 epoch...
20:27:49.368     Testing, total mean loss 0.37738, total acc 0.98050
20:27:49.369 Training @ 76 epoch...
20:27:49.643   Training iter 50, batch loss 0.0629, batch acc 0.9962
20:27:49.927   Training iter 100, batch loss 0.0581, batch acc 0.9978
20:27:50.208   Training iter 150, batch loss 0.0479, batch acc 0.9978
20:27:50.519   Training iter 200, batch loss 0.0259, batch acc 0.9994
20:27:50.899   Training iter 250, batch loss 0.0355, batch acc 0.9990
20:27:51.200   Training iter 300, batch loss 0.0465, batch acc 0.9988
20:27:51.620   Training iter 350, batch loss 0.0502, batch acc 0.9974
20:27:52.026   Training iter 400, batch loss 0.0459, batch acc 0.9972
20:27:52.383   Training iter 450, batch loss 0.0477, batch acc 0.9976
20:27:52.731   Training iter 500, batch loss 0.0410, batch acc 0.9984
20:27:53.058   Training iter 550, batch loss 0.0702, batch acc 0.9958
20:27:53.337   Training iter 600, batch loss 0.0633, batch acc 0.9960
20:27:53.337 Training @ 77 epoch...
20:27:53.606   Training iter 50, batch loss 0.0686, batch acc 0.9950
20:27:53.903   Training iter 100, batch loss 0.0462, batch acc 0.9982
20:27:54.235   Training iter 150, batch loss 0.0492, batch acc 0.9964
20:27:54.532   Training iter 200, batch loss 0.0486, batch acc 0.9966
20:27:54.850   Training iter 250, batch loss 0.0469, batch acc 0.9980
20:27:55.193   Training iter 300, batch loss 0.0554, batch acc 0.9972
20:27:55.464   Training iter 350, batch loss 0.0479, batch acc 0.9976
20:27:55.726   Training iter 400, batch loss 0.0470, batch acc 0.9986
20:27:56.008   Training iter 450, batch loss 0.0613, batch acc 0.9970
20:27:56.278   Training iter 500, batch loss 0.0447, batch acc 0.9978
20:27:56.510   Training iter 550, batch loss 0.0412, batch acc 0.9986
20:27:56.814   Training iter 600, batch loss 0.0718, batch acc 0.9966
20:27:56.817 Training @ 78 epoch...
20:27:57.280   Training iter 50, batch loss 0.0510, batch acc 0.9978
20:27:57.681   Training iter 100, batch loss 0.0339, batch acc 0.9990
20:27:58.143   Training iter 150, batch loss 0.0482, batch acc 0.9982
20:27:58.454   Training iter 200, batch loss 0.0602, batch acc 0.9968
20:27:58.742   Training iter 250, batch loss 0.0458, batch acc 0.9980
20:27:59.022   Training iter 300, batch loss 0.0834, batch acc 0.9960
20:27:59.330   Training iter 350, batch loss 0.0524, batch acc 0.9974
20:27:59.659   Training iter 400, batch loss 0.0597, batch acc 0.9978
20:27:59.984   Training iter 450, batch loss 0.0546, batch acc 0.9972
20:28:00.358   Training iter 500, batch loss 0.0552, batch acc 0.9974
20:28:00.692   Training iter 550, batch loss 0.0622, batch acc 0.9972
20:28:01.081   Training iter 600, batch loss 0.0826, batch acc 0.9956
20:28:01.082 Training @ 79 epoch...
20:28:01.339   Training iter 50, batch loss 0.0830, batch acc 0.9952
20:28:01.610   Training iter 100, batch loss 0.0685, batch acc 0.9964
20:28:01.881   Training iter 150, batch loss 0.0518, batch acc 0.9972
20:28:02.165   Training iter 200, batch loss 0.0594, batch acc 0.9974
20:28:02.427   Training iter 250, batch loss 0.0596, batch acc 0.9978
20:28:02.696   Training iter 300, batch loss 0.0473, batch acc 0.9970
20:28:03.035   Training iter 350, batch loss 0.0469, batch acc 0.9978
20:28:03.363   Training iter 400, batch loss 0.0416, batch acc 0.9976
20:28:03.720   Training iter 450, batch loss 0.0553, batch acc 0.9970
20:28:04.107   Training iter 500, batch loss 0.0462, batch acc 0.9972
20:28:04.494   Training iter 550, batch loss 0.0498, batch acc 0.9970
20:28:04.782   Training iter 600, batch loss 0.0377, batch acc 0.9986
20:28:04.782 Training @ 80 epoch...
20:28:05.111   Training iter 50, batch loss 0.0328, batch acc 0.9990
20:28:05.446   Training iter 100, batch loss 0.0814, batch acc 0.9958
20:28:05.834   Training iter 150, batch loss 0.0483, batch acc 0.9988
20:28:07.146   Training iter 200, batch loss 0.0439, batch acc 0.9974
20:28:07.626   Training iter 250, batch loss 0.0346, batch acc 0.9984
20:28:08.123   Training iter 300, batch loss 0.0519, batch acc 0.9976
20:28:08.513   Training iter 350, batch loss 0.0351, batch acc 0.9994
20:28:08.856   Training iter 400, batch loss 0.0387, batch acc 0.9982
20:28:09.149   Training iter 450, batch loss 0.0562, batch acc 0.9974
20:28:09.472   Training iter 500, batch loss 0.0690, batch acc 0.9966
20:28:09.848   Training iter 550, batch loss 0.0842, batch acc 0.9954
20:28:10.235   Training iter 600, batch loss 0.0512, batch acc 0.9980
20:28:10.236 Testing @ 80 epoch...
20:28:10.474     Testing, total mean loss 0.39239, total acc 0.97920
20:28:10.474 Training @ 81 epoch...
20:28:10.807   Training iter 50, batch loss 0.0386, batch acc 0.9990
20:28:11.065   Training iter 100, batch loss 0.0524, batch acc 0.9970
20:28:11.402   Training iter 150, batch loss 0.0365, batch acc 0.9978
20:28:11.704   Training iter 200, batch loss 0.0368, batch acc 0.9988
20:28:12.052   Training iter 250, batch loss 0.0643, batch acc 0.9960
20:28:12.364   Training iter 300, batch loss 0.0583, batch acc 0.9968
20:28:12.701   Training iter 350, batch loss 0.0604, batch acc 0.9976
20:28:13.015   Training iter 400, batch loss 0.0642, batch acc 0.9974
20:28:13.306   Training iter 450, batch loss 0.0538, batch acc 0.9972
20:28:13.574   Training iter 500, batch loss 0.0696, batch acc 0.9964
20:28:13.840   Training iter 550, batch loss 0.0652, batch acc 0.9964
20:28:14.147   Training iter 600, batch loss 0.0588, batch acc 0.9974
20:28:14.148 Training @ 82 epoch...
20:28:14.403   Training iter 50, batch loss 0.0441, batch acc 0.9984
20:28:14.749   Training iter 100, batch loss 0.0311, batch acc 0.9986
20:28:15.098   Training iter 150, batch loss 0.0263, batch acc 0.9990
20:28:15.484   Training iter 200, batch loss 0.0618, batch acc 0.9972
20:28:15.851   Training iter 250, batch loss 0.0457, batch acc 0.9976
20:28:16.311   Training iter 300, batch loss 0.0749, batch acc 0.9960
20:28:16.816   Training iter 350, batch loss 0.0477, batch acc 0.9978
20:28:17.195   Training iter 400, batch loss 0.0351, batch acc 0.9988
20:28:17.668   Training iter 450, batch loss 0.0619, batch acc 0.9956
20:28:18.034   Training iter 500, batch loss 0.0640, batch acc 0.9974
20:28:18.449   Training iter 550, batch loss 0.0733, batch acc 0.9958
20:28:18.800   Training iter 600, batch loss 0.0689, batch acc 0.9956
20:28:18.802 Training @ 83 epoch...
20:28:19.195   Training iter 50, batch loss 0.0515, batch acc 0.9976
20:28:19.508   Training iter 100, batch loss 0.0669, batch acc 0.9950
20:28:19.942   Training iter 150, batch loss 0.0321, batch acc 0.9986
20:28:20.233   Training iter 200, batch loss 0.0524, batch acc 0.9988
20:28:20.536   Training iter 250, batch loss 0.0641, batch acc 0.9962
20:28:21.080   Training iter 300, batch loss 0.0580, batch acc 0.9972
20:28:23.067   Training iter 350, batch loss 0.0494, batch acc 0.9980
20:28:25.021   Training iter 400, batch loss 0.0555, batch acc 0.9978
20:28:25.683   Training iter 450, batch loss 0.0560, batch acc 0.9970
20:28:25.962   Training iter 500, batch loss 0.0613, batch acc 0.9978
20:28:26.271   Training iter 550, batch loss 0.0695, batch acc 0.9962
20:28:26.548   Training iter 600, batch loss 0.0641, batch acc 0.9966
20:28:26.549 Training @ 84 epoch...
20:28:26.835   Training iter 50, batch loss 0.0355, batch acc 0.9986
20:28:27.152   Training iter 100, batch loss 0.0441, batch acc 0.9974
20:28:27.487   Training iter 150, batch loss 0.0464, batch acc 0.9988
20:28:27.910   Training iter 200, batch loss 0.0464, batch acc 0.9980
20:28:28.207   Training iter 250, batch loss 0.0391, batch acc 0.9978
20:28:28.501   Training iter 300, batch loss 0.0375, batch acc 0.9982
20:28:28.806   Training iter 350, batch loss 0.0401, batch acc 0.9988
20:28:29.156   Training iter 400, batch loss 0.0709, batch acc 0.9964
20:28:29.488   Training iter 450, batch loss 0.0410, batch acc 0.9984
20:28:29.952   Training iter 500, batch loss 0.0454, batch acc 0.9976
20:28:30.304   Training iter 550, batch loss 0.0600, batch acc 0.9956
20:28:30.745   Training iter 600, batch loss 0.0470, batch acc 0.9980
20:28:30.747 Training @ 85 epoch...
20:28:31.133   Training iter 50, batch loss 0.0371, batch acc 0.9984
20:28:31.502   Training iter 100, batch loss 0.0450, batch acc 0.9976
20:28:31.855   Training iter 150, batch loss 0.0362, batch acc 0.9984
20:28:32.154   Training iter 200, batch loss 0.0494, batch acc 0.9982
20:28:32.502   Training iter 250, batch loss 0.0523, batch acc 0.9982
20:28:32.914   Training iter 300, batch loss 0.0698, batch acc 0.9966
20:28:33.246   Training iter 350, batch loss 0.0602, batch acc 0.9966
20:28:33.698   Training iter 400, batch loss 0.0583, batch acc 0.9962
20:28:34.063   Training iter 450, batch loss 0.0610, batch acc 0.9974
20:28:34.398   Training iter 500, batch loss 0.0380, batch acc 0.9996
20:28:34.776   Training iter 550, batch loss 0.0655, batch acc 0.9974
20:28:35.172   Training iter 600, batch loss 0.0622, batch acc 0.9970
20:28:35.172 Testing @ 85 epoch...
20:28:35.461     Testing, total mean loss 0.34907, total acc 0.98140
20:28:35.461 Training @ 86 epoch...
20:28:35.870   Training iter 50, batch loss 0.0433, batch acc 0.9978
20:28:36.356   Training iter 100, batch loss 0.0459, batch acc 0.9980
20:28:36.700   Training iter 150, batch loss 0.0390, batch acc 0.9984
20:28:37.096   Training iter 200, batch loss 0.0478, batch acc 0.9978
20:28:37.614   Training iter 250, batch loss 0.0359, batch acc 0.9984
20:28:37.996   Training iter 300, batch loss 0.0301, batch acc 0.9990
20:28:38.403   Training iter 350, batch loss 0.0472, batch acc 0.9976
20:28:38.801   Training iter 400, batch loss 0.0576, batch acc 0.9976
20:28:39.250   Training iter 450, batch loss 0.0435, batch acc 0.9994
20:28:39.621   Training iter 500, batch loss 0.0468, batch acc 0.9976
20:28:40.172   Training iter 550, batch loss 0.0422, batch acc 0.9986
20:28:40.614   Training iter 600, batch loss 0.0553, batch acc 0.9972
20:28:40.615 Training @ 87 epoch...
20:28:41.062   Training iter 50, batch loss 0.0382, batch acc 0.9972
20:28:41.499   Training iter 100, batch loss 0.0362, batch acc 0.9986
20:28:41.929   Training iter 150, batch loss 0.0406, batch acc 0.9982
20:28:42.399   Training iter 200, batch loss 0.0408, batch acc 0.9984
20:28:42.807   Training iter 250, batch loss 0.0530, batch acc 0.9980
20:28:43.140   Training iter 300, batch loss 0.0446, batch acc 0.9974
20:28:43.504   Training iter 350, batch loss 0.0406, batch acc 0.9986
20:28:43.845   Training iter 400, batch loss 0.0446, batch acc 0.9980
20:28:44.168   Training iter 450, batch loss 0.0363, batch acc 0.9982
20:28:44.508   Training iter 500, batch loss 0.0725, batch acc 0.9962
20:28:44.928   Training iter 550, batch loss 0.0442, batch acc 0.9984
20:28:45.337   Training iter 600, batch loss 0.0406, batch acc 0.9986
20:28:45.337 Training @ 88 epoch...
20:28:45.654   Training iter 50, batch loss 0.0453, batch acc 0.9974
20:28:46.016   Training iter 100, batch loss 0.0247, batch acc 0.9990
20:28:46.310   Training iter 150, batch loss 0.0365, batch acc 0.9988
20:28:46.621   Training iter 200, batch loss 0.0602, batch acc 0.9968
20:28:47.126   Training iter 250, batch loss 0.1092, batch acc 0.9942
20:28:47.438   Training iter 300, batch loss 0.0909, batch acc 0.9944
20:28:47.777   Training iter 350, batch loss 0.0407, batch acc 0.9980
20:28:48.185   Training iter 400, batch loss 0.0471, batch acc 0.9976
20:28:48.507   Training iter 450, batch loss 0.0459, batch acc 0.9970
20:28:48.882   Training iter 500, batch loss 0.0589, batch acc 0.9968
20:28:49.182   Training iter 550, batch loss 0.0704, batch acc 0.9966
20:28:49.507   Training iter 600, batch loss 0.0546, batch acc 0.9974
20:28:49.508 Training @ 89 epoch...
20:28:49.829   Training iter 50, batch loss 0.0415, batch acc 0.9990
20:28:50.118   Training iter 100, batch loss 0.0529, batch acc 0.9972
20:28:50.614   Training iter 150, batch loss 0.0444, batch acc 0.9978
20:28:50.996   Training iter 200, batch loss 0.0366, batch acc 0.9988
20:28:51.413   Training iter 250, batch loss 0.0625, batch acc 0.9958
20:28:51.721   Training iter 300, batch loss 0.0382, batch acc 0.9984
20:28:52.118   Training iter 350, batch loss 0.0562, batch acc 0.9972
20:28:52.416   Training iter 400, batch loss 0.0648, batch acc 0.9962
20:28:52.704   Training iter 450, batch loss 0.0522, batch acc 0.9972
20:28:52.980   Training iter 500, batch loss 0.0597, batch acc 0.9984
20:28:53.377   Training iter 550, batch loss 0.0943, batch acc 0.9950
20:28:53.787   Training iter 600, batch loss 0.0830, batch acc 0.9960
20:28:53.788 Training @ 90 epoch...
20:28:54.231   Training iter 50, batch loss 0.0539, batch acc 0.9974
20:28:54.671   Training iter 100, batch loss 0.0508, batch acc 0.9970
20:28:55.042   Training iter 150, batch loss 0.0369, batch acc 0.9982
20:28:55.373   Training iter 200, batch loss 0.0384, batch acc 0.9986
20:28:55.841   Training iter 250, batch loss 0.0484, batch acc 0.9972
20:28:56.297   Training iter 300, batch loss 0.0319, batch acc 0.9994
20:28:56.665   Training iter 350, batch loss 0.0634, batch acc 0.9976
20:28:57.016   Training iter 400, batch loss 0.0580, batch acc 0.9970
20:28:57.299   Training iter 450, batch loss 0.0748, batch acc 0.9964
20:28:57.611   Training iter 500, batch loss 0.0524, batch acc 0.9980
20:28:58.115   Training iter 550, batch loss 0.0562, batch acc 0.9974
20:28:58.397   Training iter 600, batch loss 0.0451, batch acc 0.9982
20:28:58.398 Testing @ 90 epoch...
20:28:58.602     Testing, total mean loss 0.33519, total acc 0.98250
20:28:58.602 Training @ 91 epoch...
20:28:58.871   Training iter 50, batch loss 0.0560, batch acc 0.9972
20:28:59.435   Training iter 100, batch loss 0.0568, batch acc 0.9966
20:28:59.964   Training iter 150, batch loss 0.0492, batch acc 0.9974
20:29:00.317   Training iter 200, batch loss 0.0432, batch acc 0.9982
20:29:00.611   Training iter 250, batch loss 0.0378, batch acc 0.9982
20:29:00.918   Training iter 300, batch loss 0.0400, batch acc 0.9984
20:29:01.209   Training iter 350, batch loss 0.0401, batch acc 0.9980
20:29:01.527   Training iter 400, batch loss 0.0377, batch acc 0.9986
20:29:01.848   Training iter 450, batch loss 0.0582, batch acc 0.9966
20:29:02.244   Training iter 500, batch loss 0.0582, batch acc 0.9972
20:29:02.641   Training iter 550, batch loss 0.0492, batch acc 0.9978
20:29:02.945   Training iter 600, batch loss 0.0417, batch acc 0.9982
20:29:02.946 Training @ 92 epoch...
20:29:03.245   Training iter 50, batch loss 0.0578, batch acc 0.9976
20:29:03.552   Training iter 100, batch loss 0.0424, batch acc 0.9984
20:29:03.808   Training iter 150, batch loss 0.0512, batch acc 0.9976
20:29:04.104   Training iter 200, batch loss 0.0285, batch acc 0.9990
20:29:04.390   Training iter 250, batch loss 0.0351, batch acc 0.9988
20:29:04.729   Training iter 300, batch loss 0.0522, batch acc 0.9964
20:29:05.128   Training iter 350, batch loss 0.0530, batch acc 0.9976
20:29:05.525   Training iter 400, batch loss 0.0584, batch acc 0.9976
20:29:05.832   Training iter 450, batch loss 0.0551, batch acc 0.9970
20:29:06.130   Training iter 500, batch loss 0.0638, batch acc 0.9958
20:29:06.430   Training iter 550, batch loss 0.0655, batch acc 0.9962
20:29:06.754   Training iter 600, batch loss 0.0540, batch acc 0.9968
20:29:06.755 Training @ 93 epoch...
20:29:07.959   Training iter 50, batch loss 0.0415, batch acc 0.9976
20:29:08.486   Training iter 100, batch loss 0.0415, batch acc 0.9984
20:29:08.803   Training iter 150, batch loss 0.0383, batch acc 0.9980
20:29:09.139   Training iter 200, batch loss 0.0498, batch acc 0.9990
20:29:09.468   Training iter 250, batch loss 0.0527, batch acc 0.9976
20:29:09.774   Training iter 300, batch loss 0.0343, batch acc 0.9978
20:29:10.108   Training iter 350, batch loss 0.0672, batch acc 0.9968
20:29:10.403   Training iter 400, batch loss 0.0494, batch acc 0.9978
20:29:10.723   Training iter 450, batch loss 0.0443, batch acc 0.9984
20:29:11.046   Training iter 500, batch loss 0.0352, batch acc 0.9984
20:29:11.461   Training iter 550, batch loss 0.0447, batch acc 0.9970
20:29:11.760   Training iter 600, batch loss 0.0618, batch acc 0.9962
20:29:11.761 Training @ 94 epoch...
20:29:12.222   Training iter 50, batch loss 0.0305, batch acc 0.9986
20:29:13.033   Training iter 100, batch loss 0.0465, batch acc 0.9980
20:29:13.385   Training iter 150, batch loss 0.0369, batch acc 0.9986
20:29:13.785   Training iter 200, batch loss 0.0794, batch acc 0.9952
20:29:14.163   Training iter 250, batch loss 0.0363, batch acc 0.9978
20:29:14.539   Training iter 300, batch loss 0.0555, batch acc 0.9966
20:29:14.849   Training iter 350, batch loss 0.0437, batch acc 0.9988
20:29:15.148   Training iter 400, batch loss 0.0573, batch acc 0.9966
20:29:15.443   Training iter 450, batch loss 0.0506, batch acc 0.9970
20:29:15.731   Training iter 500, batch loss 0.0392, batch acc 0.9978
20:29:16.049   Training iter 550, batch loss 0.0768, batch acc 0.9966
20:29:16.347   Training iter 600, batch loss 0.0706, batch acc 0.9970
20:29:16.349 Training @ 95 epoch...
20:29:16.662   Training iter 50, batch loss 0.0388, batch acc 0.9990
20:29:17.000   Training iter 100, batch loss 0.0531, batch acc 0.9970
20:29:17.325   Training iter 150, batch loss 0.0367, batch acc 0.9990
20:29:17.584   Training iter 200, batch loss 0.0434, batch acc 0.9984
20:29:17.847   Training iter 250, batch loss 0.0548, batch acc 0.9966
20:29:18.108   Training iter 300, batch loss 0.0751, batch acc 0.9956
20:29:18.373   Training iter 350, batch loss 0.0736, batch acc 0.9964
20:29:18.881   Training iter 400, batch loss 0.0470, batch acc 0.9978
20:29:19.367   Training iter 450, batch loss 0.0522, batch acc 0.9980
20:29:19.777   Training iter 500, batch loss 0.0383, batch acc 0.9982
20:29:20.143   Training iter 550, batch loss 0.0607, batch acc 0.9972
20:29:20.572   Training iter 600, batch loss 0.0514, batch acc 0.9976
20:29:20.574 Testing @ 95 epoch...
20:29:20.955     Testing, total mean loss 0.30337, total acc 0.98270
20:29:20.955 Training @ 96 epoch...
20:29:21.340   Training iter 50, batch loss 0.0370, batch acc 0.9982
20:29:21.692   Training iter 100, batch loss 0.0516, batch acc 0.9962
20:29:22.034   Training iter 150, batch loss 0.0412, batch acc 0.9984
20:29:22.334   Training iter 200, batch loss 0.0338, batch acc 0.9990
20:29:22.664   Training iter 250, batch loss 0.0505, batch acc 0.9970
20:29:23.015   Training iter 300, batch loss 0.0514, batch acc 0.9978
20:29:23.501   Training iter 350, batch loss 0.0623, batch acc 0.9962
20:29:23.917   Training iter 400, batch loss 0.0688, batch acc 0.9966
20:29:24.227   Training iter 450, batch loss 0.0443, batch acc 0.9978
20:29:24.610   Training iter 500, batch loss 0.0740, batch acc 0.9956
20:29:24.917   Training iter 550, batch loss 0.0871, batch acc 0.9946
20:29:25.210   Training iter 600, batch loss 0.0535, batch acc 0.9984
20:29:25.212 Training @ 97 epoch...
20:29:25.519   Training iter 50, batch loss 0.0368, batch acc 0.9978
20:29:25.966   Training iter 100, batch loss 0.0368, batch acc 0.9982
20:29:26.271   Training iter 150, batch loss 0.0462, batch acc 0.9982
20:29:26.626   Training iter 200, batch loss 0.0300, batch acc 0.9986
20:29:26.928   Training iter 250, batch loss 0.0363, batch acc 0.9984
20:29:27.739   Training iter 300, batch loss 0.0565, batch acc 0.9970
20:29:28.143   Training iter 350, batch loss 0.0468, batch acc 0.9984
20:29:28.437   Training iter 400, batch loss 0.0443, batch acc 0.9966
20:29:28.799   Training iter 450, batch loss 0.0622, batch acc 0.9970
20:29:29.083   Training iter 500, batch loss 0.0667, batch acc 0.9952
20:29:29.376   Training iter 550, batch loss 0.0298, batch acc 0.9996
20:29:29.641   Training iter 600, batch loss 0.0621, batch acc 0.9960
20:29:29.641 Training @ 98 epoch...
20:29:29.960   Training iter 50, batch loss 0.0483, batch acc 0.9978
20:29:30.234   Training iter 100, batch loss 0.0397, batch acc 0.9982
20:29:30.476   Training iter 150, batch loss 0.0358, batch acc 0.9988
20:29:30.728   Training iter 200, batch loss 0.0360, batch acc 0.9982
20:29:31.240   Training iter 250, batch loss 0.0278, batch acc 0.9988
20:29:31.661   Training iter 300, batch loss 0.0403, batch acc 0.9980
20:29:32.041   Training iter 350, batch loss 0.0374, batch acc 0.9986
20:29:32.331   Training iter 400, batch loss 0.0451, batch acc 0.9980
20:29:32.630   Training iter 450, batch loss 0.0517, batch acc 0.9986
20:29:33.043   Training iter 500, batch loss 0.0395, batch acc 0.9986
20:29:33.365   Training iter 550, batch loss 0.0495, batch acc 0.9980
20:29:33.664   Training iter 600, batch loss 0.0687, batch acc 0.9966
20:29:33.666 Training @ 99 epoch...
20:29:34.124   Training iter 50, batch loss 0.0444, batch acc 0.9982
20:29:34.515   Training iter 100, batch loss 0.0311, batch acc 0.9992
20:29:34.862   Training iter 150, batch loss 0.0316, batch acc 0.9986
20:29:35.177   Training iter 200, batch loss 0.0364, batch acc 0.9988
20:29:35.540   Training iter 250, batch loss 0.0420, batch acc 0.9980
20:29:35.842   Training iter 300, batch loss 0.0432, batch acc 0.9980
20:29:36.523   Training iter 350, batch loss 0.0312, batch acc 0.9984
20:29:36.933   Training iter 400, batch loss 0.0705, batch acc 0.9954
20:29:37.535   Training iter 450, batch loss 0.0682, batch acc 0.9966
20:29:37.924   Training iter 500, batch loss 0.0508, batch acc 0.9974
20:29:38.183   Training iter 550, batch loss 0.0443, batch acc 0.9982
20:29:38.461   Training iter 600, batch loss 0.0731, batch acc 0.9956
20:29:38.462 Testing @ 99 epoch...
20:29:38.656     Testing, total mean loss 0.33005, total acc 0.98170