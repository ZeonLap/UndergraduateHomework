20:05:34.579 Training @ 0 epoch...
20:05:35.111   Training iter 50, batch loss 0.9145, batch acc 0.1126
20:05:35.457   Training iter 100, batch loss 0.8998, batch acc 0.1016
20:05:36.023   Training iter 150, batch loss 0.8991, batch acc 0.1202
20:05:36.379   Training iter 200, batch loss 0.8978, batch acc 0.1220
20:05:36.749   Training iter 250, batch loss 0.8933, batch acc 0.2506
20:05:37.233   Training iter 300, batch loss 0.8793, batch acc 0.2582
20:05:37.685   Training iter 350, batch loss 0.8074, batch acc 0.3300
20:05:38.437   Training iter 400, batch loss 0.7207, batch acc 0.3970
20:05:39.136   Training iter 450, batch loss 0.6413, batch acc 0.5334
20:05:39.743   Training iter 500, batch loss 0.5741, batch acc 0.6190
20:05:40.184   Training iter 550, batch loss 0.5153, batch acc 0.7218
20:05:40.681   Training iter 600, batch loss 0.4506, batch acc 0.7742
20:05:40.691 Testing @ 0 epoch...
20:05:41.277     Testing, total mean loss 0.42406, total acc 0.76590
20:05:41.277 Training @ 1 epoch...
20:05:41.977   Training iter 50, batch loss 0.4153, batch acc 0.7880
20:05:42.483   Training iter 100, batch loss 0.3821, batch acc 0.8122
20:05:42.980   Training iter 150, batch loss 0.3568, batch acc 0.8338
20:05:43.633   Training iter 200, batch loss 0.3401, batch acc 0.8602
20:05:44.130   Training iter 250, batch loss 0.3117, batch acc 0.8742
20:05:44.526   Training iter 300, batch loss 0.2893, batch acc 0.8768
20:05:45.120   Training iter 350, batch loss 0.2808, batch acc 0.8854
20:05:45.550   Training iter 400, batch loss 0.2605, batch acc 0.8904
20:05:45.905   Training iter 450, batch loss 0.2442, batch acc 0.9010
20:05:46.216   Training iter 500, batch loss 0.2491, batch acc 0.8912
20:05:46.490   Training iter 550, batch loss 0.2345, batch acc 0.9010
20:05:46.831   Training iter 600, batch loss 0.2293, batch acc 0.9012
20:05:46.831 Training @ 2 epoch...
20:05:47.139   Training iter 50, batch loss 0.2219, batch acc 0.9018
20:05:47.478   Training iter 100, batch loss 0.2264, batch acc 0.8952
20:05:47.850   Training iter 150, batch loss 0.2097, batch acc 0.9100
20:05:48.206   Training iter 200, batch loss 0.2092, batch acc 0.9056
20:05:48.551   Training iter 250, batch loss 0.2026, batch acc 0.9118
20:05:49.023   Training iter 300, batch loss 0.2045, batch acc 0.9126
20:05:49.363   Training iter 350, batch loss 0.2051, batch acc 0.9052
20:05:49.622   Training iter 400, batch loss 0.2038, batch acc 0.9042
20:05:49.898   Training iter 450, batch loss 0.1857, batch acc 0.9172
20:05:50.249   Training iter 500, batch loss 0.1987, batch acc 0.9082
20:05:50.522   Training iter 550, batch loss 0.1838, batch acc 0.9178
20:05:50.830   Training iter 600, batch loss 0.1884, batch acc 0.9112
20:05:50.831 Training @ 3 epoch...
20:05:51.147   Training iter 50, batch loss 0.1893, batch acc 0.9154
20:05:51.508   Training iter 100, batch loss 0.1753, batch acc 0.9212
20:05:51.986   Training iter 150, batch loss 0.1767, batch acc 0.9182
20:05:52.477   Training iter 200, batch loss 0.1741, batch acc 0.9210
20:05:53.039   Training iter 250, batch loss 0.1802, batch acc 0.9142
20:05:53.476   Training iter 300, batch loss 0.1725, batch acc 0.9242
20:05:53.937   Training iter 350, batch loss 0.1619, batch acc 0.9266
20:05:54.439   Training iter 400, batch loss 0.1713, batch acc 0.9228
20:05:54.943   Training iter 450, batch loss 0.1652, batch acc 0.9272
20:05:55.424   Training iter 500, batch loss 0.1629, batch acc 0.9268
20:05:55.716   Training iter 550, batch loss 0.1615, batch acc 0.9264
20:05:56.276   Training iter 600, batch loss 0.1564, batch acc 0.9312
20:05:56.279 Training @ 4 epoch...
20:05:56.866   Training iter 50, batch loss 0.1572, batch acc 0.9290
20:05:57.421   Training iter 100, batch loss 0.1540, batch acc 0.9340
20:05:57.664   Training iter 150, batch loss 0.1547, batch acc 0.9324
20:05:57.935   Training iter 200, batch loss 0.1547, batch acc 0.9276
20:05:58.177   Training iter 250, batch loss 0.1440, batch acc 0.9372
20:05:58.429   Training iter 300, batch loss 0.1471, batch acc 0.9358
20:05:58.648   Training iter 350, batch loss 0.1440, batch acc 0.9336
20:05:58.906   Training iter 400, batch loss 0.1436, batch acc 0.9322
20:05:59.154   Training iter 450, batch loss 0.1452, batch acc 0.9344
20:05:59.432   Training iter 500, batch loss 0.1462, batch acc 0.9342
20:05:59.756   Training iter 550, batch loss 0.1453, batch acc 0.9356
20:06:00.515   Training iter 600, batch loss 0.1379, batch acc 0.9426
20:06:00.515 Training @ 5 epoch...
20:06:00.796   Training iter 50, batch loss 0.1402, batch acc 0.9352
20:06:01.062   Training iter 100, batch loss 0.1324, batch acc 0.9422
20:06:01.323   Training iter 150, batch loss 0.1392, batch acc 0.9364
20:06:01.562   Training iter 200, batch loss 0.1351, batch acc 0.9378
20:06:01.819   Training iter 250, batch loss 0.1295, batch acc 0.9412
20:06:02.125   Training iter 300, batch loss 0.1242, batch acc 0.9490
20:06:02.454   Training iter 350, batch loss 0.1244, batch acc 0.9480
20:06:02.770   Training iter 400, batch loss 0.1308, batch acc 0.9426
20:06:03.032   Training iter 450, batch loss 0.1269, batch acc 0.9420
20:06:03.298   Training iter 500, batch loss 0.1337, batch acc 0.9402
20:06:03.541   Training iter 550, batch loss 0.1246, batch acc 0.9468
20:06:03.836   Training iter 600, batch loss 0.1251, batch acc 0.9442
20:06:03.838 Testing @ 5 epoch...
20:06:04.042     Testing, total mean loss 0.12011, total acc 0.94740
20:06:04.042 Training @ 6 epoch...
20:06:04.311   Training iter 50, batch loss 0.1202, batch acc 0.9494
20:06:04.565   Training iter 100, batch loss 0.1214, batch acc 0.9466
20:06:04.856   Training iter 150, batch loss 0.1270, batch acc 0.9428
20:06:05.174   Training iter 200, batch loss 0.1232, batch acc 0.9470
20:06:05.508   Training iter 250, batch loss 0.1184, batch acc 0.9478
20:06:05.762   Training iter 300, batch loss 0.1234, batch acc 0.9436
20:06:06.016   Training iter 350, batch loss 0.1177, batch acc 0.9456
20:06:06.298   Training iter 400, batch loss 0.1137, batch acc 0.9502
20:06:06.562   Training iter 450, batch loss 0.1094, batch acc 0.9522
20:06:06.837   Training iter 500, batch loss 0.1203, batch acc 0.9450
20:06:07.096   Training iter 550, batch loss 0.1095, batch acc 0.9510
20:06:07.357   Training iter 600, batch loss 0.1107, batch acc 0.9540
20:06:07.358 Training @ 7 epoch...
20:06:07.682   Training iter 50, batch loss 0.1063, batch acc 0.9556
20:06:08.056   Training iter 100, batch loss 0.1108, batch acc 0.9500
20:06:08.425   Training iter 150, batch loss 0.1045, batch acc 0.9600
20:06:08.735   Training iter 200, batch loss 0.1087, batch acc 0.9540
20:06:09.088   Training iter 250, batch loss 0.1128, batch acc 0.9508
20:06:09.363   Training iter 300, batch loss 0.1114, batch acc 0.9514
20:06:09.633   Training iter 350, batch loss 0.1065, batch acc 0.9518
20:06:09.900   Training iter 400, batch loss 0.1034, batch acc 0.9552
20:06:10.169   Training iter 450, batch loss 0.1012, batch acc 0.9552
20:06:10.501   Training iter 500, batch loss 0.1042, batch acc 0.9544
20:06:10.805   Training iter 550, batch loss 0.1049, batch acc 0.9552
20:06:11.152   Training iter 600, batch loss 0.1085, batch acc 0.9558
20:06:11.153 Training @ 8 epoch...
20:06:11.429   Training iter 50, batch loss 0.0977, batch acc 0.9578
20:06:11.718   Training iter 100, batch loss 0.1072, batch acc 0.9542
20:06:12.011   Training iter 150, batch loss 0.0960, batch acc 0.9640
20:06:12.280   Training iter 200, batch loss 0.0956, batch acc 0.9626
20:06:12.544   Training iter 250, batch loss 0.0983, batch acc 0.9582
20:06:12.800   Training iter 300, batch loss 0.1000, batch acc 0.9576
20:06:13.111   Training iter 350, batch loss 0.1037, batch acc 0.9566
20:06:13.398   Training iter 400, batch loss 0.0985, batch acc 0.9586
20:06:13.714   Training iter 450, batch loss 0.0999, batch acc 0.9542
20:06:14.049   Training iter 500, batch loss 0.1007, batch acc 0.9560
20:06:14.327   Training iter 550, batch loss 0.0966, batch acc 0.9576
20:06:14.584   Training iter 600, batch loss 0.0935, batch acc 0.9618
20:06:14.586 Training @ 9 epoch...
20:06:14.871   Training iter 50, batch loss 0.0952, batch acc 0.9590
20:06:15.133   Training iter 100, batch loss 0.0926, batch acc 0.9632
20:06:15.402   Training iter 150, batch loss 0.0934, batch acc 0.9596
20:06:15.670   Training iter 200, batch loss 0.0945, batch acc 0.9604
20:06:15.960   Training iter 250, batch loss 0.0955, batch acc 0.9588
20:06:16.303   Training iter 300, batch loss 0.0888, batch acc 0.9666
20:06:16.687   Training iter 350, batch loss 0.0939, batch acc 0.9604
20:06:17.103   Training iter 400, batch loss 0.0906, batch acc 0.9644
20:06:17.424   Training iter 450, batch loss 0.0980, batch acc 0.9566
20:06:17.694   Training iter 500, batch loss 0.0935, batch acc 0.9582
20:06:17.990   Training iter 550, batch loss 0.0894, batch acc 0.9614
20:06:18.270   Training iter 600, batch loss 0.0904, batch acc 0.9640
20:06:18.271 Training @ 10 epoch...
20:06:18.549   Training iter 50, batch loss 0.0914, batch acc 0.9640
20:06:18.939   Training iter 100, batch loss 0.0878, batch acc 0.9646
20:06:19.337   Training iter 150, batch loss 0.0907, batch acc 0.9628
20:06:19.741   Training iter 200, batch loss 0.0889, batch acc 0.9634
20:06:20.150   Training iter 250, batch loss 0.0890, batch acc 0.9614
20:06:20.422   Training iter 300, batch loss 0.0835, batch acc 0.9684
20:06:20.725   Training iter 350, batch loss 0.0906, batch acc 0.9634
20:06:21.413   Training iter 400, batch loss 0.0904, batch acc 0.9586
20:06:21.765   Training iter 450, batch loss 0.0864, batch acc 0.9640
20:06:22.132   Training iter 500, batch loss 0.0885, batch acc 0.9626
20:06:22.473   Training iter 550, batch loss 0.0846, batch acc 0.9666
20:06:22.852   Training iter 600, batch loss 0.0831, batch acc 0.9654
20:06:22.853 Testing @ 10 epoch...
20:06:23.089     Testing, total mean loss 0.08770, total acc 0.96380
20:06:23.089 Training @ 11 epoch...
20:06:23.385   Training iter 50, batch loss 0.0872, batch acc 0.9644
20:06:23.662   Training iter 100, batch loss 0.0843, batch acc 0.9658
20:06:23.978   Training iter 150, batch loss 0.0821, batch acc 0.9666
20:06:24.314   Training iter 200, batch loss 0.0875, batch acc 0.9640
20:06:24.607   Training iter 250, batch loss 0.0864, batch acc 0.9624
20:06:24.928   Training iter 300, batch loss 0.0849, batch acc 0.9662
20:06:25.268   Training iter 350, batch loss 0.0832, batch acc 0.9636
20:06:25.682   Training iter 400, batch loss 0.0819, batch acc 0.9668
20:06:26.219   Training iter 450, batch loss 0.0810, batch acc 0.9700
20:06:26.663   Training iter 500, batch loss 0.0843, batch acc 0.9642
20:06:27.108   Training iter 550, batch loss 0.0820, batch acc 0.9660
20:06:27.521   Training iter 600, batch loss 0.0825, batch acc 0.9684
20:06:27.523 Training @ 12 epoch...
20:06:27.921   Training iter 50, batch loss 0.0793, batch acc 0.9690
20:06:28.428   Training iter 100, batch loss 0.0831, batch acc 0.9622
20:06:28.821   Training iter 150, batch loss 0.0811, batch acc 0.9690
20:06:29.119   Training iter 200, batch loss 0.0791, batch acc 0.9678
20:06:29.456   Training iter 250, batch loss 0.0806, batch acc 0.9680
20:06:29.821   Training iter 300, batch loss 0.0820, batch acc 0.9638
20:06:30.200   Training iter 350, batch loss 0.0779, batch acc 0.9708
20:06:30.595   Training iter 400, batch loss 0.0814, batch acc 0.9690
20:06:31.015   Training iter 450, batch loss 0.0835, batch acc 0.9636
20:06:31.390   Training iter 500, batch loss 0.0837, batch acc 0.9694
20:06:31.641   Training iter 550, batch loss 0.0793, batch acc 0.9682
20:06:32.013   Training iter 600, batch loss 0.0771, batch acc 0.9704
20:06:32.015 Training @ 13 epoch...
20:06:32.350   Training iter 50, batch loss 0.0772, batch acc 0.9706
20:06:32.667   Training iter 100, batch loss 0.0788, batch acc 0.9656
20:06:32.995   Training iter 150, batch loss 0.0814, batch acc 0.9650
20:06:33.402   Training iter 200, batch loss 0.0718, batch acc 0.9732
20:06:33.774   Training iter 250, batch loss 0.0756, batch acc 0.9706
20:06:34.123   Training iter 300, batch loss 0.0830, batch acc 0.9662
20:06:34.442   Training iter 350, batch loss 0.0801, batch acc 0.9674
20:06:34.832   Training iter 400, batch loss 0.0798, batch acc 0.9666
20:06:35.272   Training iter 450, batch loss 0.0776, batch acc 0.9676
20:06:35.621   Training iter 500, batch loss 0.0778, batch acc 0.9688
20:06:36.134   Training iter 550, batch loss 0.0794, batch acc 0.9694
20:06:36.527   Training iter 600, batch loss 0.0756, batch acc 0.9690
20:06:36.529 Training @ 14 epoch...
20:06:36.866   Training iter 50, batch loss 0.0763, batch acc 0.9698
20:06:37.299   Training iter 100, batch loss 0.0776, batch acc 0.9676
20:06:37.917   Training iter 150, batch loss 0.0745, batch acc 0.9706
20:06:38.332   Training iter 200, batch loss 0.0748, batch acc 0.9684
20:06:38.685   Training iter 250, batch loss 0.0727, batch acc 0.9746
20:06:39.056   Training iter 300, batch loss 0.0778, batch acc 0.9672
20:06:39.428   Training iter 350, batch loss 0.0734, batch acc 0.9724
20:06:39.830   Training iter 400, batch loss 0.0757, batch acc 0.9704
20:06:40.229   Training iter 450, batch loss 0.0789, batch acc 0.9682
20:06:40.493   Training iter 500, batch loss 0.0748, batch acc 0.9698
20:06:40.744   Training iter 550, batch loss 0.0763, batch acc 0.9672
20:06:41.064   Training iter 600, batch loss 0.0745, batch acc 0.9692
20:06:41.065 Training @ 15 epoch...
20:06:41.425   Training iter 50, batch loss 0.0730, batch acc 0.9698
20:06:41.775   Training iter 100, batch loss 0.0712, batch acc 0.9724
20:06:42.228   Training iter 150, batch loss 0.0717, batch acc 0.9740
20:06:42.565   Training iter 200, batch loss 0.0741, batch acc 0.9736
20:06:42.956   Training iter 250, batch loss 0.0700, batch acc 0.9732
20:06:43.333   Training iter 300, batch loss 0.0731, batch acc 0.9702
20:06:43.647   Training iter 350, batch loss 0.0760, batch acc 0.9676
20:06:43.965   Training iter 400, batch loss 0.0738, batch acc 0.9712
20:06:44.250   Training iter 450, batch loss 0.0769, batch acc 0.9668
20:06:44.702   Training iter 500, batch loss 0.0700, batch acc 0.9718
20:06:45.064   Training iter 550, batch loss 0.0774, batch acc 0.9670
20:06:45.595   Training iter 600, batch loss 0.0710, batch acc 0.9706
20:06:45.595 Testing @ 15 epoch...
20:06:46.039     Testing, total mean loss 0.07461, total acc 0.96930
20:06:46.039 Training @ 16 epoch...
20:06:46.368   Training iter 50, batch loss 0.0771, batch acc 0.9678
20:06:46.651   Training iter 100, batch loss 0.0732, batch acc 0.9716
20:06:46.971   Training iter 150, batch loss 0.0678, batch acc 0.9738
20:06:47.240   Training iter 200, batch loss 0.0697, batch acc 0.9738
20:06:47.594   Training iter 250, batch loss 0.0742, batch acc 0.9716
20:06:47.893   Training iter 300, batch loss 0.0701, batch acc 0.9732
20:06:48.285   Training iter 350, batch loss 0.0713, batch acc 0.9728
20:06:48.594   Training iter 400, batch loss 0.0758, batch acc 0.9702
20:06:49.005   Training iter 450, batch loss 0.0700, batch acc 0.9728
20:06:49.272   Training iter 500, batch loss 0.0665, batch acc 0.9736
20:06:49.531   Training iter 550, batch loss 0.0717, batch acc 0.9726
20:06:49.939   Training iter 600, batch loss 0.0702, batch acc 0.9726
20:06:49.940 Training @ 17 epoch...
20:06:50.304   Training iter 50, batch loss 0.0664, batch acc 0.9734
20:06:50.582   Training iter 100, batch loss 0.0716, batch acc 0.9724
20:06:50.888   Training iter 150, batch loss 0.0673, batch acc 0.9756
20:06:51.388   Training iter 200, batch loss 0.0753, batch acc 0.9676
20:06:51.712   Training iter 250, batch loss 0.0654, batch acc 0.9730
20:06:52.198   Training iter 300, batch loss 0.0729, batch acc 0.9720
20:06:52.540   Training iter 350, batch loss 0.0730, batch acc 0.9708
20:06:52.970   Training iter 400, batch loss 0.0688, batch acc 0.9736
20:06:53.378   Training iter 450, batch loss 0.0643, batch acc 0.9768
20:06:53.635   Training iter 500, batch loss 0.0706, batch acc 0.9726
20:06:54.045   Training iter 550, batch loss 0.0738, batch acc 0.9696
20:06:54.470   Training iter 600, batch loss 0.0663, batch acc 0.9750
20:06:54.472 Training @ 18 epoch...
20:06:54.912   Training iter 50, batch loss 0.0701, batch acc 0.9720
20:06:55.257   Training iter 100, batch loss 0.0703, batch acc 0.9724
20:06:55.622   Training iter 150, batch loss 0.0676, batch acc 0.9730
20:06:55.904   Training iter 200, batch loss 0.0656, batch acc 0.9752
20:06:56.360   Training iter 250, batch loss 0.0638, batch acc 0.9762
20:06:56.655   Training iter 300, batch loss 0.0661, batch acc 0.9736
20:06:57.015   Training iter 350, batch loss 0.0678, batch acc 0.9750
20:06:57.475   Training iter 400, batch loss 0.0706, batch acc 0.9718
20:06:57.846   Training iter 450, batch loss 0.0696, batch acc 0.9724
20:06:58.303   Training iter 500, batch loss 0.0692, batch acc 0.9750
20:06:58.852   Training iter 550, batch loss 0.0675, batch acc 0.9754
20:06:59.413   Training iter 600, batch loss 0.0695, batch acc 0.9732
20:06:59.415 Training @ 19 epoch...
20:06:59.792   Training iter 50, batch loss 0.0709, batch acc 0.9740
20:07:00.218   Training iter 100, batch loss 0.0653, batch acc 0.9766
20:07:00.593   Training iter 150, batch loss 0.0683, batch acc 0.9736
20:07:00.897   Training iter 200, batch loss 0.0639, batch acc 0.9764
20:07:01.255   Training iter 250, batch loss 0.0680, batch acc 0.9744
20:07:01.648   Training iter 300, batch loss 0.0691, batch acc 0.9758
20:07:02.072   Training iter 350, batch loss 0.0651, batch acc 0.9742
20:07:02.385   Training iter 400, batch loss 0.0655, batch acc 0.9752
20:07:02.832   Training iter 450, batch loss 0.0693, batch acc 0.9732
20:07:03.236   Training iter 500, batch loss 0.0634, batch acc 0.9766
20:07:03.638   Training iter 550, batch loss 0.0642, batch acc 0.9756
20:07:04.019   Training iter 600, batch loss 0.0663, batch acc 0.9754
20:07:04.020 Training @ 20 epoch...
20:07:04.344   Training iter 50, batch loss 0.0650, batch acc 0.9764
20:07:04.681   Training iter 100, batch loss 0.0646, batch acc 0.9758
20:07:05.082   Training iter 150, batch loss 0.0678, batch acc 0.9738
20:07:05.403   Training iter 200, batch loss 0.0645, batch acc 0.9764
20:07:05.850   Training iter 250, batch loss 0.0672, batch acc 0.9732
20:07:06.266   Training iter 300, batch loss 0.0674, batch acc 0.9766
20:07:06.519   Training iter 350, batch loss 0.0661, batch acc 0.9744
20:07:06.813   Training iter 400, batch loss 0.0646, batch acc 0.9766
20:07:07.110   Training iter 450, batch loss 0.0637, batch acc 0.9750
20:07:07.531   Training iter 500, batch loss 0.0635, batch acc 0.9768
20:07:08.014   Training iter 550, batch loss 0.0663, batch acc 0.9744
20:07:08.437   Training iter 600, batch loss 0.0631, batch acc 0.9780
20:07:08.439 Testing @ 20 epoch...
20:07:08.778     Testing, total mean loss 0.07050, total acc 0.97190
20:07:08.779 Training @ 21 epoch...
20:07:09.240   Training iter 50, batch loss 0.0654, batch acc 0.9752
20:07:09.871   Training iter 100, batch loss 0.0684, batch acc 0.9700
20:07:10.188   Training iter 150, batch loss 0.0614, batch acc 0.9776
20:07:10.537   Training iter 200, batch loss 0.0605, batch acc 0.9778
20:07:10.886   Training iter 250, batch loss 0.0656, batch acc 0.9758
20:07:11.340   Training iter 300, batch loss 0.0629, batch acc 0.9772
20:07:11.740   Training iter 350, batch loss 0.0639, batch acc 0.9768
20:07:12.243   Training iter 400, batch loss 0.0620, batch acc 0.9782
20:07:12.599   Training iter 450, batch loss 0.0688, batch acc 0.9752
20:07:13.037   Training iter 500, batch loss 0.0625, batch acc 0.9776
20:07:13.457   Training iter 550, batch loss 0.0648, batch acc 0.9756
20:07:13.805   Training iter 600, batch loss 0.0672, batch acc 0.9736
20:07:13.807 Training @ 22 epoch...
20:07:14.219   Training iter 50, batch loss 0.0628, batch acc 0.9772
20:07:14.563   Training iter 100, batch loss 0.0629, batch acc 0.9780
20:07:14.954   Training iter 150, batch loss 0.0623, batch acc 0.9772
20:07:15.338   Training iter 200, batch loss 0.0628, batch acc 0.9760
20:07:15.762   Training iter 250, batch loss 0.0606, batch acc 0.9790
20:07:16.168   Training iter 300, batch loss 0.0643, batch acc 0.9756
20:07:16.532   Training iter 350, batch loss 0.0640, batch acc 0.9764
20:07:17.249   Training iter 400, batch loss 0.0633, batch acc 0.9752
20:07:18.153   Training iter 450, batch loss 0.0642, batch acc 0.9744
20:07:18.996   Training iter 500, batch loss 0.0627, batch acc 0.9778
20:07:19.423   Training iter 550, batch loss 0.0655, batch acc 0.9760
20:07:20.097   Training iter 600, batch loss 0.0646, batch acc 0.9760
20:07:20.099 Training @ 23 epoch...
20:07:20.416   Training iter 50, batch loss 0.0600, batch acc 0.9786
20:07:20.903   Training iter 100, batch loss 0.0625, batch acc 0.9750
20:07:21.255   Training iter 150, batch loss 0.0650, batch acc 0.9746
20:07:21.571   Training iter 200, batch loss 0.0658, batch acc 0.9748
20:07:21.907   Training iter 250, batch loss 0.0624, batch acc 0.9786
20:07:22.213   Training iter 300, batch loss 0.0641, batch acc 0.9768
20:07:22.569   Training iter 350, batch loss 0.0631, batch acc 0.9764
20:07:23.198   Training iter 400, batch loss 0.0628, batch acc 0.9780
20:07:24.612   Training iter 450, batch loss 0.0554, batch acc 0.9816
20:07:25.082   Training iter 500, batch loss 0.0622, batch acc 0.9788
20:07:25.482   Training iter 550, batch loss 0.0610, batch acc 0.9770
20:07:25.836   Training iter 600, batch loss 0.0640, batch acc 0.9760
20:07:25.842 Training @ 24 epoch...
20:07:26.251   Training iter 50, batch loss 0.0577, batch acc 0.9808
20:07:26.635   Training iter 100, batch loss 0.0680, batch acc 0.9730
20:07:26.957   Training iter 150, batch loss 0.0593, batch acc 0.9802
20:07:27.297   Training iter 200, batch loss 0.0596, batch acc 0.9792
20:07:27.669   Training iter 250, batch loss 0.0647, batch acc 0.9760
20:07:28.116   Training iter 300, batch loss 0.0656, batch acc 0.9746
20:07:28.509   Training iter 350, batch loss 0.0590, batch acc 0.9782
20:07:28.927   Training iter 400, batch loss 0.0643, batch acc 0.9758
20:07:29.379   Training iter 450, batch loss 0.0570, batch acc 0.9814
20:07:29.796   Training iter 500, batch loss 0.0581, batch acc 0.9784
20:07:30.177   Training iter 550, batch loss 0.0622, batch acc 0.9780
20:07:30.481   Training iter 600, batch loss 0.0611, batch acc 0.9790
20:07:30.483 Training @ 25 epoch...
20:07:30.834   Training iter 50, batch loss 0.0597, batch acc 0.9778
20:07:31.116   Training iter 100, batch loss 0.0581, batch acc 0.9818
20:07:31.414   Training iter 150, batch loss 0.0608, batch acc 0.9778
20:07:31.706   Training iter 200, batch loss 0.0594, batch acc 0.9786
20:07:32.042   Training iter 250, batch loss 0.0617, batch acc 0.9770
20:07:32.500   Training iter 300, batch loss 0.0608, batch acc 0.9770
20:07:32.804   Training iter 350, batch loss 0.0596, batch acc 0.9796
20:07:33.136   Training iter 400, batch loss 0.0602, batch acc 0.9804
20:07:33.468   Training iter 450, batch loss 0.0609, batch acc 0.9778
20:07:33.845   Training iter 500, batch loss 0.0611, batch acc 0.9780
20:07:34.168   Training iter 550, batch loss 0.0644, batch acc 0.9756
20:07:34.489   Training iter 600, batch loss 0.0594, batch acc 0.9790
20:07:34.490 Testing @ 25 epoch...
20:07:34.802     Testing, total mean loss 0.06577, total acc 0.97530
20:07:34.802 Training @ 26 epoch...
20:07:35.154   Training iter 50, batch loss 0.0609, batch acc 0.9768
20:07:35.509   Training iter 100, batch loss 0.0609, batch acc 0.9762
20:07:35.837   Training iter 150, batch loss 0.0621, batch acc 0.9786
20:07:36.152   Training iter 200, batch loss 0.0599, batch acc 0.9782
20:07:36.555   Training iter 250, batch loss 0.0594, batch acc 0.9774
20:07:36.865   Training iter 300, batch loss 0.0547, batch acc 0.9822
20:07:37.152   Training iter 350, batch loss 0.0580, batch acc 0.9802
20:07:37.543   Training iter 400, batch loss 0.0565, batch acc 0.9818
20:07:38.001   Training iter 450, batch loss 0.0622, batch acc 0.9764
20:07:38.536   Training iter 500, batch loss 0.0608, batch acc 0.9786
20:07:39.253   Training iter 550, batch loss 0.0625, batch acc 0.9782
20:07:39.738   Training iter 600, batch loss 0.0552, batch acc 0.9822
20:07:39.738 Training @ 27 epoch...
20:07:40.072   Training iter 50, batch loss 0.0591, batch acc 0.9798
20:07:40.419   Training iter 100, batch loss 0.0568, batch acc 0.9806
20:07:40.740   Training iter 150, batch loss 0.0591, batch acc 0.9782
20:07:41.063   Training iter 200, batch loss 0.0565, batch acc 0.9830
20:07:41.411   Training iter 250, batch loss 0.0596, batch acc 0.9782
20:07:41.895   Training iter 300, batch loss 0.0572, batch acc 0.9794
20:07:42.217   Training iter 350, batch loss 0.0621, batch acc 0.9768
20:07:42.981   Training iter 400, batch loss 0.0613, batch acc 0.9768
20:07:43.295   Training iter 450, batch loss 0.0572, batch acc 0.9792
20:07:43.661   Training iter 500, batch loss 0.0570, batch acc 0.9826
20:07:44.041   Training iter 550, batch loss 0.0607, batch acc 0.9784
20:07:44.464   Training iter 600, batch loss 0.0597, batch acc 0.9784
20:07:44.465 Training @ 28 epoch...
20:07:44.813   Training iter 50, batch loss 0.0535, batch acc 0.9832
20:07:45.190   Training iter 100, batch loss 0.0590, batch acc 0.9784
20:07:45.491   Training iter 150, batch loss 0.0596, batch acc 0.9780
20:07:45.833   Training iter 200, batch loss 0.0594, batch acc 0.9796
20:07:46.150   Training iter 250, batch loss 0.0607, batch acc 0.9756
20:07:46.482   Training iter 300, batch loss 0.0528, batch acc 0.9822
20:07:46.844   Training iter 350, batch loss 0.0588, batch acc 0.9796
20:07:47.248   Training iter 400, batch loss 0.0608, batch acc 0.9792
20:07:47.532   Training iter 450, batch loss 0.0573, batch acc 0.9812
20:07:47.812   Training iter 500, batch loss 0.0587, batch acc 0.9796
20:07:48.083   Training iter 550, batch loss 0.0571, batch acc 0.9826
20:07:48.436   Training iter 600, batch loss 0.0591, batch acc 0.9794
20:07:48.436 Training @ 29 epoch...
20:07:48.722   Training iter 50, batch loss 0.0579, batch acc 0.9808
20:07:48.974   Training iter 100, batch loss 0.0577, batch acc 0.9786
20:07:49.464   Training iter 150, batch loss 0.0555, batch acc 0.9818
20:07:49.802   Training iter 200, batch loss 0.0577, batch acc 0.9800
20:07:50.139   Training iter 250, batch loss 0.0581, batch acc 0.9782
20:07:50.722   Training iter 300, batch loss 0.0556, batch acc 0.9818
20:07:51.033   Training iter 350, batch loss 0.0560, batch acc 0.9814
20:07:51.385   Training iter 400, batch loss 0.0601, batch acc 0.9786
20:07:51.667   Training iter 450, batch loss 0.0566, batch acc 0.9800
20:07:51.958   Training iter 500, batch loss 0.0585, batch acc 0.9786
20:07:52.292   Training iter 550, batch loss 0.0592, batch acc 0.9784
20:07:52.601   Training iter 600, batch loss 0.0562, batch acc 0.9826
20:07:52.603 Training @ 30 epoch...
20:07:52.890   Training iter 50, batch loss 0.0554, batch acc 0.9808
20:07:53.349   Training iter 100, batch loss 0.0554, batch acc 0.9826
20:07:53.670   Training iter 150, batch loss 0.0580, batch acc 0.9802
20:07:53.940   Training iter 200, batch loss 0.0542, batch acc 0.9834
20:07:54.220   Training iter 250, batch loss 0.0572, batch acc 0.9792
20:07:54.474   Training iter 300, batch loss 0.0587, batch acc 0.9792
20:07:54.734   Training iter 350, batch loss 0.0608, batch acc 0.9772
20:07:55.032   Training iter 400, batch loss 0.0557, batch acc 0.9806
20:07:55.360   Training iter 450, batch loss 0.0555, batch acc 0.9808
20:07:55.671   Training iter 500, batch loss 0.0542, batch acc 0.9808
20:07:56.064   Training iter 550, batch loss 0.0613, batch acc 0.9772
20:07:56.324   Training iter 600, batch loss 0.0549, batch acc 0.9834
20:07:56.325 Testing @ 30 epoch...
20:07:56.578     Testing, total mean loss 0.06240, total acc 0.97610
20:07:56.578 Training @ 31 epoch...
20:07:56.894   Training iter 50, batch loss 0.0543, batch acc 0.9820
20:07:57.354   Training iter 100, batch loss 0.0572, batch acc 0.9804
20:07:57.851   Training iter 150, batch loss 0.0516, batch acc 0.9838
20:07:58.328   Training iter 200, batch loss 0.0563, batch acc 0.9812
20:07:59.176   Training iter 250, batch loss 0.0538, batch acc 0.9820
20:08:00.006   Training iter 300, batch loss 0.0563, batch acc 0.9802
20:08:00.536   Training iter 350, batch loss 0.0563, batch acc 0.9810
20:08:01.004   Training iter 400, batch loss 0.0594, batch acc 0.9770
20:08:01.359   Training iter 450, batch loss 0.0564, batch acc 0.9808
20:08:01.913   Training iter 500, batch loss 0.0552, batch acc 0.9824
20:08:02.621   Training iter 550, batch loss 0.0603, batch acc 0.9778
20:08:03.040   Training iter 600, batch loss 0.0556, batch acc 0.9828
20:08:03.040 Training @ 32 epoch...
20:08:03.444   Training iter 50, batch loss 0.0538, batch acc 0.9806
20:08:03.827   Training iter 100, batch loss 0.0543, batch acc 0.9808
20:08:04.351   Training iter 150, batch loss 0.0550, batch acc 0.9834
20:08:04.835   Training iter 200, batch loss 0.0561, batch acc 0.9800
20:08:05.220   Training iter 250, batch loss 0.0545, batch acc 0.9810
20:08:05.577   Training iter 300, batch loss 0.0557, batch acc 0.9818
20:08:05.940   Training iter 350, batch loss 0.0563, batch acc 0.9814
20:08:06.354   Training iter 400, batch loss 0.0561, batch acc 0.9806
20:08:06.681   Training iter 450, batch loss 0.0567, batch acc 0.9802
20:08:07.034   Training iter 500, batch loss 0.0557, batch acc 0.9804
20:08:07.429   Training iter 550, batch loss 0.0573, batch acc 0.9826
20:08:07.897   Training iter 600, batch loss 0.0583, batch acc 0.9758
20:08:07.897 Training @ 33 epoch...
20:08:08.263   Training iter 50, batch loss 0.0584, batch acc 0.9792
20:08:08.736   Training iter 100, batch loss 0.0528, batch acc 0.9836
20:08:09.187   Training iter 150, batch loss 0.0550, batch acc 0.9794
20:08:09.539   Training iter 200, batch loss 0.0571, batch acc 0.9794
20:08:09.903   Training iter 250, batch loss 0.0561, batch acc 0.9804
20:08:10.351   Training iter 300, batch loss 0.0573, batch acc 0.9818
20:08:10.769   Training iter 350, batch loss 0.0552, batch acc 0.9820
20:08:11.149   Training iter 400, batch loss 0.0554, batch acc 0.9804
20:08:11.486   Training iter 450, batch loss 0.0521, batch acc 0.9828
20:08:11.826   Training iter 500, batch loss 0.0521, batch acc 0.9806
20:08:12.135   Training iter 550, batch loss 0.0555, batch acc 0.9806
20:08:12.485   Training iter 600, batch loss 0.0560, batch acc 0.9834
20:08:12.486 Training @ 34 epoch...
20:08:13.299   Training iter 50, batch loss 0.0525, batch acc 0.9812
20:08:13.632   Training iter 100, batch loss 0.0527, batch acc 0.9832
20:08:13.995   Training iter 150, batch loss 0.0567, batch acc 0.9826
20:08:14.420   Training iter 200, batch loss 0.0536, batch acc 0.9824
20:08:14.944   Training iter 250, batch loss 0.0582, batch acc 0.9804
20:08:15.324   Training iter 300, batch loss 0.0610, batch acc 0.9792
20:08:15.746   Training iter 350, batch loss 0.0568, batch acc 0.9808
20:08:16.172   Training iter 400, batch loss 0.0513, batch acc 0.9826
20:08:16.585   Training iter 450, batch loss 0.0498, batch acc 0.9830
20:08:16.936   Training iter 500, batch loss 0.0571, batch acc 0.9802
20:08:17.239   Training iter 550, batch loss 0.0526, batch acc 0.9824
20:08:17.529   Training iter 600, batch loss 0.0523, batch acc 0.9824
20:08:17.530 Training @ 35 epoch...
20:08:17.845   Training iter 50, batch loss 0.0531, batch acc 0.9822
20:08:18.216   Training iter 100, batch loss 0.0543, batch acc 0.9808
20:08:18.519   Training iter 150, batch loss 0.0543, batch acc 0.9812
20:08:18.831   Training iter 200, batch loss 0.0539, batch acc 0.9818
20:08:19.168   Training iter 250, batch loss 0.0534, batch acc 0.9822
20:08:19.653   Training iter 300, batch loss 0.0560, batch acc 0.9810
20:08:20.199   Training iter 350, batch loss 0.0538, batch acc 0.9828
20:08:20.696   Training iter 400, batch loss 0.0578, batch acc 0.9772
20:08:21.224   Training iter 450, batch loss 0.0567, batch acc 0.9808
20:08:21.786   Training iter 500, batch loss 0.0527, batch acc 0.9820
20:08:22.271   Training iter 550, batch loss 0.0499, batch acc 0.9840
20:08:22.669   Training iter 600, batch loss 0.0542, batch acc 0.9838
20:08:22.672 Testing @ 35 epoch...
20:08:22.922     Testing, total mean loss 0.06153, total acc 0.97670
20:08:22.922 Training @ 36 epoch...
20:08:23.233   Training iter 50, batch loss 0.0552, batch acc 0.9796
20:08:23.532   Training iter 100, batch loss 0.0536, batch acc 0.9808
20:08:23.906   Training iter 150, batch loss 0.0548, batch acc 0.9816
20:08:24.243   Training iter 200, batch loss 0.0530, batch acc 0.9830
20:08:24.561   Training iter 250, batch loss 0.0551, batch acc 0.9796
20:08:25.147   Training iter 300, batch loss 0.0515, batch acc 0.9834
20:08:25.484   Training iter 350, batch loss 0.0532, batch acc 0.9838
20:08:25.814   Training iter 400, batch loss 0.0528, batch acc 0.9830
20:08:26.167   Training iter 450, batch loss 0.0561, batch acc 0.9820
20:08:26.593   Training iter 500, batch loss 0.0536, batch acc 0.9858
20:08:26.988   Training iter 550, batch loss 0.0512, batch acc 0.9830
20:08:27.368   Training iter 600, batch loss 0.0522, batch acc 0.9818
20:08:27.369 Training @ 37 epoch...
20:08:27.850   Training iter 50, batch loss 0.0500, batch acc 0.9842
20:08:28.216   Training iter 100, batch loss 0.0577, batch acc 0.9788
20:08:28.517   Training iter 150, batch loss 0.0515, batch acc 0.9846
20:08:28.858   Training iter 200, batch loss 0.0532, batch acc 0.9810
20:08:29.185   Training iter 250, batch loss 0.0526, batch acc 0.9854
20:08:29.451   Training iter 300, batch loss 0.0519, batch acc 0.9818
20:08:29.761   Training iter 350, batch loss 0.0529, batch acc 0.9838
20:08:30.108   Training iter 400, batch loss 0.0559, batch acc 0.9808
20:08:30.419   Training iter 450, batch loss 0.0538, batch acc 0.9808
20:08:30.815   Training iter 500, batch loss 0.0531, batch acc 0.9816
20:08:31.162   Training iter 550, batch loss 0.0531, batch acc 0.9828
20:08:31.465   Training iter 600, batch loss 0.0533, batch acc 0.9826
20:08:31.465 Training @ 38 epoch...
20:08:31.911   Training iter 50, batch loss 0.0500, batch acc 0.9820
20:08:32.254   Training iter 100, batch loss 0.0497, batch acc 0.9836
20:08:32.608   Training iter 150, batch loss 0.0553, batch acc 0.9806
20:08:33.080   Training iter 200, batch loss 0.0532, batch acc 0.9820
20:08:34.174   Training iter 250, batch loss 0.0537, batch acc 0.9820
20:08:34.566   Training iter 300, batch loss 0.0531, batch acc 0.9838
20:08:34.836   Training iter 350, batch loss 0.0516, batch acc 0.9832
20:08:35.099   Training iter 400, batch loss 0.0505, batch acc 0.9836
20:08:35.426   Training iter 450, batch loss 0.0588, batch acc 0.9808
20:08:35.787   Training iter 500, batch loss 0.0525, batch acc 0.9826
20:08:36.108   Training iter 550, batch loss 0.0544, batch acc 0.9808
20:08:36.481   Training iter 600, batch loss 0.0515, batch acc 0.9852
20:08:36.481 Training @ 39 epoch...
20:08:36.926   Training iter 50, batch loss 0.0506, batch acc 0.9856
20:08:37.272   Training iter 100, batch loss 0.0500, batch acc 0.9852
20:08:37.615   Training iter 150, batch loss 0.0534, batch acc 0.9850
20:08:38.080   Training iter 200, batch loss 0.0530, batch acc 0.9818
20:08:38.439   Training iter 250, batch loss 0.0482, batch acc 0.9858
20:08:39.036   Training iter 300, batch loss 0.0548, batch acc 0.9826
20:08:39.454   Training iter 350, batch loss 0.0509, batch acc 0.9834
20:08:39.795   Training iter 400, batch loss 0.0552, batch acc 0.9802
20:08:40.087   Training iter 450, batch loss 0.0538, batch acc 0.9830
20:08:40.420   Training iter 500, batch loss 0.0542, batch acc 0.9822
20:08:40.700   Training iter 550, batch loss 0.0508, batch acc 0.9844
20:08:41.013   Training iter 600, batch loss 0.0547, batch acc 0.9794
20:08:41.015 Training @ 40 epoch...
20:08:41.355   Training iter 50, batch loss 0.0518, batch acc 0.9824
20:08:41.760   Training iter 100, batch loss 0.0517, batch acc 0.9820
20:08:42.187   Training iter 150, batch loss 0.0515, batch acc 0.9838
20:08:42.579   Training iter 200, batch loss 0.0531, batch acc 0.9834
20:08:42.862   Training iter 250, batch loss 0.0537, batch acc 0.9790
20:08:43.183   Training iter 300, batch loss 0.0536, batch acc 0.9814
20:08:43.588   Training iter 350, batch loss 0.0514, batch acc 0.9836
20:08:43.952   Training iter 400, batch loss 0.0503, batch acc 0.9852
20:08:44.241   Training iter 450, batch loss 0.0527, batch acc 0.9840
20:08:44.548   Training iter 500, batch loss 0.0513, batch acc 0.9836
20:08:44.895   Training iter 550, batch loss 0.0506, batch acc 0.9836
20:08:45.233   Training iter 600, batch loss 0.0520, batch acc 0.9822
20:08:45.233 Testing @ 40 epoch...
20:08:45.532     Testing, total mean loss 0.06030, total acc 0.97670
20:08:45.532 Training @ 41 epoch...
20:08:45.881   Training iter 50, batch loss 0.0482, batch acc 0.9862
20:08:46.182   Training iter 100, batch loss 0.0498, batch acc 0.9854
20:08:46.543   Training iter 150, batch loss 0.0557, batch acc 0.9800
20:08:46.929   Training iter 200, batch loss 0.0539, batch acc 0.9810
20:08:47.251   Training iter 250, batch loss 0.0506, batch acc 0.9846
20:08:47.660   Training iter 300, batch loss 0.0522, batch acc 0.9814
20:08:48.185   Training iter 350, batch loss 0.0536, batch acc 0.9824
20:08:48.596   Training iter 400, batch loss 0.0469, batch acc 0.9876
20:08:48.952   Training iter 450, batch loss 0.0512, batch acc 0.9812
20:08:49.298   Training iter 500, batch loss 0.0516, batch acc 0.9846
20:08:49.594   Training iter 550, batch loss 0.0535, batch acc 0.9814
20:08:50.096   Training iter 600, batch loss 0.0520, batch acc 0.9838
20:08:50.096 Training @ 42 epoch...
20:08:50.466   Training iter 50, batch loss 0.0540, batch acc 0.9810
20:08:50.801   Training iter 100, batch loss 0.0526, batch acc 0.9814
20:08:51.113   Training iter 150, batch loss 0.0526, batch acc 0.9830
20:08:51.442   Training iter 200, batch loss 0.0487, batch acc 0.9862
20:08:51.723   Training iter 250, batch loss 0.0511, batch acc 0.9830
20:08:52.039   Training iter 300, batch loss 0.0496, batch acc 0.9842
20:08:52.352   Training iter 350, batch loss 0.0505, batch acc 0.9828
20:08:52.678   Training iter 400, batch loss 0.0469, batch acc 0.9866
20:08:52.965   Training iter 450, batch loss 0.0503, batch acc 0.9826
20:08:53.251   Training iter 500, batch loss 0.0504, batch acc 0.9860
20:08:53.582   Training iter 550, batch loss 0.0515, batch acc 0.9842
20:08:53.897   Training iter 600, batch loss 0.0570, batch acc 0.9798
20:08:53.898 Training @ 43 epoch...
20:08:54.252   Training iter 50, batch loss 0.0506, batch acc 0.9834
20:08:54.621   Training iter 100, batch loss 0.0493, batch acc 0.9842
20:08:55.048   Training iter 150, batch loss 0.0491, batch acc 0.9856
20:08:55.416   Training iter 200, batch loss 0.0498, batch acc 0.9834
20:08:55.814   Training iter 250, batch loss 0.0529, batch acc 0.9808
20:08:56.126   Training iter 300, batch loss 0.0510, batch acc 0.9834
20:08:56.443   Training iter 350, batch loss 0.0514, batch acc 0.9822
20:08:57.085   Training iter 400, batch loss 0.0513, batch acc 0.9850
20:08:57.447   Training iter 450, batch loss 0.0508, batch acc 0.9832
20:08:57.780   Training iter 500, batch loss 0.0517, batch acc 0.9836
20:08:58.170   Training iter 550, batch loss 0.0472, batch acc 0.9858
20:08:58.461   Training iter 600, batch loss 0.0534, batch acc 0.9824
20:08:58.461 Training @ 44 epoch...
20:08:58.794   Training iter 50, batch loss 0.0496, batch acc 0.9836
20:08:59.130   Training iter 100, batch loss 0.0465, batch acc 0.9866
20:08:59.531   Training iter 150, batch loss 0.0520, batch acc 0.9830
20:08:59.854   Training iter 200, batch loss 0.0509, batch acc 0.9844
20:09:00.241   Training iter 250, batch loss 0.0524, batch acc 0.9840
20:09:00.555   Training iter 300, batch loss 0.0499, batch acc 0.9846
20:09:00.870   Training iter 350, batch loss 0.0515, batch acc 0.9830
20:09:01.169   Training iter 400, batch loss 0.0473, batch acc 0.9848
20:09:01.479   Training iter 450, batch loss 0.0499, batch acc 0.9838
20:09:01.855   Training iter 500, batch loss 0.0493, batch acc 0.9850
20:09:02.217   Training iter 550, batch loss 0.0524, batch acc 0.9834
20:09:02.708   Training iter 600, batch loss 0.0560, batch acc 0.9784
20:09:02.710 Training @ 45 epoch...
20:09:03.084   Training iter 50, batch loss 0.0495, batch acc 0.9852
20:09:03.428   Training iter 100, batch loss 0.0477, batch acc 0.9858
20:09:03.733   Training iter 150, batch loss 0.0537, batch acc 0.9808
20:09:04.060   Training iter 200, batch loss 0.0480, batch acc 0.9864
20:09:04.410   Training iter 250, batch loss 0.0501, batch acc 0.9864
20:09:04.740   Training iter 300, batch loss 0.0498, batch acc 0.9848
20:09:05.091   Training iter 350, batch loss 0.0507, batch acc 0.9836
20:09:05.469   Training iter 400, batch loss 0.0518, batch acc 0.9818
20:09:05.884   Training iter 450, batch loss 0.0493, batch acc 0.9834
20:09:06.195   Training iter 500, batch loss 0.0472, batch acc 0.9854
20:09:06.660   Training iter 550, batch loss 0.0507, batch acc 0.9832
20:09:07.154   Training iter 600, batch loss 0.0540, batch acc 0.9804
20:09:07.154 Testing @ 45 epoch...
20:09:07.446     Testing, total mean loss 0.05737, total acc 0.97830
20:09:07.446 Training @ 46 epoch...
20:09:07.897   Training iter 50, batch loss 0.0506, batch acc 0.9844
20:09:08.246   Training iter 100, batch loss 0.0492, batch acc 0.9844
20:09:08.611   Training iter 150, batch loss 0.0489, batch acc 0.9850
20:09:08.933   Training iter 200, batch loss 0.0518, batch acc 0.9832
20:09:09.270   Training iter 250, batch loss 0.0539, batch acc 0.9834
20:09:09.655   Training iter 300, batch loss 0.0497, batch acc 0.9844
20:09:09.959   Training iter 350, batch loss 0.0487, batch acc 0.9862
20:09:10.292   Training iter 400, batch loss 0.0476, batch acc 0.9858
20:09:10.595   Training iter 450, batch loss 0.0499, batch acc 0.9836
20:09:10.991   Training iter 500, batch loss 0.0493, batch acc 0.9834
20:09:11.320   Training iter 550, batch loss 0.0524, batch acc 0.9830
20:09:11.638   Training iter 600, batch loss 0.0482, batch acc 0.9830
20:09:11.638 Training @ 47 epoch...
20:09:11.999   Training iter 50, batch loss 0.0518, batch acc 0.9828
20:09:12.308   Training iter 100, batch loss 0.0470, batch acc 0.9866
20:09:12.615   Training iter 150, batch loss 0.0544, batch acc 0.9836
20:09:12.893   Training iter 200, batch loss 0.0519, batch acc 0.9840
20:09:13.205   Training iter 250, batch loss 0.0487, batch acc 0.9858
20:09:13.513   Training iter 300, batch loss 0.0496, batch acc 0.9848
20:09:13.935   Training iter 350, batch loss 0.0507, batch acc 0.9844
20:09:14.384   Training iter 400, batch loss 0.0464, batch acc 0.9858
20:09:14.683   Training iter 450, batch loss 0.0473, batch acc 0.9854
20:09:15.016   Training iter 500, batch loss 0.0525, batch acc 0.9818
20:09:15.329   Training iter 550, batch loss 0.0489, batch acc 0.9842
20:09:15.647   Training iter 600, batch loss 0.0505, batch acc 0.9844
20:09:15.652 Training @ 48 epoch...
20:09:16.019   Training iter 50, batch loss 0.0466, batch acc 0.9864
20:09:16.350   Training iter 100, batch loss 0.0517, batch acc 0.9836
20:09:16.681   Training iter 150, batch loss 0.0511, batch acc 0.9824
20:09:17.064   Training iter 200, batch loss 0.0496, batch acc 0.9824
20:09:17.400   Training iter 250, batch loss 0.0468, batch acc 0.9860
20:09:17.684   Training iter 300, batch loss 0.0508, batch acc 0.9848
20:09:18.040   Training iter 350, batch loss 0.0470, batch acc 0.9868
20:09:18.312   Training iter 400, batch loss 0.0461, batch acc 0.9878
20:09:18.635   Training iter 450, batch loss 0.0493, batch acc 0.9854
20:09:18.979   Training iter 500, batch loss 0.0512, batch acc 0.9848
20:09:19.293   Training iter 550, batch loss 0.0512, batch acc 0.9816
20:09:19.637   Training iter 600, batch loss 0.0524, batch acc 0.9818
20:09:19.638 Training @ 49 epoch...
20:09:20.006   Training iter 50, batch loss 0.0488, batch acc 0.9850
20:09:20.362   Training iter 100, batch loss 0.0477, batch acc 0.9858
20:09:20.704   Training iter 150, batch loss 0.0479, batch acc 0.9854
20:09:21.046   Training iter 200, batch loss 0.0491, batch acc 0.9858
20:09:21.569   Training iter 250, batch loss 0.0459, batch acc 0.9856
20:09:21.854   Training iter 300, batch loss 0.0512, batch acc 0.9828
20:09:22.240   Training iter 350, batch loss 0.0487, batch acc 0.9868
20:09:22.604   Training iter 400, batch loss 0.0488, batch acc 0.9834
20:09:22.941   Training iter 450, batch loss 0.0495, batch acc 0.9850
20:09:23.212   Training iter 500, batch loss 0.0512, batch acc 0.9842
20:09:23.526   Training iter 550, batch loss 0.0489, batch acc 0.9854
20:09:23.858   Training iter 600, batch loss 0.0526, batch acc 0.9822
20:09:23.860 Training @ 50 epoch...
20:09:24.183   Training iter 50, batch loss 0.0470, batch acc 0.9852
20:09:24.500   Training iter 100, batch loss 0.0494, batch acc 0.9846
20:09:24.861   Training iter 150, batch loss 0.0476, batch acc 0.9856
20:09:25.183   Training iter 200, batch loss 0.0485, batch acc 0.9844
20:09:25.546   Training iter 250, batch loss 0.0478, batch acc 0.9850
20:09:25.858   Training iter 300, batch loss 0.0446, batch acc 0.9880
20:09:26.171   Training iter 350, batch loss 0.0488, batch acc 0.9850
20:09:26.480   Training iter 400, batch loss 0.0499, batch acc 0.9846
20:09:26.770   Training iter 450, batch loss 0.0539, batch acc 0.9822
20:09:27.108   Training iter 500, batch loss 0.0461, batch acc 0.9872
20:09:27.389   Training iter 550, batch loss 0.0529, batch acc 0.9820
20:09:27.714   Training iter 600, batch loss 0.0504, batch acc 0.9852
20:09:27.715 Testing @ 50 epoch...
20:09:27.998     Testing, total mean loss 0.05829, total acc 0.97810
20:09:27.998 Training @ 51 epoch...
20:09:28.328   Training iter 50, batch loss 0.0446, batch acc 0.9868
20:09:28.610   Training iter 100, batch loss 0.0472, batch acc 0.9862
20:09:28.891   Training iter 150, batch loss 0.0452, batch acc 0.9882
20:09:29.171   Training iter 200, batch loss 0.0488, batch acc 0.9844
20:09:29.449   Training iter 250, batch loss 0.0509, batch acc 0.9820
20:09:29.704   Training iter 300, batch loss 0.0476, batch acc 0.9870
20:09:29.977   Training iter 350, batch loss 0.0497, batch acc 0.9858
20:09:30.291   Training iter 400, batch loss 0.0472, batch acc 0.9850
20:09:30.672   Training iter 450, batch loss 0.0513, batch acc 0.9830
20:09:31.067   Training iter 500, batch loss 0.0500, batch acc 0.9842
20:09:31.402   Training iter 550, batch loss 0.0491, batch acc 0.9850
20:09:31.676   Training iter 600, batch loss 0.0510, batch acc 0.9832
20:09:31.677 Training @ 52 epoch...
20:09:31.985   Training iter 50, batch loss 0.0486, batch acc 0.9860
20:09:32.254   Training iter 100, batch loss 0.0464, batch acc 0.9846
20:09:32.537   Training iter 150, batch loss 0.0479, batch acc 0.9856
20:09:32.813   Training iter 200, batch loss 0.0494, batch acc 0.9828
20:09:33.163   Training iter 250, batch loss 0.0464, batch acc 0.9856
20:09:33.499   Training iter 300, batch loss 0.0476, batch acc 0.9862
20:09:33.870   Training iter 350, batch loss 0.0512, batch acc 0.9848
20:09:34.198   Training iter 400, batch loss 0.0461, batch acc 0.9874
20:09:34.872   Training iter 450, batch loss 0.0466, batch acc 0.9854
20:09:35.245   Training iter 500, batch loss 0.0509, batch acc 0.9832
20:09:35.606   Training iter 550, batch loss 0.0500, batch acc 0.9836
20:09:35.924   Training iter 600, batch loss 0.0502, batch acc 0.9868
20:09:35.925 Training @ 53 epoch...
20:09:36.270   Training iter 50, batch loss 0.0475, batch acc 0.9836
20:09:36.631   Training iter 100, batch loss 0.0477, batch acc 0.9868
20:09:37.002   Training iter 150, batch loss 0.0470, batch acc 0.9858
20:09:37.270   Training iter 200, batch loss 0.0466, batch acc 0.9864
20:09:37.634   Training iter 250, batch loss 0.0496, batch acc 0.9846
20:09:37.994   Training iter 300, batch loss 0.0483, batch acc 0.9856
20:09:38.305   Training iter 350, batch loss 0.0488, batch acc 0.9854
20:09:38.720   Training iter 400, batch loss 0.0480, batch acc 0.9862
20:09:39.261   Training iter 450, batch loss 0.0497, batch acc 0.9834
20:09:39.623   Training iter 500, batch loss 0.0488, batch acc 0.9854
20:09:40.025   Training iter 550, batch loss 0.0480, batch acc 0.9868
20:09:40.337   Training iter 600, batch loss 0.0490, batch acc 0.9850
20:09:40.338 Training @ 54 epoch...
20:09:40.683   Training iter 50, batch loss 0.0506, batch acc 0.9844
20:09:41.112   Training iter 100, batch loss 0.0471, batch acc 0.9858
20:09:41.408   Training iter 150, batch loss 0.0444, batch acc 0.9884
20:09:41.846   Training iter 200, batch loss 0.0500, batch acc 0.9828
20:09:42.207   Training iter 250, batch loss 0.0518, batch acc 0.9824
20:09:42.671   Training iter 300, batch loss 0.0469, batch acc 0.9838
20:09:42.964   Training iter 350, batch loss 0.0466, batch acc 0.9882
20:09:43.277   Training iter 400, batch loss 0.0483, batch acc 0.9854
20:09:43.737   Training iter 450, batch loss 0.0466, batch acc 0.9884
20:09:44.139   Training iter 500, batch loss 0.0470, batch acc 0.9872
20:09:44.549   Training iter 550, batch loss 0.0494, batch acc 0.9850
20:09:44.926   Training iter 600, batch loss 0.0466, batch acc 0.9850
20:09:44.928 Training @ 55 epoch...
20:09:45.243   Training iter 50, batch loss 0.0498, batch acc 0.9828
20:09:45.574   Training iter 100, batch loss 0.0499, batch acc 0.9848
20:09:45.887   Training iter 150, batch loss 0.0463, batch acc 0.9852
20:09:46.337   Training iter 200, batch loss 0.0505, batch acc 0.9838
20:09:46.652   Training iter 250, batch loss 0.0463, batch acc 0.9872
20:09:46.964   Training iter 300, batch loss 0.0450, batch acc 0.9868
20:09:47.371   Training iter 350, batch loss 0.0467, batch acc 0.9864
20:09:47.770   Training iter 400, batch loss 0.0461, batch acc 0.9878
20:09:48.092   Training iter 450, batch loss 0.0453, batch acc 0.9876
20:09:48.546   Training iter 500, batch loss 0.0474, batch acc 0.9858
20:09:48.848   Training iter 550, batch loss 0.0485, batch acc 0.9868
20:09:49.116   Training iter 600, batch loss 0.0505, batch acc 0.9850
20:09:49.117 Testing @ 55 epoch...
20:09:49.389     Testing, total mean loss 0.05813, total acc 0.97930
20:09:49.389 Training @ 56 epoch...
20:09:49.770   Training iter 50, batch loss 0.0489, batch acc 0.9858
20:09:50.075   Training iter 100, batch loss 0.0504, batch acc 0.9844
20:09:50.386   Training iter 150, batch loss 0.0498, batch acc 0.9848
20:09:50.797   Training iter 200, batch loss 0.0486, batch acc 0.9850
20:09:51.197   Training iter 250, batch loss 0.0456, batch acc 0.9890
20:09:51.597   Training iter 300, batch loss 0.0435, batch acc 0.9878
20:09:51.927   Training iter 350, batch loss 0.0477, batch acc 0.9852
20:09:52.204   Training iter 400, batch loss 0.0450, batch acc 0.9874
20:09:52.509   Training iter 450, batch loss 0.0481, batch acc 0.9848
20:09:52.770   Training iter 500, batch loss 0.0473, batch acc 0.9850
20:09:53.084   Training iter 550, batch loss 0.0491, batch acc 0.9836
20:09:53.381   Training iter 600, batch loss 0.0476, batch acc 0.9844
20:09:53.383 Training @ 57 epoch...
20:09:53.710   Training iter 50, batch loss 0.0462, batch acc 0.9872
20:09:54.058   Training iter 100, batch loss 0.0470, batch acc 0.9850
20:09:54.349   Training iter 150, batch loss 0.0452, batch acc 0.9892
20:09:54.658   Training iter 200, batch loss 0.0452, batch acc 0.9858
20:09:54.968   Training iter 250, batch loss 0.0493, batch acc 0.9852
20:09:55.283   Training iter 300, batch loss 0.0509, batch acc 0.9834
20:09:55.592   Training iter 350, batch loss 0.0471, batch acc 0.9868
20:09:56.120   Training iter 400, batch loss 0.0497, batch acc 0.9834
20:09:56.498   Training iter 450, batch loss 0.0477, batch acc 0.9850
20:09:56.837   Training iter 500, batch loss 0.0434, batch acc 0.9872
20:09:57.202   Training iter 550, batch loss 0.0475, batch acc 0.9862
20:09:57.497   Training iter 600, batch loss 0.0478, batch acc 0.9868
20:09:57.503 Training @ 58 epoch...
20:09:57.812   Training iter 50, batch loss 0.0445, batch acc 0.9866
20:09:58.099   Training iter 100, batch loss 0.0456, batch acc 0.9872
20:09:58.375   Training iter 150, batch loss 0.0465, batch acc 0.9868
20:09:58.687   Training iter 200, batch loss 0.0485, batch acc 0.9862
20:09:59.021   Training iter 250, batch loss 0.0457, batch acc 0.9874
20:09:59.375   Training iter 300, batch loss 0.0478, batch acc 0.9870
20:09:59.773   Training iter 350, batch loss 0.0493, batch acc 0.9852
20:10:00.210   Training iter 400, batch loss 0.0485, batch acc 0.9864
20:10:00.633   Training iter 450, batch loss 0.0481, batch acc 0.9856
20:10:00.967   Training iter 500, batch loss 0.0449, batch acc 0.9888
20:10:01.255   Training iter 550, batch loss 0.0476, batch acc 0.9840
20:10:01.552   Training iter 600, batch loss 0.0492, batch acc 0.9848
20:10:01.554 Training @ 59 epoch...
20:10:01.811   Training iter 50, batch loss 0.0459, batch acc 0.9862
20:10:02.257   Training iter 100, batch loss 0.0437, batch acc 0.9882
20:10:02.618   Training iter 150, batch loss 0.0428, batch acc 0.9890
20:10:03.033   Training iter 200, batch loss 0.0476, batch acc 0.9870
20:10:03.402   Training iter 250, batch loss 0.0468, batch acc 0.9874
20:10:03.783   Training iter 300, batch loss 0.0490, batch acc 0.9848
20:10:04.168   Training iter 350, batch loss 0.0482, batch acc 0.9874
20:10:04.491   Training iter 400, batch loss 0.0480, batch acc 0.9838
20:10:04.821   Training iter 450, batch loss 0.0496, batch acc 0.9868
20:10:05.145   Training iter 500, batch loss 0.0489, batch acc 0.9854
20:10:05.492   Training iter 550, batch loss 0.0494, batch acc 0.9832
20:10:06.062   Training iter 600, batch loss 0.0463, batch acc 0.9860
20:10:06.064 Training @ 60 epoch...
20:10:06.610   Training iter 50, batch loss 0.0444, batch acc 0.9888
20:10:06.897   Training iter 100, batch loss 0.0467, batch acc 0.9856
20:10:07.280   Training iter 150, batch loss 0.0484, batch acc 0.9836
20:10:07.835   Training iter 200, batch loss 0.0453, batch acc 0.9872
20:10:08.280   Training iter 250, batch loss 0.0475, batch acc 0.9870
20:10:08.673   Training iter 300, batch loss 0.0469, batch acc 0.9864
20:10:09.187   Training iter 350, batch loss 0.0459, batch acc 0.9870
20:10:09.560   Training iter 400, batch loss 0.0473, batch acc 0.9878
20:10:09.890   Training iter 450, batch loss 0.0487, batch acc 0.9848
20:10:10.221   Training iter 500, batch loss 0.0484, batch acc 0.9846
20:10:10.689   Training iter 550, batch loss 0.0477, batch acc 0.9864
20:10:11.079   Training iter 600, batch loss 0.0486, batch acc 0.9854
20:10:11.080 Testing @ 60 epoch...
20:10:11.402     Testing, total mean loss 0.05758, total acc 0.97850
20:10:11.403 Training @ 61 epoch...
20:10:11.690   Training iter 50, batch loss 0.0441, batch acc 0.9878
20:10:11.996   Training iter 100, batch loss 0.0460, batch acc 0.9864
20:10:12.257   Training iter 150, batch loss 0.0448, batch acc 0.9868
20:10:12.644   Training iter 200, batch loss 0.0458, batch acc 0.9862
20:10:12.986   Training iter 250, batch loss 0.0459, batch acc 0.9876
20:10:13.269   Training iter 300, batch loss 0.0471, batch acc 0.9868
20:10:13.605   Training iter 350, batch loss 0.0484, batch acc 0.9850
20:10:13.997   Training iter 400, batch loss 0.0469, batch acc 0.9858
20:10:14.337   Training iter 450, batch loss 0.0468, batch acc 0.9862
20:10:14.640   Training iter 500, batch loss 0.0484, batch acc 0.9850
20:10:14.934   Training iter 550, batch loss 0.0474, batch acc 0.9872
20:10:15.238   Training iter 600, batch loss 0.0463, batch acc 0.9874
20:10:15.240 Training @ 62 epoch...
20:10:15.523   Training iter 50, batch loss 0.0462, batch acc 0.9854
20:10:15.797   Training iter 100, batch loss 0.0441, batch acc 0.9872
20:10:16.075   Training iter 150, batch loss 0.0424, batch acc 0.9884
20:10:16.418   Training iter 200, batch loss 0.0479, batch acc 0.9852
20:10:16.812   Training iter 250, batch loss 0.0451, batch acc 0.9870
20:10:17.198   Training iter 300, batch loss 0.0471, batch acc 0.9852
20:10:17.562   Training iter 350, batch loss 0.0475, batch acc 0.9856
20:10:17.888   Training iter 400, batch loss 0.0504, batch acc 0.9848
20:10:18.180   Training iter 450, batch loss 0.0476, batch acc 0.9852
20:10:18.490   Training iter 500, batch loss 0.0470, batch acc 0.9854
20:10:18.808   Training iter 550, batch loss 0.0470, batch acc 0.9866
20:10:19.076   Training iter 600, batch loss 0.0459, batch acc 0.9862
20:10:19.078 Training @ 63 epoch...
20:10:19.421   Training iter 50, batch loss 0.0443, batch acc 0.9866
20:10:19.758   Training iter 100, batch loss 0.0414, batch acc 0.9892
20:10:20.096   Training iter 150, batch loss 0.0458, batch acc 0.9866
20:10:20.415   Training iter 200, batch loss 0.0468, batch acc 0.9872
20:10:20.739   Training iter 250, batch loss 0.0494, batch acc 0.9842
20:10:21.076   Training iter 300, batch loss 0.0487, batch acc 0.9848
20:10:21.417   Training iter 350, batch loss 0.0477, batch acc 0.9860
20:10:21.682   Training iter 400, batch loss 0.0473, batch acc 0.9876
20:10:22.072   Training iter 450, batch loss 0.0410, batch acc 0.9902
20:10:22.425   Training iter 500, batch loss 0.0470, batch acc 0.9866
20:10:22.806   Training iter 550, batch loss 0.0489, batch acc 0.9854
20:10:23.148   Training iter 600, batch loss 0.0470, batch acc 0.9856
20:10:23.149 Training @ 64 epoch...
20:10:23.431   Training iter 50, batch loss 0.0472, batch acc 0.9846
20:10:23.702   Training iter 100, batch loss 0.0452, batch acc 0.9872
20:10:24.020   Training iter 150, batch loss 0.0457, batch acc 0.9870
20:10:24.301   Training iter 200, batch loss 0.0442, batch acc 0.9888
20:10:24.607   Training iter 250, batch loss 0.0460, batch acc 0.9878
20:10:24.996   Training iter 300, batch loss 0.0464, batch acc 0.9856
20:10:25.322   Training iter 350, batch loss 0.0448, batch acc 0.9868
20:10:25.655   Training iter 400, batch loss 0.0473, batch acc 0.9858
20:10:25.959   Training iter 450, batch loss 0.0449, batch acc 0.9882
20:10:26.235   Training iter 500, batch loss 0.0473, batch acc 0.9852
20:10:26.536   Training iter 550, batch loss 0.0464, batch acc 0.9866
20:10:26.802   Training iter 600, batch loss 0.0479, batch acc 0.9850
20:10:26.802 Training @ 65 epoch...
20:10:27.225   Training iter 50, batch loss 0.0462, batch acc 0.9872
20:10:27.686   Training iter 100, batch loss 0.0452, batch acc 0.9864
20:10:28.173   Training iter 150, batch loss 0.0455, batch acc 0.9866
20:10:28.592   Training iter 200, batch loss 0.0451, batch acc 0.9868
20:10:28.950   Training iter 250, batch loss 0.0444, batch acc 0.9866
20:10:29.237   Training iter 300, batch loss 0.0502, batch acc 0.9850
20:10:29.537   Training iter 350, batch loss 0.0464, batch acc 0.9890
20:10:29.784   Training iter 400, batch loss 0.0462, batch acc 0.9860
20:10:30.068   Training iter 450, batch loss 0.0442, batch acc 0.9878
20:10:30.590   Training iter 500, batch loss 0.0489, batch acc 0.9856
20:10:30.984   Training iter 550, batch loss 0.0449, batch acc 0.9866
20:10:31.332   Training iter 600, batch loss 0.0460, batch acc 0.9866
20:10:31.334 Testing @ 65 epoch...
20:10:31.598     Testing, total mean loss 0.05594, total acc 0.97940
20:10:31.598 Training @ 66 epoch...
20:10:31.878   Training iter 50, batch loss 0.0459, batch acc 0.9866
20:10:32.327   Training iter 100, batch loss 0.0446, batch acc 0.9866
20:10:32.647   Training iter 150, batch loss 0.0492, batch acc 0.9860
20:10:32.921   Training iter 200, batch loss 0.0434, batch acc 0.9874
20:10:33.202   Training iter 250, batch loss 0.0443, batch acc 0.9880
20:10:33.502   Training iter 300, batch loss 0.0434, batch acc 0.9876
20:10:33.856   Training iter 350, batch loss 0.0463, batch acc 0.9848
20:10:34.189   Training iter 400, batch loss 0.0454, batch acc 0.9870
20:10:34.524   Training iter 450, batch loss 0.0462, batch acc 0.9874
20:10:34.812   Training iter 500, batch loss 0.0476, batch acc 0.9872
20:10:35.106   Training iter 550, batch loss 0.0463, batch acc 0.9856
20:10:35.420   Training iter 600, batch loss 0.0473, batch acc 0.9858
20:10:35.422 Training @ 67 epoch...
20:10:35.693   Training iter 50, batch loss 0.0415, batch acc 0.9892
20:10:35.981   Training iter 100, batch loss 0.0474, batch acc 0.9856
20:10:36.247   Training iter 150, batch loss 0.0481, batch acc 0.9860
20:10:36.696   Training iter 200, batch loss 0.0451, batch acc 0.9880
20:10:37.119   Training iter 250, batch loss 0.0429, batch acc 0.9890
20:10:37.603   Training iter 300, batch loss 0.0478, batch acc 0.9848
20:10:38.232   Training iter 350, batch loss 0.0426, batch acc 0.9860
20:10:38.635   Training iter 400, batch loss 0.0489, batch acc 0.9862
20:10:39.004   Training iter 450, batch loss 0.0494, batch acc 0.9860
20:10:39.326   Training iter 500, batch loss 0.0458, batch acc 0.9864
20:10:39.681   Training iter 550, batch loss 0.0448, batch acc 0.9872
20:10:40.216   Training iter 600, batch loss 0.0439, batch acc 0.9882
20:10:40.217 Training @ 68 epoch...
20:10:40.666   Training iter 50, batch loss 0.0452, batch acc 0.9866
20:10:40.941   Training iter 100, batch loss 0.0447, batch acc 0.9882
20:10:41.242   Training iter 150, batch loss 0.0497, batch acc 0.9838
20:10:41.528   Training iter 200, batch loss 0.0451, batch acc 0.9874
20:10:41.916   Training iter 250, batch loss 0.0421, batch acc 0.9884
20:10:42.310   Training iter 300, batch loss 0.0479, batch acc 0.9870
20:10:42.781   Training iter 350, batch loss 0.0462, batch acc 0.9882
20:10:43.215   Training iter 400, batch loss 0.0439, batch acc 0.9898
20:10:43.497   Training iter 450, batch loss 0.0459, batch acc 0.9868
20:10:43.834   Training iter 500, batch loss 0.0449, batch acc 0.9868
20:10:44.233   Training iter 550, batch loss 0.0459, batch acc 0.9860
20:10:44.586   Training iter 600, batch loss 0.0488, batch acc 0.9846
20:10:44.587 Training @ 69 epoch...
20:10:45.008   Training iter 50, batch loss 0.0486, batch acc 0.9864
20:10:45.425   Training iter 100, batch loss 0.0445, batch acc 0.9878
20:10:45.867   Training iter 150, batch loss 0.0414, batch acc 0.9908
20:10:46.223   Training iter 200, batch loss 0.0473, batch acc 0.9840
20:10:46.646   Training iter 250, batch loss 0.0434, batch acc 0.9874
20:10:47.072   Training iter 300, batch loss 0.0456, batch acc 0.9854
20:10:47.339   Training iter 350, batch loss 0.0498, batch acc 0.9844
20:10:47.596   Training iter 400, batch loss 0.0450, batch acc 0.9880
20:10:47.935   Training iter 450, batch loss 0.0449, batch acc 0.9876
20:10:48.373   Training iter 500, batch loss 0.0464, batch acc 0.9870
20:10:48.717   Training iter 550, batch loss 0.0452, batch acc 0.9858
20:10:49.018   Training iter 600, batch loss 0.0431, batch acc 0.9886
20:10:49.020 Training @ 70 epoch...
20:10:49.352   Training iter 50, batch loss 0.0447, batch acc 0.9888
20:10:49.669   Training iter 100, batch loss 0.0458, batch acc 0.9868
20:10:50.053   Training iter 150, batch loss 0.0460, batch acc 0.9858
20:10:50.468   Training iter 200, batch loss 0.0442, batch acc 0.9878
20:10:50.915   Training iter 250, batch loss 0.0468, batch acc 0.9842
20:10:51.383   Training iter 300, batch loss 0.0455, batch acc 0.9864
20:10:51.784   Training iter 350, batch loss 0.0461, batch acc 0.9858
20:10:52.103   Training iter 400, batch loss 0.0435, batch acc 0.9898
20:10:52.418   Training iter 450, batch loss 0.0455, batch acc 0.9846
20:10:52.726   Training iter 500, batch loss 0.0464, batch acc 0.9866
20:10:53.054   Training iter 550, batch loss 0.0472, batch acc 0.9880
20:10:53.303   Training iter 600, batch loss 0.0441, batch acc 0.9888
20:10:53.304 Testing @ 70 epoch...
20:10:53.533     Testing, total mean loss 0.05489, total acc 0.98000
20:10:53.533 Training @ 71 epoch...
20:10:53.865   Training iter 50, batch loss 0.0435, batch acc 0.9886
20:10:54.214   Training iter 100, batch loss 0.0416, batch acc 0.9874
20:10:54.607   Training iter 150, batch loss 0.0448, batch acc 0.9882
20:10:54.897   Training iter 200, batch loss 0.0435, batch acc 0.9882
20:10:55.185   Training iter 250, batch loss 0.0432, batch acc 0.9888
20:10:55.460   Training iter 300, batch loss 0.0479, batch acc 0.9846
20:10:55.824   Training iter 350, batch loss 0.0446, batch acc 0.9880
20:10:56.185   Training iter 400, batch loss 0.0476, batch acc 0.9848
20:10:56.548   Training iter 450, batch loss 0.0466, batch acc 0.9874
20:10:56.964   Training iter 500, batch loss 0.0485, batch acc 0.9858
20:10:57.370   Training iter 550, batch loss 0.0419, batch acc 0.9894
20:10:57.850   Training iter 600, batch loss 0.0475, batch acc 0.9842
20:10:57.850 Training @ 72 epoch...
20:10:58.205   Training iter 50, batch loss 0.0456, batch acc 0.9876
20:10:58.583   Training iter 100, batch loss 0.0442, batch acc 0.9870
20:10:58.843   Training iter 150, batch loss 0.0457, batch acc 0.9856
20:10:59.177   Training iter 200, batch loss 0.0455, batch acc 0.9872
20:10:59.647   Training iter 250, batch loss 0.0484, batch acc 0.9846
20:11:00.078   Training iter 300, batch loss 0.0439, batch acc 0.9892
20:11:00.579   Training iter 350, batch loss 0.0435, batch acc 0.9894
20:11:00.884   Training iter 400, batch loss 0.0458, batch acc 0.9898
20:11:01.157   Training iter 450, batch loss 0.0452, batch acc 0.9878
20:11:01.494   Training iter 500, batch loss 0.0453, batch acc 0.9866
20:11:01.798   Training iter 550, batch loss 0.0452, batch acc 0.9876
20:11:02.149   Training iter 600, batch loss 0.0450, batch acc 0.9874
20:11:02.149 Training @ 73 epoch...
20:11:02.628   Training iter 50, batch loss 0.0458, batch acc 0.9856
20:11:03.073   Training iter 100, batch loss 0.0446, batch acc 0.9876
20:11:03.413   Training iter 150, batch loss 0.0453, batch acc 0.9884
20:11:03.714   Training iter 200, batch loss 0.0431, batch acc 0.9876
20:11:03.994   Training iter 250, batch loss 0.0438, batch acc 0.9868
20:11:04.436   Training iter 300, batch loss 0.0436, batch acc 0.9886
20:11:04.879   Training iter 350, batch loss 0.0450, batch acc 0.9876
20:11:05.363   Training iter 400, batch loss 0.0443, batch acc 0.9878
20:11:05.808   Training iter 450, batch loss 0.0439, batch acc 0.9872
20:11:06.131   Training iter 500, batch loss 0.0473, batch acc 0.9850
20:11:06.425   Training iter 550, batch loss 0.0464, batch acc 0.9860
20:11:06.742   Training iter 600, batch loss 0.0456, batch acc 0.9878
20:11:06.744 Training @ 74 epoch...
20:11:07.058   Training iter 50, batch loss 0.0428, batch acc 0.9888
20:11:07.445   Training iter 100, batch loss 0.0426, batch acc 0.9886
20:11:07.904   Training iter 150, batch loss 0.0471, batch acc 0.9868
20:11:08.347   Training iter 200, batch loss 0.0464, batch acc 0.9862
20:11:08.690   Training iter 250, batch loss 0.0458, batch acc 0.9858
20:11:09.045   Training iter 300, batch loss 0.0421, batch acc 0.9886
20:11:09.367   Training iter 350, batch loss 0.0424, batch acc 0.9892
20:11:09.658   Training iter 400, batch loss 0.0424, batch acc 0.9896
20:11:10.027   Training iter 450, batch loss 0.0473, batch acc 0.9860
20:11:10.316   Training iter 500, batch loss 0.0472, batch acc 0.9854
20:11:10.637   Training iter 550, batch loss 0.0471, batch acc 0.9858
20:11:11.051   Training iter 600, batch loss 0.0439, batch acc 0.9882
20:11:11.052 Training @ 75 epoch...
20:11:11.396   Training iter 50, batch loss 0.0430, batch acc 0.9890
20:11:11.841   Training iter 100, batch loss 0.0468, batch acc 0.9860
20:11:12.289   Training iter 150, batch loss 0.0400, batch acc 0.9910
20:11:12.577   Training iter 200, batch loss 0.0472, batch acc 0.9854
20:11:12.840   Training iter 250, batch loss 0.0449, batch acc 0.9872
20:11:13.134   Training iter 300, batch loss 0.0436, batch acc 0.9878
20:11:13.417   Training iter 350, batch loss 0.0436, batch acc 0.9876
20:11:13.746   Training iter 400, batch loss 0.0452, batch acc 0.9868
20:11:14.150   Training iter 450, batch loss 0.0443, batch acc 0.9886
20:11:14.599   Training iter 500, batch loss 0.0456, batch acc 0.9870
20:11:14.964   Training iter 550, batch loss 0.0464, batch acc 0.9858
20:11:15.298   Training iter 600, batch loss 0.0457, batch acc 0.9848
20:11:15.300 Testing @ 75 epoch...
20:11:15.621     Testing, total mean loss 0.05363, total acc 0.98050
20:11:15.621 Training @ 76 epoch...
20:11:15.936   Training iter 50, batch loss 0.0468, batch acc 0.9848
20:11:16.231   Training iter 100, batch loss 0.0424, batch acc 0.9892
20:11:16.616   Training iter 150, batch loss 0.0424, batch acc 0.9886
20:11:17.019   Training iter 200, batch loss 0.0474, batch acc 0.9854
20:11:17.433   Training iter 250, batch loss 0.0427, batch acc 0.9876
20:11:17.739   Training iter 300, batch loss 0.0454, batch acc 0.9866
20:11:18.122   Training iter 350, batch loss 0.0437, batch acc 0.9896
20:11:18.530   Training iter 400, batch loss 0.0456, batch acc 0.9880
20:11:18.847   Training iter 450, batch loss 0.0459, batch acc 0.9888
20:11:19.177   Training iter 500, batch loss 0.0471, batch acc 0.9864
20:11:19.522   Training iter 550, batch loss 0.0435, batch acc 0.9872
20:11:19.915   Training iter 600, batch loss 0.0441, batch acc 0.9880
20:11:19.915 Training @ 77 epoch...
20:11:20.284   Training iter 50, batch loss 0.0438, batch acc 0.9874
20:11:20.593   Training iter 100, batch loss 0.0464, batch acc 0.9874
20:11:20.923   Training iter 150, batch loss 0.0464, batch acc 0.9866
20:11:21.220   Training iter 200, batch loss 0.0443, batch acc 0.9870
20:11:21.496   Training iter 250, batch loss 0.0421, batch acc 0.9888
20:11:21.781   Training iter 300, batch loss 0.0434, batch acc 0.9886
20:11:22.088   Training iter 350, batch loss 0.0443, batch acc 0.9882
20:11:22.457   Training iter 400, batch loss 0.0467, batch acc 0.9876
20:11:22.785   Training iter 450, batch loss 0.0442, batch acc 0.9882
20:11:23.321   Training iter 500, batch loss 0.0425, batch acc 0.9878
20:11:23.742   Training iter 550, batch loss 0.0439, batch acc 0.9878
20:11:24.172   Training iter 600, batch loss 0.0452, batch acc 0.9858
20:11:24.173 Training @ 78 epoch...
20:11:24.498   Training iter 50, batch loss 0.0453, batch acc 0.9874
20:11:24.864   Training iter 100, batch loss 0.0453, batch acc 0.9864
20:11:25.189   Training iter 150, batch loss 0.0417, batch acc 0.9904
20:11:25.498   Training iter 200, batch loss 0.0468, batch acc 0.9848
20:11:25.873   Training iter 250, batch loss 0.0449, batch acc 0.9886
20:11:26.181   Training iter 300, batch loss 0.0432, batch acc 0.9878
20:11:26.486   Training iter 350, batch loss 0.0418, batch acc 0.9886
20:11:26.754   Training iter 400, batch loss 0.0449, batch acc 0.9872
20:11:27.048   Training iter 450, batch loss 0.0448, batch acc 0.9866
20:11:27.358   Training iter 500, batch loss 0.0439, batch acc 0.9876
20:11:27.648   Training iter 550, batch loss 0.0443, batch acc 0.9882
20:11:27.952   Training iter 600, batch loss 0.0427, batch acc 0.9876
20:11:27.953 Training @ 79 epoch...
20:11:28.365   Training iter 50, batch loss 0.0446, batch acc 0.9870
20:11:28.743   Training iter 100, batch loss 0.0434, batch acc 0.9894
20:11:29.090   Training iter 150, batch loss 0.0428, batch acc 0.9880
20:11:29.477   Training iter 200, batch loss 0.0432, batch acc 0.9882
20:11:29.920   Training iter 250, batch loss 0.0435, batch acc 0.9882
20:11:30.372   Training iter 300, batch loss 0.0445, batch acc 0.9876
20:11:30.711   Training iter 350, batch loss 0.0436, batch acc 0.9878
20:11:31.041   Training iter 400, batch loss 0.0452, batch acc 0.9882
20:11:31.375   Training iter 450, batch loss 0.0459, batch acc 0.9858
20:11:31.665   Training iter 500, batch loss 0.0462, batch acc 0.9866
20:11:32.018   Training iter 550, batch loss 0.0429, batch acc 0.9868
20:11:32.339   Training iter 600, batch loss 0.0439, batch acc 0.9894
20:11:32.339 Training @ 80 epoch...
20:11:32.641   Training iter 50, batch loss 0.0414, batch acc 0.9882
20:11:32.986   Training iter 100, batch loss 0.0434, batch acc 0.9896
20:11:33.332   Training iter 150, batch loss 0.0469, batch acc 0.9874
20:11:33.644   Training iter 200, batch loss 0.0430, batch acc 0.9866
20:11:34.149   Training iter 250, batch loss 0.0451, batch acc 0.9870
20:11:34.486   Training iter 300, batch loss 0.0438, batch acc 0.9874
20:11:34.831   Training iter 350, batch loss 0.0435, batch acc 0.9874
20:11:35.153   Training iter 400, batch loss 0.0464, batch acc 0.9862
20:11:35.499   Training iter 450, batch loss 0.0437, batch acc 0.9870
20:11:35.818   Training iter 500, batch loss 0.0455, batch acc 0.9870
20:11:36.159   Training iter 550, batch loss 0.0434, batch acc 0.9888
20:11:36.464   Training iter 600, batch loss 0.0428, batch acc 0.9892
20:11:36.466 Testing @ 80 epoch...
20:11:36.770     Testing, total mean loss 0.05442, total acc 0.98070
20:11:36.771 Training @ 81 epoch...
20:11:37.217   Training iter 50, batch loss 0.0418, batch acc 0.9888
20:11:37.668   Training iter 100, batch loss 0.0409, batch acc 0.9896
20:11:38.186   Training iter 150, batch loss 0.0449, batch acc 0.9874
20:11:38.650   Training iter 200, batch loss 0.0457, batch acc 0.9874
20:11:39.042   Training iter 250, batch loss 0.0437, batch acc 0.9882
20:11:39.475   Training iter 300, batch loss 0.0470, batch acc 0.9838
20:11:39.880   Training iter 350, batch loss 0.0411, batch acc 0.9884
20:11:40.252   Training iter 400, batch loss 0.0457, batch acc 0.9864
20:11:40.569   Training iter 450, batch loss 0.0453, batch acc 0.9864
20:11:40.933   Training iter 500, batch loss 0.0430, batch acc 0.9884
20:11:41.256   Training iter 550, batch loss 0.0433, batch acc 0.9890
20:11:41.516   Training iter 600, batch loss 0.0482, batch acc 0.9850
20:11:41.516 Training @ 82 epoch...
20:11:41.806   Training iter 50, batch loss 0.0416, batch acc 0.9886
20:11:42.178   Training iter 100, batch loss 0.0412, batch acc 0.9896
20:11:42.460   Training iter 150, batch loss 0.0439, batch acc 0.9884
20:11:42.769   Training iter 200, batch loss 0.0440, batch acc 0.9880
20:11:43.244   Training iter 250, batch loss 0.0404, batch acc 0.9890
20:11:43.681   Training iter 300, batch loss 0.0447, batch acc 0.9880
20:11:44.063   Training iter 350, batch loss 0.0447, batch acc 0.9884
20:11:44.306   Training iter 400, batch loss 0.0470, batch acc 0.9856
20:11:44.651   Training iter 450, batch loss 0.0468, batch acc 0.9872
20:11:45.050   Training iter 500, batch loss 0.0457, batch acc 0.9866
20:11:45.298   Training iter 550, batch loss 0.0447, batch acc 0.9898
20:11:45.695   Training iter 600, batch loss 0.0431, batch acc 0.9872
20:11:45.697 Training @ 83 epoch...
20:11:46.023   Training iter 50, batch loss 0.0423, batch acc 0.9884
20:11:46.379   Training iter 100, batch loss 0.0425, batch acc 0.9890
20:11:46.671   Training iter 150, batch loss 0.0441, batch acc 0.9870
20:11:46.990   Training iter 200, batch loss 0.0447, batch acc 0.9870
20:11:47.275   Training iter 250, batch loss 0.0478, batch acc 0.9854
20:11:47.538   Training iter 300, batch loss 0.0440, batch acc 0.9886
20:11:47.871   Training iter 350, batch loss 0.0433, batch acc 0.9876
20:11:48.199   Training iter 400, batch loss 0.0392, batch acc 0.9892
20:11:48.576   Training iter 450, batch loss 0.0455, batch acc 0.9870
20:11:48.898   Training iter 500, batch loss 0.0435, batch acc 0.9896
20:11:49.261   Training iter 550, batch loss 0.0453, batch acc 0.9866
20:11:49.540   Training iter 600, batch loss 0.0427, batch acc 0.9884
20:11:49.541 Training @ 84 epoch...
20:11:49.823   Training iter 50, batch loss 0.0430, batch acc 0.9896
20:11:50.130   Training iter 100, batch loss 0.0452, batch acc 0.9866
20:11:50.448   Training iter 150, batch loss 0.0426, batch acc 0.9882
20:11:50.715   Training iter 200, batch loss 0.0432, batch acc 0.9902
20:11:51.172   Training iter 250, batch loss 0.0438, batch acc 0.9866
20:11:51.672   Training iter 300, batch loss 0.0441, batch acc 0.9880
20:11:52.004   Training iter 350, batch loss 0.0444, batch acc 0.9862
20:11:52.445   Training iter 400, batch loss 0.0413, batch acc 0.9894
20:11:52.769   Training iter 450, batch loss 0.0459, batch acc 0.9862
20:11:53.076   Training iter 500, batch loss 0.0426, batch acc 0.9896
20:11:53.372   Training iter 550, batch loss 0.0462, batch acc 0.9846
20:11:53.720   Training iter 600, batch loss 0.0417, batch acc 0.9910
20:11:53.722 Training @ 85 epoch...
20:11:54.020   Training iter 50, batch loss 0.0423, batch acc 0.9894
20:11:54.390   Training iter 100, batch loss 0.0422, batch acc 0.9896
20:11:54.904   Training iter 150, batch loss 0.0435, batch acc 0.9878
20:11:55.584   Training iter 200, batch loss 0.0452, batch acc 0.9878
20:11:55.925   Training iter 250, batch loss 0.0439, batch acc 0.9874
20:11:56.231   Training iter 300, batch loss 0.0403, batch acc 0.9888
20:11:56.616   Training iter 350, batch loss 0.0451, batch acc 0.9868
20:11:57.107   Training iter 400, batch loss 0.0426, batch acc 0.9872
20:11:57.464   Training iter 450, batch loss 0.0465, batch acc 0.9866
20:11:57.957   Training iter 500, batch loss 0.0412, batch acc 0.9894
20:11:58.520   Training iter 550, batch loss 0.0447, batch acc 0.9896
20:11:58.871   Training iter 600, batch loss 0.0447, batch acc 0.9866
20:11:58.872 Testing @ 85 epoch...
20:11:59.156     Testing, total mean loss 0.05486, total acc 0.98080
20:11:59.157 Training @ 86 epoch...
20:11:59.640   Training iter 50, batch loss 0.0419, batch acc 0.9892
20:12:00.074   Training iter 100, batch loss 0.0455, batch acc 0.9858
20:12:00.451   Training iter 150, batch loss 0.0421, batch acc 0.9886
20:12:00.809   Training iter 200, batch loss 0.0414, batch acc 0.9884
20:12:01.136   Training iter 250, batch loss 0.0413, batch acc 0.9906
20:12:01.522   Training iter 300, batch loss 0.0424, batch acc 0.9886
20:12:01.808   Training iter 350, batch loss 0.0442, batch acc 0.9874
20:12:02.118   Training iter 400, batch loss 0.0435, batch acc 0.9884
20:12:02.419   Training iter 450, batch loss 0.0445, batch acc 0.9870
20:12:02.708   Training iter 500, batch loss 0.0441, batch acc 0.9890
20:12:03.036   Training iter 550, batch loss 0.0424, batch acc 0.9874
20:12:03.411   Training iter 600, batch loss 0.0460, batch acc 0.9858
20:12:03.412 Training @ 87 epoch...
20:12:03.756   Training iter 50, batch loss 0.0402, batch acc 0.9922
20:12:04.050   Training iter 100, batch loss 0.0448, batch acc 0.9878
20:12:04.346   Training iter 150, batch loss 0.0388, batch acc 0.9922
20:12:04.646   Training iter 200, batch loss 0.0431, batch acc 0.9866
20:12:04.963   Training iter 250, batch loss 0.0439, batch acc 0.9874
20:12:05.283   Training iter 300, batch loss 0.0430, batch acc 0.9888
20:12:05.821   Training iter 350, batch loss 0.0472, batch acc 0.9866
20:12:06.253   Training iter 400, batch loss 0.0424, batch acc 0.9888
20:12:06.722   Training iter 450, batch loss 0.0441, batch acc 0.9868
20:12:07.293   Training iter 500, batch loss 0.0449, batch acc 0.9872
20:12:07.916   Training iter 550, batch loss 0.0448, batch acc 0.9878
20:12:08.345   Training iter 600, batch loss 0.0444, batch acc 0.9860
20:12:08.347 Training @ 88 epoch...
20:12:09.848   Training iter 50, batch loss 0.0421, batch acc 0.9866
20:12:11.782   Training iter 100, batch loss 0.0415, batch acc 0.9902
20:12:13.539   Training iter 150, batch loss 0.0433, batch acc 0.9898
20:12:14.712   Training iter 200, batch loss 0.0429, batch acc 0.9882
20:12:15.067   Training iter 250, batch loss 0.0439, batch acc 0.9874
20:12:15.530   Training iter 300, batch loss 0.0452, batch acc 0.9878
20:12:15.843   Training iter 350, batch loss 0.0423, batch acc 0.9892
20:12:16.157   Training iter 400, batch loss 0.0432, batch acc 0.9868
20:12:16.452   Training iter 450, batch loss 0.0454, batch acc 0.9856
20:12:16.764   Training iter 500, batch loss 0.0430, batch acc 0.9886
20:12:17.099   Training iter 550, batch loss 0.0469, batch acc 0.9876
20:12:17.605   Training iter 600, batch loss 0.0411, batch acc 0.9898
20:12:17.607 Training @ 89 epoch...
20:12:17.958   Training iter 50, batch loss 0.0440, batch acc 0.9876
20:12:18.517   Training iter 100, batch loss 0.0417, batch acc 0.9882
20:12:18.859   Training iter 150, batch loss 0.0423, batch acc 0.9892
20:12:19.211   Training iter 200, batch loss 0.0442, batch acc 0.9866
20:12:19.542   Training iter 250, batch loss 0.0386, batch acc 0.9914
20:12:19.954   Training iter 300, batch loss 0.0440, batch acc 0.9876
20:12:20.220   Training iter 350, batch loss 0.0445, batch acc 0.9870
20:12:20.604   Training iter 400, batch loss 0.0438, batch acc 0.9884
20:12:20.949   Training iter 450, batch loss 0.0446, batch acc 0.9874
20:12:21.312   Training iter 500, batch loss 0.0463, batch acc 0.9872
20:12:21.555   Training iter 550, batch loss 0.0412, batch acc 0.9908
20:12:21.827   Training iter 600, batch loss 0.0442, batch acc 0.9876
20:12:21.828 Training @ 90 epoch...
20:12:22.173   Training iter 50, batch loss 0.0438, batch acc 0.9890
20:12:22.586   Training iter 100, batch loss 0.0435, batch acc 0.9870
20:12:22.927   Training iter 150, batch loss 0.0428, batch acc 0.9900
20:12:23.371   Training iter 200, batch loss 0.0432, batch acc 0.9874
20:12:23.704   Training iter 250, batch loss 0.0418, batch acc 0.9884
20:12:24.107   Training iter 300, batch loss 0.0415, batch acc 0.9890
20:12:24.489   Training iter 350, batch loss 0.0443, batch acc 0.9878
20:12:24.913   Training iter 400, batch loss 0.0423, batch acc 0.9888
20:12:25.394   Training iter 450, batch loss 0.0421, batch acc 0.9892
20:12:25.701   Training iter 500, batch loss 0.0436, batch acc 0.9896
20:12:26.172   Training iter 550, batch loss 0.0459, batch acc 0.9842
20:12:26.555   Training iter 600, batch loss 0.0430, batch acc 0.9904
20:12:26.556 Testing @ 90 epoch...
20:12:26.871     Testing, total mean loss 0.05489, total acc 0.98030
20:12:26.871 Training @ 91 epoch...
20:12:27.258   Training iter 50, batch loss 0.0423, batch acc 0.9896
20:12:27.598   Training iter 100, batch loss 0.0422, batch acc 0.9878
20:12:27.956   Training iter 150, batch loss 0.0455, batch acc 0.9872
20:12:28.328   Training iter 200, batch loss 0.0403, batch acc 0.9900
20:12:28.668   Training iter 250, batch loss 0.0440, batch acc 0.9900
20:12:28.971   Training iter 300, batch loss 0.0416, batch acc 0.9888
20:12:29.385   Training iter 350, batch loss 0.0425, batch acc 0.9868
20:12:29.842   Training iter 400, batch loss 0.0430, batch acc 0.9892
20:12:30.168   Training iter 450, batch loss 0.0403, batch acc 0.9882
20:12:30.481   Training iter 500, batch loss 0.0461, batch acc 0.9862
20:12:30.775   Training iter 550, batch loss 0.0461, batch acc 0.9860
20:12:31.078   Training iter 600, batch loss 0.0406, batch acc 0.9894
20:12:31.080 Training @ 92 epoch...
20:12:31.380   Training iter 50, batch loss 0.0426, batch acc 0.9896
20:12:31.674   Training iter 100, batch loss 0.0419, batch acc 0.9884
20:12:32.017   Training iter 150, batch loss 0.0432, batch acc 0.9910
20:12:32.378   Training iter 200, batch loss 0.0449, batch acc 0.9880
20:12:32.741   Training iter 250, batch loss 0.0423, batch acc 0.9878
20:12:33.066   Training iter 300, batch loss 0.0399, batch acc 0.9896
20:12:33.366   Training iter 350, batch loss 0.0424, batch acc 0.9882
20:12:33.670   Training iter 400, batch loss 0.0458, batch acc 0.9860
20:12:33.992   Training iter 450, batch loss 0.0451, batch acc 0.9864
20:12:34.308   Training iter 500, batch loss 0.0444, batch acc 0.9876
20:12:34.615   Training iter 550, batch loss 0.0439, batch acc 0.9870
20:12:34.973   Training iter 600, batch loss 0.0412, batch acc 0.9888
20:12:34.974 Training @ 93 epoch...
20:12:35.350   Training iter 50, batch loss 0.0415, batch acc 0.9896
20:12:35.712   Training iter 100, batch loss 0.0393, batch acc 0.9892
20:12:36.136   Training iter 150, batch loss 0.0445, batch acc 0.9866
20:12:36.517   Training iter 200, batch loss 0.0416, batch acc 0.9906
20:12:37.105   Training iter 250, batch loss 0.0405, batch acc 0.9904
20:12:37.470   Training iter 300, batch loss 0.0429, batch acc 0.9902
20:12:37.822   Training iter 350, batch loss 0.0432, batch acc 0.9876
20:12:38.191   Training iter 400, batch loss 0.0464, batch acc 0.9844
20:12:38.582   Training iter 450, batch loss 0.0438, batch acc 0.9866
20:12:38.914   Training iter 500, batch loss 0.0409, batch acc 0.9906
20:12:39.234   Training iter 550, batch loss 0.0423, batch acc 0.9878
20:12:39.568   Training iter 600, batch loss 0.0449, batch acc 0.9864
20:12:39.569 Training @ 94 epoch...
20:12:39.905   Training iter 50, batch loss 0.0422, batch acc 0.9874
20:12:40.188   Training iter 100, batch loss 0.0433, batch acc 0.9878
20:12:40.461   Training iter 150, batch loss 0.0422, batch acc 0.9902
20:12:40.774   Training iter 200, batch loss 0.0435, batch acc 0.9884
20:12:41.124   Training iter 250, batch loss 0.0435, batch acc 0.9880
20:12:41.511   Training iter 300, batch loss 0.0439, batch acc 0.9876
20:12:41.794   Training iter 350, batch loss 0.0423, batch acc 0.9890
20:12:42.216   Training iter 400, batch loss 0.0405, batch acc 0.9920
20:12:42.616   Training iter 450, batch loss 0.0426, batch acc 0.9886
20:12:43.007   Training iter 500, batch loss 0.0436, batch acc 0.9866
20:12:43.382   Training iter 550, batch loss 0.0447, batch acc 0.9860
20:12:43.690   Training iter 600, batch loss 0.0405, batch acc 0.9896
20:12:43.691 Training @ 95 epoch...
20:12:44.099   Training iter 50, batch loss 0.0445, batch acc 0.9870
20:12:44.428   Training iter 100, batch loss 0.0435, batch acc 0.9872
20:12:44.708   Training iter 150, batch loss 0.0411, batch acc 0.9896
20:12:45.043   Training iter 200, batch loss 0.0425, batch acc 0.9886
20:12:45.406   Training iter 250, batch loss 0.0404, batch acc 0.9890
20:12:45.696   Training iter 300, batch loss 0.0411, batch acc 0.9896
20:12:46.005   Training iter 350, batch loss 0.0411, batch acc 0.9890
20:12:46.348   Training iter 400, batch loss 0.0434, batch acc 0.9878
20:12:46.691   Training iter 450, batch loss 0.0430, batch acc 0.9884
20:12:47.112   Training iter 500, batch loss 0.0458, batch acc 0.9870
20:12:47.462   Training iter 550, batch loss 0.0404, batch acc 0.9904
20:12:47.787   Training iter 600, batch loss 0.0436, batch acc 0.9876
20:12:47.788 Testing @ 95 epoch...
20:12:47.994     Testing, total mean loss 0.05336, total acc 0.98080
20:12:47.995 Training @ 96 epoch...
20:12:48.268   Training iter 50, batch loss 0.0426, batch acc 0.9878
20:12:48.540   Training iter 100, batch loss 0.0418, batch acc 0.9890
20:12:48.893   Training iter 150, batch loss 0.0426, batch acc 0.9880
20:12:49.297   Training iter 200, batch loss 0.0419, batch acc 0.9880
20:12:49.743   Training iter 250, batch loss 0.0428, batch acc 0.9902
20:12:50.180   Training iter 300, batch loss 0.0436, batch acc 0.9884
20:12:50.514   Training iter 350, batch loss 0.0444, batch acc 0.9862
20:12:50.835   Training iter 400, batch loss 0.0447, batch acc 0.9868
20:12:51.201   Training iter 450, batch loss 0.0421, batch acc 0.9908
20:12:51.488   Training iter 500, batch loss 0.0416, batch acc 0.9886
20:12:51.755   Training iter 550, batch loss 0.0426, batch acc 0.9886
20:12:52.123   Training iter 600, batch loss 0.0433, batch acc 0.9872
20:12:52.124 Training @ 97 epoch...
20:12:52.576   Training iter 50, batch loss 0.0417, batch acc 0.9874
20:12:53.025   Training iter 100, batch loss 0.0399, batch acc 0.9900
20:12:53.373   Training iter 150, batch loss 0.0412, batch acc 0.9898
20:12:53.714   Training iter 200, batch loss 0.0425, batch acc 0.9882
20:12:54.053   Training iter 250, batch loss 0.0431, batch acc 0.9872
20:12:54.305   Training iter 300, batch loss 0.0448, batch acc 0.9868
20:12:54.578   Training iter 350, batch loss 0.0426, batch acc 0.9886
20:12:54.877   Training iter 400, batch loss 0.0400, batch acc 0.9896
20:12:55.321   Training iter 450, batch loss 0.0434, batch acc 0.9880
20:12:55.682   Training iter 500, batch loss 0.0419, batch acc 0.9880
20:12:56.062   Training iter 550, batch loss 0.0397, batch acc 0.9910
20:12:56.380   Training iter 600, batch loss 0.0477, batch acc 0.9862
20:12:56.381 Training @ 98 epoch...
20:12:56.734   Training iter 50, batch loss 0.0432, batch acc 0.9872
20:12:57.029   Training iter 100, batch loss 0.0407, batch acc 0.9888
20:12:57.295   Training iter 150, batch loss 0.0403, batch acc 0.9904
20:12:57.545   Training iter 200, batch loss 0.0428, batch acc 0.9884
20:12:57.825   Training iter 250, batch loss 0.0425, batch acc 0.9886
20:12:58.145   Training iter 300, batch loss 0.0452, batch acc 0.9852
20:12:58.462   Training iter 350, batch loss 0.0427, batch acc 0.9888
20:12:58.768   Training iter 400, batch loss 0.0401, batch acc 0.9900
20:12:59.049   Training iter 450, batch loss 0.0412, batch acc 0.9892
20:12:59.323   Training iter 500, batch loss 0.0434, batch acc 0.9894
20:12:59.584   Training iter 550, batch loss 0.0452, batch acc 0.9874
20:12:59.868   Training iter 600, batch loss 0.0426, batch acc 0.9876
20:12:59.869 Training @ 99 epoch...
20:13:00.265   Training iter 50, batch loss 0.0430, batch acc 0.9880
20:13:00.553   Training iter 100, batch loss 0.0430, batch acc 0.9890
20:13:00.847   Training iter 150, batch loss 0.0432, batch acc 0.9864
20:13:01.198   Training iter 200, batch loss 0.0418, batch acc 0.9898
20:13:01.630   Training iter 250, batch loss 0.0442, batch acc 0.9866
20:13:01.953   Training iter 300, batch loss 0.0428, batch acc 0.9888
20:13:02.230   Training iter 350, batch loss 0.0441, batch acc 0.9886
20:13:02.639   Training iter 400, batch loss 0.0429, batch acc 0.9880
20:13:03.314   Training iter 450, batch loss 0.0423, batch acc 0.9898
20:13:03.807   Training iter 500, batch loss 0.0409, batch acc 0.9894
20:13:04.514   Training iter 550, batch loss 0.0395, batch acc 0.9894
20:13:04.834   Training iter 600, batch loss 0.0417, batch acc 0.9890
20:13:04.835 Testing @ 99 epoch...
20:13:05.025     Testing, total mean loss 0.05478, total acc 0.98000