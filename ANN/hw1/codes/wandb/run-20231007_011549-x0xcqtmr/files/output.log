01:15:55.681 Training @ 0 epoch...
01:15:55.866   Training iter 50, batch loss 2.2657, batch acc 0.2550
01:15:55.971   Training iter 100, batch loss 1.7339, batch acc 0.5338
01:15:56.068   Training iter 150, batch loss 0.8949, batch acc 0.7600
01:15:56.166   Training iter 200, batch loss 0.6049, batch acc 0.8372
01:15:56.266   Training iter 250, batch loss 0.5059, batch acc 0.8576
01:15:56.368   Training iter 300, batch loss 0.4699, batch acc 0.8588
01:15:56.486   Training iter 350, batch loss 0.3732, batch acc 0.8964
01:15:56.606   Training iter 400, batch loss 0.4060, batch acc 0.8862
01:15:56.706   Training iter 450, batch loss 0.3803, batch acc 0.8912
01:15:56.817   Training iter 500, batch loss 0.3513, batch acc 0.8978
01:15:56.919   Training iter 550, batch loss 0.3616, batch acc 0.8910
01:15:57.015   Training iter 600, batch loss 0.3476, batch acc 0.8974
01:15:57.017 Testing @ 0 epoch...
01:15:57.120     Testing, total mean loss 0.32487, total acc 0.90420
01:15:57.120 Training @ 1 epoch...
01:15:57.250   Training iter 50, batch loss 0.3536, batch acc 0.8980
01:15:57.350   Training iter 100, batch loss 0.3241, batch acc 0.9068
01:15:57.442   Training iter 150, batch loss 0.3130, batch acc 0.9082
01:15:57.539   Training iter 200, batch loss 0.3200, batch acc 0.9086
01:15:57.623   Training iter 250, batch loss 0.3205, batch acc 0.9092
01:15:57.713   Training iter 300, batch loss 0.2903, batch acc 0.9110
01:15:57.809   Training iter 350, batch loss 0.2894, batch acc 0.9104
01:15:57.893   Training iter 400, batch loss 0.2863, batch acc 0.9166
01:15:58.018   Training iter 450, batch loss 0.3051, batch acc 0.9116
01:15:58.107   Training iter 500, batch loss 0.2938, batch acc 0.9170
01:15:58.201   Training iter 550, batch loss 0.2916, batch acc 0.9144
01:15:58.291   Training iter 600, batch loss 0.2728, batch acc 0.9228
01:15:58.291 Training @ 2 epoch...
01:15:58.382   Training iter 50, batch loss 0.2806, batch acc 0.9194
01:15:58.479   Training iter 100, batch loss 0.2648, batch acc 0.9174
01:15:58.574   Training iter 150, batch loss 0.2508, batch acc 0.9282
01:15:58.657   Training iter 200, batch loss 0.2397, batch acc 0.9306
01:15:58.734   Training iter 250, batch loss 0.2430, batch acc 0.9236
01:15:58.829   Training iter 300, batch loss 0.2492, batch acc 0.9258
01:15:58.904   Training iter 350, batch loss 0.2477, batch acc 0.9308
01:15:58.985   Training iter 400, batch loss 0.2407, batch acc 0.9328
01:15:59.071   Training iter 450, batch loss 0.2376, batch acc 0.9306
01:15:59.167   Training iter 500, batch loss 0.2348, batch acc 0.9368
01:15:59.267   Training iter 550, batch loss 0.2405, batch acc 0.9320
01:15:59.363   Training iter 600, batch loss 0.2270, batch acc 0.9354
01:15:59.364 Training @ 3 epoch...
01:15:59.464   Training iter 50, batch loss 0.2275, batch acc 0.9338
01:15:59.557   Training iter 100, batch loss 0.2141, batch acc 0.9402
01:15:59.653   Training iter 150, batch loss 0.2118, batch acc 0.9436
01:15:59.741   Training iter 200, batch loss 0.2028, batch acc 0.9390
01:15:59.851   Training iter 250, batch loss 0.2255, batch acc 0.9376
01:15:59.954   Training iter 300, batch loss 0.1963, batch acc 0.9436
01:16:00.306   Training iter 350, batch loss 0.1917, batch acc 0.9404
01:16:00.454   Training iter 400, batch loss 0.1960, batch acc 0.9422
01:16:00.589   Training iter 450, batch loss 0.2056, batch acc 0.9428
01:16:00.682   Training iter 500, batch loss 0.1890, batch acc 0.9440
01:16:00.765   Training iter 550, batch loss 0.2013, batch acc 0.9424
01:16:00.929   Training iter 600, batch loss 0.1974, batch acc 0.9436
01:16:00.930 Training @ 4 epoch...
01:16:01.031   Training iter 50, batch loss 0.1798, batch acc 0.9436
01:16:01.140   Training iter 100, batch loss 0.1850, batch acc 0.9464
01:16:01.259   Training iter 150, batch loss 0.1684, batch acc 0.9516
01:16:02.238   Training iter 200, batch loss 0.1880, batch acc 0.9512
01:16:02.389   Training iter 250, batch loss 0.1698, batch acc 0.9522
01:16:02.582   Training iter 300, batch loss 0.1794, batch acc 0.9500
01:16:02.900   Training iter 350, batch loss 0.1801, batch acc 0.9506
01:16:03.036   Training iter 400, batch loss 0.1667, batch acc 0.9482
01:16:03.233   Training iter 450, batch loss 0.1798, batch acc 0.9468
01:16:03.337   Training iter 500, batch loss 0.1701, batch acc 0.9520
01:16:03.447   Training iter 550, batch loss 0.1701, batch acc 0.9518
01:16:03.592   Training iter 600, batch loss 0.1660, batch acc 0.9542
01:16:03.593 Training @ 5 epoch...
01:16:03.691   Training iter 50, batch loss 0.1677, batch acc 0.9496
01:16:03.789   Training iter 100, batch loss 0.1494, batch acc 0.9562
01:16:03.969   Training iter 150, batch loss 0.1438, batch acc 0.9602
01:16:04.082   Training iter 200, batch loss 0.1714, batch acc 0.9502
01:16:04.343   Training iter 250, batch loss 0.1422, batch acc 0.9624
01:16:04.484   Training iter 300, batch loss 0.1468, batch acc 0.9590
01:16:04.687   Training iter 350, batch loss 0.1605, batch acc 0.9526
01:16:04.834   Training iter 400, batch loss 0.1479, batch acc 0.9576
01:16:05.020   Training iter 450, batch loss 0.1538, batch acc 0.9586
01:16:05.158   Training iter 500, batch loss 0.1530, batch acc 0.9556
01:16:05.333   Training iter 550, batch loss 0.1527, batch acc 0.9536
01:16:05.618   Training iter 600, batch loss 0.1623, batch acc 0.9542
01:16:05.621 Testing @ 5 epoch...
01:16:05.723     Testing, total mean loss 0.14720, total acc 0.95710
01:16:05.723 Training @ 6 epoch...
01:16:05.900   Training iter 50, batch loss 0.1370, batch acc 0.9642
01:16:06.035   Training iter 100, batch loss 0.1484, batch acc 0.9584
01:16:06.204   Training iter 150, batch loss 0.1490, batch acc 0.9612
01:16:06.389   Training iter 200, batch loss 0.1488, batch acc 0.9584
01:16:06.657   Training iter 250, batch loss 0.1526, batch acc 0.9600
01:16:06.930   Training iter 300, batch loss 0.1347, batch acc 0.9604
01:16:07.109   Training iter 350, batch loss 0.1333, batch acc 0.9608
01:16:07.218   Training iter 400, batch loss 0.1417, batch acc 0.9580
01:16:07.357   Training iter 450, batch loss 0.1288, batch acc 0.9648
01:16:07.501   Training iter 500, batch loss 0.1402, batch acc 0.9606
01:16:07.616   Training iter 550, batch loss 0.1250, batch acc 0.9650
01:16:07.793   Training iter 600, batch loss 0.1334, batch acc 0.9602
01:16:07.794 Training @ 7 epoch...
01:16:07.923   Training iter 50, batch loss 0.1222, batch acc 0.9636
01:16:08.072   Training iter 100, batch loss 0.1217, batch acc 0.9634
01:16:08.177   Training iter 150, batch loss 0.1251, batch acc 0.9634
01:16:08.341   Training iter 200, batch loss 0.1346, batch acc 0.9650
01:16:08.457   Training iter 250, batch loss 0.1331, batch acc 0.9630
01:16:08.593   Training iter 300, batch loss 0.1242, batch acc 0.9654
01:16:08.743   Training iter 350, batch loss 0.1257, batch acc 0.9668
01:16:08.908   Training iter 400, batch loss 0.1155, batch acc 0.9700
01:16:09.017   Training iter 450, batch loss 0.1185, batch acc 0.9638
01:16:09.174   Training iter 500, batch loss 0.1359, batch acc 0.9606
01:16:09.338   Training iter 550, batch loss 0.1277, batch acc 0.9640
01:16:09.464   Training iter 600, batch loss 0.1329, batch acc 0.9646
01:16:09.465 Training @ 8 epoch...
01:16:09.593   Training iter 50, batch loss 0.1289, batch acc 0.9642
01:16:09.723   Training iter 100, batch loss 0.1213, batch acc 0.9674
01:16:09.954   Training iter 150, batch loss 0.1163, batch acc 0.9674
01:16:10.067   Training iter 200, batch loss 0.1131, batch acc 0.9662
01:16:10.178   Training iter 250, batch loss 0.1103, batch acc 0.9688
01:16:10.303   Training iter 300, batch loss 0.1192, batch acc 0.9670
01:16:10.397   Training iter 350, batch loss 0.1124, batch acc 0.9670
01:16:10.476   Training iter 400, batch loss 0.1153, batch acc 0.9666
01:16:10.570   Training iter 450, batch loss 0.1205, batch acc 0.9656
01:16:10.652   Training iter 500, batch loss 0.1075, batch acc 0.9692
01:16:10.834   Training iter 550, batch loss 0.1144, batch acc 0.9706
01:16:10.975   Training iter 600, batch loss 0.1197, batch acc 0.9660
01:16:10.979 Training @ 9 epoch...
01:16:11.088   Training iter 50, batch loss 0.1165, batch acc 0.9682
01:16:11.267   Training iter 100, batch loss 0.1090, batch acc 0.9674
01:16:11.366   Training iter 150, batch loss 0.0991, batch acc 0.9742
01:16:11.488   Training iter 200, batch loss 0.1181, batch acc 0.9672
01:16:11.630   Training iter 250, batch loss 0.1201, batch acc 0.9674
01:16:11.733   Training iter 300, batch loss 0.1093, batch acc 0.9702
01:16:11.839   Training iter 350, batch loss 0.1010, batch acc 0.9716
01:16:11.931   Training iter 400, batch loss 0.1034, batch acc 0.9712
01:16:12.030   Training iter 450, batch loss 0.0999, batch acc 0.9732
01:16:12.102   Training iter 500, batch loss 0.1186, batch acc 0.9662
01:16:12.193   Training iter 550, batch loss 0.1023, batch acc 0.9722
01:16:12.288   Training iter 600, batch loss 0.1032, batch acc 0.9718
01:16:12.288 Training @ 10 epoch...
01:16:12.438   Training iter 50, batch loss 0.0955, batch acc 0.9752
01:16:12.600   Training iter 100, batch loss 0.0987, batch acc 0.9714
01:16:12.730   Training iter 150, batch loss 0.0974, batch acc 0.9754
01:16:12.853   Training iter 200, batch loss 0.0912, batch acc 0.9732
01:16:13.003   Training iter 250, batch loss 0.1077, batch acc 0.9682
01:16:13.159   Training iter 300, batch loss 0.1010, batch acc 0.9722
01:16:13.353   Training iter 350, batch loss 0.0970, batch acc 0.9720
01:16:13.467   Training iter 400, batch loss 0.1086, batch acc 0.9690
01:16:13.567   Training iter 450, batch loss 0.1087, batch acc 0.9694
01:16:13.731   Training iter 500, batch loss 0.1045, batch acc 0.9720
01:16:13.936   Training iter 550, batch loss 0.0985, batch acc 0.9728
01:16:14.059   Training iter 600, batch loss 0.1077, batch acc 0.9700
01:16:14.059 Testing @ 10 epoch...
01:16:14.152     Testing, total mean loss 0.10982, total acc 0.96830
01:16:14.152 Training @ 11 epoch...
01:16:14.292   Training iter 50, batch loss 0.0923, batch acc 0.9764
01:16:14.389   Training iter 100, batch loss 0.1042, batch acc 0.9714
01:16:14.601   Training iter 150, batch loss 0.0915, batch acc 0.9728
01:16:14.696   Training iter 200, batch loss 0.0939, batch acc 0.9742
01:16:14.820   Training iter 250, batch loss 0.1028, batch acc 0.9702
01:16:14.942   Training iter 300, batch loss 0.0991, batch acc 0.9730
01:16:15.069   Training iter 350, batch loss 0.0952, batch acc 0.9756
01:16:15.173   Training iter 400, batch loss 0.1031, batch acc 0.9728
01:16:15.272   Training iter 450, batch loss 0.0863, batch acc 0.9742
01:16:15.365   Training iter 500, batch loss 0.0966, batch acc 0.9742
01:16:15.476   Training iter 550, batch loss 0.0915, batch acc 0.9738
01:16:15.658   Training iter 600, batch loss 0.0935, batch acc 0.9746
01:16:15.660 Training @ 12 epoch...
01:16:15.780   Training iter 50, batch loss 0.0902, batch acc 0.9760
01:16:15.907   Training iter 100, batch loss 0.0854, batch acc 0.9746
01:16:16.064   Training iter 150, batch loss 0.1011, batch acc 0.9740
01:16:16.200   Training iter 200, batch loss 0.0817, batch acc 0.9788
01:16:16.289   Training iter 250, batch loss 0.0810, batch acc 0.9792
01:16:16.379   Training iter 300, batch loss 0.0937, batch acc 0.9736
01:16:16.472   Training iter 350, batch loss 0.0848, batch acc 0.9746
01:16:16.650   Training iter 400, batch loss 0.0869, batch acc 0.9766
01:16:16.828   Training iter 450, batch loss 0.0990, batch acc 0.9720
01:16:16.982   Training iter 500, batch loss 0.0919, batch acc 0.9748
01:16:17.092   Training iter 550, batch loss 0.0921, batch acc 0.9744
01:16:17.239   Training iter 600, batch loss 0.0935, batch acc 0.9722
01:16:17.239 Training @ 13 epoch...
01:16:17.395   Training iter 50, batch loss 0.0810, batch acc 0.9802
01:16:17.528   Training iter 100, batch loss 0.0721, batch acc 0.9814
01:16:17.641   Training iter 150, batch loss 0.0857, batch acc 0.9762
01:16:17.800   Training iter 200, batch loss 0.0863, batch acc 0.9750
01:16:17.906   Training iter 250, batch loss 0.0860, batch acc 0.9760
01:16:18.009   Training iter 300, batch loss 0.0913, batch acc 0.9748
01:16:18.088   Training iter 350, batch loss 0.0953, batch acc 0.9728
01:16:18.196   Training iter 400, batch loss 0.0860, batch acc 0.9766
01:16:18.338   Training iter 450, batch loss 0.0941, batch acc 0.9766
01:16:18.504   Training iter 500, batch loss 0.0787, batch acc 0.9778
01:16:18.638   Training iter 550, batch loss 0.0886, batch acc 0.9764
01:16:18.789   Training iter 600, batch loss 0.0877, batch acc 0.9732
01:16:18.792 Training @ 14 epoch...
01:16:18.922   Training iter 50, batch loss 0.0797, batch acc 0.9800
01:16:19.042   Training iter 100, batch loss 0.0812, batch acc 0.9784
01:16:19.155   Training iter 150, batch loss 0.0761, batch acc 0.9798
01:16:19.266   Training iter 200, batch loss 0.0822, batch acc 0.9790
01:16:19.348   Training iter 250, batch loss 0.0840, batch acc 0.9762
01:16:19.491   Training iter 300, batch loss 0.0950, batch acc 0.9728
01:16:19.722   Training iter 350, batch loss 0.0814, batch acc 0.9788
01:16:19.899   Training iter 400, batch loss 0.0901, batch acc 0.9788
01:16:20.056   Training iter 450, batch loss 0.0779, batch acc 0.9768
01:16:20.239   Training iter 500, batch loss 0.0795, batch acc 0.9756
01:16:20.341   Training iter 550, batch loss 0.0749, batch acc 0.9802
01:16:20.414   Training iter 600, batch loss 0.0897, batch acc 0.9742
01:16:20.415 Training @ 15 epoch...
01:16:20.508   Training iter 50, batch loss 0.0747, batch acc 0.9796
01:16:20.626   Training iter 100, batch loss 0.0807, batch acc 0.9762
01:16:20.789   Training iter 150, batch loss 0.0832, batch acc 0.9746
01:16:20.919   Training iter 200, batch loss 0.0737, batch acc 0.9802
01:16:21.012   Training iter 250, batch loss 0.0918, batch acc 0.9766
01:16:21.097   Training iter 300, batch loss 0.0721, batch acc 0.9800
01:16:21.225   Training iter 350, batch loss 0.0806, batch acc 0.9796
01:16:21.362   Training iter 400, batch loss 0.0743, batch acc 0.9800
01:16:21.495   Training iter 450, batch loss 0.0856, batch acc 0.9780
01:16:21.650   Training iter 500, batch loss 0.0861, batch acc 0.9742
01:16:21.775   Training iter 550, batch loss 0.0776, batch acc 0.9794
01:16:21.899   Training iter 600, batch loss 0.0754, batch acc 0.9790
01:16:21.901 Testing @ 15 epoch...
01:16:21.988     Testing, total mean loss 0.09585, total acc 0.97190
01:16:21.988 Training @ 16 epoch...
01:16:22.108   Training iter 50, batch loss 0.0745, batch acc 0.9808
01:16:22.252   Training iter 100, batch loss 0.0779, batch acc 0.9778
01:16:22.392   Training iter 150, batch loss 0.0834, batch acc 0.9780
01:16:22.490   Training iter 200, batch loss 0.0783, batch acc 0.9800
01:16:22.597   Training iter 250, batch loss 0.0676, batch acc 0.9828
01:16:22.801   Training iter 300, batch loss 0.0792, batch acc 0.9788
01:16:22.921   Training iter 350, batch loss 0.0696, batch acc 0.9822
01:16:23.054   Training iter 400, batch loss 0.0793, batch acc 0.9764
01:16:23.170   Training iter 450, batch loss 0.0778, batch acc 0.9798
01:16:23.265   Training iter 500, batch loss 0.0753, batch acc 0.9794
01:16:23.362   Training iter 550, batch loss 0.0806, batch acc 0.9768
01:16:23.439   Training iter 600, batch loss 0.0731, batch acc 0.9786
01:16:23.441 Training @ 17 epoch...
01:16:23.601   Training iter 50, batch loss 0.0752, batch acc 0.9808
01:16:23.740   Training iter 100, batch loss 0.0719, batch acc 0.9798
01:16:23.853   Training iter 150, batch loss 0.0786, batch acc 0.9772
01:16:23.957   Training iter 200, batch loss 0.0705, batch acc 0.9830
01:16:24.058   Training iter 250, batch loss 0.0791, batch acc 0.9788
01:16:24.167   Training iter 300, batch loss 0.0676, batch acc 0.9808
01:16:24.261   Training iter 350, batch loss 0.0766, batch acc 0.9772
01:16:24.365   Training iter 400, batch loss 0.0795, batch acc 0.9784
01:16:24.451   Training iter 450, batch loss 0.0777, batch acc 0.9792
01:16:24.534   Training iter 500, batch loss 0.0665, batch acc 0.9838
01:16:24.624   Training iter 550, batch loss 0.0682, batch acc 0.9828
01:16:24.725   Training iter 600, batch loss 0.0732, batch acc 0.9802
01:16:24.728 Training @ 18 epoch...
01:16:24.817   Training iter 50, batch loss 0.0600, batch acc 0.9858
01:16:24.904   Training iter 100, batch loss 0.0689, batch acc 0.9818
01:16:25.006   Training iter 150, batch loss 0.0677, batch acc 0.9794
01:16:25.137   Training iter 200, batch loss 0.0687, batch acc 0.9818
01:16:25.240   Training iter 250, batch loss 0.0789, batch acc 0.9788
01:16:25.363   Training iter 300, batch loss 0.0729, batch acc 0.9806
01:16:25.466   Training iter 350, batch loss 0.0806, batch acc 0.9798
01:16:25.570   Training iter 400, batch loss 0.0713, batch acc 0.9820
01:16:25.690   Training iter 450, batch loss 0.0665, batch acc 0.9830
01:16:25.820   Training iter 500, batch loss 0.0756, batch acc 0.9778
01:16:26.108   Training iter 550, batch loss 0.0769, batch acc 0.9804
01:16:26.297   Training iter 600, batch loss 0.0710, batch acc 0.9794
01:16:26.299 Training @ 19 epoch...
01:16:26.517   Training iter 50, batch loss 0.0610, batch acc 0.9822
01:16:26.684   Training iter 100, batch loss 0.0736, batch acc 0.9808
01:16:26.840   Training iter 150, batch loss 0.0772, batch acc 0.9800
01:16:27.013   Training iter 200, batch loss 0.0633, batch acc 0.9844
01:16:27.187   Training iter 250, batch loss 0.0634, batch acc 0.9848
01:16:27.382   Training iter 300, batch loss 0.0682, batch acc 0.9830
01:16:27.516   Training iter 350, batch loss 0.0753, batch acc 0.9790
01:16:27.652   Training iter 400, batch loss 0.0673, batch acc 0.9828
01:16:27.811   Training iter 450, batch loss 0.0692, batch acc 0.9796
01:16:27.923   Training iter 500, batch loss 0.0749, batch acc 0.9784
01:16:28.056   Training iter 550, batch loss 0.0691, batch acc 0.9826
01:16:28.173   Training iter 600, batch loss 0.0648, batch acc 0.9834
01:16:28.174 Training @ 20 epoch...
01:16:28.309   Training iter 50, batch loss 0.0685, batch acc 0.9824
01:16:28.425   Training iter 100, batch loss 0.0621, batch acc 0.9840
01:16:28.613   Training iter 150, batch loss 0.0681, batch acc 0.9790
01:16:28.736   Training iter 200, batch loss 0.0621, batch acc 0.9830
01:16:28.986   Training iter 250, batch loss 0.0636, batch acc 0.9834
01:16:29.102   Training iter 300, batch loss 0.0737, batch acc 0.9798
01:16:29.189   Training iter 350, batch loss 0.0676, batch acc 0.9824
01:16:29.279   Training iter 400, batch loss 0.0665, batch acc 0.9830
01:16:29.381   Training iter 450, batch loss 0.0689, batch acc 0.9810
01:16:29.484   Training iter 500, batch loss 0.0674, batch acc 0.9822
01:16:29.579   Training iter 550, batch loss 0.0783, batch acc 0.9792
01:16:29.661   Training iter 600, batch loss 0.0673, batch acc 0.9848
01:16:29.661 Testing @ 20 epoch...
01:16:29.733     Testing, total mean loss 0.08541, total acc 0.97490
01:16:29.733 Training @ 21 epoch...
01:16:29.842   Training iter 50, batch loss 0.0569, batch acc 0.9854
01:16:29.956   Training iter 100, batch loss 0.0655, batch acc 0.9838
01:16:30.068   Training iter 150, batch loss 0.0731, batch acc 0.9794
01:16:30.167   Training iter 200, batch loss 0.0731, batch acc 0.9794
01:16:30.301   Training iter 250, batch loss 0.0620, batch acc 0.9842
01:16:30.412   Training iter 300, batch loss 0.0633, batch acc 0.9840
01:16:30.508   Training iter 350, batch loss 0.0639, batch acc 0.9842
01:16:30.651   Training iter 400, batch loss 0.0734, batch acc 0.9792
01:16:30.775   Training iter 450, batch loss 0.0692, batch acc 0.9824
01:16:30.880   Training iter 500, batch loss 0.0620, batch acc 0.9846
01:16:30.990   Training iter 550, batch loss 0.0661, batch acc 0.9836
01:16:31.098   Training iter 600, batch loss 0.0595, batch acc 0.9828
01:16:31.099 Training @ 22 epoch...
01:16:31.217   Training iter 50, batch loss 0.0641, batch acc 0.9860
01:16:31.325   Training iter 100, batch loss 0.0611, batch acc 0.9840
01:16:31.463   Training iter 150, batch loss 0.0618, batch acc 0.9828
01:16:31.598   Training iter 200, batch loss 0.0579, batch acc 0.9864
01:16:31.737   Training iter 250, batch loss 0.0653, batch acc 0.9838
01:16:31.874   Training iter 300, batch loss 0.0640, batch acc 0.9834
01:16:32.023   Training iter 350, batch loss 0.0666, batch acc 0.9810
01:16:32.172   Training iter 400, batch loss 0.0685, batch acc 0.9800
01:16:32.358   Training iter 450, batch loss 0.0672, batch acc 0.9824
01:16:32.552   Training iter 500, batch loss 0.0600, batch acc 0.9846
01:16:32.691   Training iter 550, batch loss 0.0732, batch acc 0.9820
01:16:32.891   Training iter 600, batch loss 0.0621, batch acc 0.9836
01:16:32.894 Training @ 23 epoch...
01:16:33.052   Training iter 50, batch loss 0.0613, batch acc 0.9844
01:16:33.230   Training iter 100, batch loss 0.0586, batch acc 0.9862
01:16:33.405   Training iter 150, batch loss 0.0567, batch acc 0.9854
01:16:33.581   Training iter 200, batch loss 0.0623, batch acc 0.9858
01:16:33.705   Training iter 250, batch loss 0.0696, batch acc 0.9804
01:16:33.838   Training iter 300, batch loss 0.0552, batch acc 0.9866
01:16:33.979   Training iter 350, batch loss 0.0700, batch acc 0.9804
01:16:34.082   Training iter 400, batch loss 0.0580, batch acc 0.9848
01:16:34.269   Training iter 450, batch loss 0.0637, batch acc 0.9840
01:16:34.470   Training iter 500, batch loss 0.0601, batch acc 0.9848
01:16:34.583   Training iter 550, batch loss 0.0620, batch acc 0.9830
01:16:34.802   Training iter 600, batch loss 0.0657, batch acc 0.9818
01:16:34.804 Training @ 24 epoch...
01:16:35.019   Training iter 50, batch loss 0.0610, batch acc 0.9846
01:16:35.207   Training iter 100, batch loss 0.0640, batch acc 0.9838
01:16:35.312   Training iter 150, batch loss 0.0588, batch acc 0.9868
01:16:35.452   Training iter 200, batch loss 0.0622, batch acc 0.9840
01:16:35.588   Training iter 250, batch loss 0.0621, batch acc 0.9824
01:16:35.790   Training iter 300, batch loss 0.0693, batch acc 0.9796
01:16:35.928   Training iter 350, batch loss 0.0579, batch acc 0.9848
01:16:36.090   Training iter 400, batch loss 0.0558, batch acc 0.9848
01:16:36.214   Training iter 450, batch loss 0.0601, batch acc 0.9828
01:16:36.349   Training iter 500, batch loss 0.0547, batch acc 0.9850
01:16:36.481   Training iter 550, batch loss 0.0680, batch acc 0.9818
01:16:36.614   Training iter 600, batch loss 0.0605, batch acc 0.9832
01:16:36.616 Training @ 25 epoch...
01:16:36.752   Training iter 50, batch loss 0.0588, batch acc 0.9856
01:16:36.857   Training iter 100, batch loss 0.0608, batch acc 0.9854
01:16:37.002   Training iter 150, batch loss 0.0565, batch acc 0.9850
01:16:37.104   Training iter 200, batch loss 0.0591, batch acc 0.9838
01:16:37.185   Training iter 250, batch loss 0.0583, batch acc 0.9834
01:16:37.275   Training iter 300, batch loss 0.0641, batch acc 0.9824
01:16:37.366   Training iter 350, batch loss 0.0594, batch acc 0.9852
01:16:37.448   Training iter 400, batch loss 0.0630, batch acc 0.9820
01:16:37.524   Training iter 450, batch loss 0.0586, batch acc 0.9832
01:16:37.621   Training iter 500, batch loss 0.0605, batch acc 0.9862
01:16:37.719   Training iter 550, batch loss 0.0559, batch acc 0.9858
01:16:37.809   Training iter 600, batch loss 0.0654, batch acc 0.9816
01:16:37.809 Testing @ 25 epoch...
01:16:37.864     Testing, total mean loss 0.08102, total acc 0.97470
01:16:37.864 Training @ 26 epoch...
01:16:37.980   Training iter 50, batch loss 0.0582, batch acc 0.9872
01:16:38.079   Training iter 100, batch loss 0.0600, batch acc 0.9834
01:16:38.172   Training iter 150, batch loss 0.0591, batch acc 0.9850
01:16:38.272   Training iter 200, batch loss 0.0528, batch acc 0.9870
01:16:38.436   Training iter 250, batch loss 0.0543, batch acc 0.9866
01:16:38.572   Training iter 300, batch loss 0.0658, batch acc 0.9812
01:16:38.765   Training iter 350, batch loss 0.0609, batch acc 0.9852
01:16:38.933   Training iter 400, batch loss 0.0605, batch acc 0.9836
01:16:39.055   Training iter 450, batch loss 0.0555, batch acc 0.9856
01:16:39.171   Training iter 500, batch loss 0.0562, batch acc 0.9844
01:16:39.351   Training iter 550, batch loss 0.0538, batch acc 0.9864
01:16:39.474   Training iter 600, batch loss 0.0602, batch acc 0.9852
01:16:39.475 Training @ 27 epoch...
01:16:39.675   Training iter 50, batch loss 0.0558, batch acc 0.9874
01:16:39.885   Training iter 100, batch loss 0.0539, batch acc 0.9846
01:16:40.012   Training iter 150, batch loss 0.0601, batch acc 0.9846
01:16:40.122   Training iter 200, batch loss 0.0626, batch acc 0.9846
01:16:40.224   Training iter 250, batch loss 0.0534, batch acc 0.9860
01:16:40.335   Training iter 300, batch loss 0.0584, batch acc 0.9858
01:16:40.483   Training iter 350, batch loss 0.0589, batch acc 0.9862
01:16:40.582   Training iter 400, batch loss 0.0603, batch acc 0.9860
01:16:40.774   Training iter 450, batch loss 0.0525, batch acc 0.9868
01:16:41.028   Training iter 500, batch loss 0.0571, batch acc 0.9844
01:16:41.130   Training iter 550, batch loss 0.0571, batch acc 0.9864
01:16:41.221   Training iter 600, batch loss 0.0591, batch acc 0.9844
01:16:41.223 Training @ 28 epoch...
01:16:41.407   Training iter 50, batch loss 0.0487, batch acc 0.9874
01:16:41.534   Training iter 100, batch loss 0.0530, batch acc 0.9864
01:16:41.642   Training iter 150, batch loss 0.0535, batch acc 0.9866
01:16:41.749   Training iter 200, batch loss 0.0558, batch acc 0.9860
01:16:41.890   Training iter 250, batch loss 0.0588, batch acc 0.9830
01:16:42.029   Training iter 300, batch loss 0.0541, batch acc 0.9864
01:16:42.129   Training iter 350, batch loss 0.0586, batch acc 0.9854
01:16:42.212   Training iter 400, batch loss 0.0586, batch acc 0.9838
01:16:42.306   Training iter 450, batch loss 0.0567, batch acc 0.9862
01:16:42.443   Training iter 500, batch loss 0.0644, batch acc 0.9842
01:16:42.536   Training iter 550, batch loss 0.0603, batch acc 0.9846
01:16:42.642   Training iter 600, batch loss 0.0541, batch acc 0.9862
01:16:42.642 Training @ 29 epoch...
01:16:42.758   Training iter 50, batch loss 0.0513, batch acc 0.9888
01:16:42.871   Training iter 100, batch loss 0.0585, batch acc 0.9846
01:16:42.968   Training iter 150, batch loss 0.0516, batch acc 0.9874
01:16:43.070   Training iter 200, batch loss 0.0583, batch acc 0.9850
01:16:43.183   Training iter 250, batch loss 0.0629, batch acc 0.9834
01:16:43.301   Training iter 300, batch loss 0.0564, batch acc 0.9852
01:16:43.411   Training iter 350, batch loss 0.0551, batch acc 0.9862
01:16:43.524   Training iter 400, batch loss 0.0560, batch acc 0.9854
01:16:43.636   Training iter 450, batch loss 0.0540, batch acc 0.9854
01:16:43.722   Training iter 500, batch loss 0.0544, batch acc 0.9856
01:16:43.839   Training iter 550, batch loss 0.0516, batch acc 0.9876
01:16:43.938   Training iter 600, batch loss 0.0593, batch acc 0.9832
01:16:43.939 Training @ 30 epoch...
01:16:44.034   Training iter 50, batch loss 0.0512, batch acc 0.9876
01:16:44.141   Training iter 100, batch loss 0.0538, batch acc 0.9878
01:16:44.236   Training iter 150, batch loss 0.0590, batch acc 0.9854
01:16:44.318   Training iter 200, batch loss 0.0551, batch acc 0.9862
01:16:44.461   Training iter 250, batch loss 0.0502, batch acc 0.9868
01:16:44.597   Training iter 300, batch loss 0.0489, batch acc 0.9876
01:16:44.687   Training iter 350, batch loss 0.0516, batch acc 0.9860
01:16:44.816   Training iter 400, batch loss 0.0578, batch acc 0.9862
01:16:44.941   Training iter 450, batch loss 0.0549, batch acc 0.9856
01:16:45.103   Training iter 500, batch loss 0.0546, batch acc 0.9856
01:16:45.236   Training iter 550, batch loss 0.0659, batch acc 0.9844
01:16:45.387   Training iter 600, batch loss 0.0500, batch acc 0.9880
01:16:45.389 Testing @ 30 epoch...
01:16:45.471     Testing, total mean loss 0.07637, total acc 0.97640
01:16:45.471 Training @ 31 epoch...
01:16:45.634   Training iter 50, batch loss 0.0535, batch acc 0.9878
01:16:45.751   Training iter 100, batch loss 0.0503, batch acc 0.9878
01:16:45.855   Training iter 150, batch loss 0.0532, batch acc 0.9856
01:16:45.965   Training iter 200, batch loss 0.0540, batch acc 0.9854
01:16:46.066   Training iter 250, batch loss 0.0540, batch acc 0.9872
01:16:46.175   Training iter 300, batch loss 0.0531, batch acc 0.9874
01:16:46.303   Training iter 350, batch loss 0.0474, batch acc 0.9900
01:16:46.402   Training iter 400, batch loss 0.0533, batch acc 0.9862
01:16:46.513   Training iter 450, batch loss 0.0554, batch acc 0.9858
01:16:46.606   Training iter 500, batch loss 0.0552, batch acc 0.9860
01:16:46.691   Training iter 550, batch loss 0.0569, batch acc 0.9854
01:16:46.793   Training iter 600, batch loss 0.0572, batch acc 0.9866
01:16:46.794 Training @ 32 epoch...
01:16:46.881   Training iter 50, batch loss 0.0445, batch acc 0.9900
01:16:47.003   Training iter 100, batch loss 0.0575, batch acc 0.9856
01:16:47.101   Training iter 150, batch loss 0.0452, batch acc 0.9904
01:16:47.187   Training iter 200, batch loss 0.0576, batch acc 0.9854
01:16:47.299   Training iter 250, batch loss 0.0445, batch acc 0.9914
01:16:47.382   Training iter 300, batch loss 0.0493, batch acc 0.9892
01:16:47.478   Training iter 350, batch loss 0.0514, batch acc 0.9858
01:16:47.607   Training iter 400, batch loss 0.0592, batch acc 0.9856
01:16:47.714   Training iter 450, batch loss 0.0558, batch acc 0.9844
01:16:47.830   Training iter 500, batch loss 0.0530, batch acc 0.9848
01:16:47.937   Training iter 550, batch loss 0.0653, batch acc 0.9806
01:16:48.050   Training iter 600, batch loss 0.0557, batch acc 0.9848
01:16:48.051 Training @ 33 epoch...
01:16:48.165   Training iter 50, batch loss 0.0545, batch acc 0.9860
01:16:48.266   Training iter 100, batch loss 0.0516, batch acc 0.9888
01:16:48.377   Training iter 150, batch loss 0.0589, batch acc 0.9854
01:16:48.497   Training iter 200, batch loss 0.0529, batch acc 0.9862
01:16:48.578   Training iter 250, batch loss 0.0524, batch acc 0.9872
01:16:48.658   Training iter 300, batch loss 0.0564, batch acc 0.9862
01:16:48.738   Training iter 350, batch loss 0.0461, batch acc 0.9896
01:16:48.840   Training iter 400, batch loss 0.0521, batch acc 0.9856
01:16:48.924   Training iter 450, batch loss 0.0470, batch acc 0.9898
01:16:49.006   Training iter 500, batch loss 0.0512, batch acc 0.9878
01:16:49.086   Training iter 550, batch loss 0.0554, batch acc 0.9842
01:16:49.180   Training iter 600, batch loss 0.0560, batch acc 0.9844
01:16:49.181 Training @ 34 epoch...
01:16:49.263   Training iter 50, batch loss 0.0527, batch acc 0.9876
01:16:49.356   Training iter 100, batch loss 0.0478, batch acc 0.9884
01:16:49.457   Training iter 150, batch loss 0.0475, batch acc 0.9880
01:16:49.546   Training iter 200, batch loss 0.0495, batch acc 0.9892
01:16:49.672   Training iter 250, batch loss 0.0457, batch acc 0.9896
01:16:49.767   Training iter 300, batch loss 0.0532, batch acc 0.9856
01:16:49.857   Training iter 350, batch loss 0.0589, batch acc 0.9832
01:16:49.973   Training iter 400, batch loss 0.0517, batch acc 0.9886
01:16:50.163   Training iter 450, batch loss 0.0500, batch acc 0.9898
01:16:50.261   Training iter 500, batch loss 0.0578, batch acc 0.9834
01:16:50.363   Training iter 550, batch loss 0.0478, batch acc 0.9886
01:16:50.496   Training iter 600, batch loss 0.0531, batch acc 0.9866
01:16:50.497 Training @ 35 epoch...
01:16:50.615   Training iter 50, batch loss 0.0508, batch acc 0.9872
01:16:50.736   Training iter 100, batch loss 0.0533, batch acc 0.9872
01:16:50.867   Training iter 150, batch loss 0.0519, batch acc 0.9862
01:16:50.981   Training iter 200, batch loss 0.0555, batch acc 0.9870
01:16:51.094   Training iter 250, batch loss 0.0475, batch acc 0.9898
01:16:51.233   Training iter 300, batch loss 0.0512, batch acc 0.9874
01:16:51.332   Training iter 350, batch loss 0.0513, batch acc 0.9856
01:16:51.450   Training iter 400, batch loss 0.0496, batch acc 0.9894
01:16:51.552   Training iter 450, batch loss 0.0474, batch acc 0.9882
01:16:51.644   Training iter 500, batch loss 0.0522, batch acc 0.9892
01:16:51.740   Training iter 550, batch loss 0.0509, batch acc 0.9876
01:16:51.822   Training iter 600, batch loss 0.0521, batch acc 0.9868
01:16:51.823 Testing @ 35 epoch...
01:16:51.880     Testing, total mean loss 0.07212, total acc 0.97900
01:16:51.880 Training @ 36 epoch...
01:16:51.985   Training iter 50, batch loss 0.0513, batch acc 0.9872
01:16:52.070   Training iter 100, batch loss 0.0505, batch acc 0.9878
01:16:52.159   Training iter 150, batch loss 0.0445, batch acc 0.9894
01:16:52.263   Training iter 200, batch loss 0.0501, batch acc 0.9868
01:16:52.351   Training iter 250, batch loss 0.0506, batch acc 0.9878
01:16:52.449   Training iter 300, batch loss 0.0506, batch acc 0.9890
01:16:52.533   Training iter 350, batch loss 0.0496, batch acc 0.9866
01:16:52.618   Training iter 400, batch loss 0.0544, batch acc 0.9874
01:16:52.703   Training iter 450, batch loss 0.0534, batch acc 0.9870
01:16:52.782   Training iter 500, batch loss 0.0541, batch acc 0.9864
01:16:52.881   Training iter 550, batch loss 0.0482, batch acc 0.9884
01:16:52.982   Training iter 600, batch loss 0.0463, batch acc 0.9886
01:16:52.983 Training @ 37 epoch...
01:16:53.068   Training iter 50, batch loss 0.0447, batch acc 0.9892
01:16:53.174   Training iter 100, batch loss 0.0517, batch acc 0.9880
01:16:53.268   Training iter 150, batch loss 0.0479, batch acc 0.9884
01:16:53.384   Training iter 200, batch loss 0.0440, batch acc 0.9896
01:16:53.489   Training iter 250, batch loss 0.0482, batch acc 0.9896
01:16:53.590   Training iter 300, batch loss 0.0502, batch acc 0.9876
01:16:53.714   Training iter 350, batch loss 0.0527, batch acc 0.9868
01:16:53.820   Training iter 400, batch loss 0.0547, batch acc 0.9872
01:16:53.940   Training iter 450, batch loss 0.0535, batch acc 0.9862
01:16:54.031   Training iter 500, batch loss 0.0503, batch acc 0.9876
01:16:54.181   Training iter 550, batch loss 0.0472, batch acc 0.9888
01:16:54.281   Training iter 600, batch loss 0.0490, batch acc 0.9890
01:16:54.284 Training @ 38 epoch...
01:16:54.385   Training iter 50, batch loss 0.0462, batch acc 0.9884
01:16:54.464   Training iter 100, batch loss 0.0473, batch acc 0.9892
01:16:54.561   Training iter 150, batch loss 0.0545, batch acc 0.9856
01:16:54.649   Training iter 200, batch loss 0.0521, batch acc 0.9864
01:16:54.745   Training iter 250, batch loss 0.0544, batch acc 0.9868
01:16:54.833   Training iter 300, batch loss 0.0484, batch acc 0.9882
01:16:54.927   Training iter 350, batch loss 0.0511, batch acc 0.9876
01:16:55.019   Training iter 400, batch loss 0.0493, batch acc 0.9882
01:16:55.101   Training iter 450, batch loss 0.0408, batch acc 0.9910
01:16:55.187   Training iter 500, batch loss 0.0438, batch acc 0.9912
01:16:55.273   Training iter 550, batch loss 0.0565, batch acc 0.9856
01:16:55.359   Training iter 600, batch loss 0.0504, batch acc 0.9872
01:16:55.362 Training @ 39 epoch...
01:16:55.471   Training iter 50, batch loss 0.0462, batch acc 0.9888
01:16:55.615   Training iter 100, batch loss 0.0457, batch acc 0.9894
01:16:55.739   Training iter 150, batch loss 0.0467, batch acc 0.9894
01:16:55.820   Training iter 200, batch loss 0.0500, batch acc 0.9886
01:16:55.905   Training iter 250, batch loss 0.0466, batch acc 0.9902
01:16:55.983   Training iter 300, batch loss 0.0509, batch acc 0.9872
01:16:56.066   Training iter 350, batch loss 0.0548, batch acc 0.9852
01:16:56.151   Training iter 400, batch loss 0.0485, batch acc 0.9886
01:16:56.274   Training iter 450, batch loss 0.0470, batch acc 0.9908
01:16:56.357   Training iter 500, batch loss 0.0517, batch acc 0.9856
01:16:56.457   Training iter 550, batch loss 0.0495, batch acc 0.9874
01:16:56.566   Training iter 600, batch loss 0.0544, batch acc 0.9866
01:16:56.567 Training @ 40 epoch...
01:16:56.668   Training iter 50, batch loss 0.0510, batch acc 0.9872
01:16:56.747   Training iter 100, batch loss 0.0455, batch acc 0.9892
01:16:56.850   Training iter 150, batch loss 0.0486, batch acc 0.9896
01:16:56.955   Training iter 200, batch loss 0.0422, batch acc 0.9904
01:16:57.080   Training iter 250, batch loss 0.0462, batch acc 0.9888
01:16:57.205   Training iter 300, batch loss 0.0460, batch acc 0.9872
01:16:57.293   Training iter 350, batch loss 0.0489, batch acc 0.9878
01:16:57.365   Training iter 400, batch loss 0.0489, batch acc 0.9870
01:16:57.465   Training iter 450, batch loss 0.0495, batch acc 0.9884
01:16:57.548   Training iter 500, batch loss 0.0463, batch acc 0.9892
01:16:57.640   Training iter 550, batch loss 0.0535, batch acc 0.9872
01:16:57.720   Training iter 600, batch loss 0.0513, batch acc 0.9874
01:16:57.722 Testing @ 40 epoch...
01:16:57.780     Testing, total mean loss 0.07356, total acc 0.97660
01:16:57.780 Training @ 41 epoch...
01:16:58.012   Training iter 50, batch loss 0.0454, batch acc 0.9902
01:16:58.249   Training iter 100, batch loss 0.0436, batch acc 0.9914
01:16:58.403   Training iter 150, batch loss 0.0450, batch acc 0.9896
01:16:58.536   Training iter 200, batch loss 0.0435, batch acc 0.9906
01:16:58.753   Training iter 250, batch loss 0.0451, batch acc 0.9878
01:16:58.905   Training iter 300, batch loss 0.0492, batch acc 0.9872
01:16:59.312   Training iter 350, batch loss 0.0537, batch acc 0.9862
01:16:59.535   Training iter 400, batch loss 0.0477, batch acc 0.9890
01:16:59.701   Training iter 450, batch loss 0.0432, batch acc 0.9906
01:17:00.022   Training iter 500, batch loss 0.0551, batch acc 0.9868
01:17:00.432   Training iter 550, batch loss 0.0494, batch acc 0.9876
01:17:00.607   Training iter 600, batch loss 0.0477, batch acc 0.9870
01:17:00.608 Training @ 42 epoch...
01:17:00.763   Training iter 50, batch loss 0.0465, batch acc 0.9906
01:17:00.902   Training iter 100, batch loss 0.0446, batch acc 0.9896
01:17:01.081   Training iter 150, batch loss 0.0488, batch acc 0.9882
01:17:01.198   Training iter 200, batch loss 0.0478, batch acc 0.9884
01:17:01.390   Training iter 250, batch loss 0.0430, batch acc 0.9910
01:17:01.574   Training iter 300, batch loss 0.0475, batch acc 0.9906
01:17:01.798   Training iter 350, batch loss 0.0449, batch acc 0.9880
01:17:01.946   Training iter 400, batch loss 0.0501, batch acc 0.9874
01:17:02.046   Training iter 450, batch loss 0.0433, batch acc 0.9890
01:17:02.163   Training iter 500, batch loss 0.0520, batch acc 0.9864
01:17:02.273   Training iter 550, batch loss 0.0488, batch acc 0.9892
01:17:02.376   Training iter 600, batch loss 0.0512, batch acc 0.9868
01:17:02.377 Training @ 43 epoch...
01:17:02.482   Training iter 50, batch loss 0.0453, batch acc 0.9910
01:17:02.597   Training iter 100, batch loss 0.0459, batch acc 0.9900
01:17:02.736   Training iter 150, batch loss 0.0417, batch acc 0.9904
01:17:02.873   Training iter 200, batch loss 0.0460, batch acc 0.9892
01:17:03.020   Training iter 250, batch loss 0.0441, batch acc 0.9900
01:17:03.198   Training iter 300, batch loss 0.0530, batch acc 0.9854
01:17:03.346   Training iter 350, batch loss 0.0446, batch acc 0.9894
01:17:03.435   Training iter 400, batch loss 0.0483, batch acc 0.9874
01:17:03.530   Training iter 450, batch loss 0.0520, batch acc 0.9864
01:17:03.660   Training iter 500, batch loss 0.0483, batch acc 0.9894
01:17:03.748   Training iter 550, batch loss 0.0447, batch acc 0.9896
01:17:03.839   Training iter 600, batch loss 0.0456, batch acc 0.9906
01:17:03.840 Training @ 44 epoch...
01:17:03.923   Training iter 50, batch loss 0.0452, batch acc 0.9890
01:17:04.013   Training iter 100, batch loss 0.0483, batch acc 0.9892
01:17:04.107   Training iter 150, batch loss 0.0437, batch acc 0.9916
01:17:04.238   Training iter 200, batch loss 0.0461, batch acc 0.9870
01:17:04.327   Training iter 250, batch loss 0.0440, batch acc 0.9902
01:17:04.406   Training iter 300, batch loss 0.0478, batch acc 0.9876
01:17:04.571   Training iter 350, batch loss 0.0467, batch acc 0.9888
01:17:04.689   Training iter 400, batch loss 0.0487, batch acc 0.9880
01:17:04.838   Training iter 450, batch loss 0.0453, batch acc 0.9896
01:17:04.978   Training iter 500, batch loss 0.0524, batch acc 0.9862
01:17:05.085   Training iter 550, batch loss 0.0493, batch acc 0.9874
01:17:05.187   Training iter 600, batch loss 0.0428, batch acc 0.9896
01:17:05.188 Training @ 45 epoch...
01:17:05.297   Training iter 50, batch loss 0.0424, batch acc 0.9914
01:17:05.401   Training iter 100, batch loss 0.0436, batch acc 0.9898
01:17:05.534   Training iter 150, batch loss 0.0501, batch acc 0.9860
01:17:05.676   Training iter 200, batch loss 0.0441, batch acc 0.9894
01:17:05.780   Training iter 250, batch loss 0.0428, batch acc 0.9910
01:17:05.903   Training iter 300, batch loss 0.0467, batch acc 0.9916
01:17:06.023   Training iter 350, batch loss 0.0493, batch acc 0.9888
01:17:06.166   Training iter 400, batch loss 0.0496, batch acc 0.9878
01:17:06.279   Training iter 450, batch loss 0.0449, batch acc 0.9890
01:17:06.385   Training iter 500, batch loss 0.0464, batch acc 0.9890
01:17:06.499   Training iter 550, batch loss 0.0447, batch acc 0.9890
01:17:06.593   Training iter 600, batch loss 0.0462, batch acc 0.9904
01:17:06.593 Testing @ 45 epoch...
01:17:06.670     Testing, total mean loss 0.07310, total acc 0.97650
01:17:06.670 Training @ 46 epoch...
01:17:06.750   Training iter 50, batch loss 0.0430, batch acc 0.9908
01:17:06.846   Training iter 100, batch loss 0.0501, batch acc 0.9874
01:17:06.936   Training iter 150, batch loss 0.0503, batch acc 0.9872
01:17:07.043   Training iter 200, batch loss 0.0422, batch acc 0.9908
01:17:07.131   Training iter 250, batch loss 0.0467, batch acc 0.9896
01:17:07.214   Training iter 300, batch loss 0.0455, batch acc 0.9888
01:17:07.303   Training iter 350, batch loss 0.0431, batch acc 0.9896
01:17:07.416   Training iter 400, batch loss 0.0474, batch acc 0.9896
01:17:07.502   Training iter 450, batch loss 0.0435, batch acc 0.9902
01:17:07.588   Training iter 500, batch loss 0.0453, batch acc 0.9898
01:17:07.707   Training iter 550, batch loss 0.0466, batch acc 0.9884
01:17:07.822   Training iter 600, batch loss 0.0464, batch acc 0.9888
01:17:07.823 Training @ 47 epoch...
01:17:07.939   Training iter 50, batch loss 0.0415, batch acc 0.9904
01:17:08.053   Training iter 100, batch loss 0.0401, batch acc 0.9914
01:17:08.163   Training iter 150, batch loss 0.0441, batch acc 0.9886
01:17:08.278   Training iter 200, batch loss 0.0420, batch acc 0.9914
01:17:08.399   Training iter 250, batch loss 0.0499, batch acc 0.9862
01:17:08.571   Training iter 300, batch loss 0.0470, batch acc 0.9886
01:17:08.688   Training iter 350, batch loss 0.0421, batch acc 0.9906
01:17:08.773   Training iter 400, batch loss 0.0501, batch acc 0.9876
01:17:08.867   Training iter 450, batch loss 0.0470, batch acc 0.9880
01:17:08.969   Training iter 500, batch loss 0.0491, batch acc 0.9870
01:17:09.071   Training iter 550, batch loss 0.0471, batch acc 0.9890
01:17:09.183   Training iter 600, batch loss 0.0441, batch acc 0.9884
01:17:09.185 Training @ 48 epoch...
01:17:09.280   Training iter 50, batch loss 0.0448, batch acc 0.9904
01:17:09.380   Training iter 100, batch loss 0.0380, batch acc 0.9918
01:17:09.506   Training iter 150, batch loss 0.0504, batch acc 0.9886
01:17:09.611   Training iter 200, batch loss 0.0420, batch acc 0.9906
01:17:09.795   Training iter 250, batch loss 0.0463, batch acc 0.9864
01:17:09.915   Training iter 300, batch loss 0.0468, batch acc 0.9888
01:17:10.073   Training iter 350, batch loss 0.0455, batch acc 0.9898
01:17:10.186   Training iter 400, batch loss 0.0444, batch acc 0.9890
01:17:10.272   Training iter 450, batch loss 0.0459, batch acc 0.9910
01:17:10.369   Training iter 500, batch loss 0.0459, batch acc 0.9894
01:17:10.476   Training iter 550, batch loss 0.0531, batch acc 0.9866
01:17:10.571   Training iter 600, batch loss 0.0407, batch acc 0.9914
01:17:10.572 Training @ 49 epoch...
01:17:10.683   Training iter 50, batch loss 0.0403, batch acc 0.9898
01:17:10.808   Training iter 100, batch loss 0.0447, batch acc 0.9906
01:17:10.903   Training iter 150, batch loss 0.0389, batch acc 0.9914
01:17:11.022   Training iter 200, batch loss 0.0455, batch acc 0.9894
01:17:11.149   Training iter 250, batch loss 0.0447, batch acc 0.9898
01:17:11.282   Training iter 300, batch loss 0.0427, batch acc 0.9910
01:17:11.372   Training iter 350, batch loss 0.0446, batch acc 0.9900
01:17:11.454   Training iter 400, batch loss 0.0485, batch acc 0.9878
01:17:11.544   Training iter 450, batch loss 0.0486, batch acc 0.9884
01:17:11.629   Training iter 500, batch loss 0.0471, batch acc 0.9886
01:17:11.788   Training iter 550, batch loss 0.0480, batch acc 0.9898
01:17:11.876   Training iter 600, batch loss 0.0429, batch acc 0.9906
01:17:11.876 Training @ 50 epoch...
01:17:11.982   Training iter 50, batch loss 0.0440, batch acc 0.9904
01:17:12.062   Training iter 100, batch loss 0.0430, batch acc 0.9900
01:17:12.164   Training iter 150, batch loss 0.0455, batch acc 0.9898
01:17:12.256   Training iter 200, batch loss 0.0436, batch acc 0.9894
01:17:12.338   Training iter 250, batch loss 0.0446, batch acc 0.9890
01:17:12.418   Training iter 300, batch loss 0.0466, batch acc 0.9884
01:17:12.522   Training iter 350, batch loss 0.0464, batch acc 0.9892
01:17:12.603   Training iter 400, batch loss 0.0417, batch acc 0.9888
01:17:12.687   Training iter 450, batch loss 0.0460, batch acc 0.9904
01:17:12.784   Training iter 500, batch loss 0.0482, batch acc 0.9890
01:17:12.870   Training iter 550, batch loss 0.0461, batch acc 0.9880
01:17:12.958   Training iter 600, batch loss 0.0457, batch acc 0.9902
01:17:12.962 Testing @ 50 epoch...
01:17:13.005     Testing, total mean loss 0.07186, total acc 0.97790
01:17:13.005 Training @ 51 epoch...
01:17:13.095   Training iter 50, batch loss 0.0385, batch acc 0.9922
01:17:13.172   Training iter 100, batch loss 0.0440, batch acc 0.9902
01:17:13.276   Training iter 150, batch loss 0.0441, batch acc 0.9910
01:17:13.386   Training iter 200, batch loss 0.0427, batch acc 0.9908
01:17:13.502   Training iter 250, batch loss 0.0403, batch acc 0.9910
01:17:13.613   Training iter 300, batch loss 0.0450, batch acc 0.9894
01:17:13.721   Training iter 350, batch loss 0.0437, batch acc 0.9888
01:17:13.838   Training iter 400, batch loss 0.0417, batch acc 0.9910
01:17:13.932   Training iter 450, batch loss 0.0518, batch acc 0.9882
01:17:14.021   Training iter 500, batch loss 0.0488, batch acc 0.9890
01:17:14.109   Training iter 550, batch loss 0.0459, batch acc 0.9888
01:17:14.236   Training iter 600, batch loss 0.0462, batch acc 0.9866
01:17:14.238 Training @ 52 epoch...
01:17:14.388   Training iter 50, batch loss 0.0417, batch acc 0.9904
01:17:14.472   Training iter 100, batch loss 0.0451, batch acc 0.9896
01:17:14.554   Training iter 150, batch loss 0.0419, batch acc 0.9914
01:17:14.651   Training iter 200, batch loss 0.0472, batch acc 0.9878
01:17:14.734   Training iter 250, batch loss 0.0456, batch acc 0.9890
01:17:14.822   Training iter 300, batch loss 0.0430, batch acc 0.9910
01:17:14.920   Training iter 350, batch loss 0.0397, batch acc 0.9918
01:17:15.002   Training iter 400, batch loss 0.0459, batch acc 0.9886
01:17:15.089   Training iter 450, batch loss 0.0506, batch acc 0.9866
01:17:15.180   Training iter 500, batch loss 0.0432, batch acc 0.9912
01:17:15.270   Training iter 550, batch loss 0.0417, batch acc 0.9902
01:17:15.356   Training iter 600, batch loss 0.0467, batch acc 0.9900
01:17:15.357 Training @ 53 epoch...
01:17:15.456   Training iter 50, batch loss 0.0426, batch acc 0.9908
01:17:15.540   Training iter 100, batch loss 0.0456, batch acc 0.9916
01:17:15.638   Training iter 150, batch loss 0.0443, batch acc 0.9894
01:17:15.731   Training iter 200, batch loss 0.0402, batch acc 0.9898
01:17:15.814   Training iter 250, batch loss 0.0415, batch acc 0.9906
01:17:15.899   Training iter 300, batch loss 0.0501, batch acc 0.9880
01:17:15.999   Training iter 350, batch loss 0.0421, batch acc 0.9904
01:17:16.101   Training iter 400, batch loss 0.0418, batch acc 0.9906
01:17:16.202   Training iter 450, batch loss 0.0429, batch acc 0.9902
01:17:16.285   Training iter 500, batch loss 0.0453, batch acc 0.9874
01:17:16.402   Training iter 550, batch loss 0.0472, batch acc 0.9882
01:17:16.512   Training iter 600, batch loss 0.0446, batch acc 0.9884
01:17:16.513 Training @ 54 epoch...
01:17:16.615   Training iter 50, batch loss 0.0431, batch acc 0.9888
01:17:16.706   Training iter 100, batch loss 0.0420, batch acc 0.9904
01:17:16.825   Training iter 150, batch loss 0.0391, batch acc 0.9918
01:17:16.906   Training iter 200, batch loss 0.0447, batch acc 0.9900
01:17:16.998   Training iter 250, batch loss 0.0408, batch acc 0.9912
01:17:17.076   Training iter 300, batch loss 0.0442, batch acc 0.9912
01:17:17.162   Training iter 350, batch loss 0.0444, batch acc 0.9898
01:17:17.255   Training iter 400, batch loss 0.0456, batch acc 0.9914
01:17:17.334   Training iter 450, batch loss 0.0425, batch acc 0.9904
01:17:17.418   Training iter 500, batch loss 0.0486, batch acc 0.9876
01:17:17.501   Training iter 550, batch loss 0.0422, batch acc 0.9900
01:17:17.603   Training iter 600, batch loss 0.0452, batch acc 0.9874
01:17:17.604 Training @ 55 epoch...
01:17:17.695   Training iter 50, batch loss 0.0402, batch acc 0.9900
01:17:17.776   Training iter 100, batch loss 0.0441, batch acc 0.9910
01:17:17.871   Training iter 150, batch loss 0.0374, batch acc 0.9934
01:17:17.996   Training iter 200, batch loss 0.0476, batch acc 0.9864
01:17:18.115   Training iter 250, batch loss 0.0438, batch acc 0.9906
01:17:18.202   Training iter 300, batch loss 0.0357, batch acc 0.9920
01:17:18.286   Training iter 350, batch loss 0.0446, batch acc 0.9896
01:17:18.400   Training iter 400, batch loss 0.0483, batch acc 0.9882
01:17:18.486   Training iter 450, batch loss 0.0437, batch acc 0.9918
01:17:18.569   Training iter 500, batch loss 0.0462, batch acc 0.9882
01:17:18.655   Training iter 550, batch loss 0.0414, batch acc 0.9908
01:17:18.749   Training iter 600, batch loss 0.0485, batch acc 0.9878
01:17:18.750 Testing @ 55 epoch...
01:17:18.811     Testing, total mean loss 0.06986, total acc 0.97830
01:17:18.811 Training @ 56 epoch...
01:17:18.914   Training iter 50, batch loss 0.0372, batch acc 0.9920
01:17:19.022   Training iter 100, batch loss 0.0450, batch acc 0.9896
01:17:19.131   Training iter 150, batch loss 0.0451, batch acc 0.9902
01:17:19.226   Training iter 200, batch loss 0.0436, batch acc 0.9898
01:17:19.337   Training iter 250, batch loss 0.0389, batch acc 0.9926
01:17:19.461   Training iter 300, batch loss 0.0403, batch acc 0.9914
01:17:19.580   Training iter 350, batch loss 0.0419, batch acc 0.9898
01:17:19.717   Training iter 400, batch loss 0.0478, batch acc 0.9876
01:17:19.812   Training iter 450, batch loss 0.0454, batch acc 0.9896
01:17:19.911   Training iter 500, batch loss 0.0465, batch acc 0.9886
01:17:20.001   Training iter 550, batch loss 0.0401, batch acc 0.9904
01:17:20.082   Training iter 600, batch loss 0.0435, batch acc 0.9898
01:17:20.083 Training @ 57 epoch...
01:17:20.176   Training iter 50, batch loss 0.0443, batch acc 0.9892
01:17:20.272   Training iter 100, batch loss 0.0444, batch acc 0.9916
01:17:20.371   Training iter 150, batch loss 0.0403, batch acc 0.9916
01:17:20.453   Training iter 200, batch loss 0.0439, batch acc 0.9894
01:17:20.531   Training iter 250, batch loss 0.0420, batch acc 0.9890
01:17:20.608   Training iter 300, batch loss 0.0443, batch acc 0.9890
01:17:20.700   Training iter 350, batch loss 0.0385, batch acc 0.9918
01:17:20.785   Training iter 400, batch loss 0.0424, batch acc 0.9908
01:17:20.867   Training iter 450, batch loss 0.0443, batch acc 0.9896
01:17:20.967   Training iter 500, batch loss 0.0421, batch acc 0.9900
01:17:21.055   Training iter 550, batch loss 0.0429, batch acc 0.9910
01:17:21.150   Training iter 600, batch loss 0.0471, batch acc 0.9892
01:17:21.151 Training @ 58 epoch...
01:17:21.250   Training iter 50, batch loss 0.0459, batch acc 0.9908
01:17:21.334   Training iter 100, batch loss 0.0431, batch acc 0.9900
01:17:21.421   Training iter 150, batch loss 0.0410, batch acc 0.9898
01:17:21.522   Training iter 200, batch loss 0.0428, batch acc 0.9900
01:17:21.632   Training iter 250, batch loss 0.0372, batch acc 0.9930
01:17:21.746   Training iter 300, batch loss 0.0449, batch acc 0.9892
01:17:21.846   Training iter 350, batch loss 0.0442, batch acc 0.9902
01:17:21.949   Training iter 400, batch loss 0.0450, batch acc 0.9894
01:17:22.051   Training iter 450, batch loss 0.0444, batch acc 0.9888
01:17:22.162   Training iter 500, batch loss 0.0437, batch acc 0.9900
01:17:22.271   Training iter 550, batch loss 0.0412, batch acc 0.9908
01:17:22.367   Training iter 600, batch loss 0.0416, batch acc 0.9902
01:17:22.369 Training @ 59 epoch...
01:17:22.487   Training iter 50, batch loss 0.0424, batch acc 0.9914
01:17:22.567   Training iter 100, batch loss 0.0397, batch acc 0.9920
01:17:22.674   Training iter 150, batch loss 0.0371, batch acc 0.9922
01:17:22.753   Training iter 200, batch loss 0.0410, batch acc 0.9908
01:17:22.836   Training iter 250, batch loss 0.0451, batch acc 0.9896
01:17:22.943   Training iter 300, batch loss 0.0433, batch acc 0.9908
01:17:23.036   Training iter 350, batch loss 0.0408, batch acc 0.9910
01:17:23.118   Training iter 400, batch loss 0.0422, batch acc 0.9892
01:17:23.194   Training iter 450, batch loss 0.0415, batch acc 0.9904
01:17:23.293   Training iter 500, batch loss 0.0389, batch acc 0.9924
01:17:23.399   Training iter 550, batch loss 0.0468, batch acc 0.9890
01:17:23.481   Training iter 600, batch loss 0.0443, batch acc 0.9908
01:17:23.483 Training @ 60 epoch...
01:17:23.571   Training iter 50, batch loss 0.0375, batch acc 0.9936
01:17:23.666   Training iter 100, batch loss 0.0409, batch acc 0.9900
01:17:23.751   Training iter 150, batch loss 0.0393, batch acc 0.9916
01:17:23.850   Training iter 200, batch loss 0.0453, batch acc 0.9896
01:17:23.945   Training iter 250, batch loss 0.0389, batch acc 0.9908
01:17:24.027   Training iter 300, batch loss 0.0411, batch acc 0.9906
01:17:24.127   Training iter 350, batch loss 0.0466, batch acc 0.9886
01:17:24.245   Training iter 400, batch loss 0.0420, batch acc 0.9894
01:17:24.343   Training iter 450, batch loss 0.0416, batch acc 0.9916
01:17:24.443   Training iter 500, batch loss 0.0453, batch acc 0.9906
01:17:24.549   Training iter 550, batch loss 0.0416, batch acc 0.9908
01:17:24.668   Training iter 600, batch loss 0.0428, batch acc 0.9902
01:17:24.670 Testing @ 60 epoch...
01:17:24.738     Testing, total mean loss 0.07072, total acc 0.97840
01:17:24.739 Training @ 61 epoch...
01:17:24.871   Training iter 50, batch loss 0.0428, batch acc 0.9890
01:17:24.981   Training iter 100, batch loss 0.0377, batch acc 0.9918
01:17:25.117   Training iter 150, batch loss 0.0431, batch acc 0.9900
01:17:25.235   Training iter 200, batch loss 0.0373, batch acc 0.9930
01:17:25.327   Training iter 250, batch loss 0.0395, batch acc 0.9926
01:17:25.417   Training iter 300, batch loss 0.0460, batch acc 0.9884
01:17:25.513   Training iter 350, batch loss 0.0438, batch acc 0.9878
01:17:25.679   Training iter 400, batch loss 0.0445, batch acc 0.9898
01:17:25.800   Training iter 450, batch loss 0.0460, batch acc 0.9886
01:17:25.886   Training iter 500, batch loss 0.0464, batch acc 0.9886
01:17:25.976   Training iter 550, batch loss 0.0410, batch acc 0.9904
01:17:26.059   Training iter 600, batch loss 0.0408, batch acc 0.9912
01:17:26.060 Training @ 62 epoch...
01:17:26.149   Training iter 50, batch loss 0.0372, batch acc 0.9942
01:17:26.242   Training iter 100, batch loss 0.0386, batch acc 0.9904
01:17:26.337   Training iter 150, batch loss 0.0470, batch acc 0.9886
01:17:26.432   Training iter 200, batch loss 0.0430, batch acc 0.9920
01:17:26.528   Training iter 250, batch loss 0.0440, batch acc 0.9900
01:17:26.712   Training iter 300, batch loss 0.0377, batch acc 0.9918
01:17:26.805   Training iter 350, batch loss 0.0379, batch acc 0.9922
01:17:26.893   Training iter 400, batch loss 0.0431, batch acc 0.9906
01:17:27.015   Training iter 450, batch loss 0.0436, batch acc 0.9900
01:17:27.146   Training iter 500, batch loss 0.0419, batch acc 0.9910
01:17:27.272   Training iter 550, batch loss 0.0417, batch acc 0.9928
01:17:27.383   Training iter 600, batch loss 0.0456, batch acc 0.9900
01:17:27.384 Training @ 63 epoch...
01:17:27.500   Training iter 50, batch loss 0.0403, batch acc 0.9926
01:17:27.599   Training iter 100, batch loss 0.0372, batch acc 0.9928
01:17:27.718   Training iter 150, batch loss 0.0398, batch acc 0.9912
01:17:27.836   Training iter 200, batch loss 0.0413, batch acc 0.9912
01:17:27.969   Training iter 250, batch loss 0.0449, batch acc 0.9894
01:17:28.099   Training iter 300, batch loss 0.0395, batch acc 0.9918
01:17:28.242   Training iter 350, batch loss 0.0426, batch acc 0.9904
01:17:28.484   Training iter 400, batch loss 0.0419, batch acc 0.9904
01:17:28.587   Training iter 450, batch loss 0.0416, batch acc 0.9910
01:17:28.676   Training iter 500, batch loss 0.0431, batch acc 0.9896
01:17:28.759   Training iter 550, batch loss 0.0423, batch acc 0.9892
01:17:28.848   Training iter 600, batch loss 0.0382, batch acc 0.9908
01:17:28.849 Training @ 64 epoch...
01:17:28.934   Training iter 50, batch loss 0.0365, batch acc 0.9922
01:17:29.028   Training iter 100, batch loss 0.0402, batch acc 0.9918
01:17:29.112   Training iter 150, batch loss 0.0455, batch acc 0.9886
01:17:29.186   Training iter 200, batch loss 0.0428, batch acc 0.9894
01:17:29.272   Training iter 250, batch loss 0.0415, batch acc 0.9918
01:17:29.368   Training iter 300, batch loss 0.0399, batch acc 0.9912
01:17:29.461   Training iter 350, batch loss 0.0421, batch acc 0.9916
01:17:29.556   Training iter 400, batch loss 0.0425, batch acc 0.9908
01:17:29.649   Training iter 450, batch loss 0.0431, batch acc 0.9896
01:17:29.734   Training iter 500, batch loss 0.0418, batch acc 0.9904
01:17:29.829   Training iter 550, batch loss 0.0405, batch acc 0.9906
01:17:29.930   Training iter 600, batch loss 0.0395, batch acc 0.9920
01:17:29.931 Training @ 65 epoch...
01:17:30.033   Training iter 50, batch loss 0.0400, batch acc 0.9928
01:17:30.133   Training iter 100, batch loss 0.0359, batch acc 0.9928
01:17:30.244   Training iter 150, batch loss 0.0418, batch acc 0.9906
01:17:30.343   Training iter 200, batch loss 0.0385, batch acc 0.9928
01:17:30.439   Training iter 250, batch loss 0.0401, batch acc 0.9908
01:17:30.522   Training iter 300, batch loss 0.0402, batch acc 0.9910
01:17:30.619   Training iter 350, batch loss 0.0426, batch acc 0.9906
01:17:30.739   Training iter 400, batch loss 0.0407, batch acc 0.9890
01:17:30.865   Training iter 450, batch loss 0.0424, batch acc 0.9904
01:17:30.985   Training iter 500, batch loss 0.0399, batch acc 0.9924
01:17:31.096   Training iter 550, batch loss 0.0449, batch acc 0.9878
01:17:31.200   Training iter 600, batch loss 0.0469, batch acc 0.9872
01:17:31.201 Testing @ 65 epoch...
01:17:31.250     Testing, total mean loss 0.06781, total acc 0.97900
01:17:31.250 Training @ 66 epoch...
01:17:31.343   Training iter 50, batch loss 0.0422, batch acc 0.9902
01:17:31.430   Training iter 100, batch loss 0.0392, batch acc 0.9892
01:17:31.503   Training iter 150, batch loss 0.0408, batch acc 0.9914
01:17:31.598   Training iter 200, batch loss 0.0402, batch acc 0.9900
01:17:31.679   Training iter 250, batch loss 0.0412, batch acc 0.9890
01:17:31.764   Training iter 300, batch loss 0.0437, batch acc 0.9906
01:17:31.847   Training iter 350, batch loss 0.0402, batch acc 0.9908
01:17:31.934   Training iter 400, batch loss 0.0362, batch acc 0.9928
01:17:32.021   Training iter 450, batch loss 0.0395, batch acc 0.9924
01:17:32.112   Training iter 500, batch loss 0.0423, batch acc 0.9892
01:17:32.226   Training iter 550, batch loss 0.0416, batch acc 0.9922
01:17:32.332   Training iter 600, batch loss 0.0437, batch acc 0.9892
01:17:32.333 Training @ 67 epoch...
01:17:32.427   Training iter 50, batch loss 0.0448, batch acc 0.9910
01:17:32.514   Training iter 100, batch loss 0.0379, batch acc 0.9928
01:17:32.614   Training iter 150, batch loss 0.0440, batch acc 0.9898
01:17:32.695   Training iter 200, batch loss 0.0413, batch acc 0.9898
01:17:32.779   Training iter 250, batch loss 0.0377, batch acc 0.9906
01:17:32.885   Training iter 300, batch loss 0.0393, batch acc 0.9922
01:17:32.983   Training iter 350, batch loss 0.0394, batch acc 0.9926
01:17:33.082   Training iter 400, batch loss 0.0444, batch acc 0.9904
01:17:33.186   Training iter 450, batch loss 0.0406, batch acc 0.9924
01:17:33.294   Training iter 500, batch loss 0.0432, batch acc 0.9914
01:17:33.417   Training iter 550, batch loss 0.0429, batch acc 0.9910
01:17:33.538   Training iter 600, batch loss 0.0403, batch acc 0.9924
01:17:33.539 Training @ 68 epoch...
01:17:33.621   Training iter 50, batch loss 0.0383, batch acc 0.9918
01:17:33.713   Training iter 100, batch loss 0.0379, batch acc 0.9926
01:17:33.805   Training iter 150, batch loss 0.0363, batch acc 0.9936
01:17:33.899   Training iter 200, batch loss 0.0373, batch acc 0.9926
01:17:33.992   Training iter 250, batch loss 0.0457, batch acc 0.9882
01:17:34.084   Training iter 300, batch loss 0.0387, batch acc 0.9924
01:17:34.168   Training iter 350, batch loss 0.0368, batch acc 0.9912
01:17:34.259   Training iter 400, batch loss 0.0464, batch acc 0.9886
01:17:34.345   Training iter 450, batch loss 0.0453, batch acc 0.9902
01:17:34.430   Training iter 500, batch loss 0.0435, batch acc 0.9888
01:17:34.506   Training iter 550, batch loss 0.0442, batch acc 0.9902
01:17:34.596   Training iter 600, batch loss 0.0393, batch acc 0.9926
01:17:34.596 Training @ 69 epoch...
01:17:34.696   Training iter 50, batch loss 0.0397, batch acc 0.9900
01:17:34.799   Training iter 100, batch loss 0.0381, batch acc 0.9916
01:17:34.903   Training iter 150, batch loss 0.0388, batch acc 0.9910
01:17:35.066   Training iter 200, batch loss 0.0408, batch acc 0.9910
01:17:35.160   Training iter 250, batch loss 0.0468, batch acc 0.9896
01:17:35.254   Training iter 300, batch loss 0.0412, batch acc 0.9920
01:17:35.337   Training iter 350, batch loss 0.0363, batch acc 0.9918
01:17:35.481   Training iter 400, batch loss 0.0410, batch acc 0.9886
01:17:35.619   Training iter 450, batch loss 0.0449, batch acc 0.9904
01:17:35.714   Training iter 500, batch loss 0.0359, batch acc 0.9934
01:17:35.820   Training iter 550, batch loss 0.0414, batch acc 0.9912
01:17:35.923   Training iter 600, batch loss 0.0396, batch acc 0.9922
01:17:35.924 Training @ 70 epoch...
01:17:36.013   Training iter 50, batch loss 0.0386, batch acc 0.9928
01:17:36.130   Training iter 100, batch loss 0.0367, batch acc 0.9936
01:17:36.236   Training iter 150, batch loss 0.0457, batch acc 0.9902
01:17:36.371   Training iter 200, batch loss 0.0382, batch acc 0.9912
01:17:36.455   Training iter 250, batch loss 0.0364, batch acc 0.9934
01:17:36.543   Training iter 300, batch loss 0.0421, batch acc 0.9892
01:17:36.682   Training iter 350, batch loss 0.0393, batch acc 0.9920
01:17:36.782   Training iter 400, batch loss 0.0381, batch acc 0.9900
01:17:36.880   Training iter 450, batch loss 0.0394, batch acc 0.9928
01:17:37.041   Training iter 500, batch loss 0.0389, batch acc 0.9918
01:17:37.135   Training iter 550, batch loss 0.0471, batch acc 0.9892
01:17:37.234   Training iter 600, batch loss 0.0445, batch acc 0.9890
01:17:37.234 Testing @ 70 epoch...
01:17:37.288     Testing, total mean loss 0.06814, total acc 0.97960
01:17:37.288 Training @ 71 epoch...
01:17:37.367   Training iter 50, batch loss 0.0388, batch acc 0.9922
01:17:37.447   Training iter 100, batch loss 0.0391, batch acc 0.9916
01:17:37.539   Training iter 150, batch loss 0.0404, batch acc 0.9918
01:17:37.632   Training iter 200, batch loss 0.0440, batch acc 0.9920
01:17:37.727   Training iter 250, batch loss 0.0329, batch acc 0.9944
01:17:37.815   Training iter 300, batch loss 0.0396, batch acc 0.9916
01:17:37.913   Training iter 350, batch loss 0.0381, batch acc 0.9926
01:17:38.015   Training iter 400, batch loss 0.0371, batch acc 0.9930
01:17:38.102   Training iter 450, batch loss 0.0447, batch acc 0.9888
01:17:38.231   Training iter 500, batch loss 0.0379, batch acc 0.9922
01:17:38.318   Training iter 550, batch loss 0.0402, batch acc 0.9920
01:17:38.435   Training iter 600, batch loss 0.0456, batch acc 0.9902
01:17:38.438 Training @ 72 epoch...
01:17:38.542   Training iter 50, batch loss 0.0374, batch acc 0.9936
01:17:38.646   Training iter 100, batch loss 0.0355, batch acc 0.9934
01:17:38.742   Training iter 150, batch loss 0.0419, batch acc 0.9902
01:17:38.852   Training iter 200, batch loss 0.0404, batch acc 0.9902
01:17:38.958   Training iter 250, batch loss 0.0386, batch acc 0.9920
01:17:39.068   Training iter 300, batch loss 0.0411, batch acc 0.9906
01:17:39.195   Training iter 350, batch loss 0.0418, batch acc 0.9902
01:17:39.274   Training iter 400, batch loss 0.0435, batch acc 0.9896
01:17:39.359   Training iter 450, batch loss 0.0371, batch acc 0.9926
01:17:39.448   Training iter 500, batch loss 0.0423, batch acc 0.9916
01:17:39.531   Training iter 550, batch loss 0.0418, batch acc 0.9908
01:17:39.615   Training iter 600, batch loss 0.0435, batch acc 0.9892
01:17:39.617 Training @ 73 epoch...
01:17:39.734   Training iter 50, batch loss 0.0370, batch acc 0.9928
01:17:39.822   Training iter 100, batch loss 0.0373, batch acc 0.9918
01:17:39.910   Training iter 150, batch loss 0.0401, batch acc 0.9908
01:17:39.995   Training iter 200, batch loss 0.0409, batch acc 0.9908
01:17:40.067   Training iter 250, batch loss 0.0415, batch acc 0.9912
01:17:40.170   Training iter 300, batch loss 0.0415, batch acc 0.9906
01:17:40.258   Training iter 350, batch loss 0.0415, batch acc 0.9892
01:17:40.338   Training iter 400, batch loss 0.0414, batch acc 0.9904
01:17:40.431   Training iter 450, batch loss 0.0418, batch acc 0.9904
01:17:40.520   Training iter 500, batch loss 0.0421, batch acc 0.9898
01:17:40.612   Training iter 550, batch loss 0.0391, batch acc 0.9926
01:17:40.699   Training iter 600, batch loss 0.0406, batch acc 0.9922
01:17:40.701 Training @ 74 epoch...
01:17:40.810   Training iter 50, batch loss 0.0402, batch acc 0.9918
01:17:40.896   Training iter 100, batch loss 0.0411, batch acc 0.9908
01:17:40.994   Training iter 150, batch loss 0.0383, batch acc 0.9912
01:17:41.083   Training iter 200, batch loss 0.0376, batch acc 0.9914
01:17:41.186   Training iter 250, batch loss 0.0375, batch acc 0.9930
01:17:41.286   Training iter 300, batch loss 0.0450, batch acc 0.9902
01:17:41.394   Training iter 350, batch loss 0.0373, batch acc 0.9920
01:17:41.497   Training iter 400, batch loss 0.0383, batch acc 0.9916
01:17:41.610   Training iter 450, batch loss 0.0412, batch acc 0.9912
01:17:41.728   Training iter 500, batch loss 0.0402, batch acc 0.9916
01:17:41.829   Training iter 550, batch loss 0.0455, batch acc 0.9896
01:17:41.949   Training iter 600, batch loss 0.0396, batch acc 0.9920
01:17:41.952 Training @ 75 epoch...
01:17:42.047   Training iter 50, batch loss 0.0382, batch acc 0.9916
01:17:42.153   Training iter 100, batch loss 0.0394, batch acc 0.9900
01:17:42.246   Training iter 150, batch loss 0.0363, batch acc 0.9928
01:17:42.335   Training iter 200, batch loss 0.0396, batch acc 0.9922
01:17:42.433   Training iter 250, batch loss 0.0357, batch acc 0.9916
01:17:42.527   Training iter 300, batch loss 0.0394, batch acc 0.9902
01:17:42.604   Training iter 350, batch loss 0.0424, batch acc 0.9920
01:17:42.687   Training iter 400, batch loss 0.0407, batch acc 0.9900
01:17:42.768   Training iter 450, batch loss 0.0450, batch acc 0.9902
01:17:42.874   Training iter 500, batch loss 0.0387, batch acc 0.9910
01:17:42.970   Training iter 550, batch loss 0.0395, batch acc 0.9914
01:17:43.063   Training iter 600, batch loss 0.0376, batch acc 0.9928
01:17:43.063 Testing @ 75 epoch...
01:17:43.210     Testing, total mean loss 0.06847, total acc 0.97790
01:17:43.210 Training @ 76 epoch...
01:17:43.305   Training iter 50, batch loss 0.0406, batch acc 0.9908
01:17:43.401   Training iter 100, batch loss 0.0419, batch acc 0.9890
01:17:43.484   Training iter 150, batch loss 0.0394, batch acc 0.9910
01:17:43.570   Training iter 200, batch loss 0.0398, batch acc 0.9916
01:17:43.667   Training iter 250, batch loss 0.0429, batch acc 0.9916
01:17:43.794   Training iter 300, batch loss 0.0344, batch acc 0.9938
01:17:43.893   Training iter 350, batch loss 0.0380, batch acc 0.9920
01:17:43.988   Training iter 400, batch loss 0.0389, batch acc 0.9924
01:17:44.087   Training iter 450, batch loss 0.0366, batch acc 0.9916
01:17:44.206   Training iter 500, batch loss 0.0398, batch acc 0.9914
01:17:44.319   Training iter 550, batch loss 0.0382, batch acc 0.9926
01:17:44.418   Training iter 600, batch loss 0.0455, batch acc 0.9882
01:17:44.419 Training @ 77 epoch...
01:17:44.533   Training iter 50, batch loss 0.0363, batch acc 0.9926
01:17:44.642   Training iter 100, batch loss 0.0403, batch acc 0.9928
01:17:44.743   Training iter 150, batch loss 0.0372, batch acc 0.9936
01:17:44.875   Training iter 200, batch loss 0.0415, batch acc 0.9904
01:17:44.951   Training iter 250, batch loss 0.0378, batch acc 0.9906
01:17:45.066   Training iter 300, batch loss 0.0379, batch acc 0.9936
01:17:45.155   Training iter 350, batch loss 0.0379, batch acc 0.9928
01:17:45.238   Training iter 400, batch loss 0.0413, batch acc 0.9910
01:17:45.332   Training iter 450, batch loss 0.0440, batch acc 0.9898
01:17:45.416   Training iter 500, batch loss 0.0405, batch acc 0.9906
01:17:45.516   Training iter 550, batch loss 0.0452, batch acc 0.9884
01:17:45.665   Training iter 600, batch loss 0.0392, batch acc 0.9906
01:17:45.667 Training @ 78 epoch...
01:17:45.751   Training iter 50, batch loss 0.0416, batch acc 0.9914
01:17:45.832   Training iter 100, batch loss 0.0374, batch acc 0.9924
01:17:45.927   Training iter 150, batch loss 0.0381, batch acc 0.9920
01:17:46.016   Training iter 200, batch loss 0.0378, batch acc 0.9910
01:17:46.138   Training iter 250, batch loss 0.0406, batch acc 0.9920
01:17:46.236   Training iter 300, batch loss 0.0334, batch acc 0.9938
01:17:46.346   Training iter 350, batch loss 0.0395, batch acc 0.9920
01:17:46.438   Training iter 400, batch loss 0.0419, batch acc 0.9908
01:17:46.532   Training iter 450, batch loss 0.0440, batch acc 0.9896
01:17:46.612   Training iter 500, batch loss 0.0399, batch acc 0.9904
01:17:46.693   Training iter 550, batch loss 0.0373, batch acc 0.9930
01:17:46.779   Training iter 600, batch loss 0.0398, batch acc 0.9912
01:17:46.780 Training @ 79 epoch...
01:17:46.875   Training iter 50, batch loss 0.0442, batch acc 0.9900
01:17:46.972   Training iter 100, batch loss 0.0359, batch acc 0.9932
01:17:47.091   Training iter 150, batch loss 0.0424, batch acc 0.9900
01:17:47.197   Training iter 200, batch loss 0.0351, batch acc 0.9932
01:17:47.311   Training iter 250, batch loss 0.0395, batch acc 0.9912
01:17:47.419   Training iter 300, batch loss 0.0379, batch acc 0.9928
01:17:47.539   Training iter 350, batch loss 0.0367, batch acc 0.9922
01:17:47.708   Training iter 400, batch loss 0.0373, batch acc 0.9928
01:17:47.800   Training iter 450, batch loss 0.0390, batch acc 0.9910
01:17:47.889   Training iter 500, batch loss 0.0473, batch acc 0.9866
01:17:47.987   Training iter 550, batch loss 0.0417, batch acc 0.9904
01:17:48.075   Training iter 600, batch loss 0.0384, batch acc 0.9932
01:17:48.077 Training @ 80 epoch...
01:17:48.166   Training iter 50, batch loss 0.0398, batch acc 0.9902
01:17:48.268   Training iter 100, batch loss 0.0385, batch acc 0.9906
01:17:48.361   Training iter 150, batch loss 0.0389, batch acc 0.9924
01:17:48.445   Training iter 200, batch loss 0.0377, batch acc 0.9918
01:17:48.530   Training iter 250, batch loss 0.0394, batch acc 0.9914
01:17:48.627   Training iter 300, batch loss 0.0410, batch acc 0.9900
01:17:48.715   Training iter 350, batch loss 0.0383, batch acc 0.9926
01:17:48.802   Training iter 400, batch loss 0.0426, batch acc 0.9908
01:17:48.891   Training iter 450, batch loss 0.0443, batch acc 0.9892
01:17:48.979   Training iter 500, batch loss 0.0391, batch acc 0.9914
01:17:49.081   Training iter 550, batch loss 0.0395, batch acc 0.9916
01:17:49.163   Training iter 600, batch loss 0.0406, batch acc 0.9910
01:17:49.165 Testing @ 80 epoch...
01:17:49.225     Testing, total mean loss 0.06700, total acc 0.97940
01:17:49.225 Training @ 81 epoch...
01:17:49.310   Training iter 50, batch loss 0.0358, batch acc 0.9926
01:17:49.408   Training iter 100, batch loss 0.0436, batch acc 0.9908
01:17:49.499   Training iter 150, batch loss 0.0330, batch acc 0.9942
01:17:49.580   Training iter 200, batch loss 0.0407, batch acc 0.9912
01:17:49.702   Training iter 250, batch loss 0.0395, batch acc 0.9922
01:17:49.812   Training iter 300, batch loss 0.0367, batch acc 0.9912
01:17:49.913   Training iter 350, batch loss 0.0397, batch acc 0.9910
01:17:50.017   Training iter 400, batch loss 0.0427, batch acc 0.9906
01:17:50.129   Training iter 450, batch loss 0.0405, batch acc 0.9918
01:17:50.236   Training iter 500, batch loss 0.0371, batch acc 0.9930
01:17:50.350   Training iter 550, batch loss 0.0396, batch acc 0.9898
01:17:50.464   Training iter 600, batch loss 0.0415, batch acc 0.9906
01:17:50.465 Training @ 82 epoch...
01:17:50.584   Training iter 50, batch loss 0.0357, batch acc 0.9920
01:17:50.665   Training iter 100, batch loss 0.0374, batch acc 0.9938
01:17:50.751   Training iter 150, batch loss 0.0426, batch acc 0.9910
01:17:50.843   Training iter 200, batch loss 0.0383, batch acc 0.9918
01:17:50.931   Training iter 250, batch loss 0.0345, batch acc 0.9944
01:17:51.017   Training iter 300, batch loss 0.0391, batch acc 0.9910
01:17:51.120   Training iter 350, batch loss 0.0372, batch acc 0.9926
01:17:51.209   Training iter 400, batch loss 0.0425, batch acc 0.9916
01:17:51.292   Training iter 450, batch loss 0.0414, batch acc 0.9910
01:17:51.380   Training iter 500, batch loss 0.0379, batch acc 0.9912
01:17:51.469   Training iter 550, batch loss 0.0434, batch acc 0.9918
01:17:51.565   Training iter 600, batch loss 0.0398, batch acc 0.9900
01:17:51.567 Training @ 83 epoch...
01:17:51.657   Training iter 50, batch loss 0.0378, batch acc 0.9902
01:17:51.746   Training iter 100, batch loss 0.0408, batch acc 0.9926
01:17:51.835   Training iter 150, batch loss 0.0366, batch acc 0.9924
01:17:51.917   Training iter 200, batch loss 0.0396, batch acc 0.9916
01:17:52.007   Training iter 250, batch loss 0.0407, batch acc 0.9916
01:17:52.097   Training iter 300, batch loss 0.0378, batch acc 0.9926
01:17:52.197   Training iter 350, batch loss 0.0359, batch acc 0.9930
01:17:52.284   Training iter 400, batch loss 0.0423, batch acc 0.9908
01:17:52.366   Training iter 450, batch loss 0.0407, batch acc 0.9908
01:17:52.457   Training iter 500, batch loss 0.0358, batch acc 0.9926
01:17:52.547   Training iter 550, batch loss 0.0394, batch acc 0.9920
01:17:52.665   Training iter 600, batch loss 0.0400, batch acc 0.9912
01:17:52.667 Training @ 84 epoch...
01:17:52.786   Training iter 50, batch loss 0.0329, batch acc 0.9940
01:17:52.896   Training iter 100, batch loss 0.0395, batch acc 0.9916
01:17:52.993   Training iter 150, batch loss 0.0375, batch acc 0.9934
01:17:53.092   Training iter 200, batch loss 0.0392, batch acc 0.9930
01:17:53.192   Training iter 250, batch loss 0.0405, batch acc 0.9918
01:17:53.302   Training iter 300, batch loss 0.0355, batch acc 0.9934
01:17:53.418   Training iter 350, batch loss 0.0394, batch acc 0.9922
01:17:53.531   Training iter 400, batch loss 0.0381, batch acc 0.9928
01:17:53.617   Training iter 450, batch loss 0.0433, batch acc 0.9896
01:17:53.697   Training iter 500, batch loss 0.0385, batch acc 0.9920
01:17:53.786   Training iter 550, batch loss 0.0418, batch acc 0.9910
01:17:53.879   Training iter 600, batch loss 0.0379, batch acc 0.9910
01:17:53.879 Training @ 85 epoch...
01:17:54.052   Training iter 50, batch loss 0.0402, batch acc 0.9918
01:17:54.144   Training iter 100, batch loss 0.0396, batch acc 0.9918
01:17:54.232   Training iter 150, batch loss 0.0345, batch acc 0.9936
01:17:54.328   Training iter 200, batch loss 0.0382, batch acc 0.9924
01:17:54.424   Training iter 250, batch loss 0.0349, batch acc 0.9916
01:17:54.518   Training iter 300, batch loss 0.0362, batch acc 0.9924
01:17:54.615   Training iter 350, batch loss 0.0438, batch acc 0.9890
01:17:54.716   Training iter 400, batch loss 0.0384, batch acc 0.9940
01:17:54.811   Training iter 450, batch loss 0.0456, batch acc 0.9904
01:17:54.902   Training iter 500, batch loss 0.0404, batch acc 0.9908
01:17:54.993   Training iter 550, batch loss 0.0351, batch acc 0.9940
01:17:55.098   Training iter 600, batch loss 0.0405, batch acc 0.9924
01:17:55.100 Testing @ 85 epoch...
01:17:55.150     Testing, total mean loss 0.06695, total acc 0.97950
01:17:55.150 Training @ 86 epoch...
01:17:55.237   Training iter 50, batch loss 0.0386, batch acc 0.9924
01:17:55.333   Training iter 100, batch loss 0.0331, batch acc 0.9938
01:17:55.419   Training iter 150, batch loss 0.0383, batch acc 0.9918
01:17:55.499   Training iter 200, batch loss 0.0385, batch acc 0.9924
01:17:55.598   Training iter 250, batch loss 0.0391, batch acc 0.9928
01:17:55.710   Training iter 300, batch loss 0.0392, batch acc 0.9924
01:17:55.816   Training iter 350, batch loss 0.0384, batch acc 0.9894
01:17:55.929   Training iter 400, batch loss 0.0402, batch acc 0.9908
01:17:56.014   Training iter 450, batch loss 0.0405, batch acc 0.9922
01:17:56.126   Training iter 500, batch loss 0.0441, batch acc 0.9890
01:17:56.245   Training iter 550, batch loss 0.0383, batch acc 0.9922
01:17:56.399   Training iter 600, batch loss 0.0372, batch acc 0.9934
01:17:56.399 Training @ 87 epoch...
01:17:56.540   Training iter 50, batch loss 0.0398, batch acc 0.9914
01:17:56.631   Training iter 100, batch loss 0.0361, batch acc 0.9948
01:17:56.708   Training iter 150, batch loss 0.0358, batch acc 0.9926
01:17:56.787   Training iter 200, batch loss 0.0380, batch acc 0.9908
01:17:56.876   Training iter 250, batch loss 0.0386, batch acc 0.9924
01:17:56.962   Training iter 300, batch loss 0.0405, batch acc 0.9918
01:17:57.046   Training iter 350, batch loss 0.0385, batch acc 0.9940
01:17:57.140   Training iter 400, batch loss 0.0404, batch acc 0.9908
01:17:57.248   Training iter 450, batch loss 0.0365, batch acc 0.9922
01:17:57.334   Training iter 500, batch loss 0.0383, batch acc 0.9900
01:17:57.425   Training iter 550, batch loss 0.0422, batch acc 0.9902
01:17:57.509   Training iter 600, batch loss 0.0396, batch acc 0.9906
01:17:57.509 Training @ 88 epoch...
01:17:57.598   Training iter 50, batch loss 0.0359, batch acc 0.9934
01:17:57.682   Training iter 100, batch loss 0.0366, batch acc 0.9916
01:17:57.771   Training iter 150, batch loss 0.0354, batch acc 0.9918
01:17:57.860   Training iter 200, batch loss 0.0415, batch acc 0.9910
01:17:57.947   Training iter 250, batch loss 0.0434, batch acc 0.9912
01:17:58.028   Training iter 300, batch loss 0.0346, batch acc 0.9944
01:17:58.117   Training iter 350, batch loss 0.0359, batch acc 0.9930
01:17:58.213   Training iter 400, batch loss 0.0435, batch acc 0.9894
01:17:58.298   Training iter 450, batch loss 0.0387, batch acc 0.9920
01:17:58.409   Training iter 500, batch loss 0.0371, batch acc 0.9924
01:17:58.522   Training iter 550, batch loss 0.0424, batch acc 0.9898
01:17:58.629   Training iter 600, batch loss 0.0395, batch acc 0.9926
01:17:58.630 Training @ 89 epoch...
01:17:58.745   Training iter 50, batch loss 0.0359, batch acc 0.9936
01:17:58.854   Training iter 100, batch loss 0.0352, batch acc 0.9924
01:17:58.969   Training iter 150, batch loss 0.0409, batch acc 0.9902
01:17:59.060   Training iter 200, batch loss 0.0380, batch acc 0.9924
01:17:59.138   Training iter 250, batch loss 0.0388, batch acc 0.9910
01:17:59.224   Training iter 300, batch loss 0.0361, batch acc 0.9920
01:17:59.313   Training iter 350, batch loss 0.0398, batch acc 0.9928
01:17:59.400   Training iter 400, batch loss 0.0367, batch acc 0.9922
01:17:59.480   Training iter 450, batch loss 0.0375, batch acc 0.9922
01:17:59.568   Training iter 500, batch loss 0.0424, batch acc 0.9898
01:17:59.653   Training iter 550, batch loss 0.0415, batch acc 0.9912
01:17:59.731   Training iter 600, batch loss 0.0418, batch acc 0.9914
01:17:59.731 Training @ 90 epoch...
01:17:59.812   Training iter 50, batch loss 0.0370, batch acc 0.9926
01:17:59.899   Training iter 100, batch loss 0.0357, batch acc 0.9946
01:17:59.984   Training iter 150, batch loss 0.0379, batch acc 0.9932
01:18:00.096   Training iter 200, batch loss 0.0379, batch acc 0.9922
01:18:00.176   Training iter 250, batch loss 0.0376, batch acc 0.9928
01:18:00.268   Training iter 300, batch loss 0.0394, batch acc 0.9894
01:18:00.384   Training iter 350, batch loss 0.0386, batch acc 0.9918
01:18:00.513   Training iter 400, batch loss 0.0356, batch acc 0.9942
01:18:00.635   Training iter 450, batch loss 0.0407, batch acc 0.9914
01:18:00.746   Training iter 500, batch loss 0.0378, batch acc 0.9938
01:18:00.835   Training iter 550, batch loss 0.0415, batch acc 0.9908
01:18:00.923   Training iter 600, batch loss 0.0412, batch acc 0.9912
01:18:00.923 Testing @ 90 epoch...
01:18:00.977     Testing, total mean loss 0.06577, total acc 0.98020
01:18:00.977 Training @ 91 epoch...
01:18:01.091   Training iter 50, batch loss 0.0354, batch acc 0.9928
01:18:01.200   Training iter 100, batch loss 0.0331, batch acc 0.9936
01:18:01.301   Training iter 150, batch loss 0.0396, batch acc 0.9910
01:18:01.403   Training iter 200, batch loss 0.0353, batch acc 0.9942
01:18:01.504   Training iter 250, batch loss 0.0383, batch acc 0.9904
01:18:01.620   Training iter 300, batch loss 0.0406, batch acc 0.9916
01:18:01.751   Training iter 350, batch loss 0.0371, batch acc 0.9926
01:18:01.842   Training iter 400, batch loss 0.0390, batch acc 0.9902
01:18:01.933   Training iter 450, batch loss 0.0431, batch acc 0.9922
01:18:02.040   Training iter 500, batch loss 0.0414, batch acc 0.9912
01:18:02.134   Training iter 550, batch loss 0.0376, batch acc 0.9920
01:18:02.221   Training iter 600, batch loss 0.0403, batch acc 0.9918
01:18:02.223 Training @ 92 epoch...
01:18:02.310   Training iter 50, batch loss 0.0351, batch acc 0.9946
01:18:02.399   Training iter 100, batch loss 0.0371, batch acc 0.9938
01:18:02.497   Training iter 150, batch loss 0.0395, batch acc 0.9906
01:18:02.582   Training iter 200, batch loss 0.0409, batch acc 0.9924
01:18:02.670   Training iter 250, batch loss 0.0355, batch acc 0.9936
01:18:02.751   Training iter 300, batch loss 0.0355, batch acc 0.9924
01:18:02.837   Training iter 350, batch loss 0.0392, batch acc 0.9916
01:18:02.928   Training iter 400, batch loss 0.0397, batch acc 0.9924
01:18:03.012   Training iter 450, batch loss 0.0396, batch acc 0.9920
01:18:03.097   Training iter 500, batch loss 0.0396, batch acc 0.9910
01:18:03.192   Training iter 550, batch loss 0.0405, batch acc 0.9918
01:18:03.278   Training iter 600, batch loss 0.0393, batch acc 0.9898
01:18:03.279 Training @ 93 epoch...
01:18:03.351   Training iter 50, batch loss 0.0340, batch acc 0.9938
01:18:03.432   Training iter 100, batch loss 0.0400, batch acc 0.9916
01:18:03.541   Training iter 150, batch loss 0.0372, batch acc 0.9928
01:18:03.676   Training iter 200, batch loss 0.0370, batch acc 0.9932
01:18:03.812   Training iter 250, batch loss 0.0410, batch acc 0.9912
01:18:03.946   Training iter 300, batch loss 0.0370, batch acc 0.9932
01:18:04.068   Training iter 350, batch loss 0.0416, batch acc 0.9900
01:18:04.203   Training iter 400, batch loss 0.0376, batch acc 0.9934
01:18:04.312   Training iter 450, batch loss 0.0400, batch acc 0.9928
01:18:04.503   Training iter 500, batch loss 0.0350, batch acc 0.9932
01:18:04.620   Training iter 550, batch loss 0.0376, batch acc 0.9932
01:18:04.874   Training iter 600, batch loss 0.0378, batch acc 0.9930
01:18:04.875 Training @ 94 epoch...
01:18:05.011   Training iter 50, batch loss 0.0364, batch acc 0.9928
01:18:05.131   Training iter 100, batch loss 0.0414, batch acc 0.9922
01:18:05.252   Training iter 150, batch loss 0.0406, batch acc 0.9916
01:18:05.532   Training iter 200, batch loss 0.0336, batch acc 0.9944
01:18:05.665   Training iter 250, batch loss 0.0347, batch acc 0.9932
01:18:05.793   Training iter 300, batch loss 0.0363, batch acc 0.9932
01:18:05.901   Training iter 350, batch loss 0.0379, batch acc 0.9924
01:18:06.000   Training iter 400, batch loss 0.0399, batch acc 0.9912
01:18:06.109   Training iter 450, batch loss 0.0334, batch acc 0.9944
01:18:06.293   Training iter 500, batch loss 0.0371, batch acc 0.9914
01:18:06.478   Training iter 550, batch loss 0.0409, batch acc 0.9906
01:18:06.599   Training iter 600, batch loss 0.0409, batch acc 0.9908
01:18:06.600 Training @ 95 epoch...
01:18:06.771   Training iter 50, batch loss 0.0393, batch acc 0.9920
01:18:06.913   Training iter 100, batch loss 0.0343, batch acc 0.9938
01:18:07.165   Training iter 150, batch loss 0.0385, batch acc 0.9928
01:18:07.327   Training iter 200, batch loss 0.0378, batch acc 0.9920
01:18:07.520   Training iter 250, batch loss 0.0376, batch acc 0.9924
01:18:07.635   Training iter 300, batch loss 0.0349, batch acc 0.9922
01:18:07.727   Training iter 350, batch loss 0.0392, batch acc 0.9902
01:18:07.868   Training iter 400, batch loss 0.0430, batch acc 0.9930
01:18:07.975   Training iter 450, batch loss 0.0352, batch acc 0.9930
01:18:08.069   Training iter 500, batch loss 0.0361, batch acc 0.9928
01:18:08.152   Training iter 550, batch loss 0.0407, batch acc 0.9906
01:18:08.282   Training iter 600, batch loss 0.0407, batch acc 0.9912
01:18:08.284 Testing @ 95 epoch...
01:18:08.367     Testing, total mean loss 0.06675, total acc 0.97910
01:18:08.367 Training @ 96 epoch...
01:18:08.503   Training iter 50, batch loss 0.0355, batch acc 0.9940
01:18:08.685   Training iter 100, batch loss 0.0366, batch acc 0.9928
01:18:08.795   Training iter 150, batch loss 0.0395, batch acc 0.9922
01:18:08.903   Training iter 200, batch loss 0.0356, batch acc 0.9920
01:18:09.022   Training iter 250, batch loss 0.0369, batch acc 0.9940
01:18:09.157   Training iter 300, batch loss 0.0424, batch acc 0.9902
01:18:09.246   Training iter 350, batch loss 0.0349, batch acc 0.9934
01:18:09.367   Training iter 400, batch loss 0.0355, batch acc 0.9950
01:18:09.499   Training iter 450, batch loss 0.0377, batch acc 0.9908
01:18:09.634   Training iter 500, batch loss 0.0390, batch acc 0.9908
01:18:09.802   Training iter 550, batch loss 0.0432, batch acc 0.9914
01:18:09.923   Training iter 600, batch loss 0.0378, batch acc 0.9932
01:18:09.926 Training @ 97 epoch...
01:18:10.027   Training iter 50, batch loss 0.0360, batch acc 0.9926
01:18:10.164   Training iter 100, batch loss 0.0338, batch acc 0.9962
01:18:10.379   Training iter 150, batch loss 0.0368, batch acc 0.9926
01:18:10.483   Training iter 200, batch loss 0.0355, batch acc 0.9922
01:18:10.627   Training iter 250, batch loss 0.0343, batch acc 0.9926
01:18:10.738   Training iter 300, batch loss 0.0379, batch acc 0.9912
01:18:10.865   Training iter 350, batch loss 0.0354, batch acc 0.9940
01:18:10.977   Training iter 400, batch loss 0.0359, batch acc 0.9910
01:18:11.144   Training iter 450, batch loss 0.0404, batch acc 0.9922
01:18:11.229   Training iter 500, batch loss 0.0414, batch acc 0.9908
01:18:11.511   Training iter 550, batch loss 0.0457, batch acc 0.9886
01:18:11.620   Training iter 600, batch loss 0.0396, batch acc 0.9912
01:18:11.620 Training @ 98 epoch...
01:18:11.971   Training iter 50, batch loss 0.0423, batch acc 0.9892
01:18:12.075   Training iter 100, batch loss 0.0322, batch acc 0.9946
01:18:12.234   Training iter 150, batch loss 0.0349, batch acc 0.9928
01:18:12.378   Training iter 200, batch loss 0.0414, batch acc 0.9934
01:18:12.517   Training iter 250, batch loss 0.0356, batch acc 0.9936
01:18:12.628   Training iter 300, batch loss 0.0390, batch acc 0.9926
01:18:12.726   Training iter 350, batch loss 0.0386, batch acc 0.9926
01:18:12.832   Training iter 400, batch loss 0.0374, batch acc 0.9938
01:18:12.961   Training iter 450, batch loss 0.0353, batch acc 0.9942
01:18:13.103   Training iter 500, batch loss 0.0399, batch acc 0.9902
01:18:13.223   Training iter 550, batch loss 0.0369, batch acc 0.9924
01:18:13.300   Training iter 600, batch loss 0.0378, batch acc 0.9912
01:18:13.301 Training @ 99 epoch...
01:18:13.404   Training iter 50, batch loss 0.0342, batch acc 0.9938
01:18:13.496   Training iter 100, batch loss 0.0366, batch acc 0.9938
01:18:13.587   Training iter 150, batch loss 0.0349, batch acc 0.9944
01:18:13.685   Training iter 200, batch loss 0.0378, batch acc 0.9918
01:18:13.767   Training iter 250, batch loss 0.0382, batch acc 0.9910
01:18:13.863   Training iter 300, batch loss 0.0377, batch acc 0.9914
01:18:13.969   Training iter 350, batch loss 0.0373, batch acc 0.9928
01:18:14.059   Training iter 400, batch loss 0.0370, batch acc 0.9936
01:18:14.181   Training iter 450, batch loss 0.0394, batch acc 0.9928
01:18:14.367   Training iter 500, batch loss 0.0415, batch acc 0.9920
01:18:14.544   Training iter 550, batch loss 0.0358, batch acc 0.9918
01:18:14.679   Training iter 600, batch loss 0.0395, batch acc 0.9918