20:55:07.751 Training @ 0 epoch...
20:55:08.009   Training iter 50, batch loss 0.1865, batch acc 0.1208
20:55:08.255   Training iter 100, batch loss 0.1865, batch acc 0.1050
20:55:08.609   Training iter 150, batch loss 0.1865, batch acc 0.1096
20:55:08.969   Training iter 200, batch loss 0.1864, batch acc 0.1136
20:55:09.382   Training iter 250, batch loss 0.1864, batch acc 0.1156
20:55:09.653   Training iter 300, batch loss 0.1864, batch acc 0.1128
20:55:10.010   Training iter 350, batch loss 0.1864, batch acc 0.1086
20:55:10.237   Training iter 400, batch loss 0.1864, batch acc 0.1080
20:55:10.445   Training iter 450, batch loss 0.1863, batch acc 0.1152
20:55:10.819   Training iter 500, batch loss 0.1863, batch acc 0.1116
20:55:11.130   Training iter 550, batch loss 0.1862, batch acc 0.1178
20:55:11.350   Training iter 600, batch loss 0.1863, batch acc 0.1106
20:55:11.351 Testing @ 0 epoch...
20:55:11.481     Testing, total mean loss 0.18623, total acc 0.11350
20:55:11.481 Training @ 1 epoch...
20:55:11.833   Training iter 50, batch loss 0.1862, batch acc 0.1148
20:55:12.151   Training iter 100, batch loss 0.1863, batch acc 0.1086
20:55:12.437   Training iter 150, batch loss 0.1862, batch acc 0.1152
20:55:12.818   Training iter 200, batch loss 0.1862, batch acc 0.1108
20:55:13.036   Training iter 250, batch loss 0.1862, batch acc 0.1084
20:55:13.216   Training iter 300, batch loss 0.1861, batch acc 0.1092
20:55:13.435   Training iter 350, batch loss 0.1861, batch acc 0.1106
20:55:13.646   Training iter 400, batch loss 0.1861, batch acc 0.1124
20:55:13.821   Training iter 450, batch loss 0.1859, batch acc 0.1172
20:55:14.006   Training iter 500, batch loss 0.1859, batch acc 0.1140
20:55:14.206   Training iter 550, batch loss 0.1859, batch acc 0.1120
20:55:14.457   Training iter 600, batch loss 0.1858, batch acc 0.1152
20:55:14.457 Training @ 2 epoch...
20:55:14.710   Training iter 50, batch loss 0.1857, batch acc 0.1138
20:55:15.036   Training iter 100, batch loss 0.1856, batch acc 0.1076
20:55:15.362   Training iter 150, batch loss 0.1857, batch acc 0.1072
20:55:15.702   Training iter 200, batch loss 0.1853, batch acc 0.1130
20:55:15.904   Training iter 250, batch loss 0.1851, batch acc 0.1152
20:55:16.084   Training iter 300, batch loss 0.1850, batch acc 0.1136
20:55:16.266   Training iter 350, batch loss 0.1847, batch acc 0.1154
20:55:16.487   Training iter 400, batch loss 0.1844, batch acc 0.1112
20:55:16.667   Training iter 450, batch loss 0.1840, batch acc 0.1104
20:55:16.864   Training iter 500, batch loss 0.1836, batch acc 0.1092
20:55:17.091   Training iter 550, batch loss 0.1825, batch acc 0.1480
20:55:17.323   Training iter 600, batch loss 0.1818, batch acc 0.1460
20:55:17.325 Training @ 3 epoch...
20:55:17.576   Training iter 50, batch loss 0.1803, batch acc 0.1698
20:55:17.774   Training iter 100, batch loss 0.1794, batch acc 0.1750
20:55:18.010   Training iter 150, batch loss 0.1767, batch acc 0.1912
20:55:18.224   Training iter 200, batch loss 0.1741, batch acc 0.1956
20:55:18.448   Training iter 250, batch loss 0.1721, batch acc 0.1946
20:55:18.630   Training iter 300, batch loss 0.1672, batch acc 0.2192
20:55:18.898   Training iter 350, batch loss 0.1627, batch acc 0.2408
20:55:19.134   Training iter 400, batch loss 0.1570, batch acc 0.2486
20:55:19.374   Training iter 450, batch loss 0.1499, batch acc 0.2864
20:55:19.623   Training iter 500, batch loss 0.1429, batch acc 0.3300
20:55:19.865   Training iter 550, batch loss 0.1340, batch acc 0.3872
20:55:20.146   Training iter 600, batch loss 0.1260, batch acc 0.4226
20:55:20.146 Training @ 4 epoch...
20:55:20.449   Training iter 50, batch loss 0.1155, batch acc 0.4578
20:55:20.657   Training iter 100, batch loss 0.1051, batch acc 0.4800
20:55:20.927   Training iter 150, batch loss 0.0955, batch acc 0.5232
20:55:21.131   Training iter 200, batch loss 0.0896, batch acc 0.5342
20:55:21.365   Training iter 250, batch loss 0.0832, batch acc 0.5592
20:55:21.610   Training iter 300, batch loss 0.0789, batch acc 0.5656
20:55:21.809   Training iter 350, batch loss 0.0758, batch acc 0.5648
20:55:22.092   Training iter 400, batch loss 0.0717, batch acc 0.6158
20:55:22.298   Training iter 450, batch loss 0.0712, batch acc 0.5946
20:55:22.527   Training iter 500, batch loss 0.0681, batch acc 0.6308
20:55:22.864   Training iter 550, batch loss 0.0659, batch acc 0.6260
20:55:23.246   Training iter 600, batch loss 0.0633, batch acc 0.6490
20:55:23.247 Training @ 5 epoch...
20:55:23.577   Training iter 50, batch loss 0.0619, batch acc 0.6504
20:55:23.864   Training iter 100, batch loss 0.0614, batch acc 0.6602
20:55:24.066   Training iter 150, batch loss 0.0563, batch acc 0.6850
20:55:24.254   Training iter 200, batch loss 0.0547, batch acc 0.6934
20:55:24.447   Training iter 250, batch loss 0.0518, batch acc 0.6984
20:55:24.636   Training iter 300, batch loss 0.0501, batch acc 0.7086
20:55:24.875   Training iter 350, batch loss 0.0505, batch acc 0.7122
20:55:25.109   Training iter 400, batch loss 0.0484, batch acc 0.7192
20:55:25.294   Training iter 450, batch loss 0.0489, batch acc 0.7192
20:55:25.492   Training iter 500, batch loss 0.0473, batch acc 0.7350
20:55:25.748   Training iter 550, batch loss 0.0460, batch acc 0.7312
20:55:26.004   Training iter 600, batch loss 0.0427, batch acc 0.7418
20:55:26.005 Testing @ 5 epoch...
20:55:26.147     Testing, total mean loss 0.04305, total acc 0.74200
20:55:26.147 Training @ 6 epoch...
20:55:26.412   Training iter 50, batch loss 0.0432, batch acc 0.7494
20:55:26.610   Training iter 100, batch loss 0.0419, batch acc 0.7508
20:55:26.815   Training iter 150, batch loss 0.0408, batch acc 0.7568
20:55:27.043   Training iter 200, batch loss 0.0405, batch acc 0.7608
20:55:27.276   Training iter 250, batch loss 0.0407, batch acc 0.7654
20:55:27.507   Training iter 300, batch loss 0.0422, batch acc 0.7608
20:55:27.748   Training iter 350, batch loss 0.0390, batch acc 0.7616
20:55:27.957   Training iter 400, batch loss 0.0403, batch acc 0.7626
20:55:28.175   Training iter 450, batch loss 0.0387, batch acc 0.7734
20:55:28.414   Training iter 500, batch loss 0.0375, batch acc 0.7786
20:55:28.677   Training iter 550, batch loss 0.0381, batch acc 0.7726
20:55:28.925   Training iter 600, batch loss 0.0371, batch acc 0.7784
20:55:28.926 Training @ 7 epoch...
20:55:29.343   Training iter 50, batch loss 0.0366, batch acc 0.7898
20:55:29.598   Training iter 100, batch loss 0.0364, batch acc 0.7864
20:55:29.878   Training iter 150, batch loss 0.0349, batch acc 0.7900
20:55:30.108   Training iter 200, batch loss 0.0350, batch acc 0.7894
20:55:30.336   Training iter 250, batch loss 0.0358, batch acc 0.7888
20:55:30.552   Training iter 300, batch loss 0.0366, batch acc 0.7914
20:55:30.826   Training iter 350, batch loss 0.0350, batch acc 0.7944
20:55:31.043   Training iter 400, batch loss 0.0347, batch acc 0.8014
20:55:31.290   Training iter 450, batch loss 0.0347, batch acc 0.7972
20:55:31.530   Training iter 500, batch loss 0.0319, batch acc 0.8164
20:55:31.800   Training iter 550, batch loss 0.0339, batch acc 0.7956
20:55:32.065   Training iter 600, batch loss 0.0329, batch acc 0.8078
20:55:32.067 Training @ 8 epoch...
20:55:32.272   Training iter 50, batch loss 0.0328, batch acc 0.8112
20:55:32.489   Training iter 100, batch loss 0.0319, batch acc 0.8086
20:55:32.720   Training iter 150, batch loss 0.0316, batch acc 0.8118
20:55:32.946   Training iter 200, batch loss 0.0303, batch acc 0.8192
20:55:33.171   Training iter 250, batch loss 0.0323, batch acc 0.8166
20:55:33.391   Training iter 300, batch loss 0.0311, batch acc 0.8214
20:55:33.597   Training iter 350, batch loss 0.0324, batch acc 0.8220
20:55:33.809   Training iter 400, batch loss 0.0297, batch acc 0.8264
20:55:34.025   Training iter 450, batch loss 0.0297, batch acc 0.8200
20:55:34.269   Training iter 500, batch loss 0.0285, batch acc 0.8372
20:55:34.516   Training iter 550, batch loss 0.0310, batch acc 0.8178
20:55:34.791   Training iter 600, batch loss 0.0306, batch acc 0.8272
20:55:34.792 Training @ 9 epoch...
20:55:35.100   Training iter 50, batch loss 0.0287, batch acc 0.8266
20:55:35.386   Training iter 100, batch loss 0.0300, batch acc 0.8232
20:55:35.690   Training iter 150, batch loss 0.0297, batch acc 0.8324
20:55:35.967   Training iter 200, batch loss 0.0287, batch acc 0.8360
20:55:36.213   Training iter 250, batch loss 0.0288, batch acc 0.8308
20:55:36.515   Training iter 300, batch loss 0.0283, batch acc 0.8364
20:55:36.733   Training iter 350, batch loss 0.0272, batch acc 0.8410
20:55:37.020   Training iter 400, batch loss 0.0280, batch acc 0.8420
20:55:37.289   Training iter 450, batch loss 0.0282, batch acc 0.8368
20:55:37.570   Training iter 500, batch loss 0.0281, batch acc 0.8348
20:55:37.967   Training iter 550, batch loss 0.0267, batch acc 0.8400
20:55:38.209   Training iter 600, batch loss 0.0284, batch acc 0.8378
20:55:38.212 Training @ 10 epoch...
20:55:38.475   Training iter 50, batch loss 0.0267, batch acc 0.8384
20:55:38.795   Training iter 100, batch loss 0.0263, batch acc 0.8472
20:55:39.077   Training iter 150, batch loss 0.0268, batch acc 0.8414
20:55:39.362   Training iter 200, batch loss 0.0269, batch acc 0.8474
20:55:39.657   Training iter 250, batch loss 0.0262, batch acc 0.8522
20:55:39.977   Training iter 300, batch loss 0.0273, batch acc 0.8482
20:55:40.293   Training iter 350, batch loss 0.0260, batch acc 0.8508
20:55:40.784   Training iter 400, batch loss 0.0266, batch acc 0.8466
20:55:41.467   Training iter 450, batch loss 0.0274, batch acc 0.8424
20:55:41.761   Training iter 500, batch loss 0.0256, batch acc 0.8522
20:55:42.040   Training iter 550, batch loss 0.0254, batch acc 0.8482
20:55:42.295   Training iter 600, batch loss 0.0282, batch acc 0.8384
20:55:42.296 Testing @ 10 epoch...
20:55:42.448     Testing, total mean loss 0.02496, total acc 0.85280
20:55:42.449 Training @ 11 epoch...
20:55:42.729   Training iter 50, batch loss 0.0238, batch acc 0.8566
20:55:43.042   Training iter 100, batch loss 0.0251, batch acc 0.8446
20:55:43.339   Training iter 150, batch loss 0.0255, batch acc 0.8546
20:55:43.670   Training iter 200, batch loss 0.0256, batch acc 0.8540
20:55:43.950   Training iter 250, batch loss 0.0264, batch acc 0.8476
20:55:44.152   Training iter 300, batch loss 0.0267, batch acc 0.8400
20:55:44.359   Training iter 350, batch loss 0.0266, batch acc 0.8482
20:55:44.605   Training iter 400, batch loss 0.0260, batch acc 0.8554
20:55:44.922   Training iter 450, batch loss 0.0236, batch acc 0.8618
20:55:45.185   Training iter 500, batch loss 0.0247, batch acc 0.8624
20:55:45.422   Training iter 550, batch loss 0.0243, batch acc 0.8658
20:55:45.697   Training iter 600, batch loss 0.0246, batch acc 0.8544
20:55:45.698 Training @ 12 epoch...
20:55:46.074   Training iter 50, batch loss 0.0244, batch acc 0.8592
20:55:46.433   Training iter 100, batch loss 0.0258, batch acc 0.8536
20:55:46.785   Training iter 150, batch loss 0.0242, batch acc 0.8572
20:55:47.100   Training iter 200, batch loss 0.0230, batch acc 0.8638
20:55:47.342   Training iter 250, batch loss 0.0250, batch acc 0.8528
20:55:47.624   Training iter 300, batch loss 0.0239, batch acc 0.8578
20:55:47.915   Training iter 350, batch loss 0.0246, batch acc 0.8640
20:55:48.161   Training iter 400, batch loss 0.0244, batch acc 0.8620
20:55:48.427   Training iter 450, batch loss 0.0224, batch acc 0.8692
20:55:48.754   Training iter 500, batch loss 0.0242, batch acc 0.8548
20:55:49.053   Training iter 550, batch loss 0.0236, batch acc 0.8660
20:55:49.339   Training iter 600, batch loss 0.0228, batch acc 0.8690
20:55:49.339 Training @ 13 epoch...
20:55:49.607   Training iter 50, batch loss 0.0240, batch acc 0.8596
20:55:49.885   Training iter 100, batch loss 0.0231, batch acc 0.8710
20:55:50.107   Training iter 150, batch loss 0.0216, batch acc 0.8794
20:55:50.388   Training iter 200, batch loss 0.0230, batch acc 0.8688
20:55:50.653   Training iter 250, batch loss 0.0238, batch acc 0.8680
20:55:50.924   Training iter 300, batch loss 0.0235, batch acc 0.8650
20:55:51.185   Training iter 350, batch loss 0.0232, batch acc 0.8658
20:55:51.416   Training iter 400, batch loss 0.0227, batch acc 0.8664
20:55:51.721   Training iter 450, batch loss 0.0223, batch acc 0.8696
20:55:52.051   Training iter 500, batch loss 0.0232, batch acc 0.8646
20:55:52.335   Training iter 550, batch loss 0.0220, batch acc 0.8704
20:55:52.585   Training iter 600, batch loss 0.0215, batch acc 0.8720
20:55:52.586 Training @ 14 epoch...
20:55:52.839   Training iter 50, batch loss 0.0222, batch acc 0.8666
20:55:53.085   Training iter 100, batch loss 0.0213, batch acc 0.8796
20:55:53.337   Training iter 150, batch loss 0.0222, batch acc 0.8706
20:55:53.999   Training iter 200, batch loss 0.0225, batch acc 0.8686
20:55:54.467   Training iter 250, batch loss 0.0233, batch acc 0.8722
20:55:54.749   Training iter 300, batch loss 0.0211, batch acc 0.8802
20:55:55.031   Training iter 350, batch loss 0.0234, batch acc 0.8646
20:55:55.332   Training iter 400, batch loss 0.0209, batch acc 0.8776
20:55:55.614   Training iter 450, batch loss 0.0202, batch acc 0.8818
20:55:55.847   Training iter 500, batch loss 0.0219, batch acc 0.8738
20:55:56.164   Training iter 550, batch loss 0.0211, batch acc 0.8782
20:55:56.457   Training iter 600, batch loss 0.0209, batch acc 0.8820
20:55:56.458 Training @ 15 epoch...
20:55:56.717   Training iter 50, batch loss 0.0214, batch acc 0.8730
20:55:57.274   Training iter 100, batch loss 0.0226, batch acc 0.8688
20:55:57.673   Training iter 150, batch loss 0.0203, batch acc 0.8840
20:55:57.987   Training iter 200, batch loss 0.0208, batch acc 0.8842
20:55:58.273   Training iter 250, batch loss 0.0208, batch acc 0.8762
20:55:58.507   Training iter 300, batch loss 0.0209, batch acc 0.8848
20:55:58.728   Training iter 350, batch loss 0.0181, batch acc 0.8920
20:55:59.028   Training iter 400, batch loss 0.0214, batch acc 0.8772
20:55:59.304   Training iter 450, batch loss 0.0211, batch acc 0.8826
20:55:59.582   Training iter 500, batch loss 0.0199, batch acc 0.8826
20:55:59.839   Training iter 550, batch loss 0.0221, batch acc 0.8758
20:56:00.140   Training iter 600, batch loss 0.0198, batch acc 0.8824
20:56:00.141 Testing @ 15 epoch...
20:56:00.291     Testing, total mean loss 0.01967, total acc 0.88340
20:56:00.292 Training @ 16 epoch...
20:56:00.608   Training iter 50, batch loss 0.0205, batch acc 0.8848
20:56:00.983   Training iter 100, batch loss 0.0207, batch acc 0.8804
20:56:01.670   Training iter 150, batch loss 0.0195, batch acc 0.8910
20:56:02.000   Training iter 200, batch loss 0.0195, batch acc 0.8846
20:56:02.291   Training iter 250, batch loss 0.0201, batch acc 0.8784
20:56:02.523   Training iter 300, batch loss 0.0213, batch acc 0.8756
20:56:02.845   Training iter 350, batch loss 0.0194, batch acc 0.8908
20:56:03.186   Training iter 400, batch loss 0.0192, batch acc 0.8858
20:56:03.491   Training iter 450, batch loss 0.0203, batch acc 0.8804
20:56:03.785   Training iter 500, batch loss 0.0197, batch acc 0.8812
20:56:04.205   Training iter 550, batch loss 0.0191, batch acc 0.8892
20:56:04.661   Training iter 600, batch loss 0.0196, batch acc 0.8872
20:56:04.661 Training @ 17 epoch...
20:56:05.170   Training iter 50, batch loss 0.0198, batch acc 0.8788
20:56:05.611   Training iter 100, batch loss 0.0216, batch acc 0.8764
20:56:05.989   Training iter 150, batch loss 0.0194, batch acc 0.8884
20:56:06.318   Training iter 200, batch loss 0.0197, batch acc 0.8900
20:56:06.646   Training iter 250, batch loss 0.0193, batch acc 0.8878
20:56:07.033   Training iter 300, batch loss 0.0184, batch acc 0.8992
20:56:07.444   Training iter 350, batch loss 0.0184, batch acc 0.8926
20:56:08.007   Training iter 400, batch loss 0.0194, batch acc 0.8894
20:56:08.489   Training iter 450, batch loss 0.0196, batch acc 0.8898
20:56:08.956   Training iter 500, batch loss 0.0197, batch acc 0.8862
20:56:09.290   Training iter 550, batch loss 0.0180, batch acc 0.8936
20:56:09.703   Training iter 600, batch loss 0.0180, batch acc 0.8946
20:56:09.704 Training @ 18 epoch...
20:56:10.107   Training iter 50, batch loss 0.0193, batch acc 0.8928
20:56:10.586   Training iter 100, batch loss 0.0187, batch acc 0.8910
20:56:11.000   Training iter 150, batch loss 0.0187, batch acc 0.8946
20:56:11.432   Training iter 200, batch loss 0.0199, batch acc 0.8860
20:56:12.348   Training iter 250, batch loss 0.0192, batch acc 0.8872
20:56:12.808   Training iter 300, batch loss 0.0170, batch acc 0.8952
20:56:13.350   Training iter 350, batch loss 0.0184, batch acc 0.8922
20:56:13.791   Training iter 400, batch loss 0.0185, batch acc 0.8926
20:56:14.383   Training iter 450, batch loss 0.0184, batch acc 0.8966
20:56:14.774   Training iter 500, batch loss 0.0185, batch acc 0.8944
20:56:15.143   Training iter 550, batch loss 0.0192, batch acc 0.8862
20:56:15.509   Training iter 600, batch loss 0.0184, batch acc 0.8904
20:56:15.510 Training @ 19 epoch...
20:56:15.828   Training iter 50, batch loss 0.0192, batch acc 0.8992
20:56:16.265   Training iter 100, batch loss 0.0184, batch acc 0.8940
20:56:16.685   Training iter 150, batch loss 0.0183, batch acc 0.8928
20:56:16.947   Training iter 200, batch loss 0.0190, batch acc 0.8868
20:56:17.381   Training iter 250, batch loss 0.0174, batch acc 0.8976
20:56:17.776   Training iter 300, batch loss 0.0178, batch acc 0.9006
20:56:18.319   Training iter 350, batch loss 0.0188, batch acc 0.8932
20:56:18.702   Training iter 400, batch loss 0.0179, batch acc 0.8934
20:56:19.064   Training iter 450, batch loss 0.0187, batch acc 0.8908
20:56:19.392   Training iter 500, batch loss 0.0177, batch acc 0.8984
20:56:19.730   Training iter 550, batch loss 0.0170, batch acc 0.8960
20:56:20.048   Training iter 600, batch loss 0.0186, batch acc 0.8956
20:56:20.050 Training @ 20 epoch...
20:56:20.412   Training iter 50, batch loss 0.0178, batch acc 0.8980
20:56:20.959   Training iter 100, batch loss 0.0185, batch acc 0.8944
20:56:21.269   Training iter 150, batch loss 0.0179, batch acc 0.8980
20:56:21.617   Training iter 200, batch loss 0.0189, batch acc 0.8954
20:56:21.840   Training iter 250, batch loss 0.0168, batch acc 0.9010
20:56:22.112   Training iter 300, batch loss 0.0184, batch acc 0.8954
20:56:22.413   Training iter 350, batch loss 0.0173, batch acc 0.8964
20:56:22.719   Training iter 400, batch loss 0.0179, batch acc 0.8938
20:56:22.977   Training iter 450, batch loss 0.0185, batch acc 0.8958
20:56:23.200   Training iter 500, batch loss 0.0182, batch acc 0.8948
20:56:23.428   Training iter 550, batch loss 0.0165, batch acc 0.9020
20:56:23.670   Training iter 600, batch loss 0.0171, batch acc 0.8996
20:56:23.672 Testing @ 20 epoch...
20:56:23.815     Testing, total mean loss 0.01738, total acc 0.89860
20:56:23.815 Training @ 21 epoch...
20:56:24.060   Training iter 50, batch loss 0.0178, batch acc 0.8970
20:56:24.315   Training iter 100, batch loss 0.0172, batch acc 0.9012
20:56:24.541   Training iter 150, batch loss 0.0162, batch acc 0.9076
20:56:24.745   Training iter 200, batch loss 0.0178, batch acc 0.9036
20:56:24.953   Training iter 250, batch loss 0.0175, batch acc 0.8956
20:56:25.153   Training iter 300, batch loss 0.0172, batch acc 0.8972
20:56:25.355   Training iter 350, batch loss 0.0186, batch acc 0.8964
20:56:25.551   Training iter 400, batch loss 0.0175, batch acc 0.8962
20:56:25.758   Training iter 450, batch loss 0.0168, batch acc 0.9030
20:56:25.969   Training iter 500, batch loss 0.0175, batch acc 0.8978
20:56:26.174   Training iter 550, batch loss 0.0189, batch acc 0.8938
20:56:26.406   Training iter 600, batch loss 0.0162, batch acc 0.9006
20:56:26.406 Training @ 22 epoch...
20:56:26.642   Training iter 50, batch loss 0.0166, batch acc 0.9066
20:56:26.866   Training iter 100, batch loss 0.0178, batch acc 0.8938
20:56:27.121   Training iter 150, batch loss 0.0178, batch acc 0.8958
20:56:27.359   Training iter 200, batch loss 0.0159, batch acc 0.9080
20:56:27.561   Training iter 250, batch loss 0.0161, batch acc 0.9080
20:56:27.763   Training iter 300, batch loss 0.0166, batch acc 0.9038
20:56:27.974   Training iter 350, batch loss 0.0180, batch acc 0.8962
20:56:28.181   Training iter 400, batch loss 0.0179, batch acc 0.9026
20:56:28.386   Training iter 450, batch loss 0.0170, batch acc 0.9054
20:56:28.585   Training iter 500, batch loss 0.0177, batch acc 0.8982
20:56:28.792   Training iter 550, batch loss 0.0178, batch acc 0.8990
20:56:29.059   Training iter 600, batch loss 0.0159, batch acc 0.9034
20:56:29.059 Training @ 23 epoch...
20:56:29.306   Training iter 50, batch loss 0.0176, batch acc 0.9024
20:56:29.533   Training iter 100, batch loss 0.0164, batch acc 0.9010
20:56:29.783   Training iter 150, batch loss 0.0165, batch acc 0.9064
20:56:30.046   Training iter 200, batch loss 0.0169, batch acc 0.9036
20:56:30.312   Training iter 250, batch loss 0.0152, batch acc 0.9106
20:56:30.504   Training iter 300, batch loss 0.0172, batch acc 0.8994
20:56:30.706   Training iter 350, batch loss 0.0165, batch acc 0.9034
20:56:30.914   Training iter 400, batch loss 0.0166, batch acc 0.9030
20:56:31.119   Training iter 450, batch loss 0.0164, batch acc 0.9032
20:56:31.307   Training iter 500, batch loss 0.0174, batch acc 0.9022
20:56:31.501   Training iter 550, batch loss 0.0163, batch acc 0.9060
20:56:31.714   Training iter 600, batch loss 0.0180, batch acc 0.9020
20:56:31.715 Training @ 24 epoch...
20:56:31.931   Training iter 50, batch loss 0.0166, batch acc 0.9070
20:56:32.138   Training iter 100, batch loss 0.0168, batch acc 0.9014
20:56:32.356   Training iter 150, batch loss 0.0156, batch acc 0.9102
20:56:32.577   Training iter 200, batch loss 0.0169, batch acc 0.9032
20:56:32.811   Training iter 250, batch loss 0.0168, batch acc 0.8990
20:56:33.064   Training iter 300, batch loss 0.0170, batch acc 0.9086
20:56:33.312   Training iter 350, batch loss 0.0165, batch acc 0.9052
20:56:33.510   Training iter 400, batch loss 0.0162, batch acc 0.9062
20:56:33.706   Training iter 450, batch loss 0.0161, batch acc 0.9082
20:56:33.920   Training iter 500, batch loss 0.0160, batch acc 0.9048
20:56:34.128   Training iter 550, batch loss 0.0153, batch acc 0.9110
20:56:34.334   Training iter 600, batch loss 0.0172, batch acc 0.9012
20:56:34.335 Training @ 25 epoch...
20:56:34.534   Training iter 50, batch loss 0.0151, batch acc 0.9130
20:56:34.727   Training iter 100, batch loss 0.0167, batch acc 0.9066
20:56:34.935   Training iter 150, batch loss 0.0159, batch acc 0.9108
20:56:35.143   Training iter 200, batch loss 0.0158, batch acc 0.9052
20:56:35.368   Training iter 250, batch loss 0.0165, batch acc 0.9086
20:56:35.589   Training iter 300, batch loss 0.0159, batch acc 0.9072
20:56:35.814   Training iter 350, batch loss 0.0166, batch acc 0.9052
20:56:36.059   Training iter 400, batch loss 0.0166, batch acc 0.9062
20:56:36.287   Training iter 450, batch loss 0.0154, batch acc 0.9084
20:56:36.486   Training iter 500, batch loss 0.0163, batch acc 0.9012
20:56:36.691   Training iter 550, batch loss 0.0165, batch acc 0.9090
20:56:36.905   Training iter 600, batch loss 0.0159, batch acc 0.9096
20:56:36.906 Testing @ 25 epoch...
20:56:37.014     Testing, total mean loss 0.01578, total acc 0.91010
20:56:37.014 Training @ 26 epoch...
20:56:37.218   Training iter 50, batch loss 0.0174, batch acc 0.8958
20:56:37.528   Training iter 100, batch loss 0.0156, batch acc 0.9100
20:56:37.932   Training iter 150, batch loss 0.0162, batch acc 0.9038
20:56:38.232   Training iter 200, batch loss 0.0142, batch acc 0.9166
20:56:38.640   Training iter 250, batch loss 0.0160, batch acc 0.9162
20:56:39.021   Training iter 300, batch loss 0.0163, batch acc 0.9036
20:56:39.276   Training iter 350, batch loss 0.0160, batch acc 0.9134
20:56:39.483   Training iter 400, batch loss 0.0151, batch acc 0.9118
20:56:39.759   Training iter 450, batch loss 0.0154, batch acc 0.9140
20:56:40.012   Training iter 500, batch loss 0.0156, batch acc 0.9086
20:56:40.260   Training iter 550, batch loss 0.0158, batch acc 0.9108
20:56:40.468   Training iter 600, batch loss 0.0160, batch acc 0.9058
20:56:40.469 Training @ 27 epoch...
20:56:40.676   Training iter 50, batch loss 0.0154, batch acc 0.9112
20:56:40.891   Training iter 100, batch loss 0.0159, batch acc 0.9124
20:56:41.205   Training iter 150, batch loss 0.0153, batch acc 0.9104
20:56:41.455   Training iter 200, batch loss 0.0155, batch acc 0.9128
20:56:41.696   Training iter 250, batch loss 0.0153, batch acc 0.9072
20:56:41.951   Training iter 300, batch loss 0.0171, batch acc 0.9084
20:56:42.281   Training iter 350, batch loss 0.0158, batch acc 0.9084
20:56:42.483   Training iter 400, batch loss 0.0163, batch acc 0.9024
20:56:42.688   Training iter 450, batch loss 0.0142, batch acc 0.9168
20:56:42.883   Training iter 500, batch loss 0.0151, batch acc 0.9144
20:56:43.268   Training iter 550, batch loss 0.0150, batch acc 0.9154
20:56:43.890   Training iter 600, batch loss 0.0152, batch acc 0.9158
20:56:43.892 Training @ 28 epoch...
20:56:44.137   Training iter 50, batch loss 0.0145, batch acc 0.9152
20:56:44.407   Training iter 100, batch loss 0.0164, batch acc 0.9052
20:56:44.629   Training iter 150, batch loss 0.0154, batch acc 0.9110
20:56:44.884   Training iter 200, batch loss 0.0154, batch acc 0.9104
20:56:45.165   Training iter 250, batch loss 0.0148, batch acc 0.9140
20:56:45.367   Training iter 300, batch loss 0.0148, batch acc 0.9186
20:56:45.570   Training iter 350, batch loss 0.0151, batch acc 0.9148
20:56:45.790   Training iter 400, batch loss 0.0161, batch acc 0.9052
20:56:46.014   Training iter 450, batch loss 0.0147, batch acc 0.9168
20:56:46.247   Training iter 500, batch loss 0.0147, batch acc 0.9130
20:56:46.691   Training iter 550, batch loss 0.0156, batch acc 0.9092
20:56:46.933   Training iter 600, batch loss 0.0154, batch acc 0.9128
20:56:46.935 Training @ 29 epoch...
20:56:47.167   Training iter 50, batch loss 0.0155, batch acc 0.9138
20:56:47.394   Training iter 100, batch loss 0.0153, batch acc 0.9134
20:56:47.641   Training iter 150, batch loss 0.0151, batch acc 0.9132
20:56:47.893   Training iter 200, batch loss 0.0152, batch acc 0.9112
20:56:48.151   Training iter 250, batch loss 0.0140, batch acc 0.9178
20:56:48.350   Training iter 300, batch loss 0.0143, batch acc 0.9158
20:56:48.693   Training iter 350, batch loss 0.0153, batch acc 0.9108
20:56:49.094   Training iter 400, batch loss 0.0147, batch acc 0.9148
20:56:49.394   Training iter 450, batch loss 0.0141, batch acc 0.9186
20:56:49.630   Training iter 500, batch loss 0.0156, batch acc 0.9154
20:56:49.943   Training iter 550, batch loss 0.0143, batch acc 0.9138
20:56:50.255   Training iter 600, batch loss 0.0161, batch acc 0.9120
20:56:50.257 Training @ 30 epoch...
20:56:50.564   Training iter 50, batch loss 0.0144, batch acc 0.9212
20:56:50.887   Training iter 100, batch loss 0.0146, batch acc 0.9170
20:56:51.151   Training iter 150, batch loss 0.0152, batch acc 0.9122
20:56:51.399   Training iter 200, batch loss 0.0147, batch acc 0.9148
20:56:51.612   Training iter 250, batch loss 0.0151, batch acc 0.9132
20:56:51.816   Training iter 300, batch loss 0.0147, batch acc 0.9154
20:56:52.019   Training iter 350, batch loss 0.0145, batch acc 0.9150
20:56:52.294   Training iter 400, batch loss 0.0160, batch acc 0.9136
20:56:52.542   Training iter 450, batch loss 0.0143, batch acc 0.9212
20:56:52.842   Training iter 500, batch loss 0.0150, batch acc 0.9106
20:56:53.137   Training iter 550, batch loss 0.0130, batch acc 0.9234
20:56:53.382   Training iter 600, batch loss 0.0145, batch acc 0.9142
20:56:53.384 Testing @ 30 epoch...
20:56:53.535     Testing, total mean loss 0.01443, total acc 0.91700
20:56:53.535 Training @ 31 epoch...
20:56:53.865   Training iter 50, batch loss 0.0152, batch acc 0.9194
20:56:54.248   Training iter 100, batch loss 0.0142, batch acc 0.9204
20:56:54.673   Training iter 150, batch loss 0.0138, batch acc 0.9228
20:56:54.929   Training iter 200, batch loss 0.0152, batch acc 0.9114
20:56:55.175   Training iter 250, batch loss 0.0150, batch acc 0.9100
20:56:55.468   Training iter 300, batch loss 0.0144, batch acc 0.9206
20:56:55.717   Training iter 350, batch loss 0.0142, batch acc 0.9186
20:56:55.995   Training iter 400, batch loss 0.0140, batch acc 0.9204
20:56:56.277   Training iter 450, batch loss 0.0133, batch acc 0.9184
20:56:56.554   Training iter 500, batch loss 0.0152, batch acc 0.9068
20:56:57.051   Training iter 550, batch loss 0.0139, batch acc 0.9220
20:56:57.346   Training iter 600, batch loss 0.0142, batch acc 0.9188
20:56:57.347 Training @ 32 epoch...
20:56:57.712   Training iter 50, batch loss 0.0132, batch acc 0.9212
20:56:58.031   Training iter 100, batch loss 0.0156, batch acc 0.9140
20:56:58.315   Training iter 150, batch loss 0.0129, batch acc 0.9212
20:56:58.517   Training iter 200, batch loss 0.0138, batch acc 0.9192
20:56:58.734   Training iter 250, batch loss 0.0143, batch acc 0.9196
20:56:58.972   Training iter 300, batch loss 0.0137, batch acc 0.9238
20:56:59.305   Training iter 350, batch loss 0.0148, batch acc 0.9182
20:56:59.663   Training iter 400, batch loss 0.0148, batch acc 0.9132
20:56:59.963   Training iter 450, batch loss 0.0138, batch acc 0.9256
20:57:00.238   Training iter 500, batch loss 0.0149, batch acc 0.9140
20:57:00.435   Training iter 550, batch loss 0.0140, batch acc 0.9208
20:57:00.654   Training iter 600, batch loss 0.0138, batch acc 0.9186
20:57:00.657 Training @ 33 epoch...
20:57:00.866   Training iter 50, batch loss 0.0134, batch acc 0.9198
20:57:01.115   Training iter 100, batch loss 0.0145, batch acc 0.9180
20:57:01.346   Training iter 150, batch loss 0.0135, batch acc 0.9218
20:57:01.591   Training iter 200, batch loss 0.0139, batch acc 0.9206
20:57:01.947   Training iter 250, batch loss 0.0139, batch acc 0.9218
20:57:02.264   Training iter 300, batch loss 0.0133, batch acc 0.9194
20:57:02.501   Training iter 350, batch loss 0.0149, batch acc 0.9178
20:57:02.755   Training iter 400, batch loss 0.0141, batch acc 0.9156
20:57:02.955   Training iter 450, batch loss 0.0144, batch acc 0.9194
20:57:03.172   Training iter 500, batch loss 0.0128, batch acc 0.9298
20:57:03.530   Training iter 550, batch loss 0.0140, batch acc 0.9224
20:57:03.808   Training iter 600, batch loss 0.0139, batch acc 0.9176
20:57:03.809 Training @ 34 epoch...
20:57:04.104   Training iter 50, batch loss 0.0146, batch acc 0.9166
20:57:04.413   Training iter 100, batch loss 0.0120, batch acc 0.9288
20:57:04.828   Training iter 150, batch loss 0.0137, batch acc 0.9198
20:57:05.310   Training iter 200, batch loss 0.0129, batch acc 0.9254
20:57:05.596   Training iter 250, batch loss 0.0134, batch acc 0.9236
20:57:05.835   Training iter 300, batch loss 0.0138, batch acc 0.9194
20:57:06.079   Training iter 350, batch loss 0.0134, batch acc 0.9246
20:57:06.421   Training iter 400, batch loss 0.0139, batch acc 0.9202
20:57:06.716   Training iter 450, batch loss 0.0141, batch acc 0.9176
20:57:06.934   Training iter 500, batch loss 0.0135, batch acc 0.9242
20:57:07.179   Training iter 550, batch loss 0.0145, batch acc 0.9186
20:57:07.460   Training iter 600, batch loss 0.0138, batch acc 0.9204
20:57:07.462 Training @ 35 epoch...
20:57:07.712   Training iter 50, batch loss 0.0132, batch acc 0.9252
20:57:08.062   Training iter 100, batch loss 0.0127, batch acc 0.9292
20:57:08.395   Training iter 150, batch loss 0.0132, batch acc 0.9234
20:57:08.805   Training iter 200, batch loss 0.0140, batch acc 0.9224
20:57:09.126   Training iter 250, batch loss 0.0130, batch acc 0.9264
20:57:09.385   Training iter 300, batch loss 0.0131, batch acc 0.9212
20:57:09.610   Training iter 350, batch loss 0.0134, batch acc 0.9224
20:57:09.872   Training iter 400, batch loss 0.0134, batch acc 0.9222
20:57:10.108   Training iter 450, batch loss 0.0137, batch acc 0.9236
20:57:10.383   Training iter 500, batch loss 0.0142, batch acc 0.9208
20:57:10.663   Training iter 550, batch loss 0.0133, batch acc 0.9240
20:57:10.924   Training iter 600, batch loss 0.0134, batch acc 0.9260
20:57:10.926 Testing @ 35 epoch...
20:57:11.137     Testing, total mean loss 0.01328, total acc 0.92490
20:57:11.138 Training @ 36 epoch...
20:57:11.495   Training iter 50, batch loss 0.0138, batch acc 0.9186
20:57:11.787   Training iter 100, batch loss 0.0134, batch acc 0.9200
20:57:12.045   Training iter 150, batch loss 0.0125, batch acc 0.9246
20:57:12.342   Training iter 200, batch loss 0.0135, batch acc 0.9250
20:57:12.582   Training iter 250, batch loss 0.0123, batch acc 0.9282
20:57:12.822   Training iter 300, batch loss 0.0141, batch acc 0.9244
20:57:13.747   Training iter 350, batch loss 0.0134, batch acc 0.9238
20:57:14.104   Training iter 400, batch loss 0.0146, batch acc 0.9174
20:57:14.400   Training iter 450, batch loss 0.0126, batch acc 0.9264
20:57:14.745   Training iter 500, batch loss 0.0133, batch acc 0.9270
20:57:15.031   Training iter 550, batch loss 0.0122, batch acc 0.9306
20:57:15.409   Training iter 600, batch loss 0.0124, batch acc 0.9286
20:57:15.411 Training @ 37 epoch...
20:57:15.668   Training iter 50, batch loss 0.0124, batch acc 0.9274
20:57:16.075   Training iter 100, batch loss 0.0137, batch acc 0.9242
20:57:16.464   Training iter 150, batch loss 0.0124, batch acc 0.9324
20:57:17.011   Training iter 200, batch loss 0.0126, batch acc 0.9266
20:57:17.374   Training iter 250, batch loss 0.0136, batch acc 0.9240
20:57:17.705   Training iter 300, batch loss 0.0135, batch acc 0.9228
20:57:17.992   Training iter 350, batch loss 0.0119, batch acc 0.9334
20:57:18.216   Training iter 400, batch loss 0.0128, batch acc 0.9268
20:57:18.554   Training iter 450, batch loss 0.0126, batch acc 0.9266
20:57:18.929   Training iter 500, batch loss 0.0128, batch acc 0.9240
20:57:19.295   Training iter 550, batch loss 0.0133, batch acc 0.9196
20:57:19.584   Training iter 600, batch loss 0.0134, batch acc 0.9280
20:57:19.589 Training @ 38 epoch...
20:57:19.850   Training iter 50, batch loss 0.0126, batch acc 0.9282
20:57:20.617   Training iter 100, batch loss 0.0128, batch acc 0.9288
20:57:20.856   Training iter 150, batch loss 0.0129, batch acc 0.9308
20:57:21.176   Training iter 200, batch loss 0.0136, batch acc 0.9212
20:57:21.448   Training iter 250, batch loss 0.0130, batch acc 0.9230
20:57:21.693   Training iter 300, batch loss 0.0125, batch acc 0.9308
20:57:21.996   Training iter 350, batch loss 0.0121, batch acc 0.9282
20:57:22.276   Training iter 400, batch loss 0.0134, batch acc 0.9216
20:57:22.872   Training iter 450, batch loss 0.0125, batch acc 0.9294
20:57:23.131   Training iter 500, batch loss 0.0123, batch acc 0.9330
20:57:23.507   Training iter 550, batch loss 0.0126, batch acc 0.9278
20:57:23.715   Training iter 600, batch loss 0.0125, batch acc 0.9246
20:57:23.715 Training @ 39 epoch...
20:57:23.997   Training iter 50, batch loss 0.0127, batch acc 0.9320
20:57:24.292   Training iter 100, batch loss 0.0134, batch acc 0.9254
20:57:24.600   Training iter 150, batch loss 0.0116, batch acc 0.9320
20:57:24.867   Training iter 200, batch loss 0.0125, batch acc 0.9238
20:57:25.146   Training iter 250, batch loss 0.0127, batch acc 0.9282
20:57:25.382   Training iter 300, batch loss 0.0126, batch acc 0.9246
20:57:25.634   Training iter 350, batch loss 0.0127, batch acc 0.9270
20:57:25.896   Training iter 400, batch loss 0.0124, batch acc 0.9276
20:57:26.156   Training iter 450, batch loss 0.0123, batch acc 0.9294
20:57:26.415   Training iter 500, batch loss 0.0119, batch acc 0.9346
20:57:26.625   Training iter 550, batch loss 0.0133, batch acc 0.9248
20:57:26.865   Training iter 600, batch loss 0.0122, batch acc 0.9330
20:57:26.866 Training @ 40 epoch...
20:57:27.175   Training iter 50, batch loss 0.0126, batch acc 0.9260
20:57:27.441   Training iter 100, batch loss 0.0119, batch acc 0.9340
20:57:27.668   Training iter 150, batch loss 0.0125, batch acc 0.9260
20:57:27.861   Training iter 200, batch loss 0.0124, batch acc 0.9298
20:57:28.102   Training iter 250, batch loss 0.0117, batch acc 0.9364
20:57:28.445   Training iter 300, batch loss 0.0123, batch acc 0.9322
20:57:28.711   Training iter 350, batch loss 0.0126, batch acc 0.9270
20:57:28.969   Training iter 400, batch loss 0.0122, batch acc 0.9302
20:57:29.303   Training iter 450, batch loss 0.0120, batch acc 0.9320
20:57:29.528   Training iter 500, batch loss 0.0125, batch acc 0.9294
20:57:29.823   Training iter 550, batch loss 0.0118, batch acc 0.9302
20:57:30.071   Training iter 600, batch loss 0.0133, batch acc 0.9216
20:57:30.073 Testing @ 40 epoch...
20:57:30.270     Testing, total mean loss 0.01222, total acc 0.93090
20:57:30.270 Training @ 41 epoch...
20:57:30.530   Training iter 50, batch loss 0.0112, batch acc 0.9320
20:57:30.779   Training iter 100, batch loss 0.0126, batch acc 0.9286
20:57:31.012   Training iter 150, batch loss 0.0115, batch acc 0.9308
20:57:31.276   Training iter 200, batch loss 0.0124, batch acc 0.9302
20:57:31.540   Training iter 250, batch loss 0.0109, batch acc 0.9414
20:57:31.803   Training iter 300, batch loss 0.0125, batch acc 0.9244
20:57:32.104   Training iter 350, batch loss 0.0126, batch acc 0.9294
20:57:32.315   Training iter 400, batch loss 0.0126, batch acc 0.9270
20:57:32.590   Training iter 450, batch loss 0.0122, batch acc 0.9310
20:57:32.832   Training iter 500, batch loss 0.0123, batch acc 0.9308
20:57:33.042   Training iter 550, batch loss 0.0126, batch acc 0.9286
20:57:33.325   Training iter 600, batch loss 0.0119, batch acc 0.9324
20:57:33.327 Training @ 42 epoch...
20:57:33.532   Training iter 50, batch loss 0.0127, batch acc 0.9252
20:57:33.728   Training iter 100, batch loss 0.0124, batch acc 0.9258
20:57:33.990   Training iter 150, batch loss 0.0119, batch acc 0.9348
20:57:34.231   Training iter 200, batch loss 0.0117, batch acc 0.9296
20:57:34.522   Training iter 250, batch loss 0.0125, batch acc 0.9320
20:57:34.792   Training iter 300, batch loss 0.0110, batch acc 0.9352
20:57:35.123   Training iter 350, batch loss 0.0130, batch acc 0.9246
20:57:35.386   Training iter 400, batch loss 0.0115, batch acc 0.9364
20:57:35.589   Training iter 450, batch loss 0.0107, batch acc 0.9412
20:57:35.813   Training iter 500, batch loss 0.0120, batch acc 0.9326
20:57:36.049   Training iter 550, batch loss 0.0117, batch acc 0.9344
20:57:36.276   Training iter 600, batch loss 0.0124, batch acc 0.9304
20:57:36.277 Training @ 43 epoch...
20:57:36.499   Training iter 50, batch loss 0.0126, batch acc 0.9270
20:57:36.716   Training iter 100, batch loss 0.0116, batch acc 0.9346
20:57:36.936   Training iter 150, batch loss 0.0111, batch acc 0.9336
20:57:37.222   Training iter 200, batch loss 0.0122, batch acc 0.9328
20:57:37.568   Training iter 250, batch loss 0.0115, batch acc 0.9328
20:57:38.252   Training iter 300, batch loss 0.0120, batch acc 0.9322
20:57:38.743   Training iter 350, batch loss 0.0121, batch acc 0.9318
20:57:39.447   Training iter 400, batch loss 0.0116, batch acc 0.9352
20:57:39.871   Training iter 450, batch loss 0.0118, batch acc 0.9336
20:57:40.318   Training iter 500, batch loss 0.0115, batch acc 0.9354
20:57:40.702   Training iter 550, batch loss 0.0117, batch acc 0.9332
20:57:41.345   Training iter 600, batch loss 0.0117, batch acc 0.9300
20:57:41.345 Training @ 44 epoch...
20:57:41.875   Training iter 50, batch loss 0.0115, batch acc 0.9310
20:57:42.625   Training iter 100, batch loss 0.0117, batch acc 0.9332
20:57:43.259   Training iter 150, batch loss 0.0128, batch acc 0.9226
20:57:43.724   Training iter 200, batch loss 0.0120, batch acc 0.9276
20:57:44.457   Training iter 250, batch loss 0.0113, batch acc 0.9400
20:57:44.955   Training iter 300, batch loss 0.0113, batch acc 0.9356
20:57:45.558   Training iter 350, batch loss 0.0118, batch acc 0.9314
20:57:46.058   Training iter 400, batch loss 0.0113, batch acc 0.9356
20:57:46.526   Training iter 450, batch loss 0.0117, batch acc 0.9352
20:57:46.915   Training iter 500, batch loss 0.0118, batch acc 0.9344
20:57:47.383   Training iter 550, batch loss 0.0110, batch acc 0.9384
20:57:47.925   Training iter 600, batch loss 0.0111, batch acc 0.9392
20:57:47.926 Training @ 45 epoch...
20:57:48.506   Training iter 50, batch loss 0.0116, batch acc 0.9356
20:57:48.939   Training iter 100, batch loss 0.0110, batch acc 0.9376
20:57:49.314   Training iter 150, batch loss 0.0128, batch acc 0.9280
20:57:49.684   Training iter 200, batch loss 0.0116, batch acc 0.9324
20:57:50.080   Training iter 250, batch loss 0.0112, batch acc 0.9394
20:57:50.462   Training iter 300, batch loss 0.0111, batch acc 0.9304
20:57:50.737   Training iter 350, batch loss 0.0111, batch acc 0.9372
20:57:51.029   Training iter 400, batch loss 0.0121, batch acc 0.9364
20:57:51.404   Training iter 450, batch loss 0.0104, batch acc 0.9398
20:57:51.771   Training iter 500, batch loss 0.0123, batch acc 0.9284
20:57:52.205   Training iter 550, batch loss 0.0114, batch acc 0.9340
20:57:52.594   Training iter 600, batch loss 0.0109, batch acc 0.9358
20:57:52.595 Testing @ 45 epoch...
20:57:52.762     Testing, total mean loss 0.01142, total acc 0.93320
20:57:52.763 Training @ 46 epoch...
20:57:53.341   Training iter 50, batch loss 0.0117, batch acc 0.9340
20:57:53.752   Training iter 100, batch loss 0.0103, batch acc 0.9414
20:57:54.219   Training iter 150, batch loss 0.0117, batch acc 0.9358
20:57:54.750   Training iter 200, batch loss 0.0105, batch acc 0.9376
20:57:55.192   Training iter 250, batch loss 0.0114, batch acc 0.9324
20:57:55.711   Training iter 300, batch loss 0.0133, batch acc 0.9248
20:57:56.075   Training iter 350, batch loss 0.0113, batch acc 0.9348
20:57:56.400   Training iter 400, batch loss 0.0119, batch acc 0.9346
20:57:56.802   Training iter 450, batch loss 0.0112, batch acc 0.9356
20:57:57.067   Training iter 500, batch loss 0.0114, batch acc 0.9330
20:57:57.393   Training iter 550, batch loss 0.0109, batch acc 0.9378
20:57:57.705   Training iter 600, batch loss 0.0105, batch acc 0.9396
20:57:57.707 Training @ 47 epoch...
20:57:58.057   Training iter 50, batch loss 0.0109, batch acc 0.9396
20:57:58.473   Training iter 100, batch loss 0.0109, batch acc 0.9388
20:57:58.803   Training iter 150, batch loss 0.0108, batch acc 0.9366
20:57:59.163   Training iter 200, batch loss 0.0120, batch acc 0.9276
20:57:59.444   Training iter 250, batch loss 0.0107, batch acc 0.9386
20:57:59.768   Training iter 300, batch loss 0.0111, batch acc 0.9390
20:58:00.117   Training iter 350, batch loss 0.0108, batch acc 0.9382
20:58:00.399   Training iter 400, batch loss 0.0116, batch acc 0.9326
20:58:00.698   Training iter 450, batch loss 0.0117, batch acc 0.9298
20:58:01.092   Training iter 500, batch loss 0.0112, batch acc 0.9348
20:58:01.542   Training iter 550, batch loss 0.0114, batch acc 0.9360
20:58:01.963   Training iter 600, batch loss 0.0111, batch acc 0.9382
20:58:01.965 Training @ 48 epoch...
20:58:02.356   Training iter 50, batch loss 0.0114, batch acc 0.9356
20:58:02.764   Training iter 100, batch loss 0.0106, batch acc 0.9426
20:58:03.029   Training iter 150, batch loss 0.0114, batch acc 0.9298
20:58:03.390   Training iter 200, batch loss 0.0110, batch acc 0.9344
20:58:03.705   Training iter 250, batch loss 0.0113, batch acc 0.9348
20:58:04.019   Training iter 300, batch loss 0.0110, batch acc 0.9378
20:58:04.323   Training iter 350, batch loss 0.0114, batch acc 0.9344
20:58:04.600   Training iter 400, batch loss 0.0099, batch acc 0.9432
20:58:04.899   Training iter 450, batch loss 0.0110, batch acc 0.9386
20:58:05.193   Training iter 500, batch loss 0.0118, batch acc 0.9368
20:58:05.489   Training iter 550, batch loss 0.0108, batch acc 0.9388
20:58:05.772   Training iter 600, batch loss 0.0111, batch acc 0.9364
20:58:05.774 Training @ 49 epoch...
20:58:06.057   Training iter 50, batch loss 0.0112, batch acc 0.9350
20:58:06.408   Training iter 100, batch loss 0.0107, batch acc 0.9382
20:58:06.711   Training iter 150, batch loss 0.0109, batch acc 0.9366
20:58:07.078   Training iter 200, batch loss 0.0111, batch acc 0.9386
20:58:07.379   Training iter 250, batch loss 0.0110, batch acc 0.9366
20:58:07.719   Training iter 300, batch loss 0.0107, batch acc 0.9392
20:58:08.410   Training iter 350, batch loss 0.0125, batch acc 0.9314
20:58:08.714   Training iter 400, batch loss 0.0108, batch acc 0.9372
20:58:09.142   Training iter 450, batch loss 0.0114, batch acc 0.9306
20:58:09.618   Training iter 500, batch loss 0.0112, batch acc 0.9362
20:58:10.072   Training iter 550, batch loss 0.0095, batch acc 0.9478
20:58:10.562   Training iter 600, batch loss 0.0102, batch acc 0.9390
20:58:10.563 Training @ 50 epoch...
20:58:10.935   Training iter 50, batch loss 0.0104, batch acc 0.9392
20:58:11.407   Training iter 100, batch loss 0.0100, batch acc 0.9430
20:58:11.758   Training iter 150, batch loss 0.0110, batch acc 0.9364
20:58:12.088   Training iter 200, batch loss 0.0113, batch acc 0.9366
20:58:12.431   Training iter 250, batch loss 0.0103, batch acc 0.9412
20:58:12.797   Training iter 300, batch loss 0.0109, batch acc 0.9368
20:58:13.197   Training iter 350, batch loss 0.0107, batch acc 0.9360
20:58:13.614   Training iter 400, batch loss 0.0116, batch acc 0.9338
20:58:14.125   Training iter 450, batch loss 0.0106, batch acc 0.9400
20:58:14.469   Training iter 500, batch loss 0.0115, batch acc 0.9362
20:58:14.772   Training iter 550, batch loss 0.0102, batch acc 0.9392
20:58:15.161   Training iter 600, batch loss 0.0114, batch acc 0.9338
20:58:15.162 Testing @ 50 epoch...
20:58:15.383     Testing, total mean loss 0.01085, total acc 0.93910
20:58:15.383 Training @ 51 epoch...
20:58:15.694   Training iter 50, batch loss 0.0101, batch acc 0.9438
20:58:16.073   Training iter 100, batch loss 0.0110, batch acc 0.9374
20:58:16.464   Training iter 150, batch loss 0.0112, batch acc 0.9346
20:58:16.856   Training iter 200, batch loss 0.0109, batch acc 0.9364
20:58:17.237   Training iter 250, batch loss 0.0111, batch acc 0.9382
20:58:17.512   Training iter 300, batch loss 0.0104, batch acc 0.9388
20:58:17.809   Training iter 350, batch loss 0.0104, batch acc 0.9414
20:58:18.155   Training iter 400, batch loss 0.0113, batch acc 0.9324
20:58:18.491   Training iter 450, batch loss 0.0107, batch acc 0.9404
20:58:18.824   Training iter 500, batch loss 0.0105, batch acc 0.9414
20:58:19.160   Training iter 550, batch loss 0.0098, batch acc 0.9406
20:58:19.404   Training iter 600, batch loss 0.0111, batch acc 0.9356
20:58:19.404 Training @ 52 epoch...
20:58:19.647   Training iter 50, batch loss 0.0105, batch acc 0.9402
20:58:19.941   Training iter 100, batch loss 0.0104, batch acc 0.9396
20:58:20.215   Training iter 150, batch loss 0.0109, batch acc 0.9380
20:58:20.520   Training iter 200, batch loss 0.0109, batch acc 0.9362
20:58:20.817   Training iter 250, batch loss 0.0105, batch acc 0.9398
20:58:21.125   Training iter 300, batch loss 0.0104, batch acc 0.9384
20:58:21.463   Training iter 350, batch loss 0.0106, batch acc 0.9370
20:58:21.974   Training iter 400, batch loss 0.0095, batch acc 0.9444
20:58:22.410   Training iter 450, batch loss 0.0112, batch acc 0.9368
20:58:22.877   Training iter 500, batch loss 0.0096, batch acc 0.9460
20:58:23.296   Training iter 550, batch loss 0.0115, batch acc 0.9338
20:58:23.721   Training iter 600, batch loss 0.0113, batch acc 0.9376
20:58:23.721 Training @ 53 epoch...
20:58:24.008   Training iter 50, batch loss 0.0104, batch acc 0.9414
20:58:24.360   Training iter 100, batch loss 0.0107, batch acc 0.9358
20:58:24.705   Training iter 150, batch loss 0.0107, batch acc 0.9406
20:58:25.084   Training iter 200, batch loss 0.0101, batch acc 0.9450
20:58:25.531   Training iter 250, batch loss 0.0105, batch acc 0.9408
20:58:25.771   Training iter 300, batch loss 0.0100, batch acc 0.9438
20:58:26.048   Training iter 350, batch loss 0.0102, batch acc 0.9400
20:58:26.472   Training iter 400, batch loss 0.0103, batch acc 0.9404
20:58:26.760   Training iter 450, batch loss 0.0104, batch acc 0.9396
20:58:27.211   Training iter 500, batch loss 0.0100, batch acc 0.9418
20:58:27.536   Training iter 550, batch loss 0.0119, batch acc 0.9314
20:58:27.868   Training iter 600, batch loss 0.0107, batch acc 0.9378
20:58:27.869 Training @ 54 epoch...
20:58:28.214   Training iter 50, batch loss 0.0103, batch acc 0.9388
20:58:28.563   Training iter 100, batch loss 0.0105, batch acc 0.9410
20:58:28.901   Training iter 150, batch loss 0.0097, batch acc 0.9432
20:58:29.208   Training iter 200, batch loss 0.0107, batch acc 0.9398
20:58:29.462   Training iter 250, batch loss 0.0106, batch acc 0.9378
20:58:29.729   Training iter 300, batch loss 0.0102, batch acc 0.9404
20:58:30.016   Training iter 350, batch loss 0.0097, batch acc 0.9432
20:58:30.377   Training iter 400, batch loss 0.0110, batch acc 0.9372
20:58:30.731   Training iter 450, batch loss 0.0105, batch acc 0.9408
20:58:31.083   Training iter 500, batch loss 0.0107, batch acc 0.9372
20:58:31.375   Training iter 550, batch loss 0.0113, batch acc 0.9398
20:58:31.677   Training iter 600, batch loss 0.0097, batch acc 0.9442
20:58:31.678 Training @ 55 epoch...
20:58:32.024   Training iter 50, batch loss 0.0104, batch acc 0.9404
20:58:32.316   Training iter 100, batch loss 0.0104, batch acc 0.9418
20:58:32.592   Training iter 150, batch loss 0.0099, batch acc 0.9438
20:58:32.877   Training iter 200, batch loss 0.0108, batch acc 0.9404
20:58:33.198   Training iter 250, batch loss 0.0098, batch acc 0.9416
20:58:33.542   Training iter 300, batch loss 0.0100, batch acc 0.9404
20:58:33.893   Training iter 350, batch loss 0.0098, batch acc 0.9436
20:58:34.170   Training iter 400, batch loss 0.0106, batch acc 0.9384
20:58:34.431   Training iter 450, batch loss 0.0100, batch acc 0.9460
20:58:34.737   Training iter 500, batch loss 0.0112, batch acc 0.9354
20:58:34.997   Training iter 550, batch loss 0.0104, batch acc 0.9406
20:58:35.234   Training iter 600, batch loss 0.0106, batch acc 0.9376
20:58:35.234 Testing @ 55 epoch...
20:58:35.385     Testing, total mean loss 0.01029, total acc 0.94020
20:58:35.385 Training @ 56 epoch...
20:58:35.618   Training iter 50, batch loss 0.0108, batch acc 0.9366
20:58:35.967   Training iter 100, batch loss 0.0102, batch acc 0.9412
20:58:36.393   Training iter 150, batch loss 0.0110, batch acc 0.9368
20:58:36.805   Training iter 200, batch loss 0.0105, batch acc 0.9406
20:58:37.063   Training iter 250, batch loss 0.0103, batch acc 0.9432
20:58:37.336   Training iter 300, batch loss 0.0101, batch acc 0.9422
20:58:37.647   Training iter 350, batch loss 0.0095, batch acc 0.9430
20:58:38.056   Training iter 400, batch loss 0.0096, batch acc 0.9388
20:58:38.351   Training iter 450, batch loss 0.0100, batch acc 0.9420
20:58:38.576   Training iter 500, batch loss 0.0105, batch acc 0.9448
20:58:38.862   Training iter 550, batch loss 0.0107, batch acc 0.9418
20:58:39.188   Training iter 600, batch loss 0.0100, batch acc 0.9430
20:58:39.189 Training @ 57 epoch...
20:58:39.466   Training iter 50, batch loss 0.0112, batch acc 0.9348
20:58:39.746   Training iter 100, batch loss 0.0091, batch acc 0.9462
20:58:39.991   Training iter 150, batch loss 0.0106, batch acc 0.9418
20:58:40.227   Training iter 200, batch loss 0.0098, batch acc 0.9430
20:58:40.462   Training iter 250, batch loss 0.0101, batch acc 0.9436
20:58:40.717   Training iter 300, batch loss 0.0101, batch acc 0.9434
20:58:40.943   Training iter 350, batch loss 0.0099, batch acc 0.9430
20:58:41.180   Training iter 400, batch loss 0.0102, batch acc 0.9396
20:58:41.433   Training iter 450, batch loss 0.0117, batch acc 0.9362
20:58:41.722   Training iter 500, batch loss 0.0099, batch acc 0.9398
20:58:42.104   Training iter 550, batch loss 0.0097, batch acc 0.9442
20:58:42.470   Training iter 600, batch loss 0.0098, batch acc 0.9438
20:58:42.472 Training @ 58 epoch...
20:58:43.007   Training iter 50, batch loss 0.0100, batch acc 0.9432
20:58:43.607   Training iter 100, batch loss 0.0104, batch acc 0.9420
20:58:43.993   Training iter 150, batch loss 0.0096, batch acc 0.9482
20:58:44.281   Training iter 200, batch loss 0.0106, batch acc 0.9392
20:58:44.692   Training iter 250, batch loss 0.0099, batch acc 0.9416
20:58:45.183   Training iter 300, batch loss 0.0108, batch acc 0.9384
20:58:45.661   Training iter 350, batch loss 0.0092, batch acc 0.9506
20:58:46.126   Training iter 400, batch loss 0.0098, batch acc 0.9434
20:58:46.478   Training iter 450, batch loss 0.0108, batch acc 0.9370
20:58:47.109   Training iter 500, batch loss 0.0105, batch acc 0.9410
20:58:47.578   Training iter 550, batch loss 0.0098, batch acc 0.9470
20:58:47.979   Training iter 600, batch loss 0.0101, batch acc 0.9390
20:58:47.980 Training @ 59 epoch...
20:58:48.359   Training iter 50, batch loss 0.0094, batch acc 0.9444
20:58:48.665   Training iter 100, batch loss 0.0102, batch acc 0.9418
20:58:49.109   Training iter 150, batch loss 0.0106, batch acc 0.9430
20:58:49.532   Training iter 200, batch loss 0.0099, batch acc 0.9446
20:58:50.099   Training iter 250, batch loss 0.0098, batch acc 0.9422
20:58:50.643   Training iter 300, batch loss 0.0094, batch acc 0.9472
20:58:51.157   Training iter 350, batch loss 0.0101, batch acc 0.9432
20:58:51.525   Training iter 400, batch loss 0.0105, batch acc 0.9398
20:58:51.847   Training iter 450, batch loss 0.0100, batch acc 0.9442
20:58:52.093   Training iter 500, batch loss 0.0105, batch acc 0.9362
20:58:52.370   Training iter 550, batch loss 0.0097, batch acc 0.9434
20:58:52.628   Training iter 600, batch loss 0.0100, batch acc 0.9424
20:58:52.628 Training @ 60 epoch...
20:58:52.889   Training iter 50, batch loss 0.0100, batch acc 0.9452
20:58:53.157   Training iter 100, batch loss 0.0101, batch acc 0.9408
20:58:53.443   Training iter 150, batch loss 0.0093, batch acc 0.9470
20:58:53.740   Training iter 200, batch loss 0.0103, batch acc 0.9384
20:58:54.070   Training iter 250, batch loss 0.0098, batch acc 0.9444
20:58:54.363   Training iter 300, batch loss 0.0104, batch acc 0.9436
20:58:54.599   Training iter 350, batch loss 0.0097, batch acc 0.9398
20:58:54.848   Training iter 400, batch loss 0.0098, batch acc 0.9418
20:58:55.097   Training iter 450, batch loss 0.0096, batch acc 0.9418
20:58:55.351   Training iter 500, batch loss 0.0096, batch acc 0.9446
20:58:55.615   Training iter 550, batch loss 0.0094, batch acc 0.9480
20:58:55.849   Training iter 600, batch loss 0.0114, batch acc 0.9390
20:58:55.851 Testing @ 60 epoch...
20:58:55.993     Testing, total mean loss 0.01000, total acc 0.94240
20:58:55.993 Training @ 61 epoch...
20:58:56.275   Training iter 50, batch loss 0.0098, batch acc 0.9422
20:58:56.662   Training iter 100, batch loss 0.0096, batch acc 0.9464
20:58:57.061   Training iter 150, batch loss 0.0091, batch acc 0.9468
20:58:57.399   Training iter 200, batch loss 0.0094, batch acc 0.9454
20:58:57.847   Training iter 250, batch loss 0.0103, batch acc 0.9436
20:58:58.261   Training iter 300, batch loss 0.0094, batch acc 0.9510
20:58:58.552   Training iter 350, batch loss 0.0100, batch acc 0.9414
20:58:58.830   Training iter 400, batch loss 0.0101, batch acc 0.9406
20:58:59.124   Training iter 450, batch loss 0.0098, batch acc 0.9462
20:58:59.454   Training iter 500, batch loss 0.0104, batch acc 0.9404
20:58:59.805   Training iter 550, batch loss 0.0102, batch acc 0.9428
20:59:00.185   Training iter 600, batch loss 0.0104, batch acc 0.9414
20:59:00.185 Training @ 62 epoch...
20:59:00.467   Training iter 50, batch loss 0.0095, batch acc 0.9390
20:59:00.740   Training iter 100, batch loss 0.0091, batch acc 0.9492
20:59:01.019   Training iter 150, batch loss 0.0104, batch acc 0.9392
20:59:01.298   Training iter 200, batch loss 0.0099, batch acc 0.9464
20:59:01.592   Training iter 250, batch loss 0.0112, batch acc 0.9392
20:59:01.866   Training iter 300, batch loss 0.0094, batch acc 0.9488
20:59:02.153   Training iter 350, batch loss 0.0093, batch acc 0.9432
20:59:02.459   Training iter 400, batch loss 0.0096, batch acc 0.9454
20:59:02.862   Training iter 450, batch loss 0.0102, batch acc 0.9440
20:59:03.162   Training iter 500, batch loss 0.0095, batch acc 0.9452
20:59:03.442   Training iter 550, batch loss 0.0097, batch acc 0.9484
20:59:03.645   Training iter 600, batch loss 0.0098, batch acc 0.9430
20:59:03.649 Training @ 63 epoch...
20:59:03.975   Training iter 50, batch loss 0.0097, batch acc 0.9454
20:59:04.302   Training iter 100, batch loss 0.0098, batch acc 0.9440
20:59:04.541   Training iter 150, batch loss 0.0098, batch acc 0.9454
20:59:04.825   Training iter 200, batch loss 0.0092, batch acc 0.9474
20:59:05.072   Training iter 250, batch loss 0.0099, batch acc 0.9444
20:59:05.325   Training iter 300, batch loss 0.0098, batch acc 0.9444
20:59:05.600   Training iter 350, batch loss 0.0093, batch acc 0.9456
20:59:05.912   Training iter 400, batch loss 0.0100, batch acc 0.9406
20:59:06.247   Training iter 450, batch loss 0.0107, batch acc 0.9394
20:59:06.459   Training iter 500, batch loss 0.0098, batch acc 0.9446
20:59:06.702   Training iter 550, batch loss 0.0094, batch acc 0.9480
20:59:06.924   Training iter 600, batch loss 0.0096, batch acc 0.9442
20:59:06.925 Training @ 64 epoch...
20:59:07.181   Training iter 50, batch loss 0.0093, batch acc 0.9464
20:59:07.419   Training iter 100, batch loss 0.0100, batch acc 0.9394
20:59:07.725   Training iter 150, batch loss 0.0097, batch acc 0.9482
20:59:08.109   Training iter 200, batch loss 0.0103, batch acc 0.9410
20:59:08.395   Training iter 250, batch loss 0.0099, batch acc 0.9438
20:59:08.713   Training iter 300, batch loss 0.0097, batch acc 0.9476
20:59:09.010   Training iter 350, batch loss 0.0092, batch acc 0.9470
20:59:09.267   Training iter 400, batch loss 0.0098, batch acc 0.9440
20:59:09.499   Training iter 450, batch loss 0.0095, batch acc 0.9458
20:59:09.744   Training iter 500, batch loss 0.0099, batch acc 0.9402
20:59:09.989   Training iter 550, batch loss 0.0093, batch acc 0.9506
20:59:10.245   Training iter 600, batch loss 0.0097, batch acc 0.9440
20:59:10.246 Training @ 65 epoch...
20:59:10.494   Training iter 50, batch loss 0.0096, batch acc 0.9416
20:59:10.741   Training iter 100, batch loss 0.0092, batch acc 0.9464
20:59:10.994   Training iter 150, batch loss 0.0103, batch acc 0.9458
20:59:11.265   Training iter 200, batch loss 0.0090, batch acc 0.9486
20:59:11.550   Training iter 250, batch loss 0.0097, batch acc 0.9392
20:59:11.868   Training iter 300, batch loss 0.0095, batch acc 0.9456
20:59:12.131   Training iter 350, batch loss 0.0103, batch acc 0.9460
20:59:12.399   Training iter 400, batch loss 0.0088, batch acc 0.9516
20:59:12.646   Training iter 450, batch loss 0.0095, batch acc 0.9432
20:59:12.882   Training iter 500, batch loss 0.0111, batch acc 0.9418
20:59:13.118   Training iter 550, batch loss 0.0094, batch acc 0.9454
20:59:13.950   Training iter 600, batch loss 0.0094, batch acc 0.9426
20:59:13.951 Testing @ 65 epoch...
20:59:14.180     Testing, total mean loss 0.00991, total acc 0.94310
20:59:14.180 Training @ 66 epoch...
20:59:14.512   Training iter 50, batch loss 0.0095, batch acc 0.9434
20:59:14.821   Training iter 100, batch loss 0.0094, batch acc 0.9470
20:59:15.148   Training iter 150, batch loss 0.0098, batch acc 0.9438
20:59:15.660   Training iter 200, batch loss 0.0093, batch acc 0.9486
20:59:15.946   Training iter 250, batch loss 0.0092, batch acc 0.9486
20:59:16.219   Training iter 300, batch loss 0.0097, batch acc 0.9424
20:59:16.511   Training iter 350, batch loss 0.0091, batch acc 0.9484
20:59:16.752   Training iter 400, batch loss 0.0101, batch acc 0.9436
20:59:17.096   Training iter 450, batch loss 0.0094, batch acc 0.9476
20:59:17.404   Training iter 500, batch loss 0.0107, batch acc 0.9374
20:59:17.696   Training iter 550, batch loss 0.0094, batch acc 0.9450
20:59:17.997   Training iter 600, batch loss 0.0094, batch acc 0.9484
20:59:17.998 Training @ 67 epoch...
20:59:18.259   Training iter 50, batch loss 0.0101, batch acc 0.9422
20:59:18.513   Training iter 100, batch loss 0.0097, batch acc 0.9500
20:59:18.756   Training iter 150, batch loss 0.0091, batch acc 0.9480
20:59:19.027   Training iter 200, batch loss 0.0088, batch acc 0.9488
20:59:19.265   Training iter 250, batch loss 0.0095, batch acc 0.9444
20:59:19.480   Training iter 300, batch loss 0.0099, batch acc 0.9432
20:59:19.721   Training iter 350, batch loss 0.0090, batch acc 0.9450
20:59:20.004   Training iter 400, batch loss 0.0091, batch acc 0.9496
20:59:20.309   Training iter 450, batch loss 0.0097, batch acc 0.9486
20:59:20.605   Training iter 500, batch loss 0.0094, batch acc 0.9470
20:59:20.900   Training iter 550, batch loss 0.0095, batch acc 0.9458
20:59:21.160   Training iter 600, batch loss 0.0104, batch acc 0.9432
20:59:21.161 Training @ 68 epoch...
20:59:21.430   Training iter 50, batch loss 0.0095, batch acc 0.9486
20:59:21.854   Training iter 100, batch loss 0.0095, batch acc 0.9482
20:59:22.183   Training iter 150, batch loss 0.0099, batch acc 0.9438
20:59:22.444   Training iter 200, batch loss 0.0095, batch acc 0.9436
20:59:22.730   Training iter 250, batch loss 0.0087, batch acc 0.9478
20:59:23.052   Training iter 300, batch loss 0.0096, batch acc 0.9474
20:59:23.373   Training iter 350, batch loss 0.0096, batch acc 0.9452
20:59:23.702   Training iter 400, batch loss 0.0097, batch acc 0.9440
20:59:23.916   Training iter 450, batch loss 0.0095, batch acc 0.9460
20:59:24.166   Training iter 500, batch loss 0.0091, batch acc 0.9460
20:59:24.422   Training iter 550, batch loss 0.0098, batch acc 0.9438
20:59:24.686   Training iter 600, batch loss 0.0096, batch acc 0.9472
20:59:24.686 Training @ 69 epoch...
20:59:24.905   Training iter 50, batch loss 0.0098, batch acc 0.9454
20:59:25.155   Training iter 100, batch loss 0.0092, batch acc 0.9488
20:59:25.384   Training iter 150, batch loss 0.0090, batch acc 0.9450
20:59:25.633   Training iter 200, batch loss 0.0087, batch acc 0.9510
20:59:25.969   Training iter 250, batch loss 0.0099, batch acc 0.9472
20:59:26.273   Training iter 300, batch loss 0.0102, batch acc 0.9430
20:59:26.523   Training iter 350, batch loss 0.0092, batch acc 0.9460
20:59:26.758   Training iter 400, batch loss 0.0091, batch acc 0.9466
20:59:26.956   Training iter 450, batch loss 0.0099, batch acc 0.9424
20:59:27.217   Training iter 500, batch loss 0.0096, batch acc 0.9394
20:59:27.458   Training iter 550, batch loss 0.0093, batch acc 0.9494
20:59:27.695   Training iter 600, batch loss 0.0093, batch acc 0.9450
20:59:27.696 Training @ 70 epoch...
20:59:27.941   Training iter 50, batch loss 0.0091, batch acc 0.9478
20:59:28.202   Training iter 100, batch loss 0.0098, batch acc 0.9436
20:59:28.485   Training iter 150, batch loss 0.0098, batch acc 0.9462
20:59:28.786   Training iter 200, batch loss 0.0085, batch acc 0.9520
20:59:29.091   Training iter 250, batch loss 0.0096, batch acc 0.9462
20:59:29.392   Training iter 300, batch loss 0.0086, batch acc 0.9506
20:59:29.586   Training iter 350, batch loss 0.0099, batch acc 0.9426
20:59:29.905   Training iter 400, batch loss 0.0095, batch acc 0.9432
20:59:30.170   Training iter 450, batch loss 0.0102, batch acc 0.9450
20:59:30.412   Training iter 500, batch loss 0.0086, batch acc 0.9472
20:59:30.661   Training iter 550, batch loss 0.0097, batch acc 0.9430
20:59:30.902   Training iter 600, batch loss 0.0093, batch acc 0.9502
20:59:30.904 Testing @ 70 epoch...
20:59:31.024     Testing, total mean loss 0.00954, total acc 0.94450
20:59:31.024 Training @ 71 epoch...
20:59:31.235   Training iter 50, batch loss 0.0091, batch acc 0.9500
20:59:31.561   Training iter 100, batch loss 0.0090, batch acc 0.9486
20:59:31.873   Training iter 150, batch loss 0.0092, batch acc 0.9478
20:59:32.216   Training iter 200, batch loss 0.0093, batch acc 0.9476
20:59:32.452   Training iter 250, batch loss 0.0099, batch acc 0.9442
20:59:32.681   Training iter 300, batch loss 0.0098, batch acc 0.9410
20:59:32.943   Training iter 350, batch loss 0.0094, batch acc 0.9486
20:59:33.178   Training iter 400, batch loss 0.0097, batch acc 0.9444
20:59:33.412   Training iter 450, batch loss 0.0088, batch acc 0.9480
20:59:33.643   Training iter 500, batch loss 0.0097, batch acc 0.9444
20:59:33.890   Training iter 550, batch loss 0.0087, batch acc 0.9500
20:59:34.145   Training iter 600, batch loss 0.0095, batch acc 0.9458
20:59:34.145 Training @ 72 epoch...
20:59:34.414   Training iter 50, batch loss 0.0096, batch acc 0.9470
20:59:34.719   Training iter 100, batch loss 0.0103, batch acc 0.9456
20:59:35.024   Training iter 150, batch loss 0.0092, batch acc 0.9458
20:59:35.304   Training iter 200, batch loss 0.0091, batch acc 0.9490
20:59:35.509   Training iter 250, batch loss 0.0096, batch acc 0.9458
20:59:35.722   Training iter 300, batch loss 0.0094, batch acc 0.9456
20:59:35.978   Training iter 350, batch loss 0.0090, batch acc 0.9470
20:59:36.381   Training iter 400, batch loss 0.0086, batch acc 0.9486
20:59:36.745   Training iter 450, batch loss 0.0082, batch acc 0.9542
20:59:37.092   Training iter 500, batch loss 0.0093, batch acc 0.9484
20:59:37.445   Training iter 550, batch loss 0.0102, batch acc 0.9420
20:59:37.814   Training iter 600, batch loss 0.0091, batch acc 0.9482
20:59:37.816 Training @ 73 epoch...
20:59:38.203   Training iter 50, batch loss 0.0089, batch acc 0.9492
20:59:38.541   Training iter 100, batch loss 0.0090, batch acc 0.9500
20:59:38.840   Training iter 150, batch loss 0.0091, batch acc 0.9506
20:59:39.109   Training iter 200, batch loss 0.0090, batch acc 0.9508
20:59:39.361   Training iter 250, batch loss 0.0089, batch acc 0.9494
20:59:39.768   Training iter 300, batch loss 0.0104, batch acc 0.9420
20:59:40.151   Training iter 350, batch loss 0.0087, batch acc 0.9494
20:59:40.583   Training iter 400, batch loss 0.0095, batch acc 0.9430
20:59:40.957   Training iter 450, batch loss 0.0100, batch acc 0.9392
20:59:41.452   Training iter 500, batch loss 0.0093, batch acc 0.9516
20:59:41.797   Training iter 550, batch loss 0.0091, batch acc 0.9482
20:59:42.109   Training iter 600, batch loss 0.0092, batch acc 0.9464
20:59:42.110 Training @ 74 epoch...
20:59:42.612   Training iter 50, batch loss 0.0094, batch acc 0.9498
20:59:42.996   Training iter 100, batch loss 0.0093, batch acc 0.9484
20:59:43.381   Training iter 150, batch loss 0.0081, batch acc 0.9540
20:59:43.735   Training iter 200, batch loss 0.0098, batch acc 0.9486
20:59:44.105   Training iter 250, batch loss 0.0088, batch acc 0.9486
20:59:44.456   Training iter 300, batch loss 0.0096, batch acc 0.9450
20:59:44.826   Training iter 350, batch loss 0.0094, batch acc 0.9452
20:59:45.158   Training iter 400, batch loss 0.0097, batch acc 0.9434
20:59:45.430   Training iter 450, batch loss 0.0086, batch acc 0.9512
20:59:45.716   Training iter 500, batch loss 0.0090, batch acc 0.9476
20:59:46.081   Training iter 550, batch loss 0.0094, batch acc 0.9472
20:59:46.451   Training iter 600, batch loss 0.0093, batch acc 0.9462
20:59:46.453 Training @ 75 epoch...
20:59:46.792   Training iter 50, batch loss 0.0095, batch acc 0.9480
20:59:47.161   Training iter 100, batch loss 0.0095, batch acc 0.9458
20:59:47.538   Training iter 150, batch loss 0.0094, batch acc 0.9478
20:59:47.819   Training iter 200, batch loss 0.0086, batch acc 0.9464
20:59:48.177   Training iter 250, batch loss 0.0085, batch acc 0.9496
20:59:48.504   Training iter 300, batch loss 0.0086, batch acc 0.9510
20:59:48.770   Training iter 350, batch loss 0.0105, batch acc 0.9416
20:59:49.111   Training iter 400, batch loss 0.0096, batch acc 0.9462
20:59:49.551   Training iter 450, batch loss 0.0091, batch acc 0.9506
20:59:50.037   Training iter 500, batch loss 0.0090, batch acc 0.9526
20:59:50.369   Training iter 550, batch loss 0.0087, batch acc 0.9518
20:59:50.637   Training iter 600, batch loss 0.0088, batch acc 0.9502
20:59:50.639 Testing @ 75 epoch...
20:59:50.768     Testing, total mean loss 0.00937, total acc 0.94660
20:59:50.768 Training @ 76 epoch...
20:59:51.034   Training iter 50, batch loss 0.0092, batch acc 0.9472
20:59:51.288   Training iter 100, batch loss 0.0092, batch acc 0.9492
20:59:51.560   Training iter 150, batch loss 0.0092, batch acc 0.9508
20:59:51.806   Training iter 200, batch loss 0.0094, batch acc 0.9472
20:59:52.146   Training iter 250, batch loss 0.0093, batch acc 0.9486
20:59:52.559   Training iter 300, batch loss 0.0095, batch acc 0.9464
20:59:53.145   Training iter 350, batch loss 0.0086, batch acc 0.9496
20:59:53.491   Training iter 400, batch loss 0.0091, batch acc 0.9470
20:59:54.050   Training iter 450, batch loss 0.0083, batch acc 0.9496
20:59:54.396   Training iter 500, batch loss 0.0090, batch acc 0.9512
20:59:54.900   Training iter 550, batch loss 0.0093, batch acc 0.9458
20:59:55.295   Training iter 600, batch loss 0.0096, batch acc 0.9452
20:59:55.297 Training @ 77 epoch...
20:59:55.754   Training iter 50, batch loss 0.0092, batch acc 0.9454
20:59:56.007   Training iter 100, batch loss 0.0086, batch acc 0.9530
20:59:56.282   Training iter 150, batch loss 0.0087, batch acc 0.9502
20:59:56.533   Training iter 200, batch loss 0.0092, batch acc 0.9458
20:59:56.794   Training iter 250, batch loss 0.0097, batch acc 0.9434
20:59:57.304   Training iter 300, batch loss 0.0090, batch acc 0.9496
20:59:57.546   Training iter 350, batch loss 0.0086, batch acc 0.9532
20:59:57.824   Training iter 400, batch loss 0.0097, batch acc 0.9472
20:59:58.283   Training iter 450, batch loss 0.0092, batch acc 0.9500
20:59:58.594   Training iter 500, batch loss 0.0098, batch acc 0.9450
20:59:58.854   Training iter 550, batch loss 0.0086, batch acc 0.9486
20:59:59.132   Training iter 600, batch loss 0.0089, batch acc 0.9498
20:59:59.133 Training @ 78 epoch...
20:59:59.381   Training iter 50, batch loss 0.0096, batch acc 0.9458
20:59:59.646   Training iter 100, batch loss 0.0088, batch acc 0.9500
21:00:00.026   Training iter 150, batch loss 0.0088, batch acc 0.9502
21:00:00.390   Training iter 200, batch loss 0.0095, batch acc 0.9478
21:00:00.706   Training iter 250, batch loss 0.0090, batch acc 0.9462
21:00:01.095   Training iter 300, batch loss 0.0097, batch acc 0.9452
21:00:01.572   Training iter 350, batch loss 0.0092, batch acc 0.9458
21:00:01.982   Training iter 400, batch loss 0.0081, batch acc 0.9576
21:00:02.207   Training iter 450, batch loss 0.0096, batch acc 0.9478
21:00:02.539   Training iter 500, batch loss 0.0088, batch acc 0.9472
21:00:02.987   Training iter 550, batch loss 0.0088, batch acc 0.9524
21:00:03.279   Training iter 600, batch loss 0.0089, batch acc 0.9538
21:00:03.280 Training @ 79 epoch...
21:00:03.536   Training iter 50, batch loss 0.0098, batch acc 0.9486
21:00:03.937   Training iter 100, batch loss 0.0090, batch acc 0.9500
21:00:04.354   Training iter 150, batch loss 0.0090, batch acc 0.9456
21:00:04.757   Training iter 200, batch loss 0.0085, batch acc 0.9506
21:00:05.164   Training iter 250, batch loss 0.0092, batch acc 0.9484
21:00:05.550   Training iter 300, batch loss 0.0094, batch acc 0.9472
21:00:05.886   Training iter 350, batch loss 0.0089, batch acc 0.9476
21:00:06.146   Training iter 400, batch loss 0.0084, batch acc 0.9528
21:00:06.549   Training iter 450, batch loss 0.0093, batch acc 0.9468
21:00:06.869   Training iter 500, batch loss 0.0093, batch acc 0.9482
21:00:07.445   Training iter 550, batch loss 0.0090, batch acc 0.9506
21:00:08.043   Training iter 600, batch loss 0.0084, batch acc 0.9530
21:00:08.043 Training @ 80 epoch...
21:00:08.673   Training iter 50, batch loss 0.0092, batch acc 0.9476
21:00:08.897   Training iter 100, batch loss 0.0089, batch acc 0.9502
21:00:09.159   Training iter 150, batch loss 0.0098, batch acc 0.9454
21:00:09.438   Training iter 200, batch loss 0.0088, batch acc 0.9478
21:00:09.758   Training iter 250, batch loss 0.0093, batch acc 0.9464
21:00:10.231   Training iter 300, batch loss 0.0085, batch acc 0.9514
21:00:10.489   Training iter 350, batch loss 0.0094, batch acc 0.9522
21:00:10.842   Training iter 400, batch loss 0.0084, batch acc 0.9510
21:00:11.219   Training iter 450, batch loss 0.0084, batch acc 0.9484
21:00:11.582   Training iter 500, batch loss 0.0090, batch acc 0.9500
21:00:12.030   Training iter 550, batch loss 0.0092, batch acc 0.9486
21:00:12.349   Training iter 600, batch loss 0.0089, batch acc 0.9518
21:00:12.349 Testing @ 80 epoch...
21:00:12.541     Testing, total mean loss 0.00920, total acc 0.94760
21:00:12.541 Training @ 81 epoch...
21:00:12.858   Training iter 50, batch loss 0.0091, batch acc 0.9494
21:00:13.163   Training iter 100, batch loss 0.0087, batch acc 0.9518
21:00:13.494   Training iter 150, batch loss 0.0082, batch acc 0.9526
21:00:13.780   Training iter 200, batch loss 0.0086, batch acc 0.9524
21:00:14.074   Training iter 250, batch loss 0.0090, batch acc 0.9472
21:00:14.419   Training iter 300, batch loss 0.0088, batch acc 0.9476
21:00:14.850   Training iter 350, batch loss 0.0097, batch acc 0.9482
21:00:15.280   Training iter 400, batch loss 0.0092, batch acc 0.9442
21:00:15.681   Training iter 450, batch loss 0.0092, batch acc 0.9478
21:00:16.078   Training iter 500, batch loss 0.0089, batch acc 0.9476
21:00:16.483   Training iter 550, batch loss 0.0093, batch acc 0.9530
21:00:16.789   Training iter 600, batch loss 0.0089, batch acc 0.9498
21:00:16.790 Training @ 82 epoch...
21:00:17.051   Training iter 50, batch loss 0.0086, batch acc 0.9526
21:00:17.374   Training iter 100, batch loss 0.0087, batch acc 0.9526
21:00:17.667   Training iter 150, batch loss 0.0086, batch acc 0.9502
21:00:17.962   Training iter 200, batch loss 0.0091, batch acc 0.9524
21:00:18.289   Training iter 250, batch loss 0.0091, batch acc 0.9514
21:00:18.593   Training iter 300, batch loss 0.0091, batch acc 0.9482
21:00:18.999   Training iter 350, batch loss 0.0094, batch acc 0.9438
21:00:19.302   Training iter 400, batch loss 0.0090, batch acc 0.9462
21:00:19.676   Training iter 450, batch loss 0.0083, batch acc 0.9532
21:00:19.961   Training iter 500, batch loss 0.0087, batch acc 0.9468
21:00:20.236   Training iter 550, batch loss 0.0097, batch acc 0.9448
21:00:20.503   Training iter 600, batch loss 0.0089, batch acc 0.9452
21:00:20.504 Training @ 83 epoch...
21:00:20.764   Training iter 50, batch loss 0.0081, batch acc 0.9536
21:00:21.118   Training iter 100, batch loss 0.0089, batch acc 0.9532
21:00:21.444   Training iter 150, batch loss 0.0087, batch acc 0.9508
21:00:21.749   Training iter 200, batch loss 0.0091, batch acc 0.9528
21:00:22.159   Training iter 250, batch loss 0.0086, batch acc 0.9506
21:00:22.503   Training iter 300, batch loss 0.0091, batch acc 0.9472
21:00:22.875   Training iter 350, batch loss 0.0088, batch acc 0.9482
21:00:23.323   Training iter 400, batch loss 0.0093, batch acc 0.9492
21:00:23.677   Training iter 450, batch loss 0.0094, batch acc 0.9488
21:00:23.987   Training iter 500, batch loss 0.0091, batch acc 0.9470
21:00:24.242   Training iter 550, batch loss 0.0091, batch acc 0.9490
21:00:24.745   Training iter 600, batch loss 0.0088, batch acc 0.9508
21:00:24.746 Training @ 84 epoch...
21:00:25.044   Training iter 50, batch loss 0.0090, batch acc 0.9480
21:00:25.456   Training iter 100, batch loss 0.0090, batch acc 0.9506
21:00:25.881   Training iter 150, batch loss 0.0088, batch acc 0.9444
21:00:26.179   Training iter 200, batch loss 0.0088, batch acc 0.9488
21:00:26.526   Training iter 250, batch loss 0.0087, batch acc 0.9514
21:00:26.863   Training iter 300, batch loss 0.0085, batch acc 0.9530
21:00:27.269   Training iter 350, batch loss 0.0084, batch acc 0.9536
21:00:27.619   Training iter 400, batch loss 0.0092, batch acc 0.9462
21:00:28.048   Training iter 450, batch loss 0.0088, batch acc 0.9502
21:00:28.470   Training iter 500, batch loss 0.0091, batch acc 0.9516
21:00:28.753   Training iter 550, batch loss 0.0096, batch acc 0.9456
21:00:29.000   Training iter 600, batch loss 0.0084, batch acc 0.9524
21:00:29.001 Training @ 85 epoch...
21:00:29.319   Training iter 50, batch loss 0.0101, batch acc 0.9422
21:00:29.673   Training iter 100, batch loss 0.0086, batch acc 0.9492
21:00:29.998   Training iter 150, batch loss 0.0082, batch acc 0.9504
21:00:30.364   Training iter 200, batch loss 0.0091, batch acc 0.9484
21:00:30.787   Training iter 250, batch loss 0.0090, batch acc 0.9526
21:00:31.134   Training iter 300, batch loss 0.0085, batch acc 0.9508
21:00:31.382   Training iter 350, batch loss 0.0084, batch acc 0.9524
21:00:31.617   Training iter 400, batch loss 0.0084, batch acc 0.9512
21:00:31.869   Training iter 450, batch loss 0.0090, batch acc 0.9498
21:00:32.127   Training iter 500, batch loss 0.0086, batch acc 0.9540
21:00:32.385   Training iter 550, batch loss 0.0094, batch acc 0.9470
21:00:32.685   Training iter 600, batch loss 0.0089, batch acc 0.9536
21:00:32.687 Testing @ 85 epoch...
21:00:32.811     Testing, total mean loss 0.00893, total acc 0.95060
21:00:32.811 Training @ 86 epoch...
21:00:33.078   Training iter 50, batch loss 0.0093, batch acc 0.9508
21:00:33.449   Training iter 100, batch loss 0.0090, batch acc 0.9486
21:00:33.910   Training iter 150, batch loss 0.0085, batch acc 0.9512
21:00:34.383   Training iter 200, batch loss 0.0095, batch acc 0.9486
21:00:34.649   Training iter 250, batch loss 0.0083, batch acc 0.9526
21:00:34.955   Training iter 300, batch loss 0.0091, batch acc 0.9494
21:00:35.203   Training iter 350, batch loss 0.0079, batch acc 0.9572
21:00:35.463   Training iter 400, batch loss 0.0091, batch acc 0.9474
21:00:35.734   Training iter 450, batch loss 0.0091, batch acc 0.9484
21:00:36.318   Training iter 500, batch loss 0.0084, batch acc 0.9542
21:00:36.693   Training iter 550, batch loss 0.0084, batch acc 0.9508
21:00:36.970   Training iter 600, batch loss 0.0092, batch acc 0.9474
21:00:36.971 Training @ 87 epoch...
21:00:37.220   Training iter 50, batch loss 0.0081, batch acc 0.9550
21:00:37.653   Training iter 100, batch loss 0.0081, batch acc 0.9532
21:00:38.306   Training iter 150, batch loss 0.0087, batch acc 0.9492
21:00:38.684   Training iter 200, batch loss 0.0089, batch acc 0.9546
21:00:39.179   Training iter 250, batch loss 0.0088, batch acc 0.9510
21:00:39.723   Training iter 300, batch loss 0.0085, batch acc 0.9508
21:00:39.971   Training iter 350, batch loss 0.0097, batch acc 0.9492
21:00:40.253   Training iter 400, batch loss 0.0086, batch acc 0.9534
21:00:40.522   Training iter 450, batch loss 0.0089, batch acc 0.9474
21:00:40.769   Training iter 500, batch loss 0.0095, batch acc 0.9462
21:00:41.027   Training iter 550, batch loss 0.0092, batch acc 0.9496
21:00:41.375   Training iter 600, batch loss 0.0086, batch acc 0.9508
21:00:41.377 Training @ 88 epoch...
21:00:41.860   Training iter 50, batch loss 0.0092, batch acc 0.9516
21:00:42.159   Training iter 100, batch loss 0.0089, batch acc 0.9478
21:00:42.730   Training iter 150, batch loss 0.0087, batch acc 0.9484
21:00:43.060   Training iter 200, batch loss 0.0080, batch acc 0.9570
21:00:43.390   Training iter 250, batch loss 0.0083, batch acc 0.9498
21:00:43.738   Training iter 300, batch loss 0.0090, batch acc 0.9494
21:00:43.997   Training iter 350, batch loss 0.0084, batch acc 0.9530
21:00:44.226   Training iter 400, batch loss 0.0081, batch acc 0.9536
21:00:44.468   Training iter 450, batch loss 0.0093, batch acc 0.9448
21:00:44.746   Training iter 500, batch loss 0.0089, batch acc 0.9500
21:00:45.180   Training iter 550, batch loss 0.0091, batch acc 0.9512
21:00:45.651   Training iter 600, batch loss 0.0089, batch acc 0.9494
21:00:45.652 Training @ 89 epoch...
21:00:45.952   Training iter 50, batch loss 0.0088, batch acc 0.9500
21:00:46.267   Training iter 100, batch loss 0.0090, batch acc 0.9472
21:00:46.545   Training iter 150, batch loss 0.0087, batch acc 0.9484
21:00:46.783   Training iter 200, batch loss 0.0083, batch acc 0.9526
21:00:47.223   Training iter 250, batch loss 0.0091, batch acc 0.9488
21:00:47.786   Training iter 300, batch loss 0.0088, batch acc 0.9498
21:00:48.108   Training iter 350, batch loss 0.0090, batch acc 0.9514
21:00:48.382   Training iter 400, batch loss 0.0082, batch acc 0.9514
21:00:48.772   Training iter 450, batch loss 0.0088, batch acc 0.9538
21:00:49.019   Training iter 500, batch loss 0.0084, batch acc 0.9550
21:00:49.269   Training iter 550, batch loss 0.0089, batch acc 0.9504
21:00:49.515   Training iter 600, batch loss 0.0089, batch acc 0.9524
21:00:49.516 Training @ 90 epoch...
21:00:49.746   Training iter 50, batch loss 0.0079, batch acc 0.9552
21:00:50.002   Training iter 100, batch loss 0.0086, batch acc 0.9512
21:00:50.242   Training iter 150, batch loss 0.0085, batch acc 0.9490
21:00:50.516   Training iter 200, batch loss 0.0086, batch acc 0.9524
21:00:50.827   Training iter 250, batch loss 0.0090, batch acc 0.9524
21:00:51.133   Training iter 300, batch loss 0.0086, batch acc 0.9542
21:00:51.410   Training iter 350, batch loss 0.0088, batch acc 0.9496
21:00:51.664   Training iter 400, batch loss 0.0088, batch acc 0.9482
21:00:51.912   Training iter 450, batch loss 0.0095, batch acc 0.9470
21:00:52.196   Training iter 500, batch loss 0.0087, batch acc 0.9516
21:00:52.456   Training iter 550, batch loss 0.0087, batch acc 0.9486
21:00:52.705   Training iter 600, batch loss 0.0086, batch acc 0.9492
21:00:52.706 Testing @ 90 epoch...
21:00:52.830     Testing, total mean loss 0.00881, total acc 0.95050
21:00:52.830 Training @ 91 epoch...
21:00:53.110   Training iter 50, batch loss 0.0078, batch acc 0.9560
21:00:53.410   Training iter 100, batch loss 0.0090, batch acc 0.9498
21:00:53.727   Training iter 150, batch loss 0.0094, batch acc 0.9450
21:00:54.052   Training iter 200, batch loss 0.0084, batch acc 0.9514
21:00:54.306   Training iter 250, batch loss 0.0087, batch acc 0.9518
21:00:54.559   Training iter 300, batch loss 0.0089, batch acc 0.9502
21:00:54.794   Training iter 350, batch loss 0.0087, batch acc 0.9546
21:00:55.119   Training iter 400, batch loss 0.0084, batch acc 0.9508
21:00:55.407   Training iter 450, batch loss 0.0091, batch acc 0.9520
21:00:55.648   Training iter 500, batch loss 0.0089, batch acc 0.9514
21:00:55.889   Training iter 550, batch loss 0.0086, batch acc 0.9480
21:00:56.127   Training iter 600, batch loss 0.0082, batch acc 0.9550
21:00:56.128 Training @ 92 epoch...
21:00:56.416   Training iter 50, batch loss 0.0094, batch acc 0.9512
21:00:56.742   Training iter 100, batch loss 0.0082, batch acc 0.9532
21:00:57.109   Training iter 150, batch loss 0.0079, batch acc 0.9532
21:00:57.430   Training iter 200, batch loss 0.0093, batch acc 0.9476
21:00:57.737   Training iter 250, batch loss 0.0087, batch acc 0.9490
21:00:58.124   Training iter 300, batch loss 0.0082, batch acc 0.9542
21:00:58.446   Training iter 350, batch loss 0.0081, batch acc 0.9526
21:00:58.795   Training iter 400, batch loss 0.0087, batch acc 0.9488
21:00:59.060   Training iter 450, batch loss 0.0087, batch acc 0.9494
21:00:59.373   Training iter 500, batch loss 0.0092, batch acc 0.9462
21:00:59.651   Training iter 550, batch loss 0.0090, batch acc 0.9528
21:01:00.081   Training iter 600, batch loss 0.0082, batch acc 0.9534
21:01:00.081 Training @ 93 epoch...
21:01:00.435   Training iter 50, batch loss 0.0088, batch acc 0.9486
21:01:00.879   Training iter 100, batch loss 0.0094, batch acc 0.9472
21:01:01.220   Training iter 150, batch loss 0.0086, batch acc 0.9534
21:01:01.762   Training iter 200, batch loss 0.0086, batch acc 0.9538
21:01:02.199   Training iter 250, batch loss 0.0088, batch acc 0.9500
21:01:02.637   Training iter 300, batch loss 0.0083, batch acc 0.9518
21:01:03.003   Training iter 350, batch loss 0.0092, batch acc 0.9520
21:01:03.420   Training iter 400, batch loss 0.0092, batch acc 0.9462
21:01:03.652   Training iter 450, batch loss 0.0082, batch acc 0.9538
21:01:03.901   Training iter 500, batch loss 0.0078, batch acc 0.9542
21:01:04.154   Training iter 550, batch loss 0.0078, batch acc 0.9576
21:01:04.391   Training iter 600, batch loss 0.0091, batch acc 0.9474
21:01:04.392 Training @ 94 epoch...
21:01:04.652   Training iter 50, batch loss 0.0088, batch acc 0.9500
21:01:04.911   Training iter 100, batch loss 0.0086, batch acc 0.9488
21:01:05.212   Training iter 150, batch loss 0.0090, batch acc 0.9532
21:01:05.518   Training iter 200, batch loss 0.0083, batch acc 0.9552
21:01:05.813   Training iter 250, batch loss 0.0090, batch acc 0.9482
21:01:06.177   Training iter 300, batch loss 0.0092, batch acc 0.9512
21:01:06.474   Training iter 350, batch loss 0.0092, batch acc 0.9490
21:01:06.840   Training iter 400, batch loss 0.0077, batch acc 0.9520
21:01:07.184   Training iter 450, batch loss 0.0079, batch acc 0.9558
21:01:07.738   Training iter 500, batch loss 0.0089, batch acc 0.9516
21:01:08.271   Training iter 550, batch loss 0.0089, batch acc 0.9528
21:01:08.552   Training iter 600, batch loss 0.0078, batch acc 0.9576
21:01:08.553 Training @ 95 epoch...
21:01:09.003   Training iter 50, batch loss 0.0090, batch acc 0.9500
21:01:09.419   Training iter 100, batch loss 0.0083, batch acc 0.9550
21:01:09.748   Training iter 150, batch loss 0.0084, batch acc 0.9490
21:01:10.102   Training iter 200, batch loss 0.0079, batch acc 0.9532
21:01:10.382   Training iter 250, batch loss 0.0083, batch acc 0.9560
21:01:10.669   Training iter 300, batch loss 0.0088, batch acc 0.9504
21:01:11.049   Training iter 350, batch loss 0.0089, batch acc 0.9490
21:01:11.384   Training iter 400, batch loss 0.0091, batch acc 0.9494
21:01:11.710   Training iter 450, batch loss 0.0090, batch acc 0.9510
21:01:11.969   Training iter 500, batch loss 0.0081, batch acc 0.9542
21:01:12.411   Training iter 550, batch loss 0.0088, batch acc 0.9534
21:01:12.629   Training iter 600, batch loss 0.0084, batch acc 0.9508
21:01:12.629 Testing @ 95 epoch...
21:01:12.750     Testing, total mean loss 0.00881, total acc 0.95070
21:01:12.750 Training @ 96 epoch...
21:01:13.051   Training iter 50, batch loss 0.0086, batch acc 0.9542
21:01:13.360   Training iter 100, batch loss 0.0089, batch acc 0.9506
21:01:13.811   Training iter 150, batch loss 0.0085, batch acc 0.9520
21:01:14.160   Training iter 200, batch loss 0.0089, batch acc 0.9522
21:01:14.499   Training iter 250, batch loss 0.0086, batch acc 0.9494
21:01:14.853   Training iter 300, batch loss 0.0087, batch acc 0.9510
21:01:15.154   Training iter 350, batch loss 0.0085, batch acc 0.9518
21:01:15.453   Training iter 400, batch loss 0.0084, batch acc 0.9544
21:01:15.771   Training iter 450, batch loss 0.0086, batch acc 0.9542
21:01:16.159   Training iter 500, batch loss 0.0081, batch acc 0.9514
21:01:16.446   Training iter 550, batch loss 0.0090, batch acc 0.9476
21:01:16.790   Training iter 600, batch loss 0.0079, batch acc 0.9580
21:01:16.791 Training @ 97 epoch...
21:01:17.159   Training iter 50, batch loss 0.0082, batch acc 0.9556
21:01:17.472   Training iter 100, batch loss 0.0086, batch acc 0.9474
21:01:17.721   Training iter 150, batch loss 0.0083, batch acc 0.9502
21:01:17.973   Training iter 200, batch loss 0.0088, batch acc 0.9502
21:01:18.261   Training iter 250, batch loss 0.0091, batch acc 0.9496
21:01:18.520   Training iter 300, batch loss 0.0087, batch acc 0.9528
21:01:18.794   Training iter 350, batch loss 0.0080, batch acc 0.9524
21:01:19.140   Training iter 400, batch loss 0.0085, batch acc 0.9524
21:01:19.413   Training iter 450, batch loss 0.0084, batch acc 0.9516
21:01:19.841   Training iter 500, batch loss 0.0083, batch acc 0.9540
21:01:20.263   Training iter 550, batch loss 0.0091, batch acc 0.9516
21:01:20.614   Training iter 600, batch loss 0.0084, batch acc 0.9554
21:01:20.615 Training @ 98 epoch...
21:01:20.895   Training iter 50, batch loss 0.0084, batch acc 0.9552
21:01:21.411   Training iter 100, batch loss 0.0086, batch acc 0.9518
21:01:21.787   Training iter 150, batch loss 0.0086, batch acc 0.9514
21:01:22.191   Training iter 200, batch loss 0.0083, batch acc 0.9534
21:01:22.611   Training iter 250, batch loss 0.0081, batch acc 0.9512
21:01:22.949   Training iter 300, batch loss 0.0079, batch acc 0.9598
21:01:23.374   Training iter 350, batch loss 0.0088, batch acc 0.9514
21:01:23.644   Training iter 400, batch loss 0.0076, batch acc 0.9584
21:01:23.894   Training iter 450, batch loss 0.0094, batch acc 0.9482
21:01:24.159   Training iter 500, batch loss 0.0083, batch acc 0.9526
21:01:24.391   Training iter 550, batch loss 0.0092, batch acc 0.9478
21:01:24.630   Training iter 600, batch loss 0.0091, batch acc 0.9522
21:01:24.631 Training @ 99 epoch...
21:01:24.876   Training iter 50, batch loss 0.0089, batch acc 0.9514
21:01:25.161   Training iter 100, batch loss 0.0088, batch acc 0.9516
21:01:25.465   Training iter 150, batch loss 0.0086, batch acc 0.9548
21:01:25.771   Training iter 200, batch loss 0.0079, batch acc 0.9566
21:01:26.076   Training iter 250, batch loss 0.0083, batch acc 0.9560
21:01:26.329   Training iter 300, batch loss 0.0090, batch acc 0.9526
21:01:26.589   Training iter 350, batch loss 0.0074, batch acc 0.9556
21:01:26.856   Training iter 400, batch loss 0.0085, batch acc 0.9520
21:01:27.104   Training iter 450, batch loss 0.0081, batch acc 0.9540
21:01:27.382   Training iter 500, batch loss 0.0086, batch acc 0.9526
21:01:27.664   Training iter 550, batch loss 0.0087, batch acc 0.9492
21:01:27.968   Training iter 600, batch loss 0.0089, batch acc 0.9506
21:01:27.969 Testing @ 99 epoch...
21:01:28.163     Testing, total mean loss 0.00864, total acc 0.95160