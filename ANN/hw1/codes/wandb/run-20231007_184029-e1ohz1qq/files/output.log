18:40:33.093 Training @ 0 epoch...
18:40:33.336   Training iter 50, batch loss 0.8339, batch acc 0.3562
18:40:33.581   Training iter 100, batch loss 0.5477, batch acc 0.7116
18:40:33.717   Training iter 150, batch loss 0.4517, batch acc 0.8020
18:40:33.856   Training iter 200, batch loss 0.3862, batch acc 0.8552
18:40:33.973   Training iter 250, batch loss 0.3459, batch acc 0.8656
18:40:34.198   Training iter 300, batch loss 0.3123, batch acc 0.8708
18:40:34.336   Training iter 350, batch loss 0.2907, batch acc 0.8842
18:40:34.497   Training iter 400, batch loss 0.2688, batch acc 0.8954
18:40:34.613   Training iter 450, batch loss 0.2643, batch acc 0.8880
18:40:34.728   Training iter 500, batch loss 0.2436, batch acc 0.8990
18:40:34.839   Training iter 550, batch loss 0.2362, batch acc 0.8982
18:40:35.003   Training iter 600, batch loss 0.2291, batch acc 0.9056
18:40:35.004 Testing @ 0 epoch...
18:40:35.107     Testing, total mean loss 0.21850, total acc 0.91170
18:40:35.107 Training @ 1 epoch...
18:40:35.213   Training iter 50, batch loss 0.2260, batch acc 0.9052
18:40:35.343   Training iter 100, batch loss 0.2280, batch acc 0.9004
18:40:35.460   Training iter 150, batch loss 0.2185, batch acc 0.9110
18:40:35.709   Training iter 200, batch loss 0.2122, batch acc 0.9108
18:40:35.945   Training iter 250, batch loss 0.2068, batch acc 0.9116
18:40:36.062   Training iter 300, batch loss 0.2088, batch acc 0.9130
18:40:36.177   Training iter 350, batch loss 0.1987, batch acc 0.9162
18:40:36.300   Training iter 400, batch loss 0.1932, batch acc 0.9200
18:40:36.453   Training iter 450, batch loss 0.2041, batch acc 0.9108
18:40:36.555   Training iter 500, batch loss 0.1946, batch acc 0.9214
18:40:36.655   Training iter 550, batch loss 0.1902, batch acc 0.9216
18:40:36.760   Training iter 600, batch loss 0.1985, batch acc 0.9174
18:40:36.760 Training @ 2 epoch...
18:40:36.859   Training iter 50, batch loss 0.1929, batch acc 0.9196
18:40:36.967   Training iter 100, batch loss 0.1808, batch acc 0.9308
18:40:37.074   Training iter 150, batch loss 0.1806, batch acc 0.9262
18:40:37.195   Training iter 200, batch loss 0.1796, batch acc 0.9234
18:40:37.314   Training iter 250, batch loss 0.1815, batch acc 0.9304
18:40:37.442   Training iter 300, batch loss 0.1793, batch acc 0.9264
18:40:37.562   Training iter 350, batch loss 0.1720, batch acc 0.9344
18:40:37.758   Training iter 400, batch loss 0.1698, batch acc 0.9294
18:40:37.892   Training iter 450, batch loss 0.1731, batch acc 0.9328
18:40:37.994   Training iter 500, batch loss 0.1792, batch acc 0.9256
18:40:38.143   Training iter 550, batch loss 0.1745, batch acc 0.9342
18:40:38.267   Training iter 600, batch loss 0.1710, batch acc 0.9310
18:40:38.268 Training @ 3 epoch...
18:40:38.393   Training iter 50, batch loss 0.1609, batch acc 0.9410
18:40:38.513   Training iter 100, batch loss 0.1681, batch acc 0.9336
18:40:38.630   Training iter 150, batch loss 0.1646, batch acc 0.9366
18:40:38.750   Training iter 200, batch loss 0.1617, batch acc 0.9366
18:40:38.840   Training iter 250, batch loss 0.1651, batch acc 0.9330
18:40:38.942   Training iter 300, batch loss 0.1616, batch acc 0.9402
18:40:39.073   Training iter 350, batch loss 0.1602, batch acc 0.9398
18:40:39.174   Training iter 400, batch loss 0.1519, batch acc 0.9436
18:40:39.377   Training iter 450, batch loss 0.1528, batch acc 0.9452
18:40:39.526   Training iter 500, batch loss 0.1534, batch acc 0.9418
18:40:39.674   Training iter 550, batch loss 0.1520, batch acc 0.9446
18:40:39.829   Training iter 600, batch loss 0.1510, batch acc 0.9428
18:40:39.829 Training @ 4 epoch...
18:40:39.972   Training iter 50, batch loss 0.1528, batch acc 0.9452
18:40:40.109   Training iter 100, batch loss 0.1525, batch acc 0.9430
18:40:40.233   Training iter 150, batch loss 0.1444, batch acc 0.9466
18:40:40.385   Training iter 200, batch loss 0.1465, batch acc 0.9494
18:40:40.475   Training iter 250, batch loss 0.1422, batch acc 0.9492
18:40:40.573   Training iter 300, batch loss 0.1435, batch acc 0.9508
18:40:40.672   Training iter 350, batch loss 0.1507, batch acc 0.9430
18:40:40.794   Training iter 400, batch loss 0.1376, batch acc 0.9558
18:40:40.901   Training iter 450, batch loss 0.1452, batch acc 0.9482
18:40:40.995   Training iter 500, batch loss 0.1424, batch acc 0.9484
18:40:41.095   Training iter 550, batch loss 0.1429, batch acc 0.9472
18:40:41.185   Training iter 600, batch loss 0.1437, batch acc 0.9472
18:40:41.186 Training @ 5 epoch...
18:40:41.291   Training iter 50, batch loss 0.1397, batch acc 0.9500
18:40:41.406   Training iter 100, batch loss 0.1353, batch acc 0.9522
18:40:41.498   Training iter 150, batch loss 0.1349, batch acc 0.9550
18:40:41.586   Training iter 200, batch loss 0.1368, batch acc 0.9540
18:40:41.681   Training iter 250, batch loss 0.1368, batch acc 0.9526
18:40:41.784   Training iter 300, batch loss 0.1316, batch acc 0.9536
18:40:41.880   Training iter 350, batch loss 0.1355, batch acc 0.9530
18:40:41.978   Training iter 400, batch loss 0.1339, batch acc 0.9558
18:40:42.081   Training iter 450, batch loss 0.1385, batch acc 0.9554
18:40:42.185   Training iter 500, batch loss 0.1378, batch acc 0.9522
18:40:42.279   Training iter 550, batch loss 0.1382, batch acc 0.9498
18:40:42.394   Training iter 600, batch loss 0.1330, batch acc 0.9560
18:40:42.396 Testing @ 5 epoch...
18:40:42.487     Testing, total mean loss 0.13203, total acc 0.95300
18:40:42.487 Training @ 6 epoch...
18:40:42.599   Training iter 50, batch loss 0.1367, batch acc 0.9502
18:40:42.721   Training iter 100, batch loss 0.1278, batch acc 0.9570
18:40:42.833   Training iter 150, batch loss 0.1373, batch acc 0.9514
18:40:42.978   Training iter 200, batch loss 0.1320, batch acc 0.9588
18:40:43.102   Training iter 250, batch loss 0.1281, batch acc 0.9568
18:40:43.201   Training iter 300, batch loss 0.1201, batch acc 0.9626
18:40:43.300   Training iter 350, batch loss 0.1358, batch acc 0.9522
18:40:43.401   Training iter 400, batch loss 0.1269, batch acc 0.9610
18:40:43.493   Training iter 450, batch loss 0.1238, batch acc 0.9596
18:40:43.606   Training iter 500, batch loss 0.1260, batch acc 0.9562
18:40:43.729   Training iter 550, batch loss 0.1280, batch acc 0.9552
18:40:43.849   Training iter 600, batch loss 0.1242, batch acc 0.9602
18:40:43.851 Training @ 7 epoch...
18:40:43.949   Training iter 50, batch loss 0.1182, batch acc 0.9628
18:40:44.082   Training iter 100, batch loss 0.1298, batch acc 0.9554
18:40:44.178   Training iter 150, batch loss 0.1257, batch acc 0.9592
18:40:44.278   Training iter 200, batch loss 0.1251, batch acc 0.9598
18:40:44.375   Training iter 250, batch loss 0.1247, batch acc 0.9594
18:40:44.472   Training iter 300, batch loss 0.1225, batch acc 0.9560
18:40:44.567   Training iter 350, batch loss 0.1165, batch acc 0.9660
18:40:44.675   Training iter 400, batch loss 0.1208, batch acc 0.9610
18:40:44.769   Training iter 450, batch loss 0.1210, batch acc 0.9608
18:40:44.864   Training iter 500, batch loss 0.1230, batch acc 0.9580
18:40:44.974   Training iter 550, batch loss 0.1232, batch acc 0.9594
18:40:45.088   Training iter 600, batch loss 0.1207, batch acc 0.9618
18:40:45.090 Training @ 8 epoch...
18:40:45.223   Training iter 50, batch loss 0.1241, batch acc 0.9538
18:40:45.409   Training iter 100, batch loss 0.1211, batch acc 0.9590
18:40:45.568   Training iter 150, batch loss 0.1195, batch acc 0.9616
18:40:45.684   Training iter 200, batch loss 0.1175, batch acc 0.9660
18:40:45.817   Training iter 250, batch loss 0.1151, batch acc 0.9650
18:40:45.954   Training iter 300, batch loss 0.1187, batch acc 0.9620
18:40:46.067   Training iter 350, batch loss 0.1205, batch acc 0.9608
18:40:46.179   Training iter 400, batch loss 0.1178, batch acc 0.9642
18:40:46.274   Training iter 450, batch loss 0.1158, batch acc 0.9618
18:40:46.371   Training iter 500, batch loss 0.1156, batch acc 0.9648
18:40:46.469   Training iter 550, batch loss 0.1156, batch acc 0.9652
18:40:46.555   Training iter 600, batch loss 0.1148, batch acc 0.9626
18:40:46.556 Training @ 9 epoch...
18:40:46.657   Training iter 50, batch loss 0.1164, batch acc 0.9616
18:40:46.759   Training iter 100, batch loss 0.1090, batch acc 0.9652
18:40:46.859   Training iter 150, batch loss 0.1174, batch acc 0.9588
18:40:46.958   Training iter 200, batch loss 0.1194, batch acc 0.9576
18:40:47.057   Training iter 250, batch loss 0.1162, batch acc 0.9634
18:40:47.148   Training iter 300, batch loss 0.1123, batch acc 0.9680
18:40:47.244   Training iter 350, batch loss 0.1152, batch acc 0.9630
18:40:47.368   Training iter 400, batch loss 0.1114, batch acc 0.9692
18:40:47.470   Training iter 450, batch loss 0.1108, batch acc 0.9676
18:40:47.564   Training iter 500, batch loss 0.1128, batch acc 0.9642
18:40:47.669   Training iter 550, batch loss 0.1162, batch acc 0.9616
18:40:47.778   Training iter 600, batch loss 0.1164, batch acc 0.9592
18:40:47.779 Training @ 10 epoch...
18:40:47.904   Training iter 50, batch loss 0.1098, batch acc 0.9666
18:40:48.017   Training iter 100, batch loss 0.1082, batch acc 0.9654
18:40:48.127   Training iter 150, batch loss 0.1149, batch acc 0.9620
18:40:48.240   Training iter 200, batch loss 0.1106, batch acc 0.9646
18:40:48.376   Training iter 250, batch loss 0.1123, batch acc 0.9652
18:40:48.492   Training iter 300, batch loss 0.1096, batch acc 0.9640
18:40:48.611   Training iter 350, batch loss 0.1140, batch acc 0.9646
18:40:48.748   Training iter 400, batch loss 0.1116, batch acc 0.9670
18:40:48.877   Training iter 450, batch loss 0.1116, batch acc 0.9612
18:40:49.013   Training iter 500, batch loss 0.1138, batch acc 0.9642
18:40:49.174   Training iter 550, batch loss 0.1067, batch acc 0.9664
18:40:49.316   Training iter 600, batch loss 0.1107, batch acc 0.9648
18:40:49.317 Testing @ 10 epoch...
18:40:49.415     Testing, total mean loss 0.11216, total acc 0.96390
18:40:49.415 Training @ 11 epoch...
18:40:49.521   Training iter 50, batch loss 0.1101, batch acc 0.9658
18:40:49.620   Training iter 100, batch loss 0.1079, batch acc 0.9668
18:40:49.720   Training iter 150, batch loss 0.1109, batch acc 0.9656
18:40:49.820   Training iter 200, batch loss 0.1090, batch acc 0.9680
18:40:49.928   Training iter 250, batch loss 0.1070, batch acc 0.9652
18:40:50.031   Training iter 300, batch loss 0.1065, batch acc 0.9714
18:40:50.136   Training iter 350, batch loss 0.1109, batch acc 0.9656
18:40:50.237   Training iter 400, batch loss 0.1079, batch acc 0.9670
18:40:50.335   Training iter 450, batch loss 0.1104, batch acc 0.9602
18:40:50.452   Training iter 500, batch loss 0.1062, batch acc 0.9674
18:40:50.551   Training iter 550, batch loss 0.1120, batch acc 0.9622
18:40:50.649   Training iter 600, batch loss 0.1035, batch acc 0.9674
18:40:50.651 Training @ 12 epoch...
18:40:50.786   Training iter 50, batch loss 0.1058, batch acc 0.9680
18:40:50.933   Training iter 100, batch loss 0.1077, batch acc 0.9672
18:40:51.055   Training iter 150, batch loss 0.1075, batch acc 0.9656
18:40:51.176   Training iter 200, batch loss 0.1054, batch acc 0.9704
18:40:51.287   Training iter 250, batch loss 0.1081, batch acc 0.9640
18:40:51.432   Training iter 300, batch loss 0.1033, batch acc 0.9712
18:40:51.593   Training iter 350, batch loss 0.1054, batch acc 0.9672
18:40:51.697   Training iter 400, batch loss 0.1060, batch acc 0.9660
18:40:51.803   Training iter 450, batch loss 0.1034, batch acc 0.9692
18:40:51.989   Training iter 500, batch loss 0.1078, batch acc 0.9654
18:40:52.152   Training iter 550, batch loss 0.1061, batch acc 0.9648
18:40:52.342   Training iter 600, batch loss 0.1074, batch acc 0.9656
18:40:52.342 Training @ 13 epoch...
18:40:52.508   Training iter 50, batch loss 0.1027, batch acc 0.9706
18:40:52.661   Training iter 100, batch loss 0.1085, batch acc 0.9632
18:40:52.841   Training iter 150, batch loss 0.1059, batch acc 0.9672
18:40:53.010   Training iter 200, batch loss 0.1089, batch acc 0.9644
18:40:53.170   Training iter 250, batch loss 0.1061, batch acc 0.9674
18:40:53.278   Training iter 300, batch loss 0.1009, batch acc 0.9696
18:40:53.391   Training iter 350, batch loss 0.1030, batch acc 0.9710
18:40:53.501   Training iter 400, batch loss 0.0997, batch acc 0.9702
18:40:53.626   Training iter 450, batch loss 0.1011, batch acc 0.9720
18:40:53.739   Training iter 500, batch loss 0.1032, batch acc 0.9680
18:40:53.837   Training iter 550, batch loss 0.1048, batch acc 0.9652
18:40:54.025   Training iter 600, batch loss 0.1030, batch acc 0.9690
18:40:54.025 Training @ 14 epoch...
18:40:54.244   Training iter 50, batch loss 0.0990, batch acc 0.9726
18:40:54.463   Training iter 100, batch loss 0.1079, batch acc 0.9652
18:40:54.688   Training iter 150, batch loss 0.1008, batch acc 0.9690
18:40:54.882   Training iter 200, batch loss 0.1030, batch acc 0.9706
18:40:55.015   Training iter 250, batch loss 0.1054, batch acc 0.9638
18:40:55.162   Training iter 300, batch loss 0.1034, batch acc 0.9702
18:40:55.328   Training iter 350, batch loss 0.0951, batch acc 0.9698
18:40:55.450   Training iter 400, batch loss 0.1052, batch acc 0.9682
18:40:55.548   Training iter 450, batch loss 0.1064, batch acc 0.9648
18:40:55.651   Training iter 500, batch loss 0.0978, batch acc 0.9712
18:40:55.853   Training iter 550, batch loss 0.1033, batch acc 0.9672
18:40:56.149   Training iter 600, batch loss 0.1019, batch acc 0.9728
18:40:56.151 Training @ 15 epoch...
18:40:56.371   Training iter 50, batch loss 0.0983, batch acc 0.9718
18:40:56.739   Training iter 100, batch loss 0.0974, batch acc 0.9732
18:40:57.009   Training iter 150, batch loss 0.0977, batch acc 0.9712
18:40:57.270   Training iter 200, batch loss 0.0965, batch acc 0.9690
18:40:57.481   Training iter 250, batch loss 0.1010, batch acc 0.9716
18:40:57.640   Training iter 300, batch loss 0.0998, batch acc 0.9726
18:40:57.793   Training iter 350, batch loss 0.1049, batch acc 0.9662
18:40:57.940   Training iter 400, batch loss 0.1020, batch acc 0.9702
18:40:58.079   Training iter 450, batch loss 0.1053, batch acc 0.9664
18:40:58.231   Training iter 500, batch loss 0.1005, batch acc 0.9668
18:40:58.381   Training iter 550, batch loss 0.1008, batch acc 0.9688
18:40:58.545   Training iter 600, batch loss 0.1053, batch acc 0.9650
18:40:58.545 Testing @ 15 epoch...
18:40:58.660     Testing, total mean loss 0.10227, total acc 0.96850
18:40:58.660 Training @ 16 epoch...
18:40:58.823   Training iter 50, batch loss 0.0978, batch acc 0.9692
18:40:58.971   Training iter 100, batch loss 0.0977, batch acc 0.9726
18:40:59.141   Training iter 150, batch loss 0.1051, batch acc 0.9672
18:40:59.330   Training iter 200, batch loss 0.0994, batch acc 0.9708
18:40:59.542   Training iter 250, batch loss 0.0980, batch acc 0.9718
18:40:59.714   Training iter 300, batch loss 0.0976, batch acc 0.9718
18:40:59.975   Training iter 350, batch loss 0.0954, batch acc 0.9730
18:41:00.285   Training iter 400, batch loss 0.0973, batch acc 0.9698
18:41:00.443   Training iter 450, batch loss 0.0990, batch acc 0.9678
18:41:00.589   Training iter 500, batch loss 0.1021, batch acc 0.9672
18:41:00.810   Training iter 550, batch loss 0.1019, batch acc 0.9650
18:41:00.942   Training iter 600, batch loss 0.1026, batch acc 0.9678
18:41:00.943 Training @ 17 epoch...
18:41:01.148   Training iter 50, batch loss 0.0967, batch acc 0.9698
18:41:01.306   Training iter 100, batch loss 0.0951, batch acc 0.9732
18:41:01.464   Training iter 150, batch loss 0.0987, batch acc 0.9722
18:41:01.597   Training iter 200, batch loss 0.0973, batch acc 0.9716
18:41:01.731   Training iter 250, batch loss 0.0988, batch acc 0.9710
18:41:01.879   Training iter 300, batch loss 0.0979, batch acc 0.9736
18:41:02.014   Training iter 350, batch loss 0.0961, batch acc 0.9718
18:41:02.177   Training iter 400, batch loss 0.0986, batch acc 0.9696
18:41:02.343   Training iter 450, batch loss 0.1013, batch acc 0.9674
18:41:02.513   Training iter 500, batch loss 0.0981, batch acc 0.9700
18:41:02.681   Training iter 550, batch loss 0.0985, batch acc 0.9696
18:41:02.865   Training iter 600, batch loss 0.0966, batch acc 0.9712
18:41:02.866 Training @ 18 epoch...
18:41:03.054   Training iter 50, batch loss 0.0980, batch acc 0.9704
18:41:03.179   Training iter 100, batch loss 0.0981, batch acc 0.9722
18:41:03.315   Training iter 150, batch loss 0.0952, batch acc 0.9728
18:41:03.448   Training iter 200, batch loss 0.0972, batch acc 0.9682
18:41:03.594   Training iter 250, batch loss 0.0982, batch acc 0.9704
18:41:03.757   Training iter 300, batch loss 0.0943, batch acc 0.9766
18:41:03.896   Training iter 350, batch loss 0.0986, batch acc 0.9690
18:41:04.037   Training iter 400, batch loss 0.0998, batch acc 0.9688
18:41:04.173   Training iter 450, batch loss 0.0966, batch acc 0.9748
18:41:04.346   Training iter 500, batch loss 0.0960, batch acc 0.9708
18:41:04.542   Training iter 550, batch loss 0.0970, batch acc 0.9704
18:41:04.690   Training iter 600, batch loss 0.0949, batch acc 0.9700
18:41:04.691 Training @ 19 epoch...
18:41:04.924   Training iter 50, batch loss 0.0948, batch acc 0.9714
18:41:05.113   Training iter 100, batch loss 0.0969, batch acc 0.9684
18:41:05.322   Training iter 150, batch loss 0.0961, batch acc 0.9724
18:41:05.487   Training iter 200, batch loss 0.0999, batch acc 0.9696
18:41:05.672   Training iter 250, batch loss 0.0870, batch acc 0.9766
18:41:05.852   Training iter 300, batch loss 0.0962, batch acc 0.9686
18:41:06.045   Training iter 350, batch loss 0.0971, batch acc 0.9708
18:41:06.196   Training iter 400, batch loss 0.0922, batch acc 0.9758
18:41:06.463   Training iter 450, batch loss 0.1031, batch acc 0.9646
18:41:06.690   Training iter 500, batch loss 0.0928, batch acc 0.9748
18:41:06.820   Training iter 550, batch loss 0.0979, batch acc 0.9706
18:41:07.014   Training iter 600, batch loss 0.0995, batch acc 0.9704
18:41:07.015 Training @ 20 epoch...
18:41:07.161   Training iter 50, batch loss 0.0939, batch acc 0.9722
18:41:07.303   Training iter 100, batch loss 0.1001, batch acc 0.9690
18:41:07.460   Training iter 150, batch loss 0.0918, batch acc 0.9732
18:41:07.624   Training iter 200, batch loss 0.0964, batch acc 0.9736
18:41:07.819   Training iter 250, batch loss 0.0922, batch acc 0.9732
18:41:07.997   Training iter 300, batch loss 0.0926, batch acc 0.9736
18:41:08.148   Training iter 350, batch loss 0.0929, batch acc 0.9746
18:41:08.337   Training iter 400, batch loss 0.1005, batch acc 0.9714
18:41:08.521   Training iter 450, batch loss 0.0976, batch acc 0.9668
18:41:08.695   Training iter 500, batch loss 0.0940, batch acc 0.9718
18:41:08.914   Training iter 550, batch loss 0.0920, batch acc 0.9744
18:41:09.089   Training iter 600, batch loss 0.0957, batch acc 0.9714
18:41:09.090 Testing @ 20 epoch...
18:41:09.211     Testing, total mean loss 0.10147, total acc 0.96970
18:41:09.211 Training @ 21 epoch...
18:41:09.373   Training iter 50, batch loss 0.0914, batch acc 0.9750
18:41:09.513   Training iter 100, batch loss 0.0951, batch acc 0.9716
18:41:09.659   Training iter 150, batch loss 0.0916, batch acc 0.9738
18:41:09.810   Training iter 200, batch loss 0.0936, batch acc 0.9736
18:41:09.965   Training iter 250, batch loss 0.0898, batch acc 0.9766
18:41:10.147   Training iter 300, batch loss 0.0978, batch acc 0.9712
18:41:10.309   Training iter 350, batch loss 0.0952, batch acc 0.9714
18:41:10.463   Training iter 400, batch loss 0.0956, batch acc 0.9724
18:41:10.661   Training iter 450, batch loss 0.0931, batch acc 0.9724
18:41:10.913   Training iter 500, batch loss 0.0945, batch acc 0.9732
18:41:11.144   Training iter 550, batch loss 0.0947, batch acc 0.9700
18:41:11.489   Training iter 600, batch loss 0.0968, batch acc 0.9696
18:41:11.490 Training @ 22 epoch...
18:41:11.691   Training iter 50, batch loss 0.0939, batch acc 0.9720
18:41:11.912   Training iter 100, batch loss 0.0896, batch acc 0.9726
18:41:12.155   Training iter 150, batch loss 0.0947, batch acc 0.9710
18:41:12.479   Training iter 200, batch loss 0.0915, batch acc 0.9758
18:41:12.682   Training iter 250, batch loss 0.0919, batch acc 0.9728
18:41:12.801   Training iter 300, batch loss 0.0896, batch acc 0.9758
18:41:12.913   Training iter 350, batch loss 0.0982, batch acc 0.9686
18:41:13.060   Training iter 400, batch loss 0.0935, batch acc 0.9740
18:41:13.184   Training iter 450, batch loss 0.0910, batch acc 0.9756
18:41:13.281   Training iter 500, batch loss 0.0925, batch acc 0.9730
18:41:13.496   Training iter 550, batch loss 0.0934, batch acc 0.9736
18:41:13.699   Training iter 600, batch loss 0.0985, batch acc 0.9702
18:41:13.699 Training @ 23 epoch...
18:41:13.885   Training iter 50, batch loss 0.0922, batch acc 0.9768
18:41:14.037   Training iter 100, batch loss 0.0920, batch acc 0.9736
18:41:14.199   Training iter 150, batch loss 0.0961, batch acc 0.9678
18:41:14.348   Training iter 200, batch loss 0.0934, batch acc 0.9728
18:41:14.488   Training iter 250, batch loss 0.0937, batch acc 0.9718
18:41:14.671   Training iter 300, batch loss 0.0915, batch acc 0.9748
18:41:14.814   Training iter 350, batch loss 0.0911, batch acc 0.9754
18:41:14.951   Training iter 400, batch loss 0.0954, batch acc 0.9700
18:41:15.060   Training iter 450, batch loss 0.0913, batch acc 0.9724
18:41:15.174   Training iter 500, batch loss 0.0936, batch acc 0.9736
18:41:15.277   Training iter 550, batch loss 0.0880, batch acc 0.9760
18:41:15.446   Training iter 600, batch loss 0.0926, batch acc 0.9736
18:41:15.448 Training @ 24 epoch...
18:41:15.675   Training iter 50, batch loss 0.0939, batch acc 0.9718
18:41:15.963   Training iter 100, batch loss 0.0895, batch acc 0.9752
18:41:16.529   Training iter 150, batch loss 0.0922, batch acc 0.9718
18:41:16.688   Training iter 200, batch loss 0.0943, batch acc 0.9704
18:41:16.862   Training iter 250, batch loss 0.0930, batch acc 0.9746
18:41:17.000   Training iter 300, batch loss 0.0937, batch acc 0.9714
18:41:17.148   Training iter 350, batch loss 0.0914, batch acc 0.9742
18:41:17.310   Training iter 400, batch loss 0.0937, batch acc 0.9714
18:41:17.587   Training iter 450, batch loss 0.0863, batch acc 0.9790
18:41:17.738   Training iter 500, batch loss 0.0939, batch acc 0.9720
18:41:17.896   Training iter 550, batch loss 0.0906, batch acc 0.9748
18:41:18.044   Training iter 600, batch loss 0.0887, batch acc 0.9746
18:41:18.046 Training @ 25 epoch...
18:41:18.172   Training iter 50, batch loss 0.0907, batch acc 0.9754
18:41:18.393   Training iter 100, batch loss 0.0903, batch acc 0.9732
18:41:18.562   Training iter 150, batch loss 0.0875, batch acc 0.9746
18:41:18.722   Training iter 200, batch loss 0.0914, batch acc 0.9724
18:41:18.907   Training iter 250, batch loss 0.0918, batch acc 0.9730
18:41:19.083   Training iter 300, batch loss 0.0925, batch acc 0.9740
18:41:19.218   Training iter 350, batch loss 0.0923, batch acc 0.9756
18:41:19.443   Training iter 400, batch loss 0.0899, batch acc 0.9760
18:41:19.623   Training iter 450, batch loss 0.0959, batch acc 0.9718
18:41:19.794   Training iter 500, batch loss 0.0891, batch acc 0.9732
18:41:20.117   Training iter 550, batch loss 0.0933, batch acc 0.9738
18:41:20.323   Training iter 600, batch loss 0.0895, batch acc 0.9760
18:41:20.324 Testing @ 25 epoch...
18:41:20.456     Testing, total mean loss 0.09684, total acc 0.97000
18:41:20.456 Training @ 26 epoch...
18:41:20.619   Training iter 50, batch loss 0.0870, batch acc 0.9760
18:41:20.759   Training iter 100, batch loss 0.0901, batch acc 0.9754
18:41:21.026   Training iter 150, batch loss 0.0887, batch acc 0.9754
18:41:21.142   Training iter 200, batch loss 0.0895, batch acc 0.9760
18:41:21.298   Training iter 250, batch loss 0.0922, batch acc 0.9736
18:41:21.444   Training iter 300, batch loss 0.0903, batch acc 0.9740
18:41:21.590   Training iter 350, batch loss 0.0912, batch acc 0.9736
18:41:21.723   Training iter 400, batch loss 0.0909, batch acc 0.9742
18:41:21.873   Training iter 450, batch loss 0.0912, batch acc 0.9750
18:41:22.023   Training iter 500, batch loss 0.0886, batch acc 0.9760
18:41:22.204   Training iter 550, batch loss 0.0945, batch acc 0.9678
18:41:22.376   Training iter 600, batch loss 0.0924, batch acc 0.9744
18:41:22.377 Training @ 27 epoch...
18:41:22.547   Training iter 50, batch loss 0.0866, batch acc 0.9782
18:41:22.729   Training iter 100, batch loss 0.0892, batch acc 0.9752
18:41:22.952   Training iter 150, batch loss 0.0880, batch acc 0.9770
18:41:23.140   Training iter 200, batch loss 0.0881, batch acc 0.9762
18:41:23.294   Training iter 250, batch loss 0.0917, batch acc 0.9732
18:41:23.506   Training iter 300, batch loss 0.0921, batch acc 0.9710
18:41:23.742   Training iter 350, batch loss 0.0869, batch acc 0.9758
18:41:23.990   Training iter 400, batch loss 0.0949, batch acc 0.9732
18:41:24.164   Training iter 450, batch loss 0.0886, batch acc 0.9770
18:41:24.357   Training iter 500, batch loss 0.0905, batch acc 0.9740
18:41:24.510   Training iter 550, batch loss 0.0880, batch acc 0.9752
18:41:24.754   Training iter 600, batch loss 0.0936, batch acc 0.9716
18:41:24.755 Training @ 28 epoch...
18:41:24.957   Training iter 50, batch loss 0.0883, batch acc 0.9752
18:41:25.107   Training iter 100, batch loss 0.0887, batch acc 0.9748
18:41:25.288   Training iter 150, batch loss 0.0898, batch acc 0.9758
18:41:25.435   Training iter 200, batch loss 0.0873, batch acc 0.9766
18:41:25.557   Training iter 250, batch loss 0.0865, batch acc 0.9754
18:41:25.727   Training iter 300, batch loss 0.0881, batch acc 0.9776
18:41:25.961   Training iter 350, batch loss 0.0904, batch acc 0.9760
18:41:26.092   Training iter 400, batch loss 0.0916, batch acc 0.9720
18:41:26.212   Training iter 450, batch loss 0.0901, batch acc 0.9744
18:41:26.342   Training iter 500, batch loss 0.0911, batch acc 0.9720
18:41:26.449   Training iter 550, batch loss 0.0881, batch acc 0.9750
18:41:26.562   Training iter 600, batch loss 0.0908, batch acc 0.9744
18:41:26.564 Training @ 29 epoch...
18:41:26.681   Training iter 50, batch loss 0.0837, batch acc 0.9802
18:41:26.795   Training iter 100, batch loss 0.0884, batch acc 0.9724
18:41:26.918   Training iter 150, batch loss 0.0896, batch acc 0.9758
18:41:27.044   Training iter 200, batch loss 0.0880, batch acc 0.9766
18:41:27.154   Training iter 250, batch loss 0.0833, batch acc 0.9764
18:41:27.295   Training iter 300, batch loss 0.0913, batch acc 0.9718
18:41:27.424   Training iter 350, batch loss 0.0928, batch acc 0.9752
18:41:27.562   Training iter 400, batch loss 0.0886, batch acc 0.9738
18:41:27.692   Training iter 450, batch loss 0.0863, batch acc 0.9756
18:41:27.892   Training iter 500, batch loss 0.0937, batch acc 0.9718
18:41:28.065   Training iter 550, batch loss 0.0868, batch acc 0.9766
18:41:28.255   Training iter 600, batch loss 0.0882, batch acc 0.9766
18:41:28.256 Training @ 30 epoch...
18:41:28.380   Training iter 50, batch loss 0.0852, batch acc 0.9788
18:41:28.554   Training iter 100, batch loss 0.0890, batch acc 0.9764
18:41:28.728   Training iter 150, batch loss 0.0854, batch acc 0.9784
18:41:28.882   Training iter 200, batch loss 0.0899, batch acc 0.9736
18:41:29.037   Training iter 250, batch loss 0.0895, batch acc 0.9712
18:41:29.217   Training iter 300, batch loss 0.0898, batch acc 0.9734
18:41:29.357   Training iter 350, batch loss 0.0878, batch acc 0.9734
18:41:29.514   Training iter 400, batch loss 0.0869, batch acc 0.9760
18:41:29.734   Training iter 450, batch loss 0.0917, batch acc 0.9748
18:41:29.902   Training iter 500, batch loss 0.0871, batch acc 0.9754
18:41:30.138   Training iter 550, batch loss 0.0884, batch acc 0.9754
18:41:30.268   Training iter 600, batch loss 0.0864, batch acc 0.9756
18:41:30.269 Testing @ 30 epoch...
18:41:30.363     Testing, total mean loss 0.09555, total acc 0.97150
18:41:30.363 Training @ 31 epoch...
18:41:30.487   Training iter 50, batch loss 0.0848, batch acc 0.9778
18:41:30.607   Training iter 100, batch loss 0.0846, batch acc 0.9762
18:41:30.721   Training iter 150, batch loss 0.0848, batch acc 0.9768
18:41:30.838   Training iter 200, batch loss 0.0897, batch acc 0.9752
18:41:30.947   Training iter 250, batch loss 0.0872, batch acc 0.9754
18:41:31.080   Training iter 300, batch loss 0.0913, batch acc 0.9728
18:41:31.239   Training iter 350, batch loss 0.0881, batch acc 0.9732
18:41:31.345   Training iter 400, batch loss 0.0868, batch acc 0.9744
18:41:31.485   Training iter 450, batch loss 0.0891, batch acc 0.9764
18:41:31.627   Training iter 500, batch loss 0.0869, batch acc 0.9756
18:41:31.774   Training iter 550, batch loss 0.0864, batch acc 0.9758
18:41:31.909   Training iter 600, batch loss 0.0875, batch acc 0.9744
18:41:31.911 Training @ 32 epoch...
18:41:32.046   Training iter 50, batch loss 0.0847, batch acc 0.9782
18:41:32.172   Training iter 100, batch loss 0.0877, batch acc 0.9774
18:41:32.283   Training iter 150, batch loss 0.0907, batch acc 0.9728
18:41:32.387   Training iter 200, batch loss 0.0898, batch acc 0.9732
18:41:32.489   Training iter 250, batch loss 0.0840, batch acc 0.9782
18:41:32.589   Training iter 300, batch loss 0.0841, batch acc 0.9768
18:41:32.705   Training iter 350, batch loss 0.0896, batch acc 0.9754
18:41:32.808   Training iter 400, batch loss 0.0848, batch acc 0.9768
18:41:32.926   Training iter 450, batch loss 0.0859, batch acc 0.9770
18:41:33.027   Training iter 500, batch loss 0.0872, batch acc 0.9744
18:41:33.147   Training iter 550, batch loss 0.0854, batch acc 0.9758
18:41:33.260   Training iter 600, batch loss 0.0899, batch acc 0.9752
18:41:33.261 Training @ 33 epoch...
18:41:33.541   Training iter 50, batch loss 0.0874, batch acc 0.9756
18:41:33.747   Training iter 100, batch loss 0.0848, batch acc 0.9752
18:41:33.913   Training iter 150, batch loss 0.0860, batch acc 0.9768
18:41:34.098   Training iter 200, batch loss 0.0849, batch acc 0.9782
18:41:34.325   Training iter 250, batch loss 0.0830, batch acc 0.9812
18:41:34.504   Training iter 300, batch loss 0.0913, batch acc 0.9700
18:41:34.663   Training iter 350, batch loss 0.0862, batch acc 0.9782
18:41:34.860   Training iter 400, batch loss 0.0899, batch acc 0.9746
18:41:35.041   Training iter 450, batch loss 0.0895, batch acc 0.9758
18:41:35.186   Training iter 500, batch loss 0.0806, batch acc 0.9788
18:41:35.321   Training iter 550, batch loss 0.0899, batch acc 0.9708
18:41:35.501   Training iter 600, batch loss 0.0873, batch acc 0.9766
18:41:35.501 Training @ 34 epoch...
18:41:35.694   Training iter 50, batch loss 0.0845, batch acc 0.9742
18:41:35.906   Training iter 100, batch loss 0.0850, batch acc 0.9766
18:41:36.095   Training iter 150, batch loss 0.0886, batch acc 0.9728
18:41:36.378   Training iter 200, batch loss 0.0850, batch acc 0.9778
18:41:36.560   Training iter 250, batch loss 0.0849, batch acc 0.9756
18:41:36.734   Training iter 300, batch loss 0.0866, batch acc 0.9742
18:41:36.975   Training iter 350, batch loss 0.0858, batch acc 0.9744
18:41:37.211   Training iter 400, batch loss 0.0864, batch acc 0.9766
18:41:37.459   Training iter 450, batch loss 0.0826, batch acc 0.9792
18:41:37.659   Training iter 500, batch loss 0.0893, batch acc 0.9760
18:41:37.943   Training iter 550, batch loss 0.0898, batch acc 0.9742
18:41:38.432   Training iter 600, batch loss 0.0871, batch acc 0.9750
18:41:38.433 Training @ 35 epoch...
18:41:38.707   Training iter 50, batch loss 0.0861, batch acc 0.9766
18:41:38.898   Training iter 100, batch loss 0.0794, batch acc 0.9792
18:41:39.090   Training iter 150, batch loss 0.0852, batch acc 0.9776
18:41:39.304   Training iter 200, batch loss 0.0861, batch acc 0.9774
18:41:39.469   Training iter 250, batch loss 0.0837, batch acc 0.9782
18:41:39.608   Training iter 300, batch loss 0.0866, batch acc 0.9746
18:41:39.746   Training iter 350, batch loss 0.0837, batch acc 0.9770
18:41:39.977   Training iter 400, batch loss 0.0890, batch acc 0.9728
18:41:40.314   Training iter 450, batch loss 0.0893, batch acc 0.9752
18:41:40.714   Training iter 500, batch loss 0.0866, batch acc 0.9768
18:41:41.087   Training iter 550, batch loss 0.0862, batch acc 0.9764
18:41:41.306   Training iter 600, batch loss 0.0858, batch acc 0.9766
18:41:41.308 Testing @ 35 epoch...
18:41:41.426     Testing, total mean loss 0.09188, total acc 0.97160
18:41:41.427 Training @ 36 epoch...
18:41:41.705   Training iter 50, batch loss 0.0843, batch acc 0.9768
18:41:42.039   Training iter 100, batch loss 0.0829, batch acc 0.9800
18:41:42.269   Training iter 150, batch loss 0.0816, batch acc 0.9796
18:41:42.429   Training iter 200, batch loss 0.0822, batch acc 0.9782
18:41:42.616   Training iter 250, batch loss 0.0859, batch acc 0.9734
18:41:42.796   Training iter 300, batch loss 0.0908, batch acc 0.9726
18:41:42.995   Training iter 350, batch loss 0.0863, batch acc 0.9748
18:41:43.265   Training iter 400, batch loss 0.0867, batch acc 0.9754
18:41:43.466   Training iter 450, batch loss 0.0850, batch acc 0.9772
18:41:43.749   Training iter 500, batch loss 0.0879, batch acc 0.9750
18:41:44.003   Training iter 550, batch loss 0.0882, batch acc 0.9770
18:41:44.187   Training iter 600, batch loss 0.0861, batch acc 0.9774
18:41:44.188 Training @ 37 epoch...
18:41:44.358   Training iter 50, batch loss 0.0817, batch acc 0.9766
18:41:44.543   Training iter 100, batch loss 0.0784, batch acc 0.9812
18:41:44.723   Training iter 150, batch loss 0.0899, batch acc 0.9738
18:41:44.894   Training iter 200, batch loss 0.0840, batch acc 0.9780
18:41:45.087   Training iter 250, batch loss 0.0836, batch acc 0.9744
18:41:45.241   Training iter 300, batch loss 0.0898, batch acc 0.9730
18:41:45.395   Training iter 350, batch loss 0.0850, batch acc 0.9772
18:41:45.616   Training iter 400, batch loss 0.0829, batch acc 0.9782
18:41:45.809   Training iter 450, batch loss 0.0869, batch acc 0.9744
18:41:46.015   Training iter 500, batch loss 0.0834, batch acc 0.9778
18:41:46.204   Training iter 550, batch loss 0.0890, batch acc 0.9756
18:41:46.392   Training iter 600, batch loss 0.0854, batch acc 0.9764
18:41:46.393 Training @ 38 epoch...
18:41:46.604   Training iter 50, batch loss 0.0828, batch acc 0.9780
18:41:46.799   Training iter 100, batch loss 0.0854, batch acc 0.9768
18:41:46.948   Training iter 150, batch loss 0.0798, batch acc 0.9784
18:41:47.106   Training iter 200, batch loss 0.0829, batch acc 0.9778
18:41:47.247   Training iter 250, batch loss 0.0856, batch acc 0.9800
18:41:47.391   Training iter 300, batch loss 0.0871, batch acc 0.9736
18:41:47.530   Training iter 350, batch loss 0.0848, batch acc 0.9760
18:41:47.681   Training iter 400, batch loss 0.0838, batch acc 0.9776
18:41:47.827   Training iter 450, batch loss 0.0863, batch acc 0.9756
18:41:47.976   Training iter 500, batch loss 0.0850, batch acc 0.9772
18:41:48.137   Training iter 550, batch loss 0.0863, batch acc 0.9766
18:41:48.273   Training iter 600, batch loss 0.0845, batch acc 0.9772
18:41:48.275 Training @ 39 epoch...
18:41:48.443   Training iter 50, batch loss 0.0811, batch acc 0.9802
18:41:48.604   Training iter 100, batch loss 0.0814, batch acc 0.9776
18:41:48.766   Training iter 150, batch loss 0.0784, batch acc 0.9802
18:41:48.940   Training iter 200, batch loss 0.0838, batch acc 0.9744
18:41:49.142   Training iter 250, batch loss 0.0840, batch acc 0.9768
18:41:49.321   Training iter 300, batch loss 0.0839, batch acc 0.9766
18:41:49.511   Training iter 350, batch loss 0.0875, batch acc 0.9746
18:41:49.703   Training iter 400, batch loss 0.0871, batch acc 0.9748
18:41:49.887   Training iter 450, batch loss 0.0836, batch acc 0.9770
18:41:50.053   Training iter 500, batch loss 0.0891, batch acc 0.9734
18:41:50.230   Training iter 550, batch loss 0.0820, batch acc 0.9804
18:41:50.376   Training iter 600, batch loss 0.0877, batch acc 0.9760
18:41:50.377 Training @ 40 epoch...
18:41:50.529   Training iter 50, batch loss 0.0842, batch acc 0.9766
18:41:50.705   Training iter 100, batch loss 0.0803, batch acc 0.9776
18:41:50.910   Training iter 150, batch loss 0.0864, batch acc 0.9770
18:41:51.109   Training iter 200, batch loss 0.0838, batch acc 0.9802
18:41:51.286   Training iter 250, batch loss 0.0823, batch acc 0.9772
18:41:51.462   Training iter 300, batch loss 0.0869, batch acc 0.9774
18:41:51.778   Training iter 350, batch loss 0.0845, batch acc 0.9792
18:41:51.961   Training iter 400, batch loss 0.0820, batch acc 0.9780
18:41:52.149   Training iter 450, batch loss 0.0803, batch acc 0.9772
18:41:52.332   Training iter 500, batch loss 0.0834, batch acc 0.9762
18:41:52.592   Training iter 550, batch loss 0.0832, batch acc 0.9778
18:41:52.732   Training iter 600, batch loss 0.0863, batch acc 0.9732
18:41:52.733 Testing @ 40 epoch...
18:41:52.862     Testing, total mean loss 0.09032, total acc 0.97260
18:41:52.862 Training @ 41 epoch...
18:41:53.058   Training iter 50, batch loss 0.0781, batch acc 0.9768
18:41:53.215   Training iter 100, batch loss 0.0822, batch acc 0.9778
18:41:53.389   Training iter 150, batch loss 0.0849, batch acc 0.9784
18:41:53.572   Training iter 200, batch loss 0.0855, batch acc 0.9760
18:41:53.806   Training iter 250, batch loss 0.0843, batch acc 0.9762
18:41:53.997   Training iter 300, batch loss 0.0878, batch acc 0.9754
18:41:54.285   Training iter 350, batch loss 0.0848, batch acc 0.9754
18:41:54.453   Training iter 400, batch loss 0.0796, batch acc 0.9792
18:41:54.614   Training iter 450, batch loss 0.0858, batch acc 0.9752
18:41:54.838   Training iter 500, batch loss 0.0839, batch acc 0.9786
18:41:55.032   Training iter 550, batch loss 0.0820, batch acc 0.9786
18:41:55.275   Training iter 600, batch loss 0.0803, batch acc 0.9794
18:41:55.277 Training @ 42 epoch...
18:41:55.494   Training iter 50, batch loss 0.0848, batch acc 0.9770
18:41:55.777   Training iter 100, batch loss 0.0790, batch acc 0.9790
18:41:55.978   Training iter 150, batch loss 0.0821, batch acc 0.9782
18:41:56.253   Training iter 200, batch loss 0.0789, batch acc 0.9808
18:41:56.412   Training iter 250, batch loss 0.0846, batch acc 0.9768
18:41:56.621   Training iter 300, batch loss 0.0845, batch acc 0.9756
18:41:56.859   Training iter 350, batch loss 0.0835, batch acc 0.9752
18:41:57.042   Training iter 400, batch loss 0.0849, batch acc 0.9754
18:41:57.321   Training iter 450, batch loss 0.0854, batch acc 0.9784
18:41:57.547   Training iter 500, batch loss 0.0829, batch acc 0.9770
18:41:57.758   Training iter 550, batch loss 0.0827, batch acc 0.9780
18:41:57.976   Training iter 600, batch loss 0.0849, batch acc 0.9750
18:41:57.977 Training @ 43 epoch...
18:41:58.160   Training iter 50, batch loss 0.0813, batch acc 0.9790
18:41:58.358   Training iter 100, batch loss 0.0831, batch acc 0.9788
18:41:58.594   Training iter 150, batch loss 0.0802, batch acc 0.9784
18:41:58.795   Training iter 200, batch loss 0.0791, batch acc 0.9788
18:41:58.931   Training iter 250, batch loss 0.0843, batch acc 0.9770
18:41:59.068   Training iter 300, batch loss 0.0807, batch acc 0.9782
18:41:59.229   Training iter 350, batch loss 0.0816, batch acc 0.9780
18:41:59.490   Training iter 400, batch loss 0.0836, batch acc 0.9770
18:41:59.641   Training iter 450, batch loss 0.0878, batch acc 0.9728
18:41:59.786   Training iter 500, batch loss 0.0833, batch acc 0.9760
18:41:59.931   Training iter 550, batch loss 0.0838, batch acc 0.9776
18:42:00.094   Training iter 600, batch loss 0.0834, batch acc 0.9790
18:42:00.096 Training @ 44 epoch...
18:42:00.252   Training iter 50, batch loss 0.0816, batch acc 0.9778
18:42:00.407   Training iter 100, batch loss 0.0773, batch acc 0.9784
18:42:00.607   Training iter 150, batch loss 0.0802, batch acc 0.9810
18:42:00.780   Training iter 200, batch loss 0.0801, batch acc 0.9774
18:42:01.008   Training iter 250, batch loss 0.0802, batch acc 0.9794
18:42:01.223   Training iter 300, batch loss 0.0813, batch acc 0.9788
18:42:01.441   Training iter 350, batch loss 0.0831, batch acc 0.9760
18:42:01.590   Training iter 400, batch loss 0.0846, batch acc 0.9764
18:42:01.731   Training iter 450, batch loss 0.0816, batch acc 0.9760
18:42:01.879   Training iter 500, batch loss 0.0826, batch acc 0.9802
18:42:02.047   Training iter 550, batch loss 0.0869, batch acc 0.9756
18:42:02.180   Training iter 600, batch loss 0.0873, batch acc 0.9766
18:42:02.181 Training @ 45 epoch...
18:42:02.347   Training iter 50, batch loss 0.0839, batch acc 0.9752
18:42:02.527   Training iter 100, batch loss 0.0846, batch acc 0.9750
18:42:02.672   Training iter 150, batch loss 0.0806, batch acc 0.9786
18:42:02.878   Training iter 200, batch loss 0.0815, batch acc 0.9792
18:42:03.019   Training iter 250, batch loss 0.0797, batch acc 0.9794
18:42:03.198   Training iter 300, batch loss 0.0860, batch acc 0.9764
18:42:03.444   Training iter 350, batch loss 0.0791, batch acc 0.9788
18:42:03.662   Training iter 400, batch loss 0.0809, batch acc 0.9804
18:42:03.837   Training iter 450, batch loss 0.0821, batch acc 0.9806
18:42:04.054   Training iter 500, batch loss 0.0814, batch acc 0.9798
18:42:04.241   Training iter 550, batch loss 0.0814, batch acc 0.9760
18:42:04.396   Training iter 600, batch loss 0.0835, batch acc 0.9786
18:42:04.396 Testing @ 45 epoch...
18:42:04.571     Testing, total mean loss 0.09005, total acc 0.97260
18:42:04.571 Training @ 46 epoch...
18:42:04.805   Training iter 50, batch loss 0.0839, batch acc 0.9762
18:42:04.986   Training iter 100, batch loss 0.0821, batch acc 0.9790
18:42:05.197   Training iter 150, batch loss 0.0840, batch acc 0.9756
18:42:05.350   Training iter 200, batch loss 0.0832, batch acc 0.9766
18:42:05.525   Training iter 250, batch loss 0.0806, batch acc 0.9800
18:42:05.693   Training iter 300, batch loss 0.0777, batch acc 0.9802
18:42:05.873   Training iter 350, batch loss 0.0824, batch acc 0.9782
18:42:06.029   Training iter 400, batch loss 0.0778, batch acc 0.9796
18:42:06.197   Training iter 450, batch loss 0.0830, batch acc 0.9780
18:42:06.396   Training iter 500, batch loss 0.0813, batch acc 0.9794
18:42:06.608   Training iter 550, batch loss 0.0846, batch acc 0.9770
18:42:06.810   Training iter 600, batch loss 0.0812, batch acc 0.9772
18:42:06.811 Training @ 47 epoch...
18:42:07.011   Training iter 50, batch loss 0.0777, batch acc 0.9812
18:42:07.212   Training iter 100, batch loss 0.0836, batch acc 0.9756
18:42:07.375   Training iter 150, batch loss 0.0803, batch acc 0.9782
18:42:07.529   Training iter 200, batch loss 0.0816, batch acc 0.9794
18:42:07.738   Training iter 250, batch loss 0.0794, batch acc 0.9806
18:42:07.896   Training iter 300, batch loss 0.0813, batch acc 0.9772
18:42:08.063   Training iter 350, batch loss 0.0828, batch acc 0.9772
18:42:08.221   Training iter 400, batch loss 0.0806, batch acc 0.9782
18:42:08.368   Training iter 450, batch loss 0.0847, batch acc 0.9806
18:42:08.547   Training iter 500, batch loss 0.0832, batch acc 0.9792
18:42:08.714   Training iter 550, batch loss 0.0850, batch acc 0.9754
18:42:08.878   Training iter 600, batch loss 0.0845, batch acc 0.9758
18:42:08.879 Training @ 48 epoch...
18:42:09.031   Training iter 50, batch loss 0.0800, batch acc 0.9794
18:42:09.207   Training iter 100, batch loss 0.0756, batch acc 0.9824
18:42:09.362   Training iter 150, batch loss 0.0782, batch acc 0.9798
18:42:09.532   Training iter 200, batch loss 0.0806, batch acc 0.9772
18:42:09.710   Training iter 250, batch loss 0.0800, batch acc 0.9770
18:42:09.881   Training iter 300, batch loss 0.0855, batch acc 0.9754
18:42:10.060   Training iter 350, batch loss 0.0833, batch acc 0.9778
18:42:10.196   Training iter 400, batch loss 0.0833, batch acc 0.9760
18:42:10.337   Training iter 450, batch loss 0.0808, batch acc 0.9794
18:42:10.477   Training iter 500, batch loss 0.0851, batch acc 0.9758
18:42:10.622   Training iter 550, batch loss 0.0812, batch acc 0.9786
18:42:10.987   Training iter 600, batch loss 0.0819, batch acc 0.9770
18:42:10.987 Training @ 49 epoch...
18:42:11.137   Training iter 50, batch loss 0.0837, batch acc 0.9804
18:42:11.323   Training iter 100, batch loss 0.0791, batch acc 0.9806
18:42:11.491   Training iter 150, batch loss 0.0774, batch acc 0.9786
18:42:11.695   Training iter 200, batch loss 0.0764, batch acc 0.9778
18:42:11.891   Training iter 250, batch loss 0.0844, batch acc 0.9742
18:42:12.117   Training iter 300, batch loss 0.0761, batch acc 0.9806
18:42:12.338   Training iter 350, batch loss 0.0841, batch acc 0.9770
18:42:12.545   Training iter 400, batch loss 0.0861, batch acc 0.9770
18:42:12.824   Training iter 450, batch loss 0.0776, batch acc 0.9822
18:42:13.024   Training iter 500, batch loss 0.0800, batch acc 0.9794
18:42:13.180   Training iter 550, batch loss 0.0802, batch acc 0.9800
18:42:13.328   Training iter 600, batch loss 0.0844, batch acc 0.9746
18:42:13.329 Training @ 50 epoch...
18:42:13.465   Training iter 50, batch loss 0.0828, batch acc 0.9756
18:42:13.688   Training iter 100, batch loss 0.0738, batch acc 0.9836
18:42:13.849   Training iter 150, batch loss 0.0789, batch acc 0.9810
18:42:13.998   Training iter 200, batch loss 0.0812, batch acc 0.9794
18:42:14.144   Training iter 250, batch loss 0.0832, batch acc 0.9784
18:42:14.310   Training iter 300, batch loss 0.0783, batch acc 0.9812
18:42:14.492   Training iter 350, batch loss 0.0805, batch acc 0.9784
18:42:14.671   Training iter 400, batch loss 0.0813, batch acc 0.9780
18:42:14.862   Training iter 450, batch loss 0.0818, batch acc 0.9772
18:42:15.080   Training iter 500, batch loss 0.0853, batch acc 0.9754
18:42:15.289   Training iter 550, batch loss 0.0783, batch acc 0.9788
18:42:15.481   Training iter 600, batch loss 0.0805, batch acc 0.9802
18:42:15.482 Testing @ 50 epoch...
18:42:15.654     Testing, total mean loss 0.09102, total acc 0.97190
18:42:15.654 Training @ 51 epoch...
18:42:15.998   Training iter 50, batch loss 0.0781, batch acc 0.9788
18:42:16.195   Training iter 100, batch loss 0.0756, batch acc 0.9822
18:42:16.382   Training iter 150, batch loss 0.0833, batch acc 0.9750
18:42:16.541   Training iter 200, batch loss 0.0789, batch acc 0.9806
18:42:16.707   Training iter 250, batch loss 0.0777, batch acc 0.9792
18:42:16.855   Training iter 300, batch loss 0.0787, batch acc 0.9778
18:42:16.996   Training iter 350, batch loss 0.0842, batch acc 0.9776
18:42:17.142   Training iter 400, batch loss 0.0786, batch acc 0.9790
18:42:17.380   Training iter 450, batch loss 0.0818, batch acc 0.9772
18:42:17.532   Training iter 500, batch loss 0.0849, batch acc 0.9728
18:42:17.680   Training iter 550, batch loss 0.0798, batch acc 0.9808
18:42:17.830   Training iter 600, batch loss 0.0825, batch acc 0.9772
18:42:17.830 Training @ 52 epoch...
18:42:18.031   Training iter 50, batch loss 0.0775, batch acc 0.9824
18:42:18.209   Training iter 100, batch loss 0.0806, batch acc 0.9792
18:42:18.391   Training iter 150, batch loss 0.0790, batch acc 0.9800
18:42:18.578   Training iter 200, batch loss 0.0781, batch acc 0.9796
18:42:18.780   Training iter 250, batch loss 0.0829, batch acc 0.9740
18:42:18.936   Training iter 300, batch loss 0.0787, batch acc 0.9782
18:42:19.089   Training iter 350, batch loss 0.0810, batch acc 0.9786
18:42:19.231   Training iter 400, batch loss 0.0835, batch acc 0.9756
18:42:19.381   Training iter 450, batch loss 0.0827, batch acc 0.9764
18:42:19.528   Training iter 500, batch loss 0.0759, batch acc 0.9816
18:42:19.659   Training iter 550, batch loss 0.0792, batch acc 0.9782
18:42:19.797   Training iter 600, batch loss 0.0829, batch acc 0.9800
18:42:19.798 Training @ 53 epoch...
18:42:19.949   Training iter 50, batch loss 0.0765, batch acc 0.9802
18:42:20.095   Training iter 100, batch loss 0.0774, batch acc 0.9800
18:42:20.232   Training iter 150, batch loss 0.0840, batch acc 0.9774
18:42:20.382   Training iter 200, batch loss 0.0764, batch acc 0.9806
18:42:20.524   Training iter 250, batch loss 0.0796, batch acc 0.9792
18:42:20.656   Training iter 300, batch loss 0.0812, batch acc 0.9810
18:42:20.837   Training iter 350, batch loss 0.0809, batch acc 0.9746
18:42:20.999   Training iter 400, batch loss 0.0806, batch acc 0.9776
18:42:21.171   Training iter 450, batch loss 0.0812, batch acc 0.9802
18:42:21.461   Training iter 500, batch loss 0.0804, batch acc 0.9806
18:42:21.975   Training iter 550, batch loss 0.0814, batch acc 0.9774
18:42:22.194   Training iter 600, batch loss 0.0804, batch acc 0.9766
18:42:22.195 Training @ 54 epoch...
18:42:22.427   Training iter 50, batch loss 0.0798, batch acc 0.9784
18:42:22.671   Training iter 100, batch loss 0.0773, batch acc 0.9808
18:42:22.799   Training iter 150, batch loss 0.0786, batch acc 0.9768
18:42:22.971   Training iter 200, batch loss 0.0807, batch acc 0.9798
18:42:23.160   Training iter 250, batch loss 0.0782, batch acc 0.9806
18:42:23.271   Training iter 300, batch loss 0.0779, batch acc 0.9804
18:42:23.387   Training iter 350, batch loss 0.0857, batch acc 0.9758
18:42:23.546   Training iter 400, batch loss 0.0793, batch acc 0.9790
18:42:23.674   Training iter 450, batch loss 0.0818, batch acc 0.9764
18:42:23.871   Training iter 500, batch loss 0.0798, batch acc 0.9788
18:42:24.078   Training iter 550, batch loss 0.0827, batch acc 0.9770
18:42:24.266   Training iter 600, batch loss 0.0775, batch acc 0.9792
18:42:24.267 Training @ 55 epoch...
18:42:24.470   Training iter 50, batch loss 0.0809, batch acc 0.9788
18:42:24.646   Training iter 100, batch loss 0.0793, batch acc 0.9776
18:42:24.838   Training iter 150, batch loss 0.0785, batch acc 0.9810
18:42:25.068   Training iter 200, batch loss 0.0794, batch acc 0.9760
18:42:25.222   Training iter 250, batch loss 0.0781, batch acc 0.9790
18:42:25.358   Training iter 300, batch loss 0.0816, batch acc 0.9766
18:42:25.523   Training iter 350, batch loss 0.0778, batch acc 0.9802
18:42:25.663   Training iter 400, batch loss 0.0784, batch acc 0.9788
18:42:25.821   Training iter 450, batch loss 0.0826, batch acc 0.9778
18:42:25.970   Training iter 500, batch loss 0.0805, batch acc 0.9790
18:42:26.103   Training iter 550, batch loss 0.0773, batch acc 0.9820
18:42:26.256   Training iter 600, batch loss 0.0777, batch acc 0.9780
18:42:26.258 Testing @ 55 epoch...
18:42:26.419     Testing, total mean loss 0.08788, total acc 0.97260
18:42:26.419 Training @ 56 epoch...
18:42:26.621   Training iter 50, batch loss 0.0805, batch acc 0.9774
18:42:26.786   Training iter 100, batch loss 0.0754, batch acc 0.9824
18:42:26.999   Training iter 150, batch loss 0.0753, batch acc 0.9814
18:42:27.209   Training iter 200, batch loss 0.0746, batch acc 0.9792
18:42:27.392   Training iter 250, batch loss 0.0751, batch acc 0.9822
18:42:27.561   Training iter 300, batch loss 0.0794, batch acc 0.9786
18:42:27.757   Training iter 350, batch loss 0.0782, batch acc 0.9792
18:42:27.971   Training iter 400, batch loss 0.0786, batch acc 0.9800
18:42:28.099   Training iter 450, batch loss 0.0824, batch acc 0.9768
18:42:28.205   Training iter 500, batch loss 0.0829, batch acc 0.9776
18:42:28.319   Training iter 550, batch loss 0.0825, batch acc 0.9772
18:42:28.425   Training iter 600, batch loss 0.0835, batch acc 0.9760
18:42:28.427 Training @ 57 epoch...
18:42:28.535   Training iter 50, batch loss 0.0803, batch acc 0.9760
18:42:28.664   Training iter 100, batch loss 0.0765, batch acc 0.9816
18:42:28.778   Training iter 150, batch loss 0.0783, batch acc 0.9814
18:42:28.896   Training iter 200, batch loss 0.0795, batch acc 0.9798
18:42:29.003   Training iter 250, batch loss 0.0729, batch acc 0.9832
18:42:29.140   Training iter 300, batch loss 0.0829, batch acc 0.9784
18:42:29.253   Training iter 350, batch loss 0.0786, batch acc 0.9802
18:42:29.365   Training iter 400, batch loss 0.0801, batch acc 0.9798
18:42:29.483   Training iter 450, batch loss 0.0816, batch acc 0.9764
18:42:29.600   Training iter 500, batch loss 0.0801, batch acc 0.9796
18:42:29.713   Training iter 550, batch loss 0.0797, batch acc 0.9784
18:42:29.822   Training iter 600, batch loss 0.0773, batch acc 0.9792
18:42:29.823 Training @ 58 epoch...
18:42:29.976   Training iter 50, batch loss 0.0779, batch acc 0.9820
18:42:30.125   Training iter 100, batch loss 0.0758, batch acc 0.9804
18:42:30.255   Training iter 150, batch loss 0.0780, batch acc 0.9804
18:42:30.391   Training iter 200, batch loss 0.0773, batch acc 0.9800
18:42:30.563   Training iter 250, batch loss 0.0796, batch acc 0.9792
18:42:30.740   Training iter 300, batch loss 0.0771, batch acc 0.9806
18:42:30.964   Training iter 350, batch loss 0.0798, batch acc 0.9768
18:42:31.153   Training iter 400, batch loss 0.0812, batch acc 0.9776
18:42:31.327   Training iter 450, batch loss 0.0809, batch acc 0.9786
18:42:31.476   Training iter 500, batch loss 0.0776, batch acc 0.9792
18:42:31.681   Training iter 550, batch loss 0.0802, batch acc 0.9764
18:42:31.795   Training iter 600, batch loss 0.0800, batch acc 0.9774
18:42:31.796 Training @ 59 epoch...
18:42:31.972   Training iter 50, batch loss 0.0752, batch acc 0.9822
18:42:32.145   Training iter 100, batch loss 0.0778, batch acc 0.9820
18:42:32.369   Training iter 150, batch loss 0.0746, batch acc 0.9796
18:42:32.546   Training iter 200, batch loss 0.0795, batch acc 0.9790
18:42:32.695   Training iter 250, batch loss 0.0814, batch acc 0.9754
18:42:32.881   Training iter 300, batch loss 0.0764, batch acc 0.9816
18:42:33.092   Training iter 350, batch loss 0.0831, batch acc 0.9744
18:42:33.426   Training iter 400, batch loss 0.0789, batch acc 0.9806
18:42:33.590   Training iter 450, batch loss 0.0769, batch acc 0.9812
18:42:33.779   Training iter 500, batch loss 0.0783, batch acc 0.9790
18:42:33.977   Training iter 550, batch loss 0.0813, batch acc 0.9812
18:42:34.151   Training iter 600, batch loss 0.0798, batch acc 0.9796
18:42:34.152 Training @ 60 epoch...
18:42:34.271   Training iter 50, batch loss 0.0795, batch acc 0.9796
18:42:34.437   Training iter 100, batch loss 0.0758, batch acc 0.9810
18:42:34.565   Training iter 150, batch loss 0.0763, batch acc 0.9802
18:42:34.713   Training iter 200, batch loss 0.0739, batch acc 0.9834
18:42:34.863   Training iter 250, batch loss 0.0775, batch acc 0.9794
18:42:35.023   Training iter 300, batch loss 0.0795, batch acc 0.9796
18:42:35.249   Training iter 350, batch loss 0.0794, batch acc 0.9786
18:42:35.427   Training iter 400, batch loss 0.0796, batch acc 0.9780
18:42:35.572   Training iter 450, batch loss 0.0808, batch acc 0.9788
18:42:35.759   Training iter 500, batch loss 0.0779, batch acc 0.9786
18:42:35.971   Training iter 550, batch loss 0.0799, batch acc 0.9796
18:42:36.180   Training iter 600, batch loss 0.0797, batch acc 0.9782
18:42:36.181 Testing @ 60 epoch...
18:42:36.341     Testing, total mean loss 0.08963, total acc 0.97380
18:42:36.341 Training @ 61 epoch...
18:42:36.565   Training iter 50, batch loss 0.0772, batch acc 0.9824
18:42:36.703   Training iter 100, batch loss 0.0821, batch acc 0.9782
18:42:36.844   Training iter 150, batch loss 0.0767, batch acc 0.9804
18:42:37.002   Training iter 200, batch loss 0.0752, batch acc 0.9826
18:42:37.116   Training iter 250, batch loss 0.0731, batch acc 0.9822
18:42:37.225   Training iter 300, batch loss 0.0817, batch acc 0.9772
18:42:37.342   Training iter 350, batch loss 0.0758, batch acc 0.9796
18:42:37.507   Training iter 400, batch loss 0.0812, batch acc 0.9784
18:42:37.636   Training iter 450, batch loss 0.0805, batch acc 0.9788
18:42:37.837   Training iter 500, batch loss 0.0791, batch acc 0.9792
18:42:37.970   Training iter 550, batch loss 0.0830, batch acc 0.9776
18:42:38.095   Training iter 600, batch loss 0.0771, batch acc 0.9806
18:42:38.096 Training @ 62 epoch...
18:42:38.200   Training iter 50, batch loss 0.0732, batch acc 0.9824
18:42:38.311   Training iter 100, batch loss 0.0826, batch acc 0.9780
18:42:38.439   Training iter 150, batch loss 0.0775, batch acc 0.9804
18:42:38.575   Training iter 200, batch loss 0.0792, batch acc 0.9792
18:42:38.691   Training iter 250, batch loss 0.0851, batch acc 0.9734
18:42:38.797   Training iter 300, batch loss 0.0739, batch acc 0.9814
18:42:38.946   Training iter 350, batch loss 0.0752, batch acc 0.9828
18:42:39.096   Training iter 400, batch loss 0.0800, batch acc 0.9760
18:42:39.232   Training iter 450, batch loss 0.0779, batch acc 0.9786
18:42:39.365   Training iter 500, batch loss 0.0770, batch acc 0.9788
18:42:39.510   Training iter 550, batch loss 0.0773, batch acc 0.9792
18:42:39.648   Training iter 600, batch loss 0.0785, batch acc 0.9806
18:42:39.649 Training @ 63 epoch...
18:42:39.783   Training iter 50, batch loss 0.0748, batch acc 0.9814
18:42:39.915   Training iter 100, batch loss 0.0779, batch acc 0.9804
18:42:40.073   Training iter 150, batch loss 0.0758, batch acc 0.9826
18:42:40.297   Training iter 200, batch loss 0.0746, batch acc 0.9812
18:42:40.605   Training iter 250, batch loss 0.0811, batch acc 0.9784
18:42:40.804   Training iter 300, batch loss 0.0751, batch acc 0.9822
18:42:40.974   Training iter 350, batch loss 0.0777, batch acc 0.9788
18:42:41.124   Training iter 400, batch loss 0.0785, batch acc 0.9768
18:42:41.300   Training iter 450, batch loss 0.0768, batch acc 0.9804
18:42:41.442   Training iter 500, batch loss 0.0808, batch acc 0.9746
18:42:41.581   Training iter 550, batch loss 0.0782, batch acc 0.9816
18:42:41.790   Training iter 600, batch loss 0.0780, batch acc 0.9788
18:42:41.791 Training @ 64 epoch...
18:42:41.946   Training iter 50, batch loss 0.0731, batch acc 0.9834
18:42:42.088   Training iter 100, batch loss 0.0738, batch acc 0.9830
18:42:42.231   Training iter 150, batch loss 0.0782, batch acc 0.9796
18:42:42.364   Training iter 200, batch loss 0.0760, batch acc 0.9796
18:42:42.490   Training iter 250, batch loss 0.0761, batch acc 0.9798
18:42:42.615   Training iter 300, batch loss 0.0805, batch acc 0.9758
18:42:42.746   Training iter 350, batch loss 0.0751, batch acc 0.9826
18:42:42.856   Training iter 400, batch loss 0.0744, batch acc 0.9808
18:42:43.009   Training iter 450, batch loss 0.0794, batch acc 0.9790
18:42:43.143   Training iter 500, batch loss 0.0812, batch acc 0.9758
18:42:43.345   Training iter 550, batch loss 0.0802, batch acc 0.9790
18:42:43.492   Training iter 600, batch loss 0.0802, batch acc 0.9812
18:42:43.492 Training @ 65 epoch...
18:42:43.744   Training iter 50, batch loss 0.0777, batch acc 0.9818
18:42:44.006   Training iter 100, batch loss 0.0752, batch acc 0.9810
18:42:44.243   Training iter 150, batch loss 0.0774, batch acc 0.9798
18:42:44.478   Training iter 200, batch loss 0.0793, batch acc 0.9798
18:42:44.638   Training iter 250, batch loss 0.0761, batch acc 0.9812
18:42:44.813   Training iter 300, batch loss 0.0773, batch acc 0.9802
18:42:45.114   Training iter 350, batch loss 0.0779, batch acc 0.9796
18:42:45.369   Training iter 400, batch loss 0.0759, batch acc 0.9782
18:42:45.605   Training iter 450, batch loss 0.0749, batch acc 0.9828
18:42:45.744   Training iter 500, batch loss 0.0774, batch acc 0.9810
18:42:45.981   Training iter 550, batch loss 0.0810, batch acc 0.9772
18:42:46.177   Training iter 600, batch loss 0.0783, batch acc 0.9792
18:42:46.177 Testing @ 65 epoch...
18:42:46.294     Testing, total mean loss 0.08751, total acc 0.97420
18:42:46.295 Training @ 66 epoch...
18:42:46.432   Training iter 50, batch loss 0.0727, batch acc 0.9826
18:42:46.584   Training iter 100, batch loss 0.0754, batch acc 0.9794
18:42:46.690   Training iter 150, batch loss 0.0761, batch acc 0.9826
18:42:46.792   Training iter 200, batch loss 0.0764, batch acc 0.9810
18:42:46.913   Training iter 250, batch loss 0.0777, batch acc 0.9780
18:42:47.030   Training iter 300, batch loss 0.0786, batch acc 0.9796
18:42:47.141   Training iter 350, batch loss 0.0785, batch acc 0.9812
18:42:47.261   Training iter 400, batch loss 0.0782, batch acc 0.9792
18:42:47.396   Training iter 450, batch loss 0.0799, batch acc 0.9804
18:42:47.531   Training iter 500, batch loss 0.0788, batch acc 0.9786
18:42:47.670   Training iter 550, batch loss 0.0794, batch acc 0.9774
18:42:47.817   Training iter 600, batch loss 0.0781, batch acc 0.9796
18:42:47.818 Training @ 67 epoch...
18:42:47.936   Training iter 50, batch loss 0.0763, batch acc 0.9810
18:42:48.088   Training iter 100, batch loss 0.0761, batch acc 0.9802
18:42:48.209   Training iter 150, batch loss 0.0743, batch acc 0.9782
18:42:48.341   Training iter 200, batch loss 0.0745, batch acc 0.9820
18:42:48.455   Training iter 250, batch loss 0.0731, batch acc 0.9820
18:42:48.581   Training iter 300, batch loss 0.0793, batch acc 0.9788
18:42:48.707   Training iter 350, batch loss 0.0791, batch acc 0.9798
18:42:48.826   Training iter 400, batch loss 0.0810, batch acc 0.9784
18:42:48.949   Training iter 450, batch loss 0.0770, batch acc 0.9802
18:42:49.169   Training iter 500, batch loss 0.0733, batch acc 0.9840
18:42:49.392   Training iter 550, batch loss 0.0798, batch acc 0.9792
18:42:49.644   Training iter 600, batch loss 0.0836, batch acc 0.9738
18:42:49.644 Training @ 68 epoch...
18:42:49.873   Training iter 50, batch loss 0.0753, batch acc 0.9792
18:42:50.071   Training iter 100, batch loss 0.0768, batch acc 0.9812
18:42:50.211   Training iter 150, batch loss 0.0786, batch acc 0.9806
18:42:50.430   Training iter 200, batch loss 0.0742, batch acc 0.9826
18:42:50.637   Training iter 250, batch loss 0.0761, batch acc 0.9814
18:42:50.845   Training iter 300, batch loss 0.0767, batch acc 0.9796
18:42:51.033   Training iter 350, batch loss 0.0772, batch acc 0.9796
18:42:51.225   Training iter 400, batch loss 0.0775, batch acc 0.9792
18:42:51.427   Training iter 450, batch loss 0.0777, batch acc 0.9778
18:42:51.677   Training iter 500, batch loss 0.0781, batch acc 0.9784
18:42:51.830   Training iter 550, batch loss 0.0765, batch acc 0.9820
18:42:52.010   Training iter 600, batch loss 0.0794, batch acc 0.9816
18:42:52.010 Training @ 69 epoch...
18:42:52.195   Training iter 50, batch loss 0.0772, batch acc 0.9794
18:42:52.349   Training iter 100, batch loss 0.0766, batch acc 0.9800
18:42:52.481   Training iter 150, batch loss 0.0761, batch acc 0.9832
18:42:52.600   Training iter 200, batch loss 0.0732, batch acc 0.9814
18:42:52.771   Training iter 250, batch loss 0.0786, batch acc 0.9774
18:42:52.874   Training iter 300, batch loss 0.0779, batch acc 0.9800
18:42:52.975   Training iter 350, batch loss 0.0774, batch acc 0.9818
18:42:53.083   Training iter 400, batch loss 0.0783, batch acc 0.9790
18:42:53.277   Training iter 450, batch loss 0.0772, batch acc 0.9798
18:42:53.471   Training iter 500, batch loss 0.0793, batch acc 0.9806
18:42:53.608   Training iter 550, batch loss 0.0736, batch acc 0.9826
18:42:53.809   Training iter 600, batch loss 0.0776, batch acc 0.9798
18:42:53.810 Training @ 70 epoch...
18:42:54.042   Training iter 50, batch loss 0.0739, batch acc 0.9820
18:42:54.294   Training iter 100, batch loss 0.0765, batch acc 0.9806
18:42:54.443   Training iter 150, batch loss 0.0763, batch acc 0.9820
18:42:54.598   Training iter 200, batch loss 0.0700, batch acc 0.9838
18:42:54.758   Training iter 250, batch loss 0.0752, batch acc 0.9802
18:42:54.907   Training iter 300, batch loss 0.0824, batch acc 0.9754
18:42:55.132   Training iter 350, batch loss 0.0769, batch acc 0.9802
18:42:55.287   Training iter 400, batch loss 0.0762, batch acc 0.9808
18:42:55.423   Training iter 450, batch loss 0.0788, batch acc 0.9794
18:42:55.536   Training iter 500, batch loss 0.0765, batch acc 0.9804
18:42:55.645   Training iter 550, batch loss 0.0808, batch acc 0.9806
18:42:55.763   Training iter 600, batch loss 0.0776, batch acc 0.9790
18:42:55.764 Testing @ 70 epoch...
18:42:55.859     Testing, total mean loss 0.08715, total acc 0.97360
18:42:55.859 Training @ 71 epoch...
18:42:55.996   Training iter 50, batch loss 0.0768, batch acc 0.9822
18:42:56.129   Training iter 100, batch loss 0.0779, batch acc 0.9792
18:42:56.318   Training iter 150, batch loss 0.0759, batch acc 0.9798
18:42:56.464   Training iter 200, batch loss 0.0784, batch acc 0.9790
18:42:56.660   Training iter 250, batch loss 0.0766, batch acc 0.9796
18:42:56.847   Training iter 300, batch loss 0.0765, batch acc 0.9810
18:42:56.982   Training iter 350, batch loss 0.0758, batch acc 0.9784
18:42:57.125   Training iter 400, batch loss 0.0784, batch acc 0.9792
18:42:57.279   Training iter 450, batch loss 0.0781, batch acc 0.9794
18:42:57.414   Training iter 500, batch loss 0.0772, batch acc 0.9812
18:42:57.524   Training iter 550, batch loss 0.0716, batch acc 0.9820
18:42:57.629   Training iter 600, batch loss 0.0753, batch acc 0.9842
18:42:57.631 Training @ 72 epoch...
18:42:57.738   Training iter 50, batch loss 0.0733, batch acc 0.9832
18:42:57.861   Training iter 100, batch loss 0.0745, batch acc 0.9826
18:42:57.983   Training iter 150, batch loss 0.0749, batch acc 0.9802
18:42:58.097   Training iter 200, batch loss 0.0722, batch acc 0.9838
18:42:58.204   Training iter 250, batch loss 0.0770, batch acc 0.9788
18:42:58.322   Training iter 300, batch loss 0.0751, batch acc 0.9804
18:42:58.428   Training iter 350, batch loss 0.0802, batch acc 0.9796
18:42:58.544   Training iter 400, batch loss 0.0810, batch acc 0.9772
18:42:58.658   Training iter 450, batch loss 0.0754, batch acc 0.9810
18:42:58.777   Training iter 500, batch loss 0.0772, batch acc 0.9796
18:42:58.904   Training iter 550, batch loss 0.0766, batch acc 0.9808
18:42:59.037   Training iter 600, batch loss 0.0815, batch acc 0.9750
18:42:59.038 Training @ 73 epoch...
18:42:59.181   Training iter 50, batch loss 0.0715, batch acc 0.9840
18:42:59.334   Training iter 100, batch loss 0.0756, batch acc 0.9818
18:42:59.463   Training iter 150, batch loss 0.0791, batch acc 0.9800
18:42:59.631   Training iter 200, batch loss 0.0725, batch acc 0.9826
18:42:59.762   Training iter 250, batch loss 0.0776, batch acc 0.9814
18:42:59.891   Training iter 300, batch loss 0.0798, batch acc 0.9778
18:43:00.080   Training iter 350, batch loss 0.0808, batch acc 0.9770
18:43:00.553   Training iter 400, batch loss 0.0729, batch acc 0.9826
18:43:01.142   Training iter 450, batch loss 0.0758, batch acc 0.9818
18:43:01.943   Training iter 500, batch loss 0.0761, batch acc 0.9774
18:43:03.167   Training iter 550, batch loss 0.0789, batch acc 0.9778
18:43:03.812   Training iter 600, batch loss 0.0790, batch acc 0.9788
18:43:03.813 Training @ 74 epoch...
18:43:04.525   Training iter 50, batch loss 0.0789, batch acc 0.9806
18:43:05.879   Training iter 100, batch loss 0.0737, batch acc 0.9812
18:43:06.365   Training iter 150, batch loss 0.0743, batch acc 0.9808
18:43:06.792   Training iter 200, batch loss 0.0802, batch acc 0.9792
18:43:07.447   Training iter 250, batch loss 0.0745, batch acc 0.9798
18:43:08.545   Training iter 300, batch loss 0.0723, batch acc 0.9830
18:43:08.998   Training iter 350, batch loss 0.0754, batch acc 0.9826
18:43:09.329   Training iter 400, batch loss 0.0817, batch acc 0.9766
18:43:09.628   Training iter 450, batch loss 0.0793, batch acc 0.9782
18:43:10.016   Training iter 500, batch loss 0.0754, batch acc 0.9846
18:43:10.362   Training iter 550, batch loss 0.0786, batch acc 0.9778
18:43:10.662   Training iter 600, batch loss 0.0750, batch acc 0.9818
18:43:10.663 Training @ 75 epoch...
18:43:10.998   Training iter 50, batch loss 0.0735, batch acc 0.9796
18:43:11.129   Training iter 100, batch loss 0.0758, batch acc 0.9824
18:43:11.312   Training iter 150, batch loss 0.0768, batch acc 0.9786
18:43:11.637   Training iter 200, batch loss 0.0754, batch acc 0.9812
18:43:11.812   Training iter 250, batch loss 0.0769, batch acc 0.9786
18:43:12.062   Training iter 300, batch loss 0.0733, batch acc 0.9852
18:43:12.294   Training iter 350, batch loss 0.0795, batch acc 0.9792
18:43:12.486   Training iter 400, batch loss 0.0785, batch acc 0.9796
18:43:12.631   Training iter 450, batch loss 0.0741, batch acc 0.9824
18:43:12.792   Training iter 500, batch loss 0.0771, batch acc 0.9786
18:43:12.959   Training iter 550, batch loss 0.0763, batch acc 0.9802
18:43:13.082   Training iter 600, batch loss 0.0755, batch acc 0.9814
18:43:13.083 Testing @ 75 epoch...
18:43:13.190     Testing, total mean loss 0.08518, total acc 0.97390
18:43:13.190 Training @ 76 epoch...
18:43:13.315   Training iter 50, batch loss 0.0747, batch acc 0.9808
18:43:13.541   Training iter 100, batch loss 0.0837, batch acc 0.9760
18:43:13.703   Training iter 150, batch loss 0.0748, batch acc 0.9812
18:43:13.881   Training iter 200, batch loss 0.0771, batch acc 0.9796
18:43:14.121   Training iter 250, batch loss 0.0775, batch acc 0.9842
18:43:14.288   Training iter 300, batch loss 0.0726, batch acc 0.9826
18:43:14.452   Training iter 350, batch loss 0.0724, batch acc 0.9818
18:43:14.562   Training iter 400, batch loss 0.0757, batch acc 0.9812
18:43:14.693   Training iter 450, batch loss 0.0755, batch acc 0.9818
18:43:14.896   Training iter 500, batch loss 0.0770, batch acc 0.9788
18:43:15.287   Training iter 550, batch loss 0.0761, batch acc 0.9778
18:43:15.461   Training iter 600, batch loss 0.0738, batch acc 0.9824
18:43:15.462 Training @ 77 epoch...
18:43:15.879   Training iter 50, batch loss 0.0762, batch acc 0.9830
18:43:16.707   Training iter 100, batch loss 0.0699, batch acc 0.9864
18:43:17.744   Training iter 150, batch loss 0.0750, batch acc 0.9780
18:43:18.600   Training iter 200, batch loss 0.0776, batch acc 0.9782
18:43:19.749   Training iter 250, batch loss 0.0765, batch acc 0.9818
18:43:20.633   Training iter 300, batch loss 0.0757, batch acc 0.9804
18:43:21.215   Training iter 350, batch loss 0.0742, batch acc 0.9816
18:43:21.864   Training iter 400, batch loss 0.0741, batch acc 0.9818
18:43:22.909   Training iter 450, batch loss 0.0766, batch acc 0.9818
18:43:23.521   Training iter 500, batch loss 0.0784, batch acc 0.9804
18:43:23.712   Training iter 550, batch loss 0.0802, batch acc 0.9762
18:43:23.854   Training iter 600, batch loss 0.0772, batch acc 0.9794
18:43:23.856 Training @ 78 epoch...
18:43:24.014   Training iter 50, batch loss 0.0770, batch acc 0.9796
18:43:24.160   Training iter 100, batch loss 0.0767, batch acc 0.9796
18:43:24.268   Training iter 150, batch loss 0.0713, batch acc 0.9828
18:43:24.427   Training iter 200, batch loss 0.0763, batch acc 0.9814
18:43:24.655   Training iter 250, batch loss 0.0764, batch acc 0.9808
18:43:24.775   Training iter 300, batch loss 0.0742, batch acc 0.9820
18:43:24.903   Training iter 350, batch loss 0.0768, batch acc 0.9790
18:43:25.006   Training iter 400, batch loss 0.0765, batch acc 0.9812
18:43:25.137   Training iter 450, batch loss 0.0767, batch acc 0.9798
18:43:25.260   Training iter 500, batch loss 0.0743, batch acc 0.9792
18:43:25.410   Training iter 550, batch loss 0.0754, batch acc 0.9818
18:43:25.541   Training iter 600, batch loss 0.0755, batch acc 0.9812
18:43:25.543 Training @ 79 epoch...
18:43:25.685   Training iter 50, batch loss 0.0714, batch acc 0.9814
18:43:25.844   Training iter 100, batch loss 0.0742, batch acc 0.9828
18:43:26.045   Training iter 150, batch loss 0.0740, batch acc 0.9808
18:43:26.168   Training iter 200, batch loss 0.0733, batch acc 0.9810
18:43:26.297   Training iter 250, batch loss 0.0777, batch acc 0.9784
18:43:26.492   Training iter 300, batch loss 0.0765, batch acc 0.9816
18:43:26.606   Training iter 350, batch loss 0.0741, batch acc 0.9830
18:43:26.715   Training iter 400, batch loss 0.0758, batch acc 0.9806
18:43:26.836   Training iter 450, batch loss 0.0780, batch acc 0.9796
18:43:26.956   Training iter 500, batch loss 0.0814, batch acc 0.9774
18:43:27.069   Training iter 550, batch loss 0.0712, batch acc 0.9834
18:43:27.181   Training iter 600, batch loss 0.0783, batch acc 0.9816
18:43:27.183 Training @ 80 epoch...
18:43:27.291   Training iter 50, batch loss 0.0765, batch acc 0.9830
18:43:27.402   Training iter 100, batch loss 0.0728, batch acc 0.9842
18:43:27.522   Training iter 150, batch loss 0.0695, batch acc 0.9848
18:43:27.650   Training iter 200, batch loss 0.0746, batch acc 0.9812
18:43:27.760   Training iter 250, batch loss 0.0769, batch acc 0.9796
18:43:27.865   Training iter 300, batch loss 0.0772, batch acc 0.9792
18:43:28.006   Training iter 350, batch loss 0.0759, batch acc 0.9818
18:43:28.143   Training iter 400, batch loss 0.0763, batch acc 0.9766
18:43:28.307   Training iter 450, batch loss 0.0779, batch acc 0.9798
18:43:28.474   Training iter 500, batch loss 0.0763, batch acc 0.9802
18:43:28.643   Training iter 550, batch loss 0.0771, batch acc 0.9798
18:43:28.793   Training iter 600, batch loss 0.0753, batch acc 0.9806
18:43:28.794 Testing @ 80 epoch...
18:43:28.888     Testing, total mean loss 0.08512, total acc 0.97390
18:43:28.888 Training @ 81 epoch...
18:43:28.977   Training iter 50, batch loss 0.0762, batch acc 0.9808
18:43:29.098   Training iter 100, batch loss 0.0769, batch acc 0.9802
18:43:29.225   Training iter 150, batch loss 0.0754, batch acc 0.9820
18:43:29.335   Training iter 200, batch loss 0.0715, batch acc 0.9826
18:43:29.455   Training iter 250, batch loss 0.0746, batch acc 0.9816
18:43:29.566   Training iter 300, batch loss 0.0752, batch acc 0.9796
18:43:29.669   Training iter 350, batch loss 0.0772, batch acc 0.9784
18:43:29.781   Training iter 400, batch loss 0.0754, batch acc 0.9796
18:43:29.943   Training iter 450, batch loss 0.0767, batch acc 0.9822
18:43:30.071   Training iter 500, batch loss 0.0728, batch acc 0.9842
18:43:30.214   Training iter 550, batch loss 0.0796, batch acc 0.9790
18:43:30.325   Training iter 600, batch loss 0.0719, batch acc 0.9836
18:43:30.326 Training @ 82 epoch...
18:43:30.455   Training iter 50, batch loss 0.0752, batch acc 0.9806
18:43:30.566   Training iter 100, batch loss 0.0749, batch acc 0.9812
18:43:30.685   Training iter 150, batch loss 0.0723, batch acc 0.9800
18:43:30.875   Training iter 200, batch loss 0.0782, batch acc 0.9810
18:43:31.053   Training iter 250, batch loss 0.0760, batch acc 0.9804
18:43:31.215   Training iter 300, batch loss 0.0773, batch acc 0.9816
18:43:31.365   Training iter 350, batch loss 0.0760, batch acc 0.9820
18:43:31.612   Training iter 400, batch loss 0.0693, batch acc 0.9856
18:43:31.777   Training iter 450, batch loss 0.0771, batch acc 0.9786
18:43:31.918   Training iter 500, batch loss 0.0754, batch acc 0.9804
18:43:32.065   Training iter 550, batch loss 0.0794, batch acc 0.9772
18:43:32.208   Training iter 600, batch loss 0.0733, batch acc 0.9818
18:43:32.208 Training @ 83 epoch...
18:43:32.329   Training iter 50, batch loss 0.0725, batch acc 0.9832
18:43:32.469   Training iter 100, batch loss 0.0706, batch acc 0.9814
18:43:32.577   Training iter 150, batch loss 0.0714, batch acc 0.9828
18:43:32.777   Training iter 200, batch loss 0.0780, batch acc 0.9784
18:43:32.926   Training iter 250, batch loss 0.0777, batch acc 0.9790
18:43:33.029   Training iter 300, batch loss 0.0735, batch acc 0.9806
18:43:33.213   Training iter 350, batch loss 0.0782, batch acc 0.9776
18:43:33.321   Training iter 400, batch loss 0.0777, batch acc 0.9818
18:43:33.440   Training iter 450, batch loss 0.0759, batch acc 0.9806
18:43:33.541   Training iter 500, batch loss 0.0776, batch acc 0.9828
18:43:33.662   Training iter 550, batch loss 0.0764, batch acc 0.9804
18:43:33.781   Training iter 600, batch loss 0.0765, batch acc 0.9806
18:43:33.782 Training @ 84 epoch...
18:43:33.918   Training iter 50, batch loss 0.0722, batch acc 0.9844
18:43:34.051   Training iter 100, batch loss 0.0769, batch acc 0.9816
18:43:34.186   Training iter 150, batch loss 0.0758, batch acc 0.9784
18:43:34.402   Training iter 200, batch loss 0.0784, batch acc 0.9814
18:43:34.542   Training iter 250, batch loss 0.0774, batch acc 0.9806
18:43:34.713   Training iter 300, batch loss 0.0696, batch acc 0.9860
18:43:34.926   Training iter 350, batch loss 0.0745, batch acc 0.9810
18:43:35.077   Training iter 400, batch loss 0.0771, batch acc 0.9794
18:43:35.332   Training iter 450, batch loss 0.0778, batch acc 0.9774
18:43:35.611   Training iter 500, batch loss 0.0748, batch acc 0.9808
18:43:35.756   Training iter 550, batch loss 0.0769, batch acc 0.9796
18:43:35.958   Training iter 600, batch loss 0.0723, batch acc 0.9828
18:43:35.958 Training @ 85 epoch...
18:43:36.126   Training iter 50, batch loss 0.0740, batch acc 0.9818
18:43:36.372   Training iter 100, batch loss 0.0762, batch acc 0.9816
18:43:36.634   Training iter 150, batch loss 0.0774, batch acc 0.9794
18:43:36.942   Training iter 200, batch loss 0.0753, batch acc 0.9834
18:43:37.150   Training iter 250, batch loss 0.0721, batch acc 0.9802
18:43:37.449   Training iter 300, batch loss 0.0704, batch acc 0.9838
18:43:37.740   Training iter 350, batch loss 0.0725, batch acc 0.9804
18:43:37.952   Training iter 400, batch loss 0.0764, batch acc 0.9804
18:43:38.274   Training iter 450, batch loss 0.0755, batch acc 0.9792
18:43:38.390   Training iter 500, batch loss 0.0759, batch acc 0.9820
18:43:38.590   Training iter 550, batch loss 0.0758, batch acc 0.9810
18:43:38.710   Training iter 600, batch loss 0.0773, batch acc 0.9794
18:43:38.711 Testing @ 85 epoch...
18:43:38.810     Testing, total mean loss 0.08554, total acc 0.97350
18:43:38.810 Training @ 86 epoch...
18:43:38.960   Training iter 50, batch loss 0.0765, batch acc 0.9796
18:43:39.134   Training iter 100, batch loss 0.0740, batch acc 0.9836
18:43:39.294   Training iter 150, batch loss 0.0740, batch acc 0.9778
18:43:39.438   Training iter 200, batch loss 0.0721, batch acc 0.9808
18:43:39.584   Training iter 250, batch loss 0.0765, batch acc 0.9814
18:43:39.774   Training iter 300, batch loss 0.0783, batch acc 0.9812
18:43:39.977   Training iter 350, batch loss 0.0750, batch acc 0.9832
18:43:40.335   Training iter 400, batch loss 0.0764, batch acc 0.9800
18:43:40.624   Training iter 450, batch loss 0.0721, batch acc 0.9832
18:43:40.850   Training iter 500, batch loss 0.0737, batch acc 0.9830
18:43:41.013   Training iter 550, batch loss 0.0719, batch acc 0.9834
18:43:41.194   Training iter 600, batch loss 0.0774, batch acc 0.9792
18:43:41.196 Training @ 87 epoch...
18:43:41.558   Training iter 50, batch loss 0.0767, batch acc 0.9760
18:43:42.334   Training iter 100, batch loss 0.0720, batch acc 0.9812
18:43:43.787   Training iter 150, batch loss 0.0737, batch acc 0.9812
18:43:44.558   Training iter 200, batch loss 0.0778, batch acc 0.9788
18:43:45.349   Training iter 250, batch loss 0.0758, batch acc 0.9816
18:43:46.699   Training iter 300, batch loss 0.0738, batch acc 0.9840
18:43:47.352   Training iter 350, batch loss 0.0762, batch acc 0.9812
18:43:48.362   Training iter 400, batch loss 0.0743, batch acc 0.9802
18:43:49.546   Training iter 450, batch loss 0.0765, batch acc 0.9806
18:43:50.497   Training iter 500, batch loss 0.0725, batch acc 0.9826
18:43:52.016   Training iter 550, batch loss 0.0726, batch acc 0.9844
18:43:52.949   Training iter 600, batch loss 0.0751, batch acc 0.9830
18:43:52.951 Training @ 88 epoch...
18:43:53.673   Training iter 50, batch loss 0.0770, batch acc 0.9776
18:43:54.465   Training iter 100, batch loss 0.0715, batch acc 0.9842
18:43:55.400   Training iter 150, batch loss 0.0730, batch acc 0.9824
18:43:56.064   Training iter 200, batch loss 0.0750, batch acc 0.9830
18:43:56.657   Training iter 250, batch loss 0.0727, batch acc 0.9830
18:43:56.939   Training iter 300, batch loss 0.0750, batch acc 0.9824
18:43:57.123   Training iter 350, batch loss 0.0752, batch acc 0.9808
18:43:57.294   Training iter 400, batch loss 0.0731, batch acc 0.9832
18:43:57.422   Training iter 450, batch loss 0.0769, batch acc 0.9786
18:43:57.588   Training iter 500, batch loss 0.0748, batch acc 0.9816
18:43:57.755   Training iter 550, batch loss 0.0794, batch acc 0.9796
18:43:57.881   Training iter 600, batch loss 0.0744, batch acc 0.9800
18:43:57.882 Training @ 89 epoch...
18:43:58.029   Training iter 50, batch loss 0.0755, batch acc 0.9822
18:43:58.210   Training iter 100, batch loss 0.0747, batch acc 0.9814
18:43:58.366   Training iter 150, batch loss 0.0719, batch acc 0.9804
18:43:58.614   Training iter 200, batch loss 0.0756, batch acc 0.9810
18:43:58.716   Training iter 250, batch loss 0.0750, batch acc 0.9790
18:43:58.905   Training iter 300, batch loss 0.0750, batch acc 0.9818
18:43:59.020   Training iter 350, batch loss 0.0742, batch acc 0.9824
18:43:59.125   Training iter 400, batch loss 0.0754, batch acc 0.9804
18:43:59.239   Training iter 450, batch loss 0.0746, batch acc 0.9810
18:43:59.425   Training iter 500, batch loss 0.0782, batch acc 0.9802
18:43:59.539   Training iter 550, batch loss 0.0722, batch acc 0.9848
18:43:59.670   Training iter 600, batch loss 0.0733, batch acc 0.9812
18:43:59.671 Training @ 90 epoch...
18:43:59.815   Training iter 50, batch loss 0.0727, batch acc 0.9826
18:44:00.029   Training iter 100, batch loss 0.0749, batch acc 0.9802
18:44:00.169   Training iter 150, batch loss 0.0725, batch acc 0.9840
18:44:00.342   Training iter 200, batch loss 0.0752, batch acc 0.9816
18:44:00.500   Training iter 250, batch loss 0.0744, batch acc 0.9826
18:44:00.613   Training iter 300, batch loss 0.0735, batch acc 0.9822
18:44:00.747   Training iter 350, batch loss 0.0737, batch acc 0.9814
18:44:00.914   Training iter 400, batch loss 0.0707, batch acc 0.9844
18:44:01.038   Training iter 450, batch loss 0.0760, batch acc 0.9796
18:44:01.193   Training iter 500, batch loss 0.0755, batch acc 0.9824
18:44:01.336   Training iter 550, batch loss 0.0750, batch acc 0.9816
18:44:01.483   Training iter 600, batch loss 0.0778, batch acc 0.9808
18:44:01.485 Testing @ 90 epoch...
18:44:01.606     Testing, total mean loss 0.08512, total acc 0.97390
18:44:01.607 Training @ 91 epoch...
18:44:01.762   Training iter 50, batch loss 0.0722, batch acc 0.9838
18:44:01.891   Training iter 100, batch loss 0.0723, batch acc 0.9848
18:44:02.008   Training iter 150, batch loss 0.0721, batch acc 0.9812
18:44:02.172   Training iter 200, batch loss 0.0727, batch acc 0.9832
18:44:02.323   Training iter 250, batch loss 0.0735, batch acc 0.9832
18:44:02.474   Training iter 300, batch loss 0.0716, batch acc 0.9828
18:44:02.609   Training iter 350, batch loss 0.0745, batch acc 0.9820
18:44:02.844   Training iter 400, batch loss 0.0781, batch acc 0.9792
18:44:02.994   Training iter 450, batch loss 0.0750, batch acc 0.9812
18:44:03.207   Training iter 500, batch loss 0.0735, batch acc 0.9818
18:44:03.498   Training iter 550, batch loss 0.0776, batch acc 0.9788
18:44:03.678   Training iter 600, batch loss 0.0748, batch acc 0.9808
18:44:03.680 Training @ 92 epoch...
18:44:03.842   Training iter 50, batch loss 0.0737, batch acc 0.9800
18:44:03.977   Training iter 100, batch loss 0.0729, batch acc 0.9836
18:44:04.089   Training iter 150, batch loss 0.0733, batch acc 0.9830
18:44:04.225   Training iter 200, batch loss 0.0727, batch acc 0.9822
18:44:04.353   Training iter 250, batch loss 0.0699, batch acc 0.9832
18:44:04.462   Training iter 300, batch loss 0.0738, batch acc 0.9830
18:44:04.571   Training iter 350, batch loss 0.0727, batch acc 0.9834
18:44:04.706   Training iter 400, batch loss 0.0758, batch acc 0.9812
18:44:04.810   Training iter 450, batch loss 0.0762, batch acc 0.9808
18:44:04.926   Training iter 500, batch loss 0.0753, batch acc 0.9780
18:44:05.031   Training iter 550, batch loss 0.0749, batch acc 0.9818
18:44:05.173   Training iter 600, batch loss 0.0759, batch acc 0.9814
18:44:05.175 Training @ 93 epoch...
18:44:05.298   Training iter 50, batch loss 0.0741, batch acc 0.9794
18:44:05.452   Training iter 100, batch loss 0.0736, batch acc 0.9842
18:44:05.579   Training iter 150, batch loss 0.0710, batch acc 0.9820
18:44:05.720   Training iter 200, batch loss 0.0757, batch acc 0.9828
18:44:05.853   Training iter 250, batch loss 0.0739, batch acc 0.9816
18:44:06.011   Training iter 300, batch loss 0.0732, batch acc 0.9834
18:44:06.123   Training iter 350, batch loss 0.0734, batch acc 0.9808
18:44:06.250   Training iter 400, batch loss 0.0792, batch acc 0.9808
18:44:06.355   Training iter 450, batch loss 0.0735, batch acc 0.9826
18:44:06.455   Training iter 500, batch loss 0.0741, batch acc 0.9818
18:44:06.568   Training iter 550, batch loss 0.0735, batch acc 0.9826
18:44:06.668   Training iter 600, batch loss 0.0766, batch acc 0.9800
18:44:06.669 Training @ 94 epoch...
18:44:06.789   Training iter 50, batch loss 0.0746, batch acc 0.9826
18:44:06.906   Training iter 100, batch loss 0.0727, batch acc 0.9826
18:44:07.008   Training iter 150, batch loss 0.0728, batch acc 0.9846
18:44:07.111   Training iter 200, batch loss 0.0727, batch acc 0.9828
18:44:07.233   Training iter 250, batch loss 0.0726, batch acc 0.9838
18:44:07.335   Training iter 300, batch loss 0.0746, batch acc 0.9796
18:44:07.441   Training iter 350, batch loss 0.0759, batch acc 0.9794
18:44:07.546   Training iter 400, batch loss 0.0741, batch acc 0.9812
18:44:07.651   Training iter 450, batch loss 0.0710, batch acc 0.9844
18:44:07.814   Training iter 500, batch loss 0.0773, batch acc 0.9796
18:44:07.921   Training iter 550, batch loss 0.0741, batch acc 0.9830
18:44:08.031   Training iter 600, batch loss 0.0772, batch acc 0.9810
18:44:08.037 Training @ 95 epoch...
18:44:08.184   Training iter 50, batch loss 0.0724, batch acc 0.9834
18:44:08.331   Training iter 100, batch loss 0.0724, batch acc 0.9814
18:44:08.457   Training iter 150, batch loss 0.0749, batch acc 0.9808
18:44:08.591   Training iter 200, batch loss 0.0707, batch acc 0.9842
18:44:08.740   Training iter 250, batch loss 0.0733, batch acc 0.9826
18:44:08.882   Training iter 300, batch loss 0.0746, batch acc 0.9808
18:44:08.988   Training iter 350, batch loss 0.0724, batch acc 0.9832
18:44:09.092   Training iter 400, batch loss 0.0750, batch acc 0.9812
18:44:09.208   Training iter 450, batch loss 0.0729, batch acc 0.9840
18:44:09.319   Training iter 500, batch loss 0.0776, batch acc 0.9780
18:44:09.422   Training iter 550, batch loss 0.0763, batch acc 0.9822
18:44:09.526   Training iter 600, batch loss 0.0756, batch acc 0.9820
18:44:09.527 Testing @ 95 epoch...
18:44:09.618     Testing, total mean loss 0.08390, total acc 0.97410
18:44:09.619 Training @ 96 epoch...
18:44:09.732   Training iter 50, batch loss 0.0684, batch acc 0.9842
18:44:09.855   Training iter 100, batch loss 0.0735, batch acc 0.9824
18:44:09.963   Training iter 150, batch loss 0.0741, batch acc 0.9814
18:44:10.076   Training iter 200, batch loss 0.0726, batch acc 0.9830
18:44:10.184   Training iter 250, batch loss 0.0750, batch acc 0.9804
18:44:10.303   Training iter 300, batch loss 0.0754, batch acc 0.9832
18:44:10.416   Training iter 350, batch loss 0.0785, batch acc 0.9790
18:44:10.594   Training iter 400, batch loss 0.0756, batch acc 0.9832
18:44:10.714   Training iter 450, batch loss 0.0726, batch acc 0.9846
18:44:10.835   Training iter 500, batch loss 0.0753, batch acc 0.9810
18:44:10.970   Training iter 550, batch loss 0.0728, batch acc 0.9822
18:44:11.108   Training iter 600, batch loss 0.0746, batch acc 0.9802
18:44:11.109 Training @ 97 epoch...
18:44:11.245   Training iter 50, batch loss 0.0714, batch acc 0.9814
18:44:11.370   Training iter 100, batch loss 0.0732, batch acc 0.9820
18:44:11.525   Training iter 150, batch loss 0.0717, batch acc 0.9828
18:44:11.667   Training iter 200, batch loss 0.0757, batch acc 0.9790
18:44:11.773   Training iter 250, batch loss 0.0743, batch acc 0.9782
18:44:11.891   Training iter 300, batch loss 0.0724, batch acc 0.9818
18:44:11.998   Training iter 350, batch loss 0.0759, batch acc 0.9820
18:44:12.116   Training iter 400, batch loss 0.0690, batch acc 0.9858
18:44:12.224   Training iter 450, batch loss 0.0747, batch acc 0.9814
18:44:12.320   Training iter 500, batch loss 0.0739, batch acc 0.9814
18:44:12.405   Training iter 550, batch loss 0.0740, batch acc 0.9812
18:44:12.510   Training iter 600, batch loss 0.0760, batch acc 0.9810
18:44:12.511 Training @ 98 epoch...
18:44:12.621   Training iter 50, batch loss 0.0695, batch acc 0.9846
18:44:12.737   Training iter 100, batch loss 0.0727, batch acc 0.9828
18:44:12.851   Training iter 150, batch loss 0.0716, batch acc 0.9842
18:44:12.962   Training iter 200, batch loss 0.0731, batch acc 0.9800
18:44:13.085   Training iter 250, batch loss 0.0783, batch acc 0.9792
18:44:13.196   Training iter 300, batch loss 0.0752, batch acc 0.9806
18:44:13.307   Training iter 350, batch loss 0.0724, batch acc 0.9836
18:44:13.413   Training iter 400, batch loss 0.0751, batch acc 0.9798
18:44:13.529   Training iter 450, batch loss 0.0737, batch acc 0.9828
18:44:13.723   Training iter 500, batch loss 0.0749, batch acc 0.9820
18:44:13.861   Training iter 550, batch loss 0.0740, batch acc 0.9822
18:44:13.989   Training iter 600, batch loss 0.0723, batch acc 0.9844
18:44:13.990 Training @ 99 epoch...
18:44:14.125   Training iter 50, batch loss 0.0737, batch acc 0.9832
18:44:14.265   Training iter 100, batch loss 0.0751, batch acc 0.9794
18:44:14.396   Training iter 150, batch loss 0.0738, batch acc 0.9822
18:44:14.513   Training iter 200, batch loss 0.0728, batch acc 0.9814
18:44:14.623   Training iter 250, batch loss 0.0763, batch acc 0.9786
18:44:14.729   Training iter 300, batch loss 0.0712, batch acc 0.9866
18:44:14.835   Training iter 350, batch loss 0.0739, batch acc 0.9816
18:44:14.954   Training iter 400, batch loss 0.0738, batch acc 0.9814
18:44:15.070   Training iter 450, batch loss 0.0745, batch acc 0.9816
18:44:15.175   Training iter 500, batch loss 0.0717, batch acc 0.9826
18:44:15.277   Training iter 550, batch loss 0.0725, batch acc 0.9822
18:44:15.390   Training iter 600, batch loss 0.0730, batch acc 0.9802
18:44:15.390 Testing @ 99 epoch...
18:44:15.478     Testing, total mean loss 0.08344, total acc 0.97360