18:48:36.766 Training @ 0 epoch...
18:48:37.580   Training iter 50, batch loss 23.5502, batch acc 0.4698
18:48:37.794   Training iter 100, batch loss 4.2194, batch acc 0.8224
18:48:37.981   Training iter 150, batch loss 3.2738, batch acc 0.8646
18:48:38.332   Training iter 200, batch loss 2.7417, batch acc 0.8766
18:48:38.491   Training iter 250, batch loss 2.6315, batch acc 0.8802
18:48:38.805   Training iter 300, batch loss 2.3093, batch acc 0.9000
18:48:39.053   Training iter 350, batch loss 1.7346, batch acc 0.9238
18:48:39.166   Training iter 400, batch loss 1.9213, batch acc 0.9126
18:48:39.280   Training iter 450, batch loss 1.6786, batch acc 0.9212
18:48:39.604   Training iter 500, batch loss 1.7723, batch acc 0.9200
18:48:39.791   Training iter 550, batch loss 1.5629, batch acc 0.9268
18:48:40.002   Training iter 600, batch loss 1.5961, batch acc 0.9254
18:48:40.002 Testing @ 0 epoch...
18:48:40.128     Testing, total mean loss 1.33963, total acc 0.93260
18:48:40.128 Training @ 1 epoch...
18:48:40.339   Training iter 50, batch loss 1.2849, batch acc 0.9344
18:48:40.495   Training iter 100, batch loss 1.3133, batch acc 0.9360
18:48:40.627   Training iter 150, batch loss 1.4357, batch acc 0.9300
18:48:40.776   Training iter 200, batch loss 1.1737, batch acc 0.9396
18:48:40.912   Training iter 250, batch loss 1.3137, batch acc 0.9428
18:48:41.242   Training iter 300, batch loss 1.2182, batch acc 0.9420
18:48:41.379   Training iter 350, batch loss 1.1580, batch acc 0.9440
18:48:41.533   Training iter 400, batch loss 0.9580, batch acc 0.9506
18:48:41.678   Training iter 450, batch loss 1.1944, batch acc 0.9452
18:48:41.889   Training iter 500, batch loss 1.0423, batch acc 0.9510
18:48:42.049   Training iter 550, batch loss 1.0090, batch acc 0.9472
18:48:42.202   Training iter 600, batch loss 0.9899, batch acc 0.9556
18:48:42.205 Training @ 2 epoch...
18:48:42.360   Training iter 50, batch loss 0.9835, batch acc 0.9508
18:48:42.490   Training iter 100, batch loss 0.9235, batch acc 0.9568
18:48:42.629   Training iter 150, batch loss 0.8297, batch acc 0.9548
18:48:42.760   Training iter 200, batch loss 0.9007, batch acc 0.9548
18:48:43.001   Training iter 250, batch loss 0.8345, batch acc 0.9544
18:48:43.131   Training iter 300, batch loss 0.7520, batch acc 0.9616
18:48:43.248   Training iter 350, batch loss 0.7617, batch acc 0.9640
18:48:43.349   Training iter 400, batch loss 0.8541, batch acc 0.9570
18:48:43.493   Training iter 450, batch loss 0.8551, batch acc 0.9568
18:48:43.648   Training iter 500, batch loss 0.9013, batch acc 0.9552
18:48:43.776   Training iter 550, batch loss 0.7545, batch acc 0.9598
18:48:43.917   Training iter 600, batch loss 0.8179, batch acc 0.9592
18:48:43.917 Training @ 3 epoch...
18:48:44.110   Training iter 50, batch loss 0.6531, batch acc 0.9636
18:48:44.287   Training iter 100, batch loss 0.7076, batch acc 0.9638
18:48:44.414   Training iter 150, batch loss 0.7578, batch acc 0.9656
18:48:44.548   Training iter 200, batch loss 0.6429, batch acc 0.9642
18:48:44.669   Training iter 250, batch loss 0.6426, batch acc 0.9672
18:48:44.816   Training iter 300, batch loss 0.6376, batch acc 0.9678
18:48:44.967   Training iter 350, batch loss 0.6951, batch acc 0.9624
18:48:45.095   Training iter 400, batch loss 0.5875, batch acc 0.9664
18:48:45.191   Training iter 450, batch loss 0.6774, batch acc 0.9660
18:48:45.355   Training iter 500, batch loss 0.7002, batch acc 0.9650
18:48:45.468   Training iter 550, batch loss 0.6611, batch acc 0.9636
18:48:45.580   Training iter 600, batch loss 0.6860, batch acc 0.9648
18:48:45.582 Training @ 4 epoch...
18:48:45.691   Training iter 50, batch loss 0.5590, batch acc 0.9712
18:48:45.789   Training iter 100, batch loss 0.5965, batch acc 0.9668
18:48:45.893   Training iter 150, batch loss 0.5909, batch acc 0.9654
18:48:45.990   Training iter 200, batch loss 0.6527, batch acc 0.9626
18:48:46.078   Training iter 250, batch loss 0.6532, batch acc 0.9658
18:48:46.179   Training iter 300, batch loss 0.5201, batch acc 0.9730
18:48:46.292   Training iter 350, batch loss 0.5580, batch acc 0.9712
18:48:46.407   Training iter 400, batch loss 0.5658, batch acc 0.9682
18:48:46.496   Training iter 450, batch loss 0.6290, batch acc 0.9630
18:48:46.588   Training iter 500, batch loss 0.5132, batch acc 0.9744
18:48:46.684   Training iter 550, batch loss 0.5317, batch acc 0.9700
18:48:46.801   Training iter 600, batch loss 0.5664, batch acc 0.9750
18:48:46.804 Training @ 5 epoch...
18:48:46.931   Training iter 50, batch loss 0.4758, batch acc 0.9732
18:48:47.062   Training iter 100, batch loss 0.4939, batch acc 0.9750
18:48:47.184   Training iter 150, batch loss 0.4972, batch acc 0.9740
18:48:47.325   Training iter 200, batch loss 0.4596, batch acc 0.9736
18:48:47.450   Training iter 250, batch loss 0.5265, batch acc 0.9708
18:48:47.584   Training iter 300, batch loss 0.4956, batch acc 0.9726
18:48:47.725   Training iter 350, batch loss 0.4953, batch acc 0.9732
18:48:47.838   Training iter 400, batch loss 0.4570, batch acc 0.9746
18:48:47.962   Training iter 450, batch loss 0.4843, batch acc 0.9736
18:48:48.071   Training iter 500, batch loss 0.5014, batch acc 0.9746
18:48:48.192   Training iter 550, batch loss 0.4347, batch acc 0.9750
18:48:48.307   Training iter 600, batch loss 0.5301, batch acc 0.9750
18:48:48.308 Testing @ 5 epoch...
18:48:48.393     Testing, total mean loss 0.58344, total acc 0.97090
18:48:48.393 Training @ 6 epoch...
18:48:48.509   Training iter 50, batch loss 0.4122, batch acc 0.9778
18:48:48.627   Training iter 100, batch loss 0.3775, batch acc 0.9802
18:48:48.740   Training iter 150, batch loss 0.4067, batch acc 0.9758
18:48:48.864   Training iter 200, batch loss 0.4054, batch acc 0.9760
18:48:48.970   Training iter 250, batch loss 0.4812, batch acc 0.9752
18:48:49.080   Training iter 300, batch loss 0.4520, batch acc 0.9784
18:48:49.189   Training iter 350, batch loss 0.4454, batch acc 0.9766
18:48:49.339   Training iter 400, batch loss 0.4156, batch acc 0.9758
18:48:49.451   Training iter 450, batch loss 0.4473, batch acc 0.9758
18:48:49.552   Training iter 500, batch loss 0.4374, batch acc 0.9746
18:48:49.683   Training iter 550, batch loss 0.4594, batch acc 0.9760
18:48:49.839   Training iter 600, batch loss 0.5113, batch acc 0.9748
18:48:49.840 Training @ 7 epoch...
18:48:50.072   Training iter 50, batch loss 0.3301, batch acc 0.9810
18:48:50.208   Training iter 100, batch loss 0.3944, batch acc 0.9770
18:48:50.349   Training iter 150, batch loss 0.3693, batch acc 0.9776
18:48:50.493   Training iter 200, batch loss 0.3608, batch acc 0.9804
18:48:50.606   Training iter 250, batch loss 0.3769, batch acc 0.9790
18:48:50.721   Training iter 300, batch loss 0.3860, batch acc 0.9802
18:48:50.828   Training iter 350, batch loss 0.4214, batch acc 0.9772
18:48:50.948   Training iter 400, batch loss 0.3525, batch acc 0.9810
18:48:51.089   Training iter 450, batch loss 0.3968, batch acc 0.9774
18:48:51.263   Training iter 500, batch loss 0.4015, batch acc 0.9770
18:48:51.363   Training iter 550, batch loss 0.4569, batch acc 0.9760
18:48:51.527   Training iter 600, batch loss 0.3879, batch acc 0.9778
18:48:51.528 Training @ 8 epoch...
18:48:51.630   Training iter 50, batch loss 0.3567, batch acc 0.9792
18:48:51.740   Training iter 100, batch loss 0.3063, batch acc 0.9832
18:48:51.873   Training iter 150, batch loss 0.2875, batch acc 0.9842
18:48:51.981   Training iter 200, batch loss 0.3383, batch acc 0.9802
18:48:52.092   Training iter 250, batch loss 0.3199, batch acc 0.9824
18:48:52.222   Training iter 300, batch loss 0.3691, batch acc 0.9798
18:48:52.338   Training iter 350, batch loss 0.4224, batch acc 0.9746
18:48:52.463   Training iter 400, batch loss 0.3496, batch acc 0.9810
18:48:52.647   Training iter 450, batch loss 0.3144, batch acc 0.9794
18:48:52.794   Training iter 500, batch loss 0.3617, batch acc 0.9776
18:48:52.947   Training iter 550, batch loss 0.3192, batch acc 0.9816
18:48:53.084   Training iter 600, batch loss 0.3926, batch acc 0.9784
18:48:53.085 Training @ 9 epoch...
18:48:53.240   Training iter 50, batch loss 0.2996, batch acc 0.9830
18:48:53.368   Training iter 100, batch loss 0.2903, batch acc 0.9846
18:48:53.613   Training iter 150, batch loss 0.2987, batch acc 0.9838
18:48:54.385   Training iter 200, batch loss 0.2970, batch acc 0.9814
18:48:54.583   Training iter 250, batch loss 0.3198, batch acc 0.9818
18:48:54.813   Training iter 300, batch loss 0.3374, batch acc 0.9812
18:48:55.074   Training iter 350, batch loss 0.3156, batch acc 0.9848
18:48:55.217   Training iter 400, batch loss 0.3660, batch acc 0.9802
18:48:55.359   Training iter 450, batch loss 0.3321, batch acc 0.9816
18:48:55.521   Training iter 500, batch loss 0.3219, batch acc 0.9820
18:48:55.689   Training iter 550, batch loss 0.3016, batch acc 0.9826
18:48:55.829   Training iter 600, batch loss 0.3538, batch acc 0.9788
18:48:55.830 Training @ 10 epoch...
18:48:55.976   Training iter 50, batch loss 0.2881, batch acc 0.9844
18:48:56.167   Training iter 100, batch loss 0.3291, batch acc 0.9802
18:48:56.351   Training iter 150, batch loss 0.2874, batch acc 0.9812
18:48:56.495   Training iter 200, batch loss 0.3000, batch acc 0.9838
18:48:56.624   Training iter 250, batch loss 0.2754, batch acc 0.9854
18:48:56.875   Training iter 300, batch loss 0.2886, batch acc 0.9834
18:48:57.489   Training iter 350, batch loss 0.2857, batch acc 0.9826
18:48:57.728   Training iter 400, batch loss 0.2784, batch acc 0.9850
18:48:57.877   Training iter 450, batch loss 0.3025, batch acc 0.9834
18:48:58.033   Training iter 500, batch loss 0.3024, batch acc 0.9812
18:48:58.179   Training iter 550, batch loss 0.3018, batch acc 0.9836
18:48:58.325   Training iter 600, batch loss 0.3128, batch acc 0.9820
18:48:58.326 Testing @ 10 epoch...
18:48:58.465     Testing, total mean loss 0.47844, total acc 0.97680
18:48:58.465 Training @ 11 epoch...
18:48:58.610   Training iter 50, batch loss 0.2632, batch acc 0.9846
18:48:58.771   Training iter 100, batch loss 0.2341, batch acc 0.9860
18:48:58.905   Training iter 150, batch loss 0.2703, batch acc 0.9850
18:48:59.025   Training iter 200, batch loss 0.2833, batch acc 0.9844
18:48:59.134   Training iter 250, batch loss 0.2686, batch acc 0.9858
18:48:59.312   Training iter 300, batch loss 0.2790, batch acc 0.9854
18:48:59.438   Training iter 350, batch loss 0.2605, batch acc 0.9840
18:48:59.544   Training iter 400, batch loss 0.3277, batch acc 0.9800
18:48:59.674   Training iter 450, batch loss 0.2833, batch acc 0.9836
18:48:59.778   Training iter 500, batch loss 0.2885, batch acc 0.9820
18:48:59.901   Training iter 550, batch loss 0.2816, batch acc 0.9856
18:49:00.058   Training iter 600, batch loss 0.3222, batch acc 0.9818
18:49:00.058 Training @ 12 epoch...
18:49:00.247   Training iter 50, batch loss 0.2446, batch acc 0.9864
18:49:00.362   Training iter 100, batch loss 0.2575, batch acc 0.9856
18:49:00.463   Training iter 150, batch loss 0.2316, batch acc 0.9882
18:49:00.570   Training iter 200, batch loss 0.2810, batch acc 0.9832
18:49:00.680   Training iter 250, batch loss 0.2334, batch acc 0.9840
18:49:00.807   Training iter 300, batch loss 0.2520, batch acc 0.9858
18:49:01.037   Training iter 350, batch loss 0.2608, batch acc 0.9856
18:49:01.195   Training iter 400, batch loss 0.3000, batch acc 0.9836
18:49:01.355   Training iter 450, batch loss 0.2923, batch acc 0.9830
18:49:01.534   Training iter 500, batch loss 0.2380, batch acc 0.9874
18:49:01.640   Training iter 550, batch loss 0.2745, batch acc 0.9848
18:49:01.761   Training iter 600, batch loss 0.2747, batch acc 0.9832
18:49:01.763 Training @ 13 epoch...
18:49:01.882   Training iter 50, batch loss 0.2154, batch acc 0.9876
18:49:02.075   Training iter 100, batch loss 0.1992, batch acc 0.9900
18:49:02.191   Training iter 150, batch loss 0.2396, batch acc 0.9870
18:49:02.298   Training iter 200, batch loss 0.1973, batch acc 0.9892
18:49:02.430   Training iter 250, batch loss 0.1979, batch acc 0.9886
18:49:02.547   Training iter 300, batch loss 0.2553, batch acc 0.9858
18:49:02.672   Training iter 350, batch loss 0.3179, batch acc 0.9806
18:49:02.789   Training iter 400, batch loss 0.3056, batch acc 0.9842
18:49:02.923   Training iter 450, batch loss 0.2836, batch acc 0.9844
18:49:03.046   Training iter 500, batch loss 0.2174, batch acc 0.9888
18:49:03.172   Training iter 550, batch loss 0.2538, batch acc 0.9852
18:49:03.282   Training iter 600, batch loss 0.2620, batch acc 0.9854
18:49:03.283 Training @ 14 epoch...
18:49:03.397   Training iter 50, batch loss 0.2539, batch acc 0.9886
18:49:03.555   Training iter 100, batch loss 0.1838, batch acc 0.9896
18:49:03.684   Training iter 150, batch loss 0.2443, batch acc 0.9852
18:49:03.819   Training iter 200, batch loss 0.2055, batch acc 0.9882
18:49:03.974   Training iter 250, batch loss 0.2667, batch acc 0.9852
18:49:04.279   Training iter 300, batch loss 0.2003, batch acc 0.9892
18:49:04.528   Training iter 350, batch loss 0.2252, batch acc 0.9858
18:49:04.695   Training iter 400, batch loss 0.2083, batch acc 0.9892
18:49:04.813   Training iter 450, batch loss 0.2142, batch acc 0.9886
18:49:04.967   Training iter 500, batch loss 0.2320, batch acc 0.9874
18:49:05.104   Training iter 550, batch loss 0.2416, batch acc 0.9856
18:49:05.251   Training iter 600, batch loss 0.2221, batch acc 0.9870
18:49:05.252 Training @ 15 epoch...
18:49:05.375   Training iter 50, batch loss 0.1782, batch acc 0.9902
18:49:05.566   Training iter 100, batch loss 0.2273, batch acc 0.9874
18:49:05.706   Training iter 150, batch loss 0.2138, batch acc 0.9894
18:49:05.825   Training iter 200, batch loss 0.1789, batch acc 0.9908
18:49:05.945   Training iter 250, batch loss 0.2633, batch acc 0.9844
18:49:06.063   Training iter 300, batch loss 0.2425, batch acc 0.9864
18:49:06.218   Training iter 350, batch loss 0.2253, batch acc 0.9856
18:49:06.344   Training iter 400, batch loss 0.2567, batch acc 0.9844
18:49:06.512   Training iter 450, batch loss 0.2093, batch acc 0.9878
18:49:06.664   Training iter 500, batch loss 0.1938, batch acc 0.9896
18:49:06.827   Training iter 550, batch loss 0.1957, batch acc 0.9886
18:49:07.009   Training iter 600, batch loss 0.2468, batch acc 0.9878
18:49:07.010 Testing @ 15 epoch...
18:49:07.244     Testing, total mean loss 0.46210, total acc 0.97650
18:49:07.245 Training @ 16 epoch...
18:49:07.421   Training iter 50, batch loss 0.1900, batch acc 0.9894
18:49:07.560   Training iter 100, batch loss 0.2366, batch acc 0.9866
18:49:07.676   Training iter 150, batch loss 0.2174, batch acc 0.9874
18:49:07.856   Training iter 200, batch loss 0.1861, batch acc 0.9898
18:49:07.987   Training iter 250, batch loss 0.1865, batch acc 0.9906
18:49:08.106   Training iter 300, batch loss 0.1809, batch acc 0.9892
18:49:08.231   Training iter 350, batch loss 0.2040, batch acc 0.9894
18:49:08.354   Training iter 400, batch loss 0.2040, batch acc 0.9890
18:49:08.474   Training iter 450, batch loss 0.2221, batch acc 0.9892
18:49:08.595   Training iter 500, batch loss 0.2475, batch acc 0.9854
18:49:08.710   Training iter 550, batch loss 0.2100, batch acc 0.9894
18:49:08.823   Training iter 600, batch loss 0.2336, batch acc 0.9866
18:49:08.825 Training @ 17 epoch...
18:49:08.952   Training iter 50, batch loss 0.1751, batch acc 0.9902
18:49:09.066   Training iter 100, batch loss 0.1852, batch acc 0.9904
18:49:09.165   Training iter 150, batch loss 0.1878, batch acc 0.9880
18:49:09.313   Training iter 200, batch loss 0.1853, batch acc 0.9900
18:49:09.449   Training iter 250, batch loss 0.2146, batch acc 0.9880
18:49:09.581   Training iter 300, batch loss 0.1985, batch acc 0.9888
18:49:09.715   Training iter 350, batch loss 0.2280, batch acc 0.9878
18:49:09.831   Training iter 400, batch loss 0.1893, batch acc 0.9894
18:49:09.983   Training iter 450, batch loss 0.1816, batch acc 0.9892
18:49:10.131   Training iter 500, batch loss 0.1932, batch acc 0.9898
18:49:10.277   Training iter 550, batch loss 0.2257, batch acc 0.9880
18:49:10.391   Training iter 600, batch loss 0.2306, batch acc 0.9872
18:49:10.392 Training @ 18 epoch...
18:49:10.499   Training iter 50, batch loss 0.2101, batch acc 0.9898
18:49:10.624   Training iter 100, batch loss 0.1709, batch acc 0.9912
18:49:10.746   Training iter 150, batch loss 0.1762, batch acc 0.9906
18:49:10.874   Training iter 200, batch loss 0.2187, batch acc 0.9878
18:49:11.038   Training iter 250, batch loss 0.2218, batch acc 0.9882
18:49:11.164   Training iter 300, batch loss 0.2227, batch acc 0.9878
18:49:11.298   Training iter 350, batch loss 0.1538, batch acc 0.9918
18:49:11.483   Training iter 400, batch loss 0.1931, batch acc 0.9898
18:49:11.645   Training iter 450, batch loss 0.2294, batch acc 0.9864
18:49:11.822   Training iter 500, batch loss 0.1918, batch acc 0.9898
18:49:12.001   Training iter 550, batch loss 0.1931, batch acc 0.9880
18:49:12.125   Training iter 600, batch loss 0.2059, batch acc 0.9886
18:49:12.126 Training @ 19 epoch...
18:49:12.254   Training iter 50, batch loss 0.1506, batch acc 0.9930
18:49:12.493   Training iter 100, batch loss 0.1535, batch acc 0.9914
18:49:12.724   Training iter 150, batch loss 0.1672, batch acc 0.9918
18:49:12.904   Training iter 200, batch loss 0.2223, batch acc 0.9890
18:49:13.041   Training iter 250, batch loss 0.1684, batch acc 0.9920
18:49:13.200   Training iter 300, batch loss 0.1620, batch acc 0.9904
18:49:13.354   Training iter 350, batch loss 0.1822, batch acc 0.9892
18:49:13.506   Training iter 400, batch loss 0.1887, batch acc 0.9892
18:49:13.690   Training iter 450, batch loss 0.1989, batch acc 0.9890
18:49:13.876   Training iter 500, batch loss 0.2177, batch acc 0.9874
18:49:14.010   Training iter 550, batch loss 0.1954, batch acc 0.9894
18:49:14.164   Training iter 600, batch loss 0.2184, batch acc 0.9884
18:49:14.164 Training @ 20 epoch...
18:49:14.329   Training iter 50, batch loss 0.1686, batch acc 0.9904
18:49:14.459   Training iter 100, batch loss 0.1578, batch acc 0.9922
18:49:14.598   Training iter 150, batch loss 0.1637, batch acc 0.9922
18:49:14.723   Training iter 200, batch loss 0.2012, batch acc 0.9894
18:49:14.845   Training iter 250, batch loss 0.1847, batch acc 0.9874
18:49:14.966   Training iter 300, batch loss 0.1849, batch acc 0.9918
18:49:15.096   Training iter 350, batch loss 0.2007, batch acc 0.9910
18:49:15.236   Training iter 400, batch loss 0.1467, batch acc 0.9920
18:49:15.367   Training iter 450, batch loss 0.2026, batch acc 0.9884
18:49:15.514   Training iter 500, batch loss 0.1950, batch acc 0.9886
18:49:15.691   Training iter 550, batch loss 0.1760, batch acc 0.9910
18:49:15.872   Training iter 600, batch loss 0.1923, batch acc 0.9890
18:49:15.873 Testing @ 20 epoch...
18:49:16.096     Testing, total mean loss 0.41765, total acc 0.97820
18:49:16.096 Training @ 21 epoch...
18:49:16.356   Training iter 50, batch loss 0.1584, batch acc 0.9910
18:49:16.548   Training iter 100, batch loss 0.1897, batch acc 0.9886
18:49:16.677   Training iter 150, batch loss 0.1628, batch acc 0.9918
18:49:16.812   Training iter 200, batch loss 0.1446, batch acc 0.9920
18:49:16.944   Training iter 250, batch loss 0.1580, batch acc 0.9908
18:49:17.077   Training iter 300, batch loss 0.1436, batch acc 0.9934
18:49:17.197   Training iter 350, batch loss 0.1481, batch acc 0.9922
18:49:17.315   Training iter 400, batch loss 0.1630, batch acc 0.9910
18:49:17.469   Training iter 450, batch loss 0.1785, batch acc 0.9910
18:49:17.670   Training iter 500, batch loss 0.1797, batch acc 0.9910
18:49:17.822   Training iter 550, batch loss 0.1965, batch acc 0.9898
18:49:17.972   Training iter 600, batch loss 0.1994, batch acc 0.9884
18:49:17.974 Training @ 22 epoch...
18:49:18.124   Training iter 50, batch loss 0.1667, batch acc 0.9916
18:49:18.261   Training iter 100, batch loss 0.1396, batch acc 0.9924
18:49:18.411   Training iter 150, batch loss 0.1598, batch acc 0.9924
18:49:18.585   Training iter 200, batch loss 0.1591, batch acc 0.9906
18:49:18.743   Training iter 250, batch loss 0.1437, batch acc 0.9926
18:49:18.898   Training iter 300, batch loss 0.1502, batch acc 0.9912
18:49:19.062   Training iter 350, batch loss 0.1311, batch acc 0.9934
18:49:19.208   Training iter 400, batch loss 0.1675, batch acc 0.9908
18:49:19.323   Training iter 450, batch loss 0.1879, batch acc 0.9898
18:49:19.445   Training iter 500, batch loss 0.2037, batch acc 0.9896
18:49:19.556   Training iter 550, batch loss 0.1649, batch acc 0.9904
18:49:19.684   Training iter 600, batch loss 0.2130, batch acc 0.9882
18:49:19.685 Training @ 23 epoch...
18:49:19.803   Training iter 50, batch loss 0.1054, batch acc 0.9954
18:49:19.933   Training iter 100, batch loss 0.1261, batch acc 0.9936
18:49:20.042   Training iter 150, batch loss 0.1695, batch acc 0.9902
18:49:20.149   Training iter 200, batch loss 0.1593, batch acc 0.9916
18:49:20.279   Training iter 250, batch loss 0.1669, batch acc 0.9910
18:49:20.376   Training iter 300, batch loss 0.1581, batch acc 0.9916
18:49:20.482   Training iter 350, batch loss 0.1939, batch acc 0.9902
18:49:20.594   Training iter 400, batch loss 0.1570, batch acc 0.9922
18:49:20.706   Training iter 450, batch loss 0.1927, batch acc 0.9906
18:49:20.831   Training iter 500, batch loss 0.1498, batch acc 0.9928
18:49:20.944   Training iter 550, batch loss 0.1705, batch acc 0.9922
18:49:21.097   Training iter 600, batch loss 0.1691, batch acc 0.9914
18:49:21.099 Training @ 24 epoch...
18:49:21.244   Training iter 50, batch loss 0.1448, batch acc 0.9936
18:49:21.395   Training iter 100, batch loss 0.1357, batch acc 0.9918
18:49:21.527   Training iter 150, batch loss 0.1696, batch acc 0.9920
18:49:21.665   Training iter 200, batch loss 0.1560, batch acc 0.9928
18:49:21.814   Training iter 250, batch loss 0.1304, batch acc 0.9942
18:49:22.041   Training iter 300, batch loss 0.1312, batch acc 0.9934
18:49:22.183   Training iter 350, batch loss 0.1827, batch acc 0.9894
18:49:22.300   Training iter 400, batch loss 0.1538, batch acc 0.9928
18:49:22.420   Training iter 450, batch loss 0.1271, batch acc 0.9934
18:49:22.546   Training iter 500, batch loss 0.1628, batch acc 0.9918
18:49:22.675   Training iter 550, batch loss 0.1506, batch acc 0.9926
18:49:23.141   Training iter 600, batch loss 0.1643, batch acc 0.9920
18:49:23.143 Training @ 25 epoch...
18:49:23.309   Training iter 50, batch loss 0.1331, batch acc 0.9926
18:49:23.464   Training iter 100, batch loss 0.1250, batch acc 0.9940
18:49:23.575   Training iter 150, batch loss 0.1553, batch acc 0.9914
18:49:23.708   Training iter 200, batch loss 0.1366, batch acc 0.9926
18:49:23.822   Training iter 250, batch loss 0.1172, batch acc 0.9948
18:49:23.938   Training iter 300, batch loss 0.1438, batch acc 0.9926
18:49:24.091   Training iter 350, batch loss 0.1351, batch acc 0.9934
18:49:24.241   Training iter 400, batch loss 0.1754, batch acc 0.9916
18:49:24.372   Training iter 450, batch loss 0.1764, batch acc 0.9912
18:49:24.521   Training iter 500, batch loss 0.1819, batch acc 0.9904
18:49:24.645   Training iter 550, batch loss 0.1704, batch acc 0.9924
18:49:24.771   Training iter 600, batch loss 0.1944, batch acc 0.9892
18:49:24.773 Testing @ 25 epoch...
18:49:24.883     Testing, total mean loss 0.47680, total acc 0.97670
18:49:24.883 Training @ 26 epoch...
18:49:25.051   Training iter 50, batch loss 0.1644, batch acc 0.9914
18:49:25.175   Training iter 100, batch loss 0.1079, batch acc 0.9952
18:49:25.283   Training iter 150, batch loss 0.1278, batch acc 0.9946
18:49:25.401   Training iter 200, batch loss 0.1480, batch acc 0.9908
18:49:25.509   Training iter 250, batch loss 0.1189, batch acc 0.9940
18:49:25.627   Training iter 300, batch loss 0.1681, batch acc 0.9906
18:49:25.749   Training iter 350, batch loss 0.1369, batch acc 0.9938
18:49:25.873   Training iter 400, batch loss 0.1471, batch acc 0.9932
18:49:26.001   Training iter 450, batch loss 0.1459, batch acc 0.9928
18:49:26.134   Training iter 500, batch loss 0.1623, batch acc 0.9916
18:49:26.248   Training iter 550, batch loss 0.1417, batch acc 0.9936
18:49:26.364   Training iter 600, batch loss 0.1694, batch acc 0.9924
18:49:26.364 Training @ 27 epoch...
18:49:26.493   Training iter 50, batch loss 0.1625, batch acc 0.9904
18:49:26.607   Training iter 100, batch loss 0.1226, batch acc 0.9942
18:49:26.737   Training iter 150, batch loss 0.1200, batch acc 0.9938
18:49:26.857   Training iter 200, batch loss 0.1287, batch acc 0.9932
18:49:26.981   Training iter 250, batch loss 0.1193, batch acc 0.9952
18:49:27.186   Training iter 300, batch loss 0.1840, batch acc 0.9906
18:49:27.344   Training iter 350, batch loss 0.1459, batch acc 0.9934
18:49:27.508   Training iter 400, batch loss 0.1334, batch acc 0.9940
18:49:27.675   Training iter 450, batch loss 0.1532, batch acc 0.9932
18:49:27.859   Training iter 500, batch loss 0.1612, batch acc 0.9914
18:49:27.980   Training iter 550, batch loss 0.1503, batch acc 0.9934
18:49:28.117   Training iter 600, batch loss 0.1692, batch acc 0.9912
18:49:28.117 Training @ 28 epoch...
18:49:28.254   Training iter 50, batch loss 0.1110, batch acc 0.9948
18:49:28.406   Training iter 100, batch loss 0.1110, batch acc 0.9944
18:49:28.542   Training iter 150, batch loss 0.1185, batch acc 0.9944
18:49:28.688   Training iter 200, batch loss 0.1358, batch acc 0.9944
18:49:28.806   Training iter 250, batch loss 0.1180, batch acc 0.9944
18:49:28.927   Training iter 300, batch loss 0.1691, batch acc 0.9912
18:49:29.085   Training iter 350, batch loss 0.1581, batch acc 0.9922
18:49:29.231   Training iter 400, batch loss 0.1175, batch acc 0.9940
18:49:29.357   Training iter 450, batch loss 0.1459, batch acc 0.9930
18:49:29.476   Training iter 500, batch loss 0.1568, batch acc 0.9918
18:49:29.590   Training iter 550, batch loss 0.1487, batch acc 0.9930
18:49:29.716   Training iter 600, batch loss 0.1815, batch acc 0.9900
18:49:29.716 Training @ 29 epoch...
18:49:29.859   Training iter 50, batch loss 0.1353, batch acc 0.9928
18:49:30.016   Training iter 100, batch loss 0.1340, batch acc 0.9942
18:49:30.190   Training iter 150, batch loss 0.1510, batch acc 0.9918
18:49:30.331   Training iter 200, batch loss 0.1142, batch acc 0.9942
18:49:30.478   Training iter 250, batch loss 0.1698, batch acc 0.9902
18:49:30.626   Training iter 300, batch loss 0.1477, batch acc 0.9926
18:49:30.776   Training iter 350, batch loss 0.1397, batch acc 0.9934
18:49:30.903   Training iter 400, batch loss 0.1184, batch acc 0.9946
18:49:31.029   Training iter 450, batch loss 0.1337, batch acc 0.9934
18:49:31.216   Training iter 500, batch loss 0.1498, batch acc 0.9938
18:49:31.410   Training iter 550, batch loss 0.1418, batch acc 0.9920
18:49:31.522   Training iter 600, batch loss 0.1792, batch acc 0.9914
18:49:31.523 Training @ 30 epoch...
18:49:31.618   Training iter 50, batch loss 0.1301, batch acc 0.9932
18:49:31.722   Training iter 100, batch loss 0.1204, batch acc 0.9938
18:49:31.835   Training iter 150, batch loss 0.1158, batch acc 0.9948
18:49:31.956   Training iter 200, batch loss 0.1224, batch acc 0.9932
18:49:32.088   Training iter 250, batch loss 0.1380, batch acc 0.9934
18:49:32.202   Training iter 300, batch loss 0.1263, batch acc 0.9938
18:49:32.321   Training iter 350, batch loss 0.1025, batch acc 0.9956
18:49:32.494   Training iter 400, batch loss 0.1686, batch acc 0.9914
18:49:32.613   Training iter 450, batch loss 0.1369, batch acc 0.9938
18:49:32.815   Training iter 500, batch loss 0.1419, batch acc 0.9928
18:49:32.966   Training iter 550, batch loss 0.1314, batch acc 0.9934
18:49:33.100   Training iter 600, batch loss 0.1546, batch acc 0.9930
18:49:33.102 Testing @ 30 epoch...
18:49:33.236     Testing, total mean loss 0.43011, total acc 0.97740
18:49:33.236 Training @ 31 epoch...
18:49:33.367   Training iter 50, batch loss 0.1162, batch acc 0.9950
18:49:33.521   Training iter 100, batch loss 0.1215, batch acc 0.9938
18:49:33.710   Training iter 150, batch loss 0.1182, batch acc 0.9948
18:49:33.895   Training iter 200, batch loss 0.1424, batch acc 0.9922
18:49:34.071   Training iter 250, batch loss 0.1136, batch acc 0.9946
18:49:34.201   Training iter 300, batch loss 0.1231, batch acc 0.9944
18:49:34.322   Training iter 350, batch loss 0.1092, batch acc 0.9946
18:49:34.443   Training iter 400, batch loss 0.1216, batch acc 0.9958
18:49:34.552   Training iter 450, batch loss 0.1307, batch acc 0.9936
18:49:34.657   Training iter 500, batch loss 0.1372, batch acc 0.9940
18:49:34.774   Training iter 550, batch loss 0.1506, batch acc 0.9922
18:49:34.905   Training iter 600, batch loss 0.1399, batch acc 0.9934
18:49:34.906 Training @ 32 epoch...
18:49:35.099   Training iter 50, batch loss 0.1133, batch acc 0.9948
18:49:35.243   Training iter 100, batch loss 0.1192, batch acc 0.9944
18:49:35.367   Training iter 150, batch loss 0.1113, batch acc 0.9954
18:49:35.493   Training iter 200, batch loss 0.1190, batch acc 0.9936
18:49:35.621   Training iter 250, batch loss 0.1212, batch acc 0.9940
18:49:35.758   Training iter 300, batch loss 0.1343, batch acc 0.9938
18:49:35.891   Training iter 350, batch loss 0.1306, batch acc 0.9960
18:49:36.046   Training iter 400, batch loss 0.1215, batch acc 0.9952
18:49:36.200   Training iter 450, batch loss 0.1352, batch acc 0.9934
18:49:36.345   Training iter 500, batch loss 0.1602, batch acc 0.9906
18:49:36.489   Training iter 550, batch loss 0.1207, batch acc 0.9958
18:49:36.646   Training iter 600, batch loss 0.1039, batch acc 0.9946
18:49:36.648 Training @ 33 epoch...
18:49:36.788   Training iter 50, batch loss 0.1235, batch acc 0.9934
18:49:36.899   Training iter 100, batch loss 0.1204, batch acc 0.9948
18:49:37.010   Training iter 150, batch loss 0.1119, batch acc 0.9946
18:49:37.140   Training iter 200, batch loss 0.1252, batch acc 0.9944
18:49:37.378   Training iter 250, batch loss 0.1127, batch acc 0.9944
18:49:37.497   Training iter 300, batch loss 0.1257, batch acc 0.9940
18:49:37.625   Training iter 350, batch loss 0.1058, batch acc 0.9956
18:49:37.800   Training iter 400, batch loss 0.1342, batch acc 0.9934
18:49:37.913   Training iter 450, batch loss 0.1187, batch acc 0.9948
18:49:38.040   Training iter 500, batch loss 0.1380, batch acc 0.9932
18:49:38.156   Training iter 550, batch loss 0.1337, batch acc 0.9936
18:49:38.270   Training iter 600, batch loss 0.1318, batch acc 0.9938
18:49:38.271 Training @ 34 epoch...
18:49:38.385   Training iter 50, batch loss 0.1009, batch acc 0.9964
18:49:38.517   Training iter 100, batch loss 0.1191, batch acc 0.9950
18:49:38.700   Training iter 150, batch loss 0.1357, batch acc 0.9934
18:49:38.862   Training iter 200, batch loss 0.1250, batch acc 0.9934
18:49:39.029   Training iter 250, batch loss 0.1229, batch acc 0.9946
18:49:39.200   Training iter 300, batch loss 0.1047, batch acc 0.9946
18:49:39.354   Training iter 350, batch loss 0.1397, batch acc 0.9928
18:49:39.510   Training iter 400, batch loss 0.1483, batch acc 0.9932
18:49:39.651   Training iter 450, batch loss 0.1046, batch acc 0.9964
18:49:39.779   Training iter 500, batch loss 0.1157, batch acc 0.9950
18:49:39.915   Training iter 550, batch loss 0.1374, batch acc 0.9946
18:49:40.051   Training iter 600, batch loss 0.1239, batch acc 0.9930
18:49:40.053 Training @ 35 epoch...
18:49:40.181   Training iter 50, batch loss 0.0950, batch acc 0.9960
18:49:40.315   Training iter 100, batch loss 0.1143, batch acc 0.9954
18:49:40.458   Training iter 150, batch loss 0.1017, batch acc 0.9964
18:49:40.575   Training iter 200, batch loss 0.1207, batch acc 0.9956
18:49:40.701   Training iter 250, batch loss 0.1398, batch acc 0.9942
18:49:40.832   Training iter 300, batch loss 0.1230, batch acc 0.9948
18:49:40.963   Training iter 350, batch loss 0.1404, batch acc 0.9936
18:49:41.090   Training iter 400, batch loss 0.1363, batch acc 0.9934
18:49:41.214   Training iter 450, batch loss 0.1375, batch acc 0.9928
18:49:41.324   Training iter 500, batch loss 0.1383, batch acc 0.9930
18:49:41.456   Training iter 550, batch loss 0.1390, batch acc 0.9922
18:49:41.618   Training iter 600, batch loss 0.1474, batch acc 0.9926
18:49:41.618 Testing @ 35 epoch...
18:49:41.741     Testing, total mean loss 0.38112, total acc 0.98010
18:49:41.741 Training @ 36 epoch...
18:49:41.896   Training iter 50, batch loss 0.0970, batch acc 0.9966
18:49:42.055   Training iter 100, batch loss 0.0880, batch acc 0.9962
18:49:42.220   Training iter 150, batch loss 0.0884, batch acc 0.9968
18:49:42.337   Training iter 200, batch loss 0.1298, batch acc 0.9956
18:49:42.444   Training iter 250, batch loss 0.1321, batch acc 0.9944
18:49:42.572   Training iter 300, batch loss 0.1018, batch acc 0.9954
18:49:42.693   Training iter 350, batch loss 0.1155, batch acc 0.9942
18:49:42.806   Training iter 400, batch loss 0.1398, batch acc 0.9944
18:49:42.981   Training iter 450, batch loss 0.1125, batch acc 0.9948
18:49:43.094   Training iter 500, batch loss 0.1115, batch acc 0.9936
18:49:43.221   Training iter 550, batch loss 0.1462, batch acc 0.9930
18:49:43.346   Training iter 600, batch loss 0.1359, batch acc 0.9932
18:49:43.348 Training @ 37 epoch...
18:49:43.464   Training iter 50, batch loss 0.1161, batch acc 0.9946
18:49:43.599   Training iter 100, batch loss 0.1083, batch acc 0.9958
18:49:43.724   Training iter 150, batch loss 0.0927, batch acc 0.9950
18:49:43.860   Training iter 200, batch loss 0.1208, batch acc 0.9946
18:49:44.040   Training iter 250, batch loss 0.1312, batch acc 0.9940
18:49:44.151   Training iter 300, batch loss 0.0914, batch acc 0.9956
18:49:44.292   Training iter 350, batch loss 0.1189, batch acc 0.9950
18:49:44.439   Training iter 400, batch loss 0.1242, batch acc 0.9940
18:49:44.591   Training iter 450, batch loss 0.1203, batch acc 0.9954
18:49:44.722   Training iter 500, batch loss 0.1537, batch acc 0.9938
18:49:44.866   Training iter 550, batch loss 0.1456, batch acc 0.9936
18:49:45.039   Training iter 600, batch loss 0.1200, batch acc 0.9948
18:49:45.040 Training @ 38 epoch...
18:49:45.174   Training iter 50, batch loss 0.0934, batch acc 0.9956
18:49:45.299   Training iter 100, batch loss 0.1092, batch acc 0.9942
18:49:45.424   Training iter 150, batch loss 0.1135, batch acc 0.9948
18:49:45.544   Training iter 200, batch loss 0.1224, batch acc 0.9938
18:49:45.665   Training iter 250, batch loss 0.1223, batch acc 0.9948
18:49:45.784   Training iter 300, batch loss 0.1045, batch acc 0.9948
18:49:45.913   Training iter 350, batch loss 0.1105, batch acc 0.9950
18:49:46.025   Training iter 400, batch loss 0.1502, batch acc 0.9932
18:49:46.142   Training iter 450, batch loss 0.1188, batch acc 0.9946
18:49:46.285   Training iter 500, batch loss 0.1318, batch acc 0.9942
18:49:46.417   Training iter 550, batch loss 0.1453, batch acc 0.9926
18:49:46.541   Training iter 600, batch loss 0.1660, batch acc 0.9916
18:49:46.541 Training @ 39 epoch...
18:49:46.667   Training iter 50, batch loss 0.1054, batch acc 0.9954
18:49:46.799   Training iter 100, batch loss 0.1243, batch acc 0.9950
18:49:46.964   Training iter 150, batch loss 0.1304, batch acc 0.9942
18:49:47.103   Training iter 200, batch loss 0.1346, batch acc 0.9948
18:49:47.252   Training iter 250, batch loss 0.1024, batch acc 0.9950
18:49:47.360   Training iter 300, batch loss 0.1247, batch acc 0.9944
18:49:47.466   Training iter 350, batch loss 0.1124, batch acc 0.9944
18:49:47.588   Training iter 400, batch loss 0.1018, batch acc 0.9952
18:49:47.712   Training iter 450, batch loss 0.1131, batch acc 0.9952
18:49:47.852   Training iter 500, batch loss 0.1169, batch acc 0.9942
18:49:47.965   Training iter 550, batch loss 0.1294, batch acc 0.9946
18:49:48.082   Training iter 600, batch loss 0.1107, batch acc 0.9962
18:49:48.083 Training @ 40 epoch...
18:49:48.202   Training iter 50, batch loss 0.1430, batch acc 0.9946
18:49:48.345   Training iter 100, batch loss 0.1042, batch acc 0.9970
18:49:48.460   Training iter 150, batch loss 0.0948, batch acc 0.9962
18:49:48.582   Training iter 200, batch loss 0.1266, batch acc 0.9948
18:49:48.700   Training iter 250, batch loss 0.1159, batch acc 0.9946
18:49:48.815   Training iter 300, batch loss 0.1088, batch acc 0.9956
18:49:48.923   Training iter 350, batch loss 0.0998, batch acc 0.9966
18:49:49.040   Training iter 400, batch loss 0.0987, batch acc 0.9958
18:49:49.168   Training iter 450, batch loss 0.1083, batch acc 0.9950
18:49:49.282   Training iter 500, batch loss 0.1058, batch acc 0.9968
18:49:49.390   Training iter 550, batch loss 0.1234, batch acc 0.9944
18:49:49.517   Training iter 600, batch loss 0.1205, batch acc 0.9940
18:49:49.518 Testing @ 40 epoch...
18:49:49.625     Testing, total mean loss 0.39735, total acc 0.97950
18:49:49.625 Training @ 41 epoch...
18:49:49.751   Training iter 50, batch loss 0.0843, batch acc 0.9962
18:49:49.901   Training iter 100, batch loss 0.0949, batch acc 0.9956
18:49:50.096   Training iter 150, batch loss 0.1053, batch acc 0.9948
18:49:50.261   Training iter 200, batch loss 0.1035, batch acc 0.9956
18:49:50.415   Training iter 250, batch loss 0.1010, batch acc 0.9944
18:49:50.581   Training iter 300, batch loss 0.0986, batch acc 0.9952
18:49:50.760   Training iter 350, batch loss 0.1077, batch acc 0.9956
18:49:50.883   Training iter 400, batch loss 0.1330, batch acc 0.9958
18:49:51.026   Training iter 450, batch loss 0.1088, batch acc 0.9948
18:49:51.160   Training iter 500, batch loss 0.1196, batch acc 0.9952
18:49:51.293   Training iter 550, batch loss 0.0933, batch acc 0.9952
18:49:51.428   Training iter 600, batch loss 0.1139, batch acc 0.9950
18:49:51.429 Training @ 42 epoch...
18:49:51.558   Training iter 50, batch loss 0.0848, batch acc 0.9968
18:49:51.692   Training iter 100, batch loss 0.0781, batch acc 0.9972
18:49:51.833   Training iter 150, batch loss 0.1039, batch acc 0.9966
18:49:51.974   Training iter 200, batch loss 0.1233, batch acc 0.9944
18:49:52.112   Training iter 250, batch loss 0.0946, batch acc 0.9964
18:49:52.245   Training iter 300, batch loss 0.1165, batch acc 0.9950
18:49:52.371   Training iter 350, batch loss 0.1246, batch acc 0.9944
18:49:52.511   Training iter 400, batch loss 0.1087, batch acc 0.9950
18:49:52.631   Training iter 450, batch loss 0.1144, batch acc 0.9940
18:49:52.768   Training iter 500, batch loss 0.1181, batch acc 0.9946
18:49:52.930   Training iter 550, batch loss 0.1155, batch acc 0.9950
18:49:53.090   Training iter 600, batch loss 0.1386, batch acc 0.9940
18:49:53.091 Training @ 43 epoch...
18:49:53.228   Training iter 50, batch loss 0.0976, batch acc 0.9968
18:49:53.427   Training iter 100, batch loss 0.1109, batch acc 0.9950
18:49:53.590   Training iter 150, batch loss 0.0903, batch acc 0.9960
18:49:53.752   Training iter 200, batch loss 0.0919, batch acc 0.9970
18:49:53.910   Training iter 250, batch loss 0.1084, batch acc 0.9960
18:49:54.049   Training iter 300, batch loss 0.0940, batch acc 0.9964
18:49:54.176   Training iter 350, batch loss 0.1093, batch acc 0.9956
18:49:54.294   Training iter 400, batch loss 0.1101, batch acc 0.9954
18:49:54.410   Training iter 450, batch loss 0.1043, batch acc 0.9950
18:49:54.580   Training iter 500, batch loss 0.1118, batch acc 0.9958
18:49:54.713   Training iter 550, batch loss 0.1451, batch acc 0.9932
18:49:54.830   Training iter 600, batch loss 0.1252, batch acc 0.9944
18:49:54.832 Training @ 44 epoch...
18:49:54.962   Training iter 50, batch loss 0.1001, batch acc 0.9952
18:49:55.081   Training iter 100, batch loss 0.0902, batch acc 0.9968
18:49:55.210   Training iter 150, batch loss 0.1025, batch acc 0.9970
18:49:55.326   Training iter 200, batch loss 0.1129, batch acc 0.9950
18:49:55.444   Training iter 250, batch loss 0.1034, batch acc 0.9958
18:49:55.570   Training iter 300, batch loss 0.1140, batch acc 0.9958
18:49:55.675   Training iter 350, batch loss 0.1167, batch acc 0.9948
18:49:55.817   Training iter 400, batch loss 0.1161, batch acc 0.9960
18:49:55.957   Training iter 450, batch loss 0.1471, batch acc 0.9938
18:49:56.112   Training iter 500, batch loss 0.1273, batch acc 0.9928
18:49:56.262   Training iter 550, batch loss 0.1017, batch acc 0.9960
18:49:56.407   Training iter 600, batch loss 0.1518, batch acc 0.9920
18:49:56.408 Training @ 45 epoch...
18:49:56.574   Training iter 50, batch loss 0.0947, batch acc 0.9964
18:49:56.691   Training iter 100, batch loss 0.1012, batch acc 0.9954
18:49:56.812   Training iter 150, batch loss 0.0994, batch acc 0.9970
18:49:56.950   Training iter 200, batch loss 0.1049, batch acc 0.9956
18:49:57.124   Training iter 250, batch loss 0.0892, batch acc 0.9966
18:49:57.229   Training iter 300, batch loss 0.1121, batch acc 0.9958
18:49:57.342   Training iter 350, batch loss 0.1130, batch acc 0.9948
18:49:57.460   Training iter 400, batch loss 0.1176, batch acc 0.9936
18:49:57.583   Training iter 450, batch loss 0.1323, batch acc 0.9940
18:49:57.719   Training iter 500, batch loss 0.1179, batch acc 0.9954
18:49:57.843   Training iter 550, batch loss 0.1159, batch acc 0.9952
18:49:57.975   Training iter 600, batch loss 0.1344, batch acc 0.9940
18:49:57.977 Testing @ 45 epoch...
18:49:58.076     Testing, total mean loss 0.39410, total acc 0.97980
18:49:58.076 Training @ 46 epoch...
18:49:58.191   Training iter 50, batch loss 0.1016, batch acc 0.9966
18:49:58.308   Training iter 100, batch loss 0.0948, batch acc 0.9958
18:49:58.418   Training iter 150, batch loss 0.0881, batch acc 0.9966
18:49:58.525   Training iter 200, batch loss 0.0934, batch acc 0.9960
18:49:58.662   Training iter 250, batch loss 0.1077, batch acc 0.9952
18:49:58.804   Training iter 300, batch loss 0.0935, batch acc 0.9964
18:49:58.946   Training iter 350, batch loss 0.1222, batch acc 0.9954
18:49:59.099   Training iter 400, batch loss 0.1025, batch acc 0.9948
18:49:59.243   Training iter 450, batch loss 0.1139, batch acc 0.9956
18:49:59.387   Training iter 500, batch loss 0.0994, batch acc 0.9962
18:49:59.494   Training iter 550, batch loss 0.1109, batch acc 0.9952
18:49:59.609   Training iter 600, batch loss 0.1174, batch acc 0.9944
18:49:59.610 Training @ 47 epoch...
18:49:59.731   Training iter 50, batch loss 0.0971, batch acc 0.9958
18:49:59.852   Training iter 100, batch loss 0.1013, batch acc 0.9956
18:49:59.977   Training iter 150, batch loss 0.0803, batch acc 0.9972
18:50:00.105   Training iter 200, batch loss 0.1447, batch acc 0.9936
18:50:00.214   Training iter 250, batch loss 0.1019, batch acc 0.9962
18:50:00.338   Training iter 300, batch loss 0.1068, batch acc 0.9956
18:50:00.459   Training iter 350, batch loss 0.1179, batch acc 0.9946
18:50:00.584   Training iter 400, batch loss 0.0968, batch acc 0.9968
18:50:00.704   Training iter 450, batch loss 0.1021, batch acc 0.9950
18:50:00.819   Training iter 500, batch loss 0.1223, batch acc 0.9942
18:50:00.926   Training iter 550, batch loss 0.1067, batch acc 0.9962
18:50:01.059   Training iter 600, batch loss 0.1063, batch acc 0.9948
18:50:01.060 Training @ 48 epoch...
18:50:01.190   Training iter 50, batch loss 0.0894, batch acc 0.9974
18:50:01.306   Training iter 100, batch loss 0.0777, batch acc 0.9972
18:50:01.498   Training iter 150, batch loss 0.1017, batch acc 0.9958
18:50:01.664   Training iter 200, batch loss 0.1054, batch acc 0.9958
18:50:01.848   Training iter 250, batch loss 0.1079, batch acc 0.9948
18:50:02.030   Training iter 300, batch loss 0.1101, batch acc 0.9960
18:50:02.223   Training iter 350, batch loss 0.1150, batch acc 0.9960
18:50:02.365   Training iter 400, batch loss 0.1099, batch acc 0.9952
18:50:02.530   Training iter 450, batch loss 0.1187, batch acc 0.9950
18:50:02.776   Training iter 500, batch loss 0.1119, batch acc 0.9942
18:50:02.962   Training iter 550, batch loss 0.1103, batch acc 0.9952
18:50:03.104   Training iter 600, batch loss 0.1462, batch acc 0.9944
18:50:03.107 Training @ 49 epoch...
18:50:03.240   Training iter 50, batch loss 0.0822, batch acc 0.9972
18:50:03.390   Training iter 100, batch loss 0.1036, batch acc 0.9960
18:50:03.528   Training iter 150, batch loss 0.1148, batch acc 0.9930
18:50:03.658   Training iter 200, batch loss 0.0890, batch acc 0.9966
18:50:03.799   Training iter 250, batch loss 0.1162, batch acc 0.9944
18:50:03.915   Training iter 300, batch loss 0.0949, batch acc 0.9972
18:50:04.101   Training iter 350, batch loss 0.0909, batch acc 0.9950
18:50:04.255   Training iter 400, batch loss 0.1057, batch acc 0.9954
18:50:04.421   Training iter 450, batch loss 0.0995, batch acc 0.9958
18:50:04.655   Training iter 500, batch loss 0.1094, batch acc 0.9960
18:50:04.819   Training iter 550, batch loss 0.1253, batch acc 0.9942
18:50:04.997   Training iter 600, batch loss 0.1030, batch acc 0.9952
18:50:04.997 Training @ 50 epoch...
18:50:05.168   Training iter 50, batch loss 0.0695, batch acc 0.9978
18:50:05.296   Training iter 100, batch loss 0.0914, batch acc 0.9966
18:50:05.412   Training iter 150, batch loss 0.0795, batch acc 0.9980
18:50:05.551   Training iter 200, batch loss 0.0932, batch acc 0.9966
18:50:05.663   Training iter 250, batch loss 0.0887, batch acc 0.9962
18:50:05.775   Training iter 300, batch loss 0.1150, batch acc 0.9940
18:50:05.909   Training iter 350, batch loss 0.0996, batch acc 0.9960
18:50:06.041   Training iter 400, batch loss 0.1268, batch acc 0.9948
18:50:06.169   Training iter 450, batch loss 0.1064, batch acc 0.9960
18:50:06.293   Training iter 500, batch loss 0.1190, batch acc 0.9950
18:50:06.404   Training iter 550, batch loss 0.1439, batch acc 0.9944
18:50:06.606   Training iter 600, batch loss 0.1021, batch acc 0.9962
18:50:06.607 Testing @ 50 epoch...
18:50:06.713     Testing, total mean loss 0.39113, total acc 0.97930
18:50:06.713 Training @ 51 epoch...
18:50:06.832   Training iter 50, batch loss 0.0861, batch acc 0.9962
18:50:07.033   Training iter 100, batch loss 0.1110, batch acc 0.9952
18:50:07.291   Training iter 150, batch loss 0.0992, batch acc 0.9968
18:50:07.416   Training iter 200, batch loss 0.1019, batch acc 0.9956
18:50:07.549   Training iter 250, batch loss 0.0924, batch acc 0.9970
18:50:07.750   Training iter 300, batch loss 0.0893, batch acc 0.9964
18:50:07.905   Training iter 350, batch loss 0.1127, batch acc 0.9964
18:50:08.065   Training iter 400, batch loss 0.1154, batch acc 0.9954
18:50:08.176   Training iter 450, batch loss 0.0999, batch acc 0.9968
18:50:08.392   Training iter 500, batch loss 0.1335, batch acc 0.9952
18:50:08.521   Training iter 550, batch loss 0.0815, batch acc 0.9970
18:50:08.638   Training iter 600, batch loss 0.0932, batch acc 0.9966
18:50:08.639 Training @ 52 epoch...
18:50:08.752   Training iter 50, batch loss 0.1084, batch acc 0.9966
18:50:08.876   Training iter 100, batch loss 0.1227, batch acc 0.9950
18:50:08.995   Training iter 150, batch loss 0.0989, batch acc 0.9964
18:50:09.106   Training iter 200, batch loss 0.0891, batch acc 0.9966
18:50:09.235   Training iter 250, batch loss 0.1024, batch acc 0.9966
18:50:09.356   Training iter 300, batch loss 0.0973, batch acc 0.9950
18:50:09.476   Training iter 350, batch loss 0.1292, batch acc 0.9944
18:50:09.595   Training iter 400, batch loss 0.1147, batch acc 0.9946
18:50:09.705   Training iter 450, batch loss 0.1167, batch acc 0.9962
18:50:09.831   Training iter 500, batch loss 0.1076, batch acc 0.9954
18:50:09.956   Training iter 550, batch loss 0.1521, batch acc 0.9936
18:50:10.117   Training iter 600, batch loss 0.1346, batch acc 0.9930
18:50:10.119 Training @ 53 epoch...
18:50:10.267   Training iter 50, batch loss 0.0906, batch acc 0.9970
18:50:10.407   Training iter 100, batch loss 0.0832, batch acc 0.9966
18:50:10.533   Training iter 150, batch loss 0.1176, batch acc 0.9950
18:50:10.652   Training iter 200, batch loss 0.0849, batch acc 0.9960
18:50:10.761   Training iter 250, batch loss 0.1083, batch acc 0.9954
18:50:10.888   Training iter 300, batch loss 0.0983, batch acc 0.9964
18:50:11.027   Training iter 350, batch loss 0.0770, batch acc 0.9964
18:50:11.130   Training iter 400, batch loss 0.1016, batch acc 0.9962
18:50:11.246   Training iter 450, batch loss 0.1142, batch acc 0.9968
18:50:11.363   Training iter 500, batch loss 0.1080, batch acc 0.9962
18:50:11.482   Training iter 550, batch loss 0.1080, batch acc 0.9952
18:50:11.615   Training iter 600, batch loss 0.1136, batch acc 0.9962
18:50:11.616 Training @ 54 epoch...
18:50:11.731   Training iter 50, batch loss 0.0895, batch acc 0.9968
18:50:11.880   Training iter 100, batch loss 0.0820, batch acc 0.9972
18:50:11.993   Training iter 150, batch loss 0.0782, batch acc 0.9968
18:50:12.101   Training iter 200, batch loss 0.0877, batch acc 0.9954
18:50:12.231   Training iter 250, batch loss 0.0719, batch acc 0.9970
18:50:12.344   Training iter 300, batch loss 0.1112, batch acc 0.9956
18:50:12.475   Training iter 350, batch loss 0.1041, batch acc 0.9960
18:50:12.590   Training iter 400, batch loss 0.1025, batch acc 0.9950
18:50:12.949   Training iter 450, batch loss 0.0765, batch acc 0.9966
18:50:13.127   Training iter 500, batch loss 0.0928, batch acc 0.9968
18:50:13.282   Training iter 550, batch loss 0.0998, batch acc 0.9958
18:50:13.433   Training iter 600, batch loss 0.1083, batch acc 0.9952
18:50:13.434 Training @ 55 epoch...
18:50:13.608   Training iter 50, batch loss 0.0854, batch acc 0.9968
18:50:13.766   Training iter 100, batch loss 0.0706, batch acc 0.9974
18:50:13.948   Training iter 150, batch loss 0.0901, batch acc 0.9964
18:50:14.088   Training iter 200, batch loss 0.0954, batch acc 0.9960
18:50:14.200   Training iter 250, batch loss 0.1125, batch acc 0.9948
18:50:14.318   Training iter 300, batch loss 0.1007, batch acc 0.9970
18:50:14.514   Training iter 350, batch loss 0.0862, batch acc 0.9970
18:50:14.655   Training iter 400, batch loss 0.0992, batch acc 0.9956
18:50:14.791   Training iter 450, batch loss 0.0971, batch acc 0.9972
18:50:14.905   Training iter 500, batch loss 0.1039, batch acc 0.9960
18:50:15.037   Training iter 550, batch loss 0.0956, batch acc 0.9972
18:50:15.163   Training iter 600, batch loss 0.1244, batch acc 0.9948
18:50:15.165 Testing @ 55 epoch...
18:50:15.265     Testing, total mean loss 0.38645, total acc 0.98020
18:50:15.265 Training @ 56 epoch...
18:50:15.482   Training iter 50, batch loss 0.0769, batch acc 0.9976
18:50:15.682   Training iter 100, batch loss 0.0812, batch acc 0.9972
18:50:15.913   Training iter 150, batch loss 0.0870, batch acc 0.9966
18:50:16.061   Training iter 200, batch loss 0.0702, batch acc 0.9978
18:50:16.194   Training iter 250, batch loss 0.0749, batch acc 0.9980
18:50:16.338   Training iter 300, batch loss 0.0797, batch acc 0.9966
18:50:16.477   Training iter 350, batch loss 0.0988, batch acc 0.9974
18:50:16.626   Training iter 400, batch loss 0.0906, batch acc 0.9960
18:50:16.793   Training iter 450, batch loss 0.1000, batch acc 0.9958
18:50:16.983   Training iter 500, batch loss 0.1191, batch acc 0.9960
18:50:17.168   Training iter 550, batch loss 0.1334, batch acc 0.9934
18:50:17.275   Training iter 600, batch loss 0.1259, batch acc 0.9942
18:50:17.277 Training @ 57 epoch...
18:50:17.389   Training iter 50, batch loss 0.1165, batch acc 0.9968
18:50:17.503   Training iter 100, batch loss 0.0979, batch acc 0.9962
18:50:17.701   Training iter 150, batch loss 0.0992, batch acc 0.9958
18:50:17.890   Training iter 200, batch loss 0.0964, batch acc 0.9954
18:50:18.002   Training iter 250, batch loss 0.0951, batch acc 0.9974
18:50:18.379   Training iter 300, batch loss 0.0895, batch acc 0.9966
18:50:18.572   Training iter 350, batch loss 0.0843, batch acc 0.9972
18:50:18.850   Training iter 400, batch loss 0.1024, batch acc 0.9962
18:50:19.060   Training iter 450, batch loss 0.0879, batch acc 0.9970
18:50:19.244   Training iter 500, batch loss 0.0947, batch acc 0.9956
18:50:19.428   Training iter 550, batch loss 0.1070, batch acc 0.9962
18:50:19.591   Training iter 600, batch loss 0.1309, batch acc 0.9952
18:50:19.593 Training @ 58 epoch...
18:50:19.785   Training iter 50, batch loss 0.1007, batch acc 0.9964
18:50:19.946   Training iter 100, batch loss 0.1190, batch acc 0.9940
18:50:20.079   Training iter 150, batch loss 0.0970, batch acc 0.9964
18:50:20.306   Training iter 200, batch loss 0.0709, batch acc 0.9980
18:50:20.589   Training iter 250, batch loss 0.0910, batch acc 0.9964
18:50:20.777   Training iter 300, batch loss 0.0977, batch acc 0.9960
18:50:20.898   Training iter 350, batch loss 0.1039, batch acc 0.9958
18:50:21.031   Training iter 400, batch loss 0.1037, batch acc 0.9960
18:50:21.158   Training iter 450, batch loss 0.1017, batch acc 0.9966
18:50:21.288   Training iter 500, batch loss 0.1065, batch acc 0.9962
18:50:21.462   Training iter 550, batch loss 0.0870, batch acc 0.9976
18:50:21.607   Training iter 600, batch loss 0.1021, batch acc 0.9968
18:50:21.608 Training @ 59 epoch...
18:50:21.717   Training iter 50, batch loss 0.0961, batch acc 0.9968
18:50:21.855   Training iter 100, batch loss 0.0950, batch acc 0.9956
18:50:22.014   Training iter 150, batch loss 0.0902, batch acc 0.9962
18:50:22.147   Training iter 200, batch loss 0.0858, batch acc 0.9966
18:50:22.291   Training iter 250, batch loss 0.0824, batch acc 0.9978
18:50:22.389   Training iter 300, batch loss 0.1033, batch acc 0.9964
18:50:22.546   Training iter 350, batch loss 0.0770, batch acc 0.9978
18:50:22.714   Training iter 400, batch loss 0.0893, batch acc 0.9962
18:50:22.910   Training iter 450, batch loss 0.1212, batch acc 0.9946
18:50:23.031   Training iter 500, batch loss 0.0722, batch acc 0.9976
18:50:23.178   Training iter 550, batch loss 0.1023, batch acc 0.9950
18:50:23.308   Training iter 600, batch loss 0.0940, batch acc 0.9974
18:50:23.308 Training @ 60 epoch...
18:50:23.424   Training iter 50, batch loss 0.0687, batch acc 0.9978
18:50:23.564   Training iter 100, batch loss 0.0707, batch acc 0.9966
18:50:23.692   Training iter 150, batch loss 0.0815, batch acc 0.9974
18:50:23.822   Training iter 200, batch loss 0.0793, batch acc 0.9984
18:50:23.973   Training iter 250, batch loss 0.0908, batch acc 0.9958
18:50:24.093   Training iter 300, batch loss 0.0801, batch acc 0.9976
18:50:24.264   Training iter 350, batch loss 0.0995, batch acc 0.9960
18:50:24.455   Training iter 400, batch loss 0.1022, batch acc 0.9962
18:50:24.600   Training iter 450, batch loss 0.0934, batch acc 0.9970
18:50:24.746   Training iter 500, batch loss 0.1078, batch acc 0.9950
18:50:24.939   Training iter 550, batch loss 0.1046, batch acc 0.9950
18:50:25.111   Training iter 600, batch loss 0.0966, batch acc 0.9962
18:50:25.111 Testing @ 60 epoch...
18:50:25.261     Testing, total mean loss 0.36349, total acc 0.98250
18:50:25.261 Training @ 61 epoch...
18:50:25.402   Training iter 50, batch loss 0.0621, batch acc 0.9976
18:50:25.587   Training iter 100, batch loss 0.0777, batch acc 0.9980
18:50:25.810   Training iter 150, batch loss 0.0869, batch acc 0.9970
18:50:25.945   Training iter 200, batch loss 0.1041, batch acc 0.9954
18:50:26.076   Training iter 250, batch loss 0.0855, batch acc 0.9966
18:50:26.198   Training iter 300, batch loss 0.0957, batch acc 0.9962
18:50:26.332   Training iter 350, batch loss 0.0959, batch acc 0.9950
18:50:26.474   Training iter 400, batch loss 0.0867, batch acc 0.9960
18:50:26.601   Training iter 450, batch loss 0.0990, batch acc 0.9974
18:50:26.719   Training iter 500, batch loss 0.0776, batch acc 0.9976
18:50:26.862   Training iter 550, batch loss 0.1210, batch acc 0.9952
18:50:26.989   Training iter 600, batch loss 0.0989, batch acc 0.9956
18:50:26.991 Training @ 62 epoch...
18:50:27.122   Training iter 50, batch loss 0.0889, batch acc 0.9970
18:50:27.274   Training iter 100, batch loss 0.0687, batch acc 0.9978
18:50:27.446   Training iter 150, batch loss 0.0932, batch acc 0.9950
18:50:27.596   Training iter 200, batch loss 0.0900, batch acc 0.9960
18:50:27.742   Training iter 250, batch loss 0.0976, batch acc 0.9960
18:50:27.896   Training iter 300, batch loss 0.0974, batch acc 0.9970
18:50:28.167   Training iter 350, batch loss 0.0834, batch acc 0.9974
18:50:28.321   Training iter 400, batch loss 0.1003, batch acc 0.9968
18:50:28.463   Training iter 450, batch loss 0.1071, batch acc 0.9968
18:50:28.624   Training iter 500, batch loss 0.1277, batch acc 0.9952
18:50:28.755   Training iter 550, batch loss 0.0951, batch acc 0.9974
18:50:28.884   Training iter 600, batch loss 0.1292, batch acc 0.9952
18:50:28.886 Training @ 63 epoch...
18:50:29.019   Training iter 50, batch loss 0.1078, batch acc 0.9956
18:50:29.136   Training iter 100, batch loss 0.0674, batch acc 0.9980
18:50:29.258   Training iter 150, batch loss 0.0828, batch acc 0.9964
18:50:29.419   Training iter 200, batch loss 0.0987, batch acc 0.9970
18:50:29.551   Training iter 250, batch loss 0.0698, batch acc 0.9982
18:50:29.663   Training iter 300, batch loss 0.1175, batch acc 0.9954
18:50:29.777   Training iter 350, batch loss 0.0868, batch acc 0.9964
18:50:29.899   Training iter 400, batch loss 0.1172, batch acc 0.9954
18:50:30.007   Training iter 450, batch loss 0.1056, batch acc 0.9948
18:50:30.128   Training iter 500, batch loss 0.1414, batch acc 0.9954
18:50:30.252   Training iter 550, batch loss 0.0875, batch acc 0.9968
18:50:30.369   Training iter 600, batch loss 0.0907, batch acc 0.9968
18:50:30.369 Training @ 64 epoch...
18:50:30.498   Training iter 50, batch loss 0.0843, batch acc 0.9976
18:50:30.632   Training iter 100, batch loss 0.0816, batch acc 0.9974
18:50:30.781   Training iter 150, batch loss 0.0979, batch acc 0.9964
18:50:30.916   Training iter 200, batch loss 0.0937, batch acc 0.9962
18:50:31.065   Training iter 250, batch loss 0.1049, batch acc 0.9958
18:50:31.219   Training iter 300, batch loss 0.1027, batch acc 0.9956
18:50:31.390   Training iter 350, batch loss 0.1136, batch acc 0.9964
18:50:31.516   Training iter 400, batch loss 0.1125, batch acc 0.9958
18:50:31.631   Training iter 450, batch loss 0.0859, batch acc 0.9960
18:50:31.748   Training iter 500, batch loss 0.0872, batch acc 0.9964
18:50:31.874   Training iter 550, batch loss 0.1336, batch acc 0.9952
18:50:31.993   Training iter 600, batch loss 0.1036, batch acc 0.9962
18:50:31.995 Training @ 65 epoch...
18:50:32.125   Training iter 50, batch loss 0.1007, batch acc 0.9958
18:50:32.238   Training iter 100, batch loss 0.0716, batch acc 0.9970
18:50:32.358   Training iter 150, batch loss 0.0724, batch acc 0.9976
18:50:32.480   Training iter 200, batch loss 0.0837, batch acc 0.9972
18:50:32.638   Training iter 250, batch loss 0.0799, batch acc 0.9974
18:50:32.776   Training iter 300, batch loss 0.0911, batch acc 0.9964
18:50:32.909   Training iter 350, batch loss 0.0813, batch acc 0.9978
18:50:33.027   Training iter 400, batch loss 0.0872, batch acc 0.9970
18:50:33.142   Training iter 450, batch loss 0.1233, batch acc 0.9952
18:50:33.258   Training iter 500, batch loss 0.1280, batch acc 0.9950
18:50:33.408   Training iter 550, batch loss 0.0995, batch acc 0.9960
18:50:33.551   Training iter 600, batch loss 0.1015, batch acc 0.9972
18:50:33.552 Testing @ 65 epoch...
18:50:33.679     Testing, total mean loss 0.38143, total acc 0.98000
18:50:33.679 Training @ 66 epoch...
18:50:33.824   Training iter 50, batch loss 0.0835, batch acc 0.9976
18:50:33.966   Training iter 100, batch loss 0.0791, batch acc 0.9970
18:50:34.101   Training iter 150, batch loss 0.0856, batch acc 0.9966
18:50:34.265   Training iter 200, batch loss 0.0870, batch acc 0.9972
18:50:34.385   Training iter 250, batch loss 0.0871, batch acc 0.9972
18:50:34.508   Training iter 300, batch loss 0.0811, batch acc 0.9980
18:50:34.632   Training iter 350, batch loss 0.1220, batch acc 0.9944
18:50:34.746   Training iter 400, batch loss 0.1071, batch acc 0.9966
18:50:34.873   Training iter 450, batch loss 0.0980, batch acc 0.9970
18:50:35.013   Training iter 500, batch loss 0.0829, batch acc 0.9978
18:50:35.126   Training iter 550, batch loss 0.1098, batch acc 0.9964
18:50:35.232   Training iter 600, batch loss 0.1034, batch acc 0.9966
18:50:35.233 Training @ 67 epoch...
18:50:35.451   Training iter 50, batch loss 0.0687, batch acc 0.9972
18:50:35.575   Training iter 100, batch loss 0.0978, batch acc 0.9958
18:50:35.684   Training iter 150, batch loss 0.0871, batch acc 0.9964
18:50:35.856   Training iter 200, batch loss 0.0753, batch acc 0.9974
18:50:35.994   Training iter 250, batch loss 0.0883, batch acc 0.9968
18:50:36.119   Training iter 300, batch loss 0.0969, batch acc 0.9964
18:50:36.267   Training iter 350, batch loss 0.0799, batch acc 0.9962
18:50:36.484   Training iter 400, batch loss 0.1113, batch acc 0.9960
18:50:36.663   Training iter 450, batch loss 0.0793, batch acc 0.9966
18:50:36.828   Training iter 500, batch loss 0.0960, batch acc 0.9962
18:50:37.011   Training iter 550, batch loss 0.0918, batch acc 0.9972
18:50:37.368   Training iter 600, batch loss 0.0980, batch acc 0.9978
18:50:37.369 Training @ 68 epoch...
18:50:37.527   Training iter 50, batch loss 0.0799, batch acc 0.9966
18:50:37.662   Training iter 100, batch loss 0.0867, batch acc 0.9976
18:50:37.862   Training iter 150, batch loss 0.1256, batch acc 0.9934
18:50:38.000   Training iter 200, batch loss 0.1166, batch acc 0.9954
18:50:38.126   Training iter 250, batch loss 0.1014, batch acc 0.9966
18:50:38.265   Training iter 300, batch loss 0.1016, batch acc 0.9968
18:50:38.410   Training iter 350, batch loss 0.0879, batch acc 0.9958
18:50:38.538   Training iter 400, batch loss 0.1172, batch acc 0.9952
18:50:38.648   Training iter 450, batch loss 0.1043, batch acc 0.9962
18:50:38.801   Training iter 500, batch loss 0.0693, batch acc 0.9974
18:50:38.932   Training iter 550, batch loss 0.0805, batch acc 0.9976
18:50:39.059   Training iter 600, batch loss 0.0754, batch acc 0.9968
18:50:39.059 Training @ 69 epoch...
18:50:39.206   Training iter 50, batch loss 0.0881, batch acc 0.9966
18:50:39.357   Training iter 100, batch loss 0.1207, batch acc 0.9958
18:50:39.494   Training iter 150, batch loss 0.0977, batch acc 0.9962
18:50:39.634   Training iter 200, batch loss 0.0994, batch acc 0.9964
18:50:39.777   Training iter 250, batch loss 0.0747, batch acc 0.9986
18:50:39.926   Training iter 300, batch loss 0.0866, batch acc 0.9976
18:50:40.077   Training iter 350, batch loss 0.0869, batch acc 0.9964
18:50:40.194   Training iter 400, batch loss 0.1023, batch acc 0.9964
18:50:40.313   Training iter 450, batch loss 0.0929, batch acc 0.9962
18:50:40.426   Training iter 500, batch loss 0.1000, batch acc 0.9968
18:50:40.550   Training iter 550, batch loss 0.1020, batch acc 0.9964
18:50:40.769   Training iter 600, batch loss 0.0863, batch acc 0.9962
18:50:40.772 Training @ 70 epoch...
18:50:40.908   Training iter 50, batch loss 0.0843, batch acc 0.9966
18:50:41.033   Training iter 100, batch loss 0.0662, batch acc 0.9980
18:50:41.148   Training iter 150, batch loss 0.0692, batch acc 0.9980
18:50:41.251   Training iter 200, batch loss 0.0767, batch acc 0.9974
18:50:41.373   Training iter 250, batch loss 0.0989, batch acc 0.9954
18:50:41.494   Training iter 300, batch loss 0.0819, batch acc 0.9984
18:50:41.615   Training iter 350, batch loss 0.0899, batch acc 0.9970
18:50:41.746   Training iter 400, batch loss 0.1133, batch acc 0.9950
18:50:41.869   Training iter 450, batch loss 0.0931, batch acc 0.9962
18:50:42.008   Training iter 500, batch loss 0.1003, batch acc 0.9966
18:50:42.177   Training iter 550, batch loss 0.0799, batch acc 0.9970
18:50:42.361   Training iter 600, batch loss 0.1087, batch acc 0.9962
18:50:42.362 Testing @ 70 epoch...
18:50:42.525     Testing, total mean loss 0.38455, total acc 0.98100
18:50:42.525 Training @ 71 epoch...
18:50:42.695   Training iter 50, batch loss 0.0741, batch acc 0.9974
18:50:42.831   Training iter 100, batch loss 0.0760, batch acc 0.9968
18:50:42.992   Training iter 150, batch loss 0.0754, batch acc 0.9986
18:50:43.127   Training iter 200, batch loss 0.0730, batch acc 0.9976
18:50:43.263   Training iter 250, batch loss 0.0820, batch acc 0.9972
18:50:43.392   Training iter 300, batch loss 0.0818, batch acc 0.9966
18:50:43.508   Training iter 350, batch loss 0.0856, batch acc 0.9972
18:50:43.638   Training iter 400, batch loss 0.1101, batch acc 0.9956
18:50:43.768   Training iter 450, batch loss 0.0916, batch acc 0.9964
18:50:43.888   Training iter 500, batch loss 0.0868, batch acc 0.9962
18:50:44.015   Training iter 550, batch loss 0.0911, batch acc 0.9970
18:50:44.132   Training iter 600, batch loss 0.0989, batch acc 0.9962
18:50:44.133 Training @ 72 epoch...
18:50:44.258   Training iter 50, batch loss 0.0585, batch acc 0.9976
18:50:44.382   Training iter 100, batch loss 0.0797, batch acc 0.9970
18:50:44.506   Training iter 150, batch loss 0.0882, batch acc 0.9972
18:50:44.648   Training iter 200, batch loss 0.0720, batch acc 0.9976
18:50:44.765   Training iter 250, batch loss 0.0756, batch acc 0.9970
18:50:44.884   Training iter 300, batch loss 0.0789, batch acc 0.9982
18:50:45.022   Training iter 350, batch loss 0.1078, batch acc 0.9956
18:50:45.164   Training iter 400, batch loss 0.1251, batch acc 0.9956
18:50:45.299   Training iter 450, batch loss 0.0923, batch acc 0.9970
18:50:45.443   Training iter 500, batch loss 0.1071, batch acc 0.9958
18:50:45.591   Training iter 550, batch loss 0.1138, batch acc 0.9958
18:50:45.789   Training iter 600, batch loss 0.1054, batch acc 0.9970
18:50:45.790 Training @ 73 epoch...
18:50:45.940   Training iter 50, batch loss 0.0903, batch acc 0.9974
18:50:46.063   Training iter 100, batch loss 0.0912, batch acc 0.9970
18:50:46.181   Training iter 150, batch loss 0.1048, batch acc 0.9966
18:50:46.302   Training iter 200, batch loss 0.0811, batch acc 0.9968
18:50:46.416   Training iter 250, batch loss 0.0952, batch acc 0.9970
18:50:46.549   Training iter 300, batch loss 0.0839, batch acc 0.9978
18:50:46.660   Training iter 350, batch loss 0.0953, batch acc 0.9958
18:50:46.859   Training iter 400, batch loss 0.0668, batch acc 0.9986
18:50:47.005   Training iter 450, batch loss 0.1024, batch acc 0.9958
18:50:47.118   Training iter 500, batch loss 0.1011, batch acc 0.9958
18:50:47.280   Training iter 550, batch loss 0.0850, batch acc 0.9980
18:50:47.441   Training iter 600, batch loss 0.0808, batch acc 0.9964
18:50:47.442 Training @ 74 epoch...
18:50:47.566   Training iter 50, batch loss 0.0828, batch acc 0.9976
18:50:47.712   Training iter 100, batch loss 0.0976, batch acc 0.9958
18:50:47.863   Training iter 150, batch loss 0.0848, batch acc 0.9972
18:50:48.036   Training iter 200, batch loss 0.0727, batch acc 0.9972
18:50:48.197   Training iter 250, batch loss 0.0750, batch acc 0.9986
18:50:48.351   Training iter 300, batch loss 0.0780, batch acc 0.9978
18:50:48.518   Training iter 350, batch loss 0.0944, batch acc 0.9962
18:50:48.693   Training iter 400, batch loss 0.0902, batch acc 0.9972
18:50:48.825   Training iter 450, batch loss 0.1029, batch acc 0.9958
18:50:48.941   Training iter 500, batch loss 0.1131, batch acc 0.9962
18:50:49.078   Training iter 550, batch loss 0.0898, batch acc 0.9972
18:50:49.215   Training iter 600, batch loss 0.0868, batch acc 0.9968
18:50:49.218 Training @ 75 epoch...
18:50:49.357   Training iter 50, batch loss 0.0696, batch acc 0.9978
18:50:49.482   Training iter 100, batch loss 0.0617, batch acc 0.9982
18:50:49.612   Training iter 150, batch loss 0.0680, batch acc 0.9980
18:50:49.756   Training iter 200, batch loss 0.1025, batch acc 0.9974
18:50:49.883   Training iter 250, batch loss 0.0865, batch acc 0.9970
18:50:50.008   Training iter 300, batch loss 0.1113, batch acc 0.9972
18:50:50.115   Training iter 350, batch loss 0.1009, batch acc 0.9968
18:50:50.275   Training iter 400, batch loss 0.0940, batch acc 0.9970
18:50:50.397   Training iter 450, batch loss 0.1027, batch acc 0.9950
18:50:50.510   Training iter 500, batch loss 0.1015, batch acc 0.9958
18:50:50.628   Training iter 550, batch loss 0.0922, batch acc 0.9970
18:50:50.758   Training iter 600, batch loss 0.0989, batch acc 0.9968
18:50:50.759 Testing @ 75 epoch...
18:50:50.863     Testing, total mean loss 0.37361, total acc 0.98140
18:50:50.863 Training @ 76 epoch...
18:50:51.015   Training iter 50, batch loss 0.0833, batch acc 0.9964
18:50:51.167   Training iter 100, batch loss 0.0836, batch acc 0.9970
18:50:51.316   Training iter 150, batch loss 0.0669, batch acc 0.9986
18:50:51.441   Training iter 200, batch loss 0.1036, batch acc 0.9956
18:50:51.564   Training iter 250, batch loss 0.0891, batch acc 0.9972
18:50:51.713   Training iter 300, batch loss 0.1169, batch acc 0.9950
18:50:51.852   Training iter 350, batch loss 0.0954, batch acc 0.9962
18:50:51.977   Training iter 400, batch loss 0.0922, batch acc 0.9962
18:50:52.092   Training iter 450, batch loss 0.0937, batch acc 0.9958
18:50:52.228   Training iter 500, batch loss 0.0946, batch acc 0.9956
18:50:52.402   Training iter 550, batch loss 0.0834, batch acc 0.9976
18:50:52.603   Training iter 600, batch loss 0.0874, batch acc 0.9966
18:50:52.603 Training @ 77 epoch...
18:50:52.795   Training iter 50, batch loss 0.0758, batch acc 0.9976
18:50:52.977   Training iter 100, batch loss 0.0595, batch acc 0.9988
18:50:53.177   Training iter 150, batch loss 0.0496, batch acc 0.9988
18:50:53.301   Training iter 200, batch loss 0.0617, batch acc 0.9980
18:50:53.416   Training iter 250, batch loss 0.0848, batch acc 0.9966
18:50:53.544   Training iter 300, batch loss 0.0940, batch acc 0.9968
18:50:53.656   Training iter 350, batch loss 0.0833, batch acc 0.9972
18:50:53.826   Training iter 400, batch loss 0.1044, batch acc 0.9956
18:50:53.965   Training iter 450, batch loss 0.1158, batch acc 0.9954
18:50:54.116   Training iter 500, batch loss 0.0786, batch acc 0.9974
18:50:54.254   Training iter 550, batch loss 0.0890, batch acc 0.9968
18:50:54.377   Training iter 600, batch loss 0.1518, batch acc 0.9942
18:50:54.378 Training @ 78 epoch...
18:50:54.537   Training iter 50, batch loss 0.0719, batch acc 0.9984
18:50:54.648   Training iter 100, batch loss 0.0857, batch acc 0.9964
18:50:54.756   Training iter 150, batch loss 0.0871, batch acc 0.9964
18:50:54.877   Training iter 200, batch loss 0.1008, batch acc 0.9960
18:50:55.011   Training iter 250, batch loss 0.0801, batch acc 0.9972
18:50:55.127   Training iter 300, batch loss 0.0855, batch acc 0.9968
18:50:55.248   Training iter 350, batch loss 0.0709, batch acc 0.9980
18:50:55.355   Training iter 400, batch loss 0.0953, batch acc 0.9962
18:50:55.467   Training iter 450, batch loss 0.0970, batch acc 0.9970
18:50:55.570   Training iter 500, batch loss 0.0778, batch acc 0.9978
18:50:55.661   Training iter 550, batch loss 0.0881, batch acc 0.9970
18:50:55.772   Training iter 600, batch loss 0.1154, batch acc 0.9970
18:50:55.773 Training @ 79 epoch...
18:50:55.889   Training iter 50, batch loss 0.0952, batch acc 0.9966
18:50:56.012   Training iter 100, batch loss 0.0999, batch acc 0.9966
18:50:56.128   Training iter 150, batch loss 0.0724, batch acc 0.9970
18:50:56.261   Training iter 200, batch loss 0.0840, batch acc 0.9970
18:50:56.426   Training iter 250, batch loss 0.0742, batch acc 0.9980
18:50:56.549   Training iter 300, batch loss 0.1005, batch acc 0.9958
18:50:56.697   Training iter 350, batch loss 0.0755, batch acc 0.9970
18:50:56.851   Training iter 400, batch loss 0.0830, batch acc 0.9972
18:50:57.003   Training iter 450, batch loss 0.0930, batch acc 0.9960
18:50:57.158   Training iter 500, batch loss 0.0868, batch acc 0.9976
18:50:57.351   Training iter 550, batch loss 0.0757, batch acc 0.9972
18:50:57.494   Training iter 600, batch loss 0.0985, batch acc 0.9960
18:50:57.495 Training @ 80 epoch...
18:50:57.657   Training iter 50, batch loss 0.0889, batch acc 0.9974
18:50:57.789   Training iter 100, batch loss 0.0616, batch acc 0.9982
18:50:57.914   Training iter 150, batch loss 0.0771, batch acc 0.9970
18:50:58.034   Training iter 200, batch loss 0.0972, batch acc 0.9960
18:50:58.151   Training iter 250, batch loss 0.0843, batch acc 0.9970
18:50:58.279   Training iter 300, batch loss 0.0742, batch acc 0.9972
18:50:58.398   Training iter 350, batch loss 0.0792, batch acc 0.9974
18:50:58.507   Training iter 400, batch loss 0.0954, batch acc 0.9976
18:50:58.663   Training iter 450, batch loss 0.0816, batch acc 0.9976
18:50:58.784   Training iter 500, batch loss 0.0925, batch acc 0.9970
18:50:58.924   Training iter 550, batch loss 0.1016, batch acc 0.9960
18:50:59.066   Training iter 600, batch loss 0.0895, batch acc 0.9972
18:50:59.067 Testing @ 80 epoch...
18:50:59.186     Testing, total mean loss 0.37795, total acc 0.98250
18:50:59.186 Training @ 81 epoch...
18:50:59.319   Training iter 50, batch loss 0.0869, batch acc 0.9970
18:50:59.548   Training iter 100, batch loss 0.1175, batch acc 0.9960
18:50:59.725   Training iter 150, batch loss 0.0708, batch acc 0.9980
18:50:59.879   Training iter 200, batch loss 0.0708, batch acc 0.9974
18:51:00.053   Training iter 250, batch loss 0.0789, batch acc 0.9978
18:51:00.244   Training iter 300, batch loss 0.0802, batch acc 0.9972
18:51:00.376   Training iter 350, batch loss 0.0787, batch acc 0.9976
18:51:00.495   Training iter 400, batch loss 0.0755, batch acc 0.9982
18:51:00.627   Training iter 450, batch loss 0.0825, batch acc 0.9958
18:51:00.754   Training iter 500, batch loss 0.0844, batch acc 0.9966
18:51:00.871   Training iter 550, batch loss 0.0781, batch acc 0.9972
18:51:00.985   Training iter 600, batch loss 0.0965, batch acc 0.9966
18:51:00.988 Training @ 82 epoch...
18:51:01.126   Training iter 50, batch loss 0.0791, batch acc 0.9970
18:51:01.264   Training iter 100, batch loss 0.0875, batch acc 0.9976
18:51:01.392   Training iter 150, batch loss 0.0993, batch acc 0.9964
18:51:01.507   Training iter 200, batch loss 0.0822, batch acc 0.9972
18:51:01.652   Training iter 250, batch loss 0.0875, batch acc 0.9974
18:51:01.778   Training iter 300, batch loss 0.0786, batch acc 0.9972
18:51:01.911   Training iter 350, batch loss 0.0854, batch acc 0.9970
18:51:02.050   Training iter 400, batch loss 0.0892, batch acc 0.9970
18:51:02.162   Training iter 450, batch loss 0.0783, batch acc 0.9970
18:51:02.292   Training iter 500, batch loss 0.0763, batch acc 0.9972
18:51:02.431   Training iter 550, batch loss 0.0843, batch acc 0.9962
18:51:02.590   Training iter 600, batch loss 0.0887, batch acc 0.9972
18:51:02.591 Training @ 83 epoch...
18:51:02.748   Training iter 50, batch loss 0.0727, batch acc 0.9984
18:51:02.897   Training iter 100, batch loss 0.0972, batch acc 0.9962
18:51:03.044   Training iter 150, batch loss 0.0938, batch acc 0.9966
18:51:03.212   Training iter 200, batch loss 0.0707, batch acc 0.9982
18:51:03.332   Training iter 250, batch loss 0.0936, batch acc 0.9974
18:51:03.448   Training iter 300, batch loss 0.0874, batch acc 0.9978
18:51:03.563   Training iter 350, batch loss 0.0881, batch acc 0.9976
18:51:03.688   Training iter 400, batch loss 0.0918, batch acc 0.9966
18:51:03.800   Training iter 450, batch loss 0.0963, batch acc 0.9972
18:51:03.921   Training iter 500, batch loss 0.0908, batch acc 0.9974
18:51:04.057   Training iter 550, batch loss 0.0996, batch acc 0.9960
18:51:04.199   Training iter 600, batch loss 0.1041, batch acc 0.9956
18:51:04.200 Training @ 84 epoch...
18:51:04.373   Training iter 50, batch loss 0.0809, batch acc 0.9970
18:51:04.510   Training iter 100, batch loss 0.0694, batch acc 0.9976
18:51:04.674   Training iter 150, batch loss 0.0638, batch acc 0.9980
18:51:04.823   Training iter 200, batch loss 0.0892, batch acc 0.9968
18:51:04.938   Training iter 250, batch loss 0.0777, batch acc 0.9976
18:51:05.046   Training iter 300, batch loss 0.0957, batch acc 0.9968
18:51:05.161   Training iter 350, batch loss 0.0788, batch acc 0.9980
18:51:05.308   Training iter 400, batch loss 0.0804, batch acc 0.9978
18:51:05.512   Training iter 450, batch loss 0.0779, batch acc 0.9976
18:51:05.747   Training iter 500, batch loss 0.0797, batch acc 0.9978
18:51:05.941   Training iter 550, batch loss 0.0939, batch acc 0.9966
18:51:06.104   Training iter 600, batch loss 0.0883, batch acc 0.9968
18:51:06.105 Training @ 85 epoch...
18:51:06.260   Training iter 50, batch loss 0.0849, batch acc 0.9976
18:51:06.388   Training iter 100, batch loss 0.0742, batch acc 0.9968
18:51:06.513   Training iter 150, batch loss 0.0669, batch acc 0.9982
18:51:06.652   Training iter 200, batch loss 0.1031, batch acc 0.9968
18:51:06.841   Training iter 250, batch loss 0.0799, batch acc 0.9972
18:51:06.969   Training iter 300, batch loss 0.1050, batch acc 0.9966
18:51:07.276   Training iter 350, batch loss 0.1026, batch acc 0.9972
18:51:07.529   Training iter 400, batch loss 0.0799, batch acc 0.9978
18:51:07.805   Training iter 450, batch loss 0.0705, batch acc 0.9972
18:51:08.078   Training iter 500, batch loss 0.0831, batch acc 0.9968
18:51:08.232   Training iter 550, batch loss 0.1107, batch acc 0.9948
18:51:08.374   Training iter 600, batch loss 0.0807, batch acc 0.9970
18:51:08.376 Testing @ 85 epoch...
18:51:08.652     Testing, total mean loss 0.43327, total acc 0.97790
18:51:08.652 Training @ 86 epoch...
18:51:08.829   Training iter 50, batch loss 0.0805, batch acc 0.9968
18:51:09.024   Training iter 100, batch loss 0.0642, batch acc 0.9978
18:51:09.164   Training iter 150, batch loss 0.0957, batch acc 0.9962
18:51:09.312   Training iter 200, batch loss 0.0750, batch acc 0.9980
18:51:09.431   Training iter 250, batch loss 0.0833, batch acc 0.9970
18:51:09.562   Training iter 300, batch loss 0.0868, batch acc 0.9970
18:51:09.760   Training iter 350, batch loss 0.0776, batch acc 0.9980
18:51:09.873   Training iter 400, batch loss 0.0654, batch acc 0.9976
18:51:10.035   Training iter 450, batch loss 0.0879, batch acc 0.9976
18:51:10.234   Training iter 500, batch loss 0.0720, batch acc 0.9984
18:51:10.352   Training iter 550, batch loss 0.1310, batch acc 0.9954
18:51:10.484   Training iter 600, batch loss 0.1045, batch acc 0.9958
18:51:10.485 Training @ 87 epoch...
18:51:10.631   Training iter 50, batch loss 0.0728, batch acc 0.9976
18:51:10.770   Training iter 100, batch loss 0.1000, batch acc 0.9956
18:51:10.913   Training iter 150, batch loss 0.0747, batch acc 0.9982
18:51:11.055   Training iter 200, batch loss 0.0826, batch acc 0.9964
18:51:11.202   Training iter 250, batch loss 0.0735, batch acc 0.9980
18:51:11.363   Training iter 300, batch loss 0.0946, batch acc 0.9960
18:51:11.565   Training iter 350, batch loss 0.1007, batch acc 0.9964
18:51:11.743   Training iter 400, batch loss 0.0971, batch acc 0.9964
18:51:11.901   Training iter 450, batch loss 0.0729, batch acc 0.9974
18:51:12.085   Training iter 500, batch loss 0.0758, batch acc 0.9978
18:51:12.223   Training iter 550, batch loss 0.0823, batch acc 0.9970
18:51:12.463   Training iter 600, batch loss 0.0919, batch acc 0.9976
18:51:12.463 Training @ 88 epoch...
18:51:12.700   Training iter 50, batch loss 0.0999, batch acc 0.9960
18:51:12.897   Training iter 100, batch loss 0.0724, batch acc 0.9984
18:51:13.265   Training iter 150, batch loss 0.0920, batch acc 0.9962
18:51:13.441   Training iter 200, batch loss 0.0807, batch acc 0.9976
18:51:13.572   Training iter 250, batch loss 0.0988, batch acc 0.9962
18:51:13.732   Training iter 300, batch loss 0.0818, batch acc 0.9962
18:51:13.874   Training iter 350, batch loss 0.0702, batch acc 0.9976
18:51:14.325   Training iter 400, batch loss 0.1003, batch acc 0.9966
18:51:14.533   Training iter 450, batch loss 0.0843, batch acc 0.9972
18:51:14.956   Training iter 500, batch loss 0.0934, batch acc 0.9976
18:51:16.350   Training iter 550, batch loss 0.1033, batch acc 0.9966
18:51:16.569   Training iter 600, batch loss 0.1251, batch acc 0.9944
18:51:16.571 Training @ 89 epoch...
18:51:16.915   Training iter 50, batch loss 0.0769, batch acc 0.9972
18:51:17.152   Training iter 100, batch loss 0.0718, batch acc 0.9974
18:51:17.471   Training iter 150, batch loss 0.0832, batch acc 0.9972
18:51:17.669   Training iter 200, batch loss 0.0704, batch acc 0.9980
18:51:17.894   Training iter 250, batch loss 0.0747, batch acc 0.9970
18:51:18.174   Training iter 300, batch loss 0.0810, batch acc 0.9968
18:51:18.402   Training iter 350, batch loss 0.0879, batch acc 0.9972
18:51:18.561   Training iter 400, batch loss 0.0760, batch acc 0.9980
18:51:18.709   Training iter 450, batch loss 0.0867, batch acc 0.9970
18:51:18.862   Training iter 500, batch loss 0.0826, batch acc 0.9974
18:51:19.035   Training iter 550, batch loss 0.1050, batch acc 0.9974
18:51:19.201   Training iter 600, batch loss 0.0820, batch acc 0.9982
18:51:19.203 Training @ 90 epoch...
18:51:19.377   Training iter 50, batch loss 0.0591, batch acc 0.9986
18:51:19.544   Training iter 100, batch loss 0.0679, batch acc 0.9978
18:51:19.702   Training iter 150, batch loss 0.0646, batch acc 0.9986
18:51:19.872   Training iter 200, batch loss 0.0658, batch acc 0.9978
18:51:20.028   Training iter 250, batch loss 0.0938, batch acc 0.9962
18:51:20.273   Training iter 300, batch loss 0.0896, batch acc 0.9966
18:51:20.500   Training iter 350, batch loss 0.0706, batch acc 0.9974
18:51:20.816   Training iter 400, batch loss 0.0748, batch acc 0.9968
18:51:21.211   Training iter 450, batch loss 0.1007, batch acc 0.9952
18:51:21.437   Training iter 500, batch loss 0.0818, batch acc 0.9980
18:51:21.685   Training iter 550, batch loss 0.0936, batch acc 0.9960
18:51:21.942   Training iter 600, batch loss 0.1011, batch acc 0.9962
18:51:21.942 Testing @ 90 epoch...
18:51:22.099     Testing, total mean loss 0.39366, total acc 0.97950
18:51:22.099 Training @ 91 epoch...
18:51:22.342   Training iter 50, batch loss 0.0746, batch acc 0.9978
18:51:22.494   Training iter 100, batch loss 0.0685, batch acc 0.9974
18:51:22.621   Training iter 150, batch loss 0.0876, batch acc 0.9974
18:51:22.754   Training iter 200, batch loss 0.0991, batch acc 0.9962
18:51:22.882   Training iter 250, batch loss 0.0847, batch acc 0.9968
18:51:23.028   Training iter 300, batch loss 0.0715, batch acc 0.9986
18:51:23.167   Training iter 350, batch loss 0.0797, batch acc 0.9976
18:51:23.307   Training iter 400, batch loss 0.0719, batch acc 0.9972
18:51:23.474   Training iter 450, batch loss 0.0888, batch acc 0.9974
18:51:23.684   Training iter 500, batch loss 0.0827, batch acc 0.9972
18:51:23.864   Training iter 550, batch loss 0.1040, batch acc 0.9968
18:51:24.019   Training iter 600, batch loss 0.0964, batch acc 0.9972
18:51:24.020 Training @ 92 epoch...
18:51:24.179   Training iter 50, batch loss 0.0870, batch acc 0.9974
18:51:24.358   Training iter 100, batch loss 0.0810, batch acc 0.9966
18:51:24.467   Training iter 150, batch loss 0.0763, batch acc 0.9980
18:51:24.587   Training iter 200, batch loss 0.0676, batch acc 0.9986
18:51:24.735   Training iter 250, batch loss 0.0830, batch acc 0.9970
18:51:24.856   Training iter 300, batch loss 0.0798, batch acc 0.9966
18:51:25.002   Training iter 350, batch loss 0.0951, batch acc 0.9976
18:51:25.150   Training iter 400, batch loss 0.0858, batch acc 0.9978
18:51:25.261   Training iter 450, batch loss 0.0700, batch acc 0.9984
18:51:25.371   Training iter 500, batch loss 0.0749, batch acc 0.9976
18:51:25.485   Training iter 550, batch loss 0.0792, batch acc 0.9982
18:51:25.601   Training iter 600, batch loss 0.1479, batch acc 0.9942
18:51:25.602 Training @ 93 epoch...
18:51:25.734   Training iter 50, batch loss 0.0860, batch acc 0.9978
18:51:25.861   Training iter 100, batch loss 0.0805, batch acc 0.9968
18:51:25.986   Training iter 150, batch loss 0.0745, batch acc 0.9966
18:51:26.234   Training iter 200, batch loss 0.0775, batch acc 0.9986
18:51:26.419   Training iter 250, batch loss 0.0754, batch acc 0.9974
18:51:26.578   Training iter 300, batch loss 0.1008, batch acc 0.9962
18:51:26.732   Training iter 350, batch loss 0.0868, batch acc 0.9974
18:51:26.916   Training iter 400, batch loss 0.0995, batch acc 0.9964
18:51:27.076   Training iter 450, batch loss 0.0816, batch acc 0.9970
18:51:27.232   Training iter 500, batch loss 0.0808, batch acc 0.9970
18:51:27.358   Training iter 550, batch loss 0.1072, batch acc 0.9950
18:51:27.510   Training iter 600, batch loss 0.0943, batch acc 0.9978
18:51:27.511 Training @ 94 epoch...
18:51:27.633   Training iter 50, batch loss 0.0827, batch acc 0.9972
18:51:27.765   Training iter 100, batch loss 0.0859, batch acc 0.9972
18:51:27.896   Training iter 150, batch loss 0.0697, batch acc 0.9976
18:51:28.015   Training iter 200, batch loss 0.0991, batch acc 0.9956
18:51:28.234   Training iter 250, batch loss 0.1071, batch acc 0.9956
18:51:28.363   Training iter 300, batch loss 0.0739, batch acc 0.9970
18:51:28.510   Training iter 350, batch loss 0.0606, batch acc 0.9982
18:51:28.645   Training iter 400, batch loss 0.0838, batch acc 0.9962
18:51:28.802   Training iter 450, batch loss 0.1158, batch acc 0.9964
18:51:28.921   Training iter 500, batch loss 0.0989, batch acc 0.9972
18:51:29.168   Training iter 550, batch loss 0.0872, batch acc 0.9974
18:51:29.314   Training iter 600, batch loss 0.0901, batch acc 0.9982
18:51:29.315 Training @ 95 epoch...
18:51:29.469   Training iter 50, batch loss 0.0816, batch acc 0.9980
18:51:29.640   Training iter 100, batch loss 0.0694, batch acc 0.9984
18:51:29.795   Training iter 150, batch loss 0.0628, batch acc 0.9982
18:51:29.963   Training iter 200, batch loss 0.0723, batch acc 0.9980
18:51:30.265   Training iter 250, batch loss 0.1005, batch acc 0.9972
18:51:30.384   Training iter 300, batch loss 0.1054, batch acc 0.9962
18:51:30.502   Training iter 350, batch loss 0.0847, batch acc 0.9974
18:51:30.627   Training iter 400, batch loss 0.0778, batch acc 0.9966
18:51:30.741   Training iter 450, batch loss 0.0955, batch acc 0.9958
18:51:30.884   Training iter 500, batch loss 0.0748, batch acc 0.9976
18:51:31.017   Training iter 550, batch loss 0.0907, batch acc 0.9966
18:51:31.165   Training iter 600, batch loss 0.0782, batch acc 0.9974
18:51:31.167 Testing @ 95 epoch...
18:51:31.334     Testing, total mean loss 0.36235, total acc 0.98070
18:51:31.334 Training @ 96 epoch...
18:51:31.567   Training iter 50, batch loss 0.0575, batch acc 0.9976
18:51:31.935   Training iter 100, batch loss 0.0642, batch acc 0.9978
18:51:32.310   Training iter 150, batch loss 0.0750, batch acc 0.9974
18:51:32.537   Training iter 200, batch loss 0.0919, batch acc 0.9974
18:51:32.797   Training iter 250, batch loss 0.0901, batch acc 0.9966
18:51:33.139   Training iter 300, batch loss 0.0773, batch acc 0.9974
18:51:33.402   Training iter 350, batch loss 0.0784, batch acc 0.9986
18:51:33.556   Training iter 400, batch loss 0.0794, batch acc 0.9972
18:51:33.777   Training iter 450, batch loss 0.0931, batch acc 0.9970
18:51:33.956   Training iter 500, batch loss 0.1075, batch acc 0.9966
18:51:34.104   Training iter 550, batch loss 0.1022, batch acc 0.9960
18:51:34.410   Training iter 600, batch loss 0.0922, batch acc 0.9968
18:51:34.412 Training @ 97 epoch...
18:51:34.543   Training iter 50, batch loss 0.0664, batch acc 0.9982
18:51:34.671   Training iter 100, batch loss 0.0714, batch acc 0.9974
18:51:34.832   Training iter 150, batch loss 0.0799, batch acc 0.9974
18:51:34.985   Training iter 200, batch loss 0.1084, batch acc 0.9952
18:51:35.150   Training iter 250, batch loss 0.0790, batch acc 0.9980
18:51:35.292   Training iter 300, batch loss 0.0680, batch acc 0.9982
18:51:35.482   Training iter 350, batch loss 0.0909, batch acc 0.9972
18:51:35.651   Training iter 400, batch loss 0.0932, batch acc 0.9972
18:51:35.806   Training iter 450, batch loss 0.0724, batch acc 0.9978
18:51:35.991   Training iter 500, batch loss 0.0903, batch acc 0.9968
18:51:36.191   Training iter 550, batch loss 0.0910, batch acc 0.9958
18:51:36.358   Training iter 600, batch loss 0.1036, batch acc 0.9958
18:51:36.361 Training @ 98 epoch...
18:51:36.544   Training iter 50, batch loss 0.0619, batch acc 0.9984
18:51:36.664   Training iter 100, batch loss 0.0484, batch acc 0.9990
18:51:36.789   Training iter 150, batch loss 0.0617, batch acc 0.9978
18:51:36.931   Training iter 200, batch loss 0.0828, batch acc 0.9972
18:51:37.080   Training iter 250, batch loss 0.0729, batch acc 0.9974
18:51:37.394   Training iter 300, batch loss 0.0772, batch acc 0.9972
18:51:37.496   Training iter 350, batch loss 0.0930, batch acc 0.9968
18:51:37.629   Training iter 400, batch loss 0.0987, batch acc 0.9958
18:51:37.851   Training iter 450, batch loss 0.0886, batch acc 0.9974
18:51:38.001   Training iter 500, batch loss 0.0827, batch acc 0.9978
18:51:38.142   Training iter 550, batch loss 0.0858, batch acc 0.9976
18:51:38.304   Training iter 600, batch loss 0.0751, batch acc 0.9980
18:51:38.306 Training @ 99 epoch...
18:51:38.443   Training iter 50, batch loss 0.0960, batch acc 0.9970
18:51:38.680   Training iter 100, batch loss 0.0634, batch acc 0.9980
18:51:38.830   Training iter 150, batch loss 0.0648, batch acc 0.9982
18:51:38.982   Training iter 200, batch loss 0.0719, batch acc 0.9978
18:51:39.133   Training iter 250, batch loss 0.0763, batch acc 0.9982
18:51:39.285   Training iter 300, batch loss 0.0786, batch acc 0.9976
18:51:39.413   Training iter 350, batch loss 0.0906, batch acc 0.9964
18:51:39.784   Training iter 400, batch loss 0.0835, batch acc 0.9970
18:51:39.969   Training iter 450, batch loss 0.1032, batch acc 0.9962
18:51:40.122   Training iter 500, batch loss 0.1016, batch acc 0.9972
18:51:40.244   Training iter 550, batch loss 0.0821, batch acc 0.9970
18:51:40.427   Training iter 600, batch loss 0.0778, batch acc 0.9970
18:51:40.432 Testing @ 99 epoch...
18:51:40.558     Testing, total mean loss 0.36188, total acc 0.98240